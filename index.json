[
{
	"uri": "https://info-tsi-vieljeux.github.io/projets/doomsday/",
	"title": "Doomsday",
	"tags": [],
	"description": "",
	"content": "Algorithme du Doomsday Permet de trouver de tête le jour de la semaine pour n\u0026rsquo;importe quelle date du calendrier grégorien (à partir de 1753).\nOn donne une date sous la forme $jour/mois/annee$.\nOn décompose tout d\u0026rsquo;abord $annee$ en $s\\times 100 + an$ où $s$ est le nombre de siècles ($an\u0026lt;100$).\ndoomscentury $c$ on calcule le reste de la division euclidienne par 4 du nombre de siècle $s$ on multiplié par 2 on prend le complément à 7 $$c = 7-(s\\mod 4) \\times2 $$\ndoomsyear $y$ Doomsday1 On calcule $c+y\\mod 7$\nCela donne le Doomsday de l\u0026rsquo;année :\n0 1 2 3 4 5 6 mardi mercredi jeudi vendredi samedi dimanche lundi doomsday1 $d$ Liste des doomsday $d$/$mois$ pour une année non bissextile :\n31/1 28/2 7/3 4/4 9/5 6/6 11/7 8/8 5/9 10/10 7/11 12/12 Pour une année bissextile, on ajoute 1 à $d$ pour les 2 premiers mois : 32/1 et 29/2\nAide mémoire :\njanvier et février : dernier jour du mois (+1 si bissextile)\ntous les mois pairs : $x/x$ ($\\Rightarrow d=mois$)\nmars, mai, juillet : $x+4/x$ ($\\Rightarrow d=mois+4$)\nseptembre, novembre : $x-4/x$ ($\\Rightarrow d=mois-4$)\nPlus qu\u0026rsquo;à faire la différence entre $jour$ et le doomsday du mois $d$ modulo 7 : $jour-d\\mod 7$\nSi le résultat est négatif, on ajoute 7.\nPuis on ajoute au Doomsday pour trouver le jour de la semaine.\nExemples Quel jour de la semaine tombe le 27/1/3252 ?\ndoomscentury :\n$s=32$\n$c = 7-(32 \\mod 4)\\times 2 = 7$\ndoomsyear :\n52 est pair $\\rightarrow 52/2=26$ 26 est pair $\\rightarrow 26\\mod7 = 5$ $y = 7-5=2$ Doomsday :\n$(c+y)\\mod7 = 2\\rightarrow$ jeudi\n0 1 2 3 4 5 6 jeudi vendredi samedi dimanche lundi mardi mercredi doomsday :\n3252 est une année bissextile donc le doomsday $d$ de janvier est 32.\n$(27-32)\\mod 7=-5$ et $-5+7=2$\nConclusion : le 27/1/3252 est un samedi.\nQuel jour de la semaine tombe le 17/11/1921 ?\ndoomscentury :\n$s=19$\n$c=7-(19\\mod4)\\times 2=1$\ndoomsyear :\n21 est impair $\\rightarrow (21+11)/2=16$ 16 est pair $\\rightarrow 16\\mod7=2$ $y=7-2=5$ Doomsday :\n$(c+y)\\mod7=6\\rightarrow$ lundi\n0 1 2 3 4 5 6 lundi mardi mercredi jeudi vendredi samedi dimanche doomsday :\nen novembre $d=7$\n$(17-7)\\mod7=3$\nConclusion : le 17/11/1921 tombe un jeudi.\nEntraînement Projet Reproduire le programme d'entraînement ci-dessus.\nUne solution : from random import randint from time import time nb_tent = 0 tps_moy = 0 nb_echecs = 0 def Doomsday(jour,mois,annee): doomsday = {i:i for i in range(3,13)} if bissextile: doomsday[1] = 32 doomsday[2] = 29 else: doomsday[1] = 31 doomsday[2] = 28 for m in doomsday.keys(): if m%2: if m in (3,5,7): doomsday[m] += 4 elif m in (9,11): doomsday[m] -= 4 doomcentury = (7 - ((annee // 100) % 4) * 2) % 7 an = annee-annee//100*100 if an % 2: an += 11 an //= 2 if an % 2: an += 11 an %= 7 doomyear = 7 - an ecart = (jour - doomsday[mois]) signe = \u0026#34;\u0026#34; if ecart \u0026gt; 0: signe = \u0026#34;+\u0026#34; ecart %= 7 fin = (ecart + doomcentury + doomyear) % 7 return signe,fin,ecart,doomcentury,doomyear,doomsday tps_min = 100 tps_max = 0 liste_jours = [\u0026#34;mardi\u0026#34;,\u0026#34;mercredi\u0026#34;,\u0026#34;jeudi\u0026#34;,\u0026#34;vendredi\u0026#34;,\u0026#34;samedi\u0026#34;,\u0026#34;dimanche\u0026#34;,\u0026#34;lundi\u0026#34;] while True: y = randint(1753,2150) m = randint(1,12) mois_cts = (4,6,9,11) bissextile = False if y%4 == 0 and y%400 not in (100,200,300): bissextile = True if m == 2: if bissextile: d = randint(1,29) else: d = randint(1,28) elif m in mois_cts: d = randint(1,30) else: d = randint(1,31) print(\u0026#34;date :\u0026#34;) date = \u0026#34;| {}/{}/{} |\u0026#34;.format(d,m,y) print(\u0026#34;-\u0026#34;*len(date)) print(date) print(\u0026#34;-\u0026#34;*len(date)) start = time() int_j = input(\u0026#34;Choisir le jour de la semaine (de 1 à 7) : \u0026#34;) chiffres = list(map(str,range(1,8))) while int_j not in chiffres: int_j = input(\u0026#34;saisie non valide, recommencez : \u0026#34;) int_j = int(int_j) end = time() print(\u0026#34;temps mis : {:.1f} s\\n\u0026#34;.format(end-start)) signe,fin,ecart,doomcentury,doomyear,doomsday = Doomsday(d,m,y) nb_tent += 1 jour = liste_jours[fin].upper() if (fin+1)%7+1==int_j: print(\u0026#34;Bien joué !\u0026#34;) else: print(\u0026#34;Echec...\u0026#34;) nb_echecs += 1 print(\u0026#34;-\u0026#34;*(len(jour)+4)) print(\u0026#34;| {} |\u0026#34;.format(jour)) print(\u0026#34;-\u0026#34;*(len(jour)+4)) print(\u0026#34;\\nCalculs :\u0026#34;) print(\u0026#34;-\u0026#34;*9) print(\u0026#34;doomcentury = {}\u0026#34;.format(doomcentury)) print(\u0026#34;doomyear = {}\u0026#34;.format(doomyear)) n = (doomyear + doomcentury) % 7 print(\u0026#34;=\u0026gt; Doomsday en {} = {}\u0026#34;.format(y,liste_jours[n])) print(\u0026#34;écart par rapport au doomsday du mois ({}/{})\u0026#34;.format(doomsday[m],m)) if bissextile and m in (1,2): print(\u0026#34;(année bissextile)\u0026#34;) print(\u0026#34;{}{} jours\u0026#34;.format(signe,ecart)) tps = end-start tps_moy += tps if tps \u0026lt; tps_min: tps_min = tps if tps \u0026gt; tps_max: tps_max = tps rep = input(\u0026#34;\\nTaper q pour arreter, Entree pour continuer\\n\u0026#34;) if rep == \u0026#34;q\u0026#34;: pourcent = nb_echecs/nb_tent*100 tps_moy = tps_moy/nb_tent print(\u0026#34;\\nSTATS :\u0026#34;) print(\u0026#34;-\u0026#34;*7) print(\u0026#34;nombre de tentatives : {}\u0026#34;.format(nb_tent)) print(\u0026#34;pourcentage d\u0026#39;erreurs : {:.0f}%\u0026#34;.format(pourcent)) print(\u0026#34;temps moyen : {:.1f} s\u0026#34;.format(tps_moy)) print(\u0026#34;temps max : {:.1f} s\u0026#34;.format(tps_max)) print(\u0026#34;temps min : {:.1f} s\u0026#34;.format(tps_min)) break Code suivant une méthode un poil plus efficace :\nwhile True: date = input(\u0026#34;Quelle date ? (format JJ/MM/AAAA) :\\n\u0026#34;) slash = [] for i,c in enumerate(date): if c == \u0026#34;/\u0026#34;: slash.append(i) jour, mois, annee = int(date[:slash[0]]),int(date[slash[0]+1:slash[1]]),int(date[slash[1]+1:]) if annee \u0026gt; 1600: break else: print(\u0026#34;Le calendrier Grégorien ne commence qu\u0026#39;en septembre 1752, choisir une date au-delà.\u0026#34;) liste_jours = [\u0026#34;mardi\u0026#34;,\u0026#34;mercredi\u0026#34;,\u0026#34;jeudi\u0026#34;,\u0026#34;vendredi\u0026#34;,\u0026#34;samedi\u0026#34;,\u0026#34;dimanche\u0026#34;,\u0026#34;lundi\u0026#34;] Doomsday = {i:i for i in range(3,13)} if annee%4 == 0 and annee%400 not in (100,200,300): print(\u0026#34;année bissextile\u0026#34;) Doomsday[1] = 32 Doomsday[2] = 29 else: Doomsday[1] = 31 Doomsday[2] = 28 for m in Doomsday.keys(): if m%2: if m in (3,5,7): Doomsday[m] += 4 elif m in (9,11): Doomsday[m] -= 4 print(f\u0026#34;liste des doomsday pour {annee} :\u0026#34;) joursdoom = [] for (k,v) in Doomsday.items(): joursdoom.append((k,v)) joursdoom.sort() for e in joursdoom: m,j = e print(f\u0026#34;{j}/{m}\u0026#34;) # Détermination du Doomsday doomcentury = (7 - ((annee//100)%4) * 2) % 7 print(f\u0026#34;{doomcentury = }\u0026#34;) ans = annee-annee//100*100 #doomyear = ans//12+ans%12+ans%12//4 if ans%2: ans += 11 ans //= 2 if ans%2: ans += 11 ans %= 7 doomyear = 7-ans print(f\u0026#34;{doomyear = }\u0026#34;) n = (doomyear+doomcentury)%7 print(f\u0026#34;Doomsday en {annee} = {liste_jours[n]}\u0026#34;) ecart = (jour-Doomsday[mois]) print(f\u0026#34;écart par rapport au doomsday du mois ({Doomsday[mois]}/{mois})\u0026#34;) signe = \u0026#34;\u0026#34; if ecart \u0026gt; 0: signe = \u0026#34;+\u0026#34; print(f\u0026#34;{signe}{ecart} jours\u0026#34;) ecart %= 7 fin = (ecart+doomcentury+doomyear)%7 print(\u0026#34;=\u0026gt;\u0026#34;,liste_jours[fin].upper()) Doomsday avec majuscule désigne le jour de la semaine alors que doomsday avec minuscule désigne le doomsday $d$ du mois (un nombre correspondant à une date tombant un Doomsday !).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/bonnes_pratiques/",
	"title": "Les bonnes pratiques",
	"tags": [],
	"description": "",
	"content": "Les bonnes pratiques Beaucoup de personnes amenées à coder plus ou moins régulièrement se sont un jour retrouvées à maudire leur moi du passé en reprenant un programme qu\u0026rsquo;ils avaient écrit seulement quelques semaines/mois auparavant mais qui leur est subitement devenu complètement cryptique.\nLe temps perdu est alors énorme et vécu d\u0026rsquo;autant plus douloureusement qu\u0026rsquo;il était facilement évitable\u0026hellip;\nCommenter son code Commenter son code via l\u0026rsquo;utilisation de # est la principale protection contre de telles autotortures.\nIl ne s\u0026rsquo;agit pas de commenter chaque ligne comme on voit parfois\u0026hellip;\na,b = 2,3\t# j\u0026#39;affecte la valeur 2 à la variable a et la valeur 3 à b c = a+b # j\u0026#39;affecte à c le résultat de l\u0026#39;addition entre a et b print(c) # j\u0026#39;affiche le résultat Il faut au contraire se concenter sur les points délicats susceptibles d\u0026rsquo;échapper à son moi du futur (qui n\u0026rsquo;a jamais autant de mémoire qu\u0026rsquo;on le pense).\nC\u0026rsquo;est souvent intéressant d\u0026rsquo;y justifier ses choix de programmation comme celui d\u0026rsquo;utiliser une structure de données plutôt qu\u0026rsquo;une autre (un dictionnaire plutôt qu\u0026rsquo;une liste par exemple). Ces différents choix sont en effet sensés ne rien devoir au hasard, donc autant noter clairement ce qui vous a fait préférer telle option plutôt qu\u0026rsquo;une autre, histoire que votre lecteur puisse comprendre votre démarche (et pour aider votre moi du futur à s\u0026rsquo;y retrouver).\nDe manière plus systématique, une structure minimale de commentaires permet de cadrer rapidement les points clé d\u0026rsquo;un bloc d\u0026rsquo;instruction (qu\u0026rsquo;il s\u0026rsquo;agisse d\u0026rsquo;une boucle ou d\u0026rsquo;une fonction).\nUn bloc de code utilise généralement un ou plusieurs paramètres appelés paramètres d\u0026rsquo;entrées et construit à partir d\u0026rsquo;eux un ou plusieurs paramètres de sortie.\nDans l\u0026rsquo;idéal, on commente alors chaque bloc de code en précisant dans la mesure du possibles les 3 éléments suivants :\npréconditions postconditions invariant préconditions : ce sont les conditions que doivent vérifier impérativement les paramètres d\u0026rsquo;entrée pour que le code fasse ce qui est attendu.\npostconditions : ce sont les conditions que doivent vérifier impérativement les paramètres de sortie (après le bloc).\nPar exemple, si le bloc de code est sensé calculer une moyenne sur 20, la postcondition sera que la variable de sortie soit bien un flottant compris entre 0 et 20 valant la moyenne des valeurs en entrée. invariant : propriété qui devra être vérifiée à chaque itération de manière à ce que la précondition aboutisse bien au final à la poscondition.\nExemples :\nsi l\u0026rsquo;algorithme correspond à \u0026ldquo;manger une pizza\u0026rdquo;, une précondition est la présence de la pizza et une postcondition est l\u0026rsquo;absence de ladite pizza. pour calculer une racine carrée, une précondition est que le nombre en entrée ne soit pas négatif et une postcondition est que le carré de la sortie valle le nombre en entrée. pour utiliser une recherche dichotomique, la précondition principale est que la liste soit triée. lors d\u0026rsquo;un tri par sélection l\u0026rsquo;invariant est : \u0026ldquo;la partie de la liste déjà inspectée est triée\u0026rdquo;. Exemple complet avec la division euclidienne :\n# ce code permet de calculer le quotient et le reste de la division euclidienne de a par b # préconditions : a et b entiers, a ≥ 0 et b \u0026gt; 0 a, b = 28, 5 r = a q = 0 while r \u0026gt;= b: # invariant : a = b*q + r r = r-b q = q+1 print(q,r) # postconditions : a = b*q + r, 0 ≤ r \u0026lt; b, a et b inchangés Choisir des noms explicites Bien nommer ses variables améliore fortement la lisibilité du code.\nChoisir des noms explicites qui se rapportent au rôle et/ou aux types des variables utilisées est en effet un bien meilleur guide pour le lecteur du code que des noms génériques tel a, b, c\u0026hellip;\ny_0, v_0 = 0.3, 7.2 g = -9.8 t = 0 dt = 1e-3 y, v = y_0, v_0 while y \u0026gt; 0: v += g*dt y += v*dt t += dt print(t) Un physicien comprend rapidement le but de ce code, mais d\u0026rsquo;autres choix de noms l\u0026rsquo;auraient rendu bien plus obscur.\nUtiliser des fonctions Autre pratique améliorant son code : l\u0026rsquo;utilisation de fonctions.\nBut :\néviter de réécrire du code : on appelle la fonction contenant le code à la place (toute répétition de code est globalement à éviter, comme dans un texte littéraire) ; simplifier la lecture du code (et plus les noms des fonctions seront clairs, plus la compréhension du code sera simplifiée) ; rendre son code modulaire : les fonctions construites sont autant d\u0026rsquo;outils ayant une mission clairement définie. Et on peut très bien utiliser des fonctions au sein d\u0026rsquo;autres fonctions pour améliorer encore la lisibilité. Documenter ses fonctions Les fonctions ont pour vocation d\u0026rsquo;être réutilisées (par vous ou par d\u0026rsquo;autres) et demande donc une attention particulière à leur description. Les fonctions ont ainsi droit à une forme de commentaire spéciale, le docstring, qui peut être interrogée directement par l\u0026rsquo;utilisateur (voir note ci-dessous).\nOn indique les types attendus des entrées (les paramètres) et des sorties (les retours) en inscrivant la signature de la fonction dans son docstring et on y ajoute les préconditions et les postconditions ainsi qu\u0026rsquo;une brêve descritpion.\nexemple :\ndef moyenne(notes): \u0026#34;\u0026#34;\u0026#34; calcule une moyenne sur 20 à partir de différentes notes sur 20 moyenne(notes: list) -\u0026gt; moy: float précondition: la liste notes contient des nombres entre 0 et 20 postcondition: moy est la moyenne des éléments de notes \u0026#34;\u0026#34;\u0026#34; moy = 0 for n in notes: moy += n moy /= len(notes) return moy On peut afficher le docstring d\u0026rsquo;une fonction via la méthode .__doc__.\nprint(moyenne.__doc__) calcule une moyenne sur 20 à partir de différentes notes sur 20\nmoyenne(notes:list) -\u0026gt; moy:float\nprécondition : la liste notes contient des nombres entre 0 et 20\npostcondition : moy est la moyenne des éléments de notes\nContraindre les spécifications avec des assertions En sus de noter les préconditions dans les commentaires, on peut aussi tenter de s\u0026rsquo;assurer qu\u0026rsquo;elles sont bien vérifiées. Qui vous assure en effet que votre fonction, par ailleurs parfaitement sage lorsque les entrées respectent les préconditions ne devienne pas folle dans certains cas loufoques ? C\u0026rsquo;est bien vous qui serez blamé lorsque l\u0026rsquo;entrée farfelue causera une catastrophe\u0026hellip;\nL\u0026rsquo;explosion du vol 501 d\u0026rsquo;Ariane est à cet égard un exemple édifiant. Un même programme ayant parfaitement accompli son œuvre de nombreuses années pour Ariane 4 a été réutilisé en toute sérénité dans le nouveau modèle. Mais voilà\u0026hellip; Le plan de vol différent d\u0026rsquo;Ariane 5 provoquait des accélérations très supérieures à celles enregistrées sur Ariane 4 jusqu\u0026rsquo;à déborder la capacité alors allouée au codage de ces mesures dans la station inertielle. La valeur élevée non prévue a planté le programme car elle a d\u0026rsquo;abord été répercutée sans lever d\u0026rsquo;erreur et du coup mal interprétée par les dispositifs de correction de trajectoire. Une petite assertion bien placée aurait peut-être pu économiser 1 milliard d\u0026rsquo;euros\u0026hellip;\nExemple (aux répercutions moins coûteuses) : pour s\u0026rsquo;assurer que le notes passées en argument sont bien des nombres entre 0 et 20, on peut écrire dans le corps de la fonction :\nfor n in notes: assert type(n) in (int,float) and 0\u0026lt;=n\u0026lt;=20 Tester \u0026ldquo;90% of coding is debugging. The other 10% is writing bugs\u0026rdquo;\nQuand un code ne donne pas le résultat attendu, il faut partir à la recherche de l\u0026rsquo;erreur. Pour cela, le plus simple est d\u0026rsquo;utiliser un jeu de test.\nIl s\u0026rsquo;agit tout simplement de disposer des print tout le long de son code pour afficher conjointement les valeurs réellement prises par les différentes variables à cet endroit du code et les valeurs qu\u0026rsquo;on souhaiterait.\nLe plus efficace est d\u0026rsquo;adopter une démarche dichotomique pour placer ces tests : début-milieu-fin dans un premier temps, puis on découpe en deux début-milieu et milieu-fin, etc.\nPrenons un exemple. Le programme suivant est sensé décider si la suite de caractères qu\u0026rsquo;on a entré au clavier est un palindrome ou non :\ndef bug(): res = [] fini = False print(\u0026#39;Ajoutez des caractères un par un en validant avec entrée, puis appuyez sur entrée pour terminer\u0026#39;) while not fini: elem = input(\u0026#39;\u0026#39;) if elem == \u0026#39;\u0026#39;: fini = True else: res.append(elem) tmp = res tmp.reverse() Pal = (res == tmp) if Pal: print(\u0026#39;palindrome\u0026#39;) else: print(\u0026#39;pas palindrome\u0026#39;) Lançons bug et entrons les caractères 'a','2','a'.\nLa fonction affiche alors : palindrome\nJusque-là tout va bien.\nEntrons maintenant 'a','2','b'.\nLa fonction affiche maintenant\u0026hellip; palindrome\nDonc ça bugue. Mettons en place note démarche systématique en inserrant un premier print à peu près au milieu, juste après le while. À ce niveau, on a construit la liste res, affichons-la au côté de ce qu\u0026rsquo;on attend qu\u0026rsquo;elle soit.\ndef bug(): res = [] fini = False print(\u0026#39;Ajoutez des caractères un par un en validant avec entrée, puis appuyez sur entrée pour terminer\u0026#39;) while not fini: elem = input(\u0026#39;\u0026#39;) if elem == \u0026#39;\u0026#39;: fini = True else: res.append(elem) print(\u0026#34;res devrait être [\u0026#39;a\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;b\u0026#39;] et est\u0026#34;,res) tmp = res tmp.reverse() Pal = (res == tmp) if Pal: print(\u0026#39;palindrome\u0026#39;) else: print(\u0026#39;pas palindrome\u0026#39;) Après avoir relancé bug() et retapé 'a','2' et 'b', on voit s\u0026rsquo;afficher : res devrait être ['a','2','b'] et est ['a', '2', 'b']\nOn sait maintenant que la première partie du code fait son boulot !\nConcentrons-nous sur la deuxième partie en plaçant un print avant le if. On a ici une nouvelle variable, tmp, en plus de res. Testons les deux :\ndef bug(): res = [] fini = False print(\u0026#39;Ajoutez des caractères un par un en validant avec entrée, puis appuyez sur entrée pour terminer\u0026#39;) while not fini: elem = input(\u0026#39;\u0026#39;) if elem == \u0026#39;\u0026#39;: fini = True else: res.append(elem) #print(\u0026#34;res devrait être [\u0026#39;a\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;b\u0026#39;] et est\u0026#34;,res) tmp = res tmp.reverse() Pal = (res == tmp) print(f\u0026#39;tmp = {tmp}, res = {res}\u0026#39;) if Pal: print(\u0026#39;palindrome\u0026#39;) else: print(\u0026#39;pas palindrome\u0026#39;) S\u0026rsquo;affiche alors : tmp = ['b', '2', 'a'] res = ['b', '2', 'a']\nAha ! tmp a la bonne tête, maisres aussi a été modifié, et ça, ce n\u0026rsquo;était pas prévu\u0026hellip; Le problème est donc dans les 3 lignes qui précèdent le print. On pourrait placer un nouveau test entre ces lignes, mais vous aurez sans doute déjà trouvé le piège dans lequel le codeur est tombé.\nOn aurait pu être tenté de ne pas retester res à cette étape puisqu\u0026rsquo;on venait de le faire au test précédent, mais cela aurait été du coup très mal joué (un bug dans la chasse au bug) !\nAttention, comme le dit le grand Dijkstra : \u0026ldquo;Tester décèle la présence de bugs, pas leur absence.\u0026rdquo;\nAucun test ne pourra montrer que votre programme ne contient aucun bug\u0026hellip;\nUne des expériences les plus vexantes et retorses, elle aussi vécue par beaucoup, voit le codeur présenter fièrement un programme qui répond parfaitement à ses attentes, mais qui crashe piteusement à la première utilisation d\u0026rsquo;une autre personne\u0026hellip;\nL\u0026rsquo;origine probable de cette débâcle est que le codeur n\u0026rsquo;ait pas testé son programme pour des entrées suffisamment différentes. Et si le testeur n\u0026rsquo;a pas reçu le mémo l\u0026rsquo;obligeant à ne tenter que les quelques entrées que le codeur a validées, il se retrouve en terrain miné !\nMorale : il faut tester le plus largement possible les entrées d\u0026rsquo;un programme.\nPour ne pas non plus se perdre dans une revue systématique, vous gagnerez à partitionner le domaîne des entrées en grandes classes.\nUne classe est telle qu\u0026rsquo;à l\u0026rsquo;intérieur, le programme réagisse de la même façon avec toutes les entrées. Il suffit alors de ne tester qu\u0026rsquo;une seule valeur par classe.\nExemple : si on fabrique une fonction valeur absolue, plutôt que de tester des milliers de nombres, on peut se contenter de tester une valeur dans chacune des trois classes suivantes correspondantes aux différents comportements de la fonction (et donc aux différents branchements de son code) : entrées $\u0026lt; 0$, entrées $\u0026gt; 0$ et la frontière entrées $=0$.\nEn conclusion, mieux vous aurez défini l\u0026rsquo;ensemble des entrées acceptables et bien inspecté leurs frontières, plus facilement vous pourrez guider le lecteur de votre code à l\u0026rsquo;intérieur de ces frontières de bon fonctionnement via les préconditions. Car s\u0026rsquo;il est évident pour votre moi du présent que votre code demande nécessairement un type de données précis et qu\u0026rsquo;il ne viendrait à l\u0026rsquo;idée de personne d\u0026rsquo;utiliser autre chose, attendez seulement quelques temps que le doute vous assaille en le relisant\u0026hellip; Et s\u0026rsquo;il vous arrive d\u0026rsquo;hésiter un tant soit peu, imaginez quelqu\u0026rsquo;un d\u0026rsquo;autre !\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp0/",
	"title": "TP 0 : Démarrage",
	"tags": [],
	"description": "",
	"content": " TP 0 : Démarrage Cliquez sur cette invitation pour récupérer le repository du TP. Exo 1 Combien de fois une feuille de papier d’épaisseur $e=0,1$ mm doit-elle être pliée pour atteindre la Lune ?\nÉcrivez dans la cellule suivante un code permettant d\u0026rsquo;obtenir la réponse. Le plus simple est d\u0026rsquo;utiliser une boucle while.\nWolfram alpha vous donne avec précision la distance Terre-Lune.\n### VOTRE CODE Correction (cliquer pour afficher) e = 0.1e-3 D_TL = 385e6 ep_tot = e nb_plis = 0 while ep_tot \u003c D_TL: nb_plis += 1 ep_tot *= 2 print(nb_plis) Dans la cellule suivante, affectez à la variable nb_plis la valeur entière trouvée.\nnb_plis = 0 Correction (cliquer pour afficher) 42 Exo 2 Complétez le code de la fonction palindrome pour qu\u0026rsquo;il retourne un booléen valant True si la chaîne de caractères passée en argument est bien un palindrome et False sinon.\ndef palindrome(chaine): \u0026#34;\u0026#34;\u0026#34; palindrome(chaine: string) -\u0026gt; test: bool précondition: chaine est une chaine de caractères postcondition: si chaine est un palindrome, test vaut True, et False sinon. \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE return test Correction (cliquer pour afficher) def palindrome(chaine): test = chaine == chaine[::-1] return test Exo 3 Une liste peut être utilisée comme une représentation simple d’un polynôme, $P(x)$, où les éléments sont les coefficients des puissances de $x$ successives et les indices sont les puissances elles-mêmes. Ainsi le polynôme $P(x)=3+6x+2x^3$ sera représenté par la liste [3,6,0,2].\nL\u0026rsquo;exécution du code de la cellule suivante ne donne pas le résultat attendu. Il est sensé donné la liste représentant le polynôme dérivé $P\u0026rsquo;(x)$.\nCorrigez-le afin de rendre le retour affiché correct.\nP = [3, 6, 0, 2] dPdx = [] i = 0 for c in P: i += 1 dPdx.append(i*c) dPdx [3, 12, 0, 8]\nCorrection (cliquer pour afficher) Il suffit de parcourir les éléments de $P$ en sautant le premier.\nPour cela, on peut remplacer for c in P: par for c in P[1:]:.\nOn obtient bien alors [6,0,6]. Exo 4 L’algorithme de Luhn est une formule de somme de contrôle permettant de valider un numéro de carte bancaire. On considère le numéro de carte comme une suite de nombres à 1 chiffre.\nRenverser la liste. Prendre tous les chiffres en position paire dans la liste renversée (2e chiffre, 4e chiffre, etc.) et doubler leur valeur, si le résultat dépasse 10, on ajoute les deux chiffres du résultat (par exemple 6→12→3). Sommer tous les nombres de la nouvelle liste (les modifiés et les non-modifiés) Si cette somme vaut 0 modulo 10. Le numéro de carte est valide. Compléter la fonction suivante permettant de vérifier un numéro de carte.\ndef verifcarte(numero): \u0026#34;\u0026#34;\u0026#34; verifcarte(numero: string) -\u0026gt; bool précondition: numéro est une chaîne de caractères (par exemple \u0026#39;1205 1205 1205 1205\u0026#39;) postcondition: la fonction retourne vrai si le numéro est valide et faux sinon \u0026#34;\u0026#34;\u0026#34; num = \u0026#39;\u0026#39; for c in numero: if c in \u0026#39;0123456789\u0026#39;: num += c # permet de sauter les espaces ou tirets assert len(num)==16, \u0026#39;Le numéro ne contient pas 16 chiffres\u0026#39; ### VOTRE CODE Correction (cliquer pour afficher) def verifcarte(numero): num = '' for c in numero: if c in '0123456789': num += c assert len(num)==16, 'Le numéro ne contient pas 16 chiffres' num_1 = num[::-1] num_2 = '' for i in range(1,len(num_1),2): p = int(num_1[i])*2 if p \u003c 10: num_2 += str(p) else: s = int(str(p)[0])+int(str(p)[1]) # cela revient à faire p-9 num_2 += str(s) S = 0 for c in num_2: S += int(c) if S%10 == 0: return True else: return False # Pour tester votre fonction num = \u0026#39;0000 0000 0000 9258\u0026#39; verifcarte(num) Exo 5 La suite de Syracuse est une suite d’entiers naturels définie de la manière suivante :\non part d’un nombre entier plus grand que zéro ;\ns’il est pair, on le divise par 2 ; s’il est impair, on le multiplie par 3 et on ajoute 1. En répétant l’opération, on obtient une suite d’entiers positifs dont chacun ne dépend que de son prédécesseur.\nLorsque 1 est atteint, un cycle de longueur 3 se répète sans fin : 1, 4, 2, 1, 4, 2, 1,…\nOn ajoute donc une nouvelle règle :\nsi 1 est atteint, la suite s’arrête. Appelons temps de vol le nombre de termes de la suite.\nConstruisez une fonction qui renvoie le temps de vol correspondant à une entrée donnée.\ndef tpsdevol(nombre): \u0026#34;\u0026#34;\u0026#34; tpsdevol(nombre: int) -\u0026gt; T: int précondition: nombre est un entier positif \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE return T Correction (cliquer pour afficher) def tpsdevol(nombre): tps = 0 while nombre != 1: tps += 1 if nombre%2 == 0: nombre //= 2 else: nombre = 3*nombre+1 return tps La conjecture de Syracuse (ou Collatz) dit que toutes les suites de Syracuse ont une fin.\nConfirmons la conjecture pour tous les entiers inférieurs à 100 grâce à votre fonction.\nimport matplotlib.pyplot as plt plt.style.use(\u0026#39;seaborn\u0026#39;) plt.figure(figsize=(15,8),dpi=150) X = [i for i in range(1,100)] T = [] for x in X: T.append(tpsdevol(x)) plt.plot(X,T) plt.xlabel(\u0026#39;nombre de départ\u0026#39;) plt.ylabel(\u0026#39;temps de vol\u0026#39;) Commentaire (cliquer pour afficher)\u0026nbsp; Malgré son allure enfantine, la conjecture de syracuse a résisté (et résiste encore aujourd'hui) aux plus brillants mathématiciens ayant essayé de la démontrer. "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp1recherche/",
	"title": "TP 1 : recherche simple",
	"tags": [],
	"description": "",
	"content": " TP 1 : Recherche séquentielle dans un tableau unidimensionnel. Dictionnaires. Cliquez sur cette invitation pour récupérer le repository du TP. Recherche d\u0026rsquo;un élément dans une liste Écrire une fonction recherche qui prend pour argument un élément et une liste et qui retourne True si l\u0026rsquo;élément est présent et False sinon.\nLe corps de la fonction devra comprendre une boucle.\nRq : le but de recherche est de reproduire le fonctionnement du mot clé in.\ndef recherche(x,L): \u0026#39;\u0026#39;\u0026#39; recherche(x: tout type, L: list) -\u0026gt; bool \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE Correction (cliquer pour afficher) def recherche(x,L): for e in L: if e == x: return True return False Dans le pire des cas (élément ne se trouvant pas dans la liste), combien de comparaisons doit-on opérer pour savoir si un élément est présent dans une liste de taille 400 ?\nCorrection (cliquer pour afficher) La fonction réalise une comparaison pour chaque élément $\\Rightarrow$ 400 comparaisons. Construisez une fonction dico qui prend en argument une liste L de $n$ entiers inférieurs à $n$ et qui retourne un dictionnaire de longueur $n$ dont les clés sont les $n$ premiers entiers (de 0 à $n$-1) et les valeurs comptent le nombre de fois que la clé est présente dans la liste.\nExemple : s\u0026rsquo;il y a 2 fois l\u0026rsquo;élément 18 dans la liste L, alors dico(L)[18]==2, et si l\u0026rsquo;élément 97 n\u0026rsquo;est pas présent dans la liste, alors dico(L)[97]==0.\nfrom random import randint def dico(L): \u0026#39;\u0026#39;\u0026#39; dico(L: list) -\u0026gt; dict précondition: si la longueur de L vaut n, alors L ne contient que des entiers \u0026lt; n \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE Correction (cliquer pour afficher) def dico(L): n = len(L) dic = {} for i in range(n): dic[i] = 0 for e in L: dic[e] += 1 return dic Commentaire (cliquer pour afficher) La signature de la fonction et les préconditions délimitent les types et les domaines des entrées (les arguments).\nOn peut, ou non, s'assurer de leur respect grâce à des asser.\nIci, par exemple, on aurait pu commencer le code de la fonction par les lignes suivantes\u0026nbsp;:\nn = len(L) for e in L: assert e \u003c n Définissons une fonction recherche_dico qui vérifie si un entier est bien présent :\ndef recherche_dico(e,dic): \u0026#39;\u0026#39;\u0026#39; recherche_dico(e: int, dic: dict) -\u0026gt; bool \u0026#39;\u0026#39;\u0026#39; if dic[e] \u0026gt;= 1: return True else: return False # Exemple d\u0026#39;utilisation: L = [5,2,3,1,2,0,2] dic = dico(L) (recherche_dico(3,dic),recherche_dico(4,dic)) (True, False)\nL\u0026rsquo;intérêt de recherche-dico est d\u0026rsquo;aller beaucoup plus vite que recherche comme le montre le graphe suivant (l\u0026rsquo;execution du code peut prendre quelques secondes) :\nfrom time import time from random import randint import matplotlib.pyplot as plt plt.style.use(\u0026#39;ggplot\u0026#39;) I, T_ch, T_dico = [], [], [] for i in range(1000,200000,1000): L = [] L = [randint(0,i-1) for k in range(i)] # randint(i,j) retourne un entier dans {i;...;j} # la liste L contient i éléments tirés au hasard entre 0 et i-1 dic = dico(L) # on crée un dictionnaire à partir de L grâce à la fonction \u0026#39;dico\u0026#39; element = randint(0,i-1) # \u0026#39;element\u0026#39; est un entier tiré au hasard entre 0 et i-1 start = time() # on note l\u0026#39;heure exacte recherche(element,L) stop1 = time() recherche_dico(element,dic) stop2 = time() T_ch.append(stop1-start) T_dico.append(stop2-stop1) I.append(i) plt.figure(figsize = (15,5)) plt.plot(I,T_dico,label=\u0026#34;recherche_dico\u0026#34;) plt.plot(I,T_ch,label=\u0026#34;votre fonction \u0026#39;recherche\u0026#39;\u0026#34;) plt.xlabel(\u0026#39;taille de la liste\u0026#39;) plt.ylabel(\u0026#34;temps d\u0026#39;exécution (s)\u0026#34;) plt.legend() Commentaire (cliquer pour afficher) Le graphique montre que la fonction recherche a une complexité constante (nombre constant d'opération) dans le meilleur des cas (élément à rechercher au début de la liste) et une complexité linéaire (nombre d'opérations proportionnel à la longueur de la liste) dans le pire des cas.\nPar contre, la fonction recherche_dico semble, elle, toujours de complexité constante. Recherche d\u0026rsquo;un maximum Écrire une fonction maximum qui prend pour argument une liste et qui retourne le plus grand élément de la liste.\n(Interdiciton d\u0026rsquo;utiliser la fonction native max évidemment)\ndef maximum(L) : \u0026#39;\u0026#39;\u0026#39; maximum(L: list) -\u0026gt; float ou int \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE Correction (cliquer pour afficher) def maximum(L): m = L[0] for e in L[1:]: # on commence à partir du 2e élément de L if e \u003e m: m = e return m Commentaire 1 (cliquer pour afficher) L'utilisation du découpage (slicing) L[1:] permet d'éviter l'erreur indexerror : list index out of range (qui signifie que l'indice est hors-plage) dans le cas d'une liste de seulement 1 élément. En effet, L[1:] ne renvoie alors pas une erreur mais la liste vide []. On ne rentre donc pas dans la boucle.\nOn aurait aussi pu utiliser L pour itérer car bien que cela entraîne une comparaison supplémentaire inutile, pour des grandes listes, c'est complètement insignifiant.\nRq : la fonction lèvera une erreur si L est une liste vide car dans ce cas, même L[0] n'existe pas. Commentaire 2 (cliquer pour afficher) Il faut aussi savoir construire une fonction qui renvoie l'indice du maximum (le premier indice au cas où le maximum serait présent plusieur fois)\u0026nbsp;: def indice_maximum(L): n = len(L) im = 0 for i in range(1,n): if L[i] \u003e L[im]: im = i return im Et si on a besoin des deux à la fois, on peut renvoyer le max et son indice dans un tuple\u0026nbsp;: def max_et_indice(L): n = len(L) im = 0 m = L[im] for i in range(1,n): if L[i] \u003e m: im = i m = L[im] return m,im Que se passera-t-il si on passe la liste suivante [1,3,'a',-2] en argument à maximum ?\nmaximum([1,3,\u0026#39;a\u0026#39;,-2]) Pour éviter cela, vous devrez vous assurez en amont que la liste donnée en argument contient bien que des nombres.\nRappel : type(3) renvoie int et type(2.8) renvoie float.\nVous placerez un assert en début de fonction prévenant l\u0026rsquo;utilisateur que la liste contient des types farfelus.\ndef maximum_secure(L) : \u0026#39;\u0026#39;\u0026#39; maximum(L: list) -\u0026gt; float ou int la fonction lève une \u0026#39;AsserionError\u0026#39; si la liste ne contient pas que des nombres \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE Correction (cliquer pour afficher) def maximum_secure(L) : for e in L : assert type(e)==int or type(e)==float, 'la list ne contient pas que des nombres' return maximum(L) On aurai aussi pu écrire : assert type(e) in (float,int) Construisez maintenant une fonction max_2 qui retourne le deuxième maximum défini comme le plus grand élément strictement inférieur au maximum (s\u0026rsquo;il y a plusieurs éléments ayant la valeur maximale, il ne faut pas retourner un de ceux-là).\nVotre fonction max_2 devra utiliser votre ancienne fonction maximum, mais vous ferez attention à ne pas placer maximum à l\u0026rsquo;intérieur d\u0026rsquo;une boucle.\ndef max_2(L): \u0026#39;\u0026#39;\u0026#39; max_2(L: list) -\u0026gt; float ou int précondition: L est une liste de nombres postcondition: la fonction retourne le plus grand élément strictement plus petit que le max de la liste. \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE Correction (cliquer pour afficher) def max_2(L): assert len(L)\u003e1, \"la liste ne contient qu'un élément\" x = L[0] b = False # b va servir à tester qu'un 2e max est bien présent for e in L: if e != x: b = True assert b, \"pas de second max puisque tous les éléments sont identiques\" M = maximum(L) m = M while m == M: L.remove(m) m = maximum(L) m2 = maximum(L) return m2 Ci-dessous est représentée l\u0026rsquo;évolution du temps d\u0026rsquo;exécution de la fonction native max ainsi que de la fonction maximum (si vous avez réussi à l\u0026rsquo;implémenter) en fonction de la taille de la liste en argument.\nOn remarque que cette évolution est linéaire : l\u0026rsquo;augmentation du temps d\u0026rsquo;exécution semble proportionnelle à l\u0026rsquo;augmentation de la taille de la liste.\nI, T_max, T_maximum = [], [], [] for i in range(50000,1000000,50000): L = [] for k in range(i): L += [randint(0,k)] # randint(i,j) retourne un entier dans {i;...;j} start1 = time() max(L) stop1 = time() T_max.append(stop1-start1) start2 = time() maximum(L) stop2 = time() T_maximum.append(stop2-start2) I.append(i) plt.figure(figsize = (15,5)) plt.plot(I,T_max,label = \u0026#34;la fonction Python \u0026#39;max\u0026#39;\u0026#34;) plt.plot(I,T_maximum,label = \u0026#34;votre fonction \u0026#39;maximum\u0026#39;\u0026#34;) plt.xlabel(\u0026#39;taille de la liste\u0026#39;) plt.ylabel(\u0026#34;temps d\u0026#39;exécution (s)\u0026#34;) plt.legend() Ajoutez la fonction max_2 à ce graphe et répondre dans la cellule suivante si oui ou non, le temps d\u0026rsquo;exécution de max_2 semble dépendre linéairement de la taille de la liste.\nCorrection (cliquer pour afficher) Code avec ajout de max_2\u0026nbsp;: I, T_max, T_maximum, T_max2 = [], [], [], [] for i in range(50000,1000000,50000) : L = [] for k in range(i) : L += [randint(0,k)] # randint(i,j) retourne un entier dans {i;...;j} start1 = time() max(L) stop1 = time() T_max.append(stop1-start1) start2 = time() maximum(L) stop2 = time() T_maximum.append(stop2-start2) start3 = time() max_2(L) stop3 = time() T_max2.append(stop3-start3) I.append(i) plt.figure(figsize = (15,5)) plt.plot(I, T_max, label= \"la fonction Python 'max'\") plt.plot(I, T_maximum, label= \"votre fonction 'maximum'\") plt.plot(I, T_max2, label= \"votre fonction 'max_2'\") plt.xlabel('taille de la liste') plt.ylabel(\"temps d'exécution (s)\") plt.legend() On obtient\u0026nbsp;: La fonction max_2 semble donc bien dépendre linéairement de la taille de la liste. La pente plus élevée traduit que le nombre d'opérations à réaliser pour chaque élément de la liste est plus élevé. Commentaire (cliquer pour afficher) La fonction python native n'utilise pas un meilleur algorithme. D'ailleurs sa complexité est bien linéaire mais comme souvent avec les fonctions natives, l'optimisation joue sur l'interfaçage entre le code et la machine. Le code d'une fonction native Python n'est pas écrit en Python mais dans un langage de plus bas niveau, le C, plus proche de la machine, donc plus rapide. "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/traitsgaux/",
	"title": "Traits généraux",
	"tags": [],
	"description": "",
	"content": "Traits généraux Introduction Shell et IDE Python est un langage de programmation interprété développé par Guido van Rossum en 1989. Langage impératif de haut-niveau doté d\u0026rsquo;une syntaxe simple, Python s\u0026rsquo;adapte à de nombreux contextes grâce à sa modularité ; une importante librairie de modules et packages permet en effet d\u0026rsquo;étendre ses capacités.\nPython possède son propre shell (interface en ligne de commande) : l\u0026rsquo;utilisateur entre une commande Python qui est interprétée immédiatement lorsque Entrée est tapée.\nAu lancement, le shell Python, poli, se présente :\nLes 3 chevrons sont l\u0026rsquo;invite (ou prompt) où les commandes seront écrites.\nIPython, un shell plus évolué, utilise [1] comme invite (où le chiffre dans les crochets s\u0026rsquo;incrémente à chaque commande).\nPour sortir du shell classique, il faut taper exit(), et exit ou quit pour sortie du shell IPython.\nOn peut tout à fait exécuter des commandes Python une à une dans le shell.\nUne commande qui renvoie un résultat est appelée expression, alors qu\u0026rsquo;une commande qui ne renvoie rien est une instruction.\nToute fonction est une expression, mais certaines ont en plus un effet sur l\u0026rsquo;environnement comme print() qui permet d\u0026rsquo;afficher une chaîne de caractères dans le shell ou dans un fichier (elle retourne aussi la valeur None qui est omise dans ce cas par le shell). Par une mauvaise traduction de l\u0026rsquo;anglais side effect, les fonctions qui modifient un état en dehors de leur environnement local comme une modification de la mémoire (écriture d\u0026rsquo;un fichier) ou une modification d\u0026rsquo;un périphérique (affichage sur l\u0026rsquo;écran par exemple) sont dites à effet de bord.\nPour les projets plus complexes nécessitant d\u0026rsquo;enchaîner les instructions, on écrit l\u0026rsquo;ensemble de ces commandes (le programme) dans un éditeur de texte et on enregistre le fichier avec une extension .py.\nOn demande alors à l\u0026rsquo;interprète Python d\u0026rsquo;exécuter l\u0026rsquo;ensemble du script en utilisant la commande python nom_du_fichier.py dans le shell de l\u0026rsquo;OS. Les différents retours dans le shell ne sont alors plus affichés, seuls les effets ont un\u0026hellip; effet.\nLe plus simple pour coder est d\u0026rsquo;utiliser un environnement de travail (IDE pour \u0026ldquo;integrated development environment\u0026rdquo;) qui combine un éditeur de code et un shell Python permettant d\u0026rsquo;exécuter le script entier ou une partie directement via l\u0026rsquo;interface.\nInstallation L\u0026rsquo;installation d\u0026rsquo;Anaconda rend disponible les principales bibliothèques scientifiques Python ainsi que le preformant IDE Spyder ou encore Jupyterlab (très intéressant pour les présentations de projets car associant dans une même interface texte et code pour former un notebook).\nPassons maintenant en revue quelques caractéristiques du langage Python.\nTypage dynamique Contrairement à des langages à typage statique comme le C, le type de la variable n\u0026rsquo;a pas besoin d\u0026rsquo;être déclarée en Python. On parle alors de typage dynamique.\nL\u0026rsquo;interprète Python détermine par lui-même le type en fonction de l\u0026rsquo;objet affecté à la variable.\nPrincipe d\u0026rsquo;indentation Beaucoup de langage de programmation (C++, Java par exemple) utilisent des accolades {} pour définir un bloc de code (boucles,fonctions, instructions conditionnelles). Python utilise l\u0026rsquo;indentation (décalage d\u0026rsquo;un nombre constant d\u0026rsquo;espaces blancs, généralement 4, ou une tabulation).\nfor i in range(3): mot = \u0026#39;\u0026#39; for lettre in (\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;): mot += lettre*i print(mot) Qu\u0026rsquo;est-ce qui s\u0026rsquo;affiche ?\nPortée lexicale Les variables définies à l\u0026rsquo;intérieur d\u0026rsquo;une fonction ont une portée locale. Elles ne sont pas reconnues dans le code principal (en dehors du bloc de la fonction).\nÀ l\u0026rsquo;inverse, les variables affectées dans le programme principal peuvent être utilisées partout (y compris dans la fonction) et sont dites globales.\nExemple :\ndef foo(): a = \u0026#39;locale\u0026#39; print(a) print(b) b = \u0026#39;globale\u0026#39; foo() locale\nglobale\nComme b n\u0026rsquo;est pas définie dans la bloc de la fonction, Python va la chercher dans le champ global. Mais il faut que b soit affectée avant l\u0026rsquo;appel de la fonction.\nQue se passe-t-il si une fonction définit une variable locale avec le même nom qu\u0026rsquo;une variable globale ?\nLe champ local est scruté en premier.\nExemple :\ndef foo(): a = \u0026#39;locale\u0026#39; print(a) a = \u0026#39;globale\u0026#39; foo() print(a) locale\nglobale\nNotons bien que la variable locale a n\u0026rsquo;existe que dans le bloc de définition, qu\u0026rsquo;elle ait ou non le même nom qu\u0026rsquo;une variable globale ne change rien. Elle disparait quand l\u0026rsquo;interprète sort de la fonction et n\u0026rsquo;écrase donc pas la variable globale a.\nDans l\u0026rsquo;ordre, Python regarde d\u0026rsquo;abord le champ local, puis non local (le champ englobant la fonction intérieure dans le cas de fonctions imbriquées), puis global, puis built-in (les fonctions natives qu\u0026rsquo;il convient donc de ne pas redéfinir).\nUne fonction ne peut pas modifier une variable globale sans préciser qu\u0026rsquo;elle le souhaite.\nExemple :\nx = 2 def fct1(): print(x) def fct2(): x += 1 print(x) Que se passe-t-il lorsqu\u0026rsquo;on appelle fct1() ? Et fct2() ?\nPour régler le problème, il faut utiliser le mot clé global qui permet de réaffecter la variable globale à l\u0026rsquo;intérieur de la fonction.\ndef fct2(): global x x += 1 print(x) L\u0026rsquo;appel de fct2() se fait maintenant sans heurt et 3 s\u0026rsquo;affiche.\nCe type de réaffectation est néanmoins à éviter, car il amène pas mal de confusion. C\u0026rsquo;est souvent plus logique de passer x en argument de la fonction.\nAppel de fonction par valeur Lors de l\u0026rsquo;appel d\u0026rsquo;une fonction, les arguments sont copiés et la fonction travaille alors uniquement sur cette copie.\nLa copie disparaît lors du retour au programme principal.\nSi la fonction modifie la valeur d\u0026rsquo;un de ses arguments, seule la copie sera modifiée, pas la variable du programme principal.\nOn dit que les arguments d\u0026rsquo;une fonction sont transmis par valeurs (par contraste avec la transmission par référence ou adresse comme dans le langage Java où une modification de l\u0026rsquo;argument dans la fonction se répercute dans le programme principal).\nExemple :\ndef foo(a): print(\u0026#34;valeur de \u0026#39;a\u0026#39; au début de la fonction :\u0026#34;,a) a = a*2 print(\u0026#34;valeur de \u0026#39;a\u0026#39; à la fin de la fonction :\u0026#34;,a) a = 2 print(\u0026#34;valeur de \u0026#39;a\u0026#39; dans le programme principal avant l\u0026#39;appel de la fonction :\u0026#34;,a) foo(a) print(\u0026#34;valeur de \u0026#39;a\u0026#39; dans le programme principal après l\u0026#39;appel de la fonction :\u0026#34;,a) valeur de 'a' dans le programme principal avant l'appel de la fonction : ...\nvaleur de 'a' au début de la fonction : ...\nvaleur de 'a' à la fin de la fonction : ...\nvaleur de 'a' dans le programme principal après l'appel de la fonction : ...\nNotons toutefois que si l\u0026rsquo;argument est une liste, c\u0026rsquo;est sa référence qui est cette fois transmise\u0026hellip; Toute modification de la liste dans la fonction se répercute à l\u0026rsquo;extérieur. La fonction a alors un effet de bord. C\u0026rsquo;est dû au statut mutable des listes dans Python. Et cela sera donc la même chose avec les dictionnaires, autre objet mutable.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/",
	"title": "Python",
	"tags": [],
	"description": "",
	"content": "Python Extrait du programme : Cette annexe liste limitativement les éléments du langage Python (version 3 ou supérieure) dont la connaissance est exigible des étudiants. Aucun concept sous-jacent n'est exigible au titre de la présente annexe.\nAucune connaissance sur un module particulier n'est exigible des étudiants.\nToute utilisation d'autres éléments du langage que ceux que liste cette annexe, ou d'une fonction d'un module, doit obligatoirement être accompagnée de la documentation utile, sans que puisse être attendue une quelconque maîtrise par les étudiants de ces éléments. Traits généraux Typage dynamique : l'interpréteur détermine le type à la volée lors de l'exécution du code. Principe d'indentation. Portée lexicale : lorsqu'une expression fait référence à une variable à l'intérieur d'une fonction, Python cherche la valeur définie à l'intérieur de la fonction et à défaut la valeur dans l'espace global du module. Appel de fonction par valeur : l'exécution de $f(x)$ évalue d'abord $x$ puis exécute $f$ avec la valeur calculée. Types de base Opérations sur les entiers (int) : +, -, *, //, **, % avec des opérandes positifs. Opérations sur les flottants (float) : +, -, *, /, **. Opérations sur les booléens (bool) : not, or, and (et leur caractère paresseux). Comparaisons ==, !=, \u003c, \u003e, \u003c=, \u003e=. Types structurés Structures indicées immuables (chaînes, tuples) : len, accès par indice positif valide, concaténation +, répétition *, tranche. Listes : création par compréhension [𝑒 for 𝑥 in 𝑠], par [𝑒] * n, par append successifs ; len, accès par indice positif valide; concaténation +, extraction de tranche, copie (y compris son caractère superficiel) ; pop en dernière position. Dictionnaires : création, accès, insertion, len, copy. Structures de contrôle Instruction d’affectation avec =. Dépaquetage de tuples. Instruction conditionnelle : if, elif, else. Boucle while (sans else). break, return dans un corps de boucle. Boucle for (sans else) et itération sur range(𝑎, 𝑏), une chaîne, un tuple, une liste, un dictionnaire au travers des méthodes keys et items. Définition d’une fonction def f(𝑝1,...,𝑝𝑛), return. Divers Introduction d’un commentaire avec #. Utilisation simple de print, sans paramètre facultatif. Importation de modules avec import module, import module as alias, from module import 𝑓,𝑔,... Manipulation de fichiers texte (la documentation utile de ces fonctions doit être rappelée ; tout problème relatif aux encodages est éludé) : open, read, readline, readlines, split, write, close. Assertion : assert (sans message d’erreur). "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/correctionterminaison/",
	"title": "Correction / Terminaison",
	"tags": [],
	"description": "",
	"content": "Prouver un algorithme Le mot algorithme vient de la latinisation du nom du savant arabe al-Khuwārizmī (780-850) qui a entre autres permis l\u0026rsquo;introduction de l\u0026rsquo;algèbre en Europe (et il est aussi à l\u0026rsquo;origine de ce mot).\nUn algorithme est une méthode qui sert à résoudre un problème en un nombre fini d’étapes : chercher un mot dans le dictionnaire, classer des mots par ordre alphabétique, classer des nombres par ordre de grandeur, chercher le meilleur parcours possible sur une carte, trouver une racine carrée, construire des listes de nombres premiers, etc.\nOn peut décrire un algorithme comme étant une suite d\u0026rsquo;actions à accomplir séquentiellement, dans un ordre fixé.\nPour Gérard Berry, ex titulaire de la chaire Informatique et sciences numériques au Collège de France, l\u0026rsquo;algorithmique est l\u0026rsquo;art d\u0026rsquo;organiser un calcul complexe en partant d\u0026rsquo;opérations simples (un ordinateur étant un objet extraordinairement stupide mais très obéissant).\nLes algorithmes manipulent trois types de choses :\ndes objets : bits, entiers, flottants, mots, images, etc. des structures de données (comment on organise les objets) : piles, listes, chaînes, arbres, etc. des structures de contrôle (comment on organise les opérations) : séquence, condition, boucle, etc. Face à un algorithme, on peut se poser plusieurs questions :\nEst-ce qu\u0026rsquo;il donne un résultat ou bien est-ce qu’il ne s’arrête jamais ? C\u0026rsquo;est le problème de la terminaison d\u0026rsquo;un algorithme. Est-ce qu\u0026rsquo;il donne le résultat attendu ou bien est-ce qu’il calcule n’importe quoi ? C\u0026rsquo;est le problème de la correction de l\u0026rsquo;algorithme. Est-ce qu’il donne le résultat en un temps raisonnable ou bien est-ce qu’il faut attendre plusieurs siècles ? C\u0026rsquo;est le problème de la complexité de l\u0026rsquo;algorithme. Terminaison d\u0026rsquo;un algorithme Un algorithme doit se terminer en un temps fini !\nOn est sûr qu\u0026rsquo;un algorithme termine si le nombre d\u0026rsquo;étapes est fixé.\nLes deux énemis de la terminaison sont :\nles boucles while la récursivité Algorithmes itératifs : Chez les algorithmes itératifs, notre attention se tourne exclusivement vers les boucles while (tant que), car ce sont les seuls blocs de code où le nombre d\u0026rsquo;étapes n\u0026rsquo;est pas fixé à l\u0026rsquo;avance et qui peuvent donc dégénerer en boucles infinies.\nPour prouver leur terminaison, on exhibe un variant de boucle.\nUn variant de boucle est un entier strictement positif avant l\u0026rsquo;entrée dans la boucle qui décroît strictement à chaque passage dans la boucle.\nTrouver un variant de boucle prouve que la boucle termine, car sinon il existerait une suite décroissante d\u0026rsquo;entiers naturels, ce qui est impossible.\nExemple : preuve de la terminaison de l\u0026rsquo;algorithme d\u0026rsquo;exponentiation rapide\ndef puissance(a,n): p = 1 while n \u0026gt; 0: if n%2 == 0: a *= a n //= 2 else: p *= a n -= 1 return p Si on spécifie que n doit être un entier positif, alors n est un variant de boucle. En effet :\n$n$ est bien un entier strictement positif avant chaque passage dans la boucle : $n$ est initialement un entier positif (par hypothèse) et $n$ reste entier après k passages dans la boucle (par récurrence simple). De plus, la boucle s\u0026rsquo;arrête si $n≤0$. $n$ est bien strictement décroissant : en notant $n\u0026rsquo;$ la valeur de $n$ après un passage dans la boucle, si $n$ est pair avant un passage dans la boucle, on a $\\displaystyle n\u0026rsquo;=\\frac{n}{2}$ et comme $n≥2$, $n\u0026rsquo;\u0026lt;n$. Et si $n$ est impair, alors on a $n\u0026rsquo;=n-1$ et donc à nouveau $n\u0026rsquo;\u0026lt;n$. Algorithmes récursifs : On prouve la terminaison d\u0026rsquo;un algorithme récursif par récurrence (par construction, tout ce qui est lié aux algorithme récursifs se prouve par récurrence).\nExemple : l\u0026rsquo;algorithme récursif suivant calcul la somme des n premiers entiers.\ndef sommerec(n): \u0026#34;\u0026#34;\u0026#34; sommerec(n: int) -\u0026gt; int préconditions: n est un entier positif postcondition: retourne la somme des entiers positifs ≤ n \u0026#34;\u0026#34;\u0026#34; if n == 0: return 0 else: return n + sommerec(n-1) Prouvons par récurrence sur n que l\u0026rsquo;algorithme termine :\npour n = 0, c\u0026rsquo;est bon (cas de base). supposons que l\u0026rsquo;algorithme termine pour l\u0026rsquo;entrée n-1 (ie sommerec(n-1) termine).\nPour l\u0026rsquo;entrée n, l\u0026rsquo;algorithme retourne n + sommerec(n-1), donc sommerec(n) termine. conclusion : sommerec termine pour tout n. On ne peut pas prouver automatiquement l\u0026rsquo;arrêt d\u0026rsquo;un programme.\nC\u0026rsquo;est ce qu\u0026rsquo;affirme le théorème de l\u0026rsquo;arrêt : il n\u0026rsquo;existe pas de programme prenant en entrée le code d\u0026rsquo;un programme et ses arguments et qui renvoie oui si le programme se termine pour une certaine entrée, non sinon.\nLa conjecture de syracuse (tp0) est un exemple de programme dont on ne sait pas s\u0026rsquo;il se termine pour une entrée quelconque.\nPreuve de correction d’un algorithme Ariane 501 a explosé à cause d\u0026rsquo;un bug tout petit dans un programme qui ne servait à rien.\nProuver la correction d\u0026rsquo;un algorithme permet d\u0026rsquo;éviter une telle mésaventure, mais c\u0026rsquo;est difficile. Il faut pouvoir prouver qu’un programme s’exécute correctement dans toutes les situations. Mais correct selon quels critères ? Quelles situations sont à considérer ?\nSpécifier les données acceptables (les préconditions), les résultats attendus (les postconditions) et exprimer logiquement la propriété devant lier les données aux résultats (les entrées aux sorties) sont des éléments fondamentaux. Plus précisément, on prouve qu\u0026rsquo;un algorithme fait ce qu\u0026rsquo;il est sensé faire si pour toute entrée vérifiant les préconditions, il donne une sortie vérifiant les postconditions.\nSi on prouve que pour toute donnée d\u0026rsquo;entrée qui vérifie les préconditions, l\u0026rsquo;algorithme renvoie des données de sortie vérifiant les postconditions,\non dit qu\u0026rsquo;on a prouvé la correction partielle de l\u0026rsquo;algorithme.\nSi on prouve en plus que l\u0026rsquo;algorithme termine,\non dit qu\u0026rsquo;on a prouvé la correction totale de l\u0026rsquo;algorithme.\nAlgorithmes itératifs : Les difficultés se concentrent encore au niveau des boucles. Pour prouver qu\u0026rsquo;une boucle fait bien son boulot, on utilise cette fois-ci un invariant de boucle.\nUn invariant de boucle est une propriété vraie avant le premier tour de boucle et qui se conservera pendant toute l’exécution de la boucle (donc qui restera vraie d’un tour à l’autre de la boucle), et sera toujours vraie une fois que la boucle aura fini de s’exécuter.\nUne démonstration par invariant de boucle se déroule en 3 étapes analogues à une preuve par récurrence (seule la terminaison diffère) :\nEntrée de boucle = initialisation ($\\rightarrow$ initialisation) :\non démontre que juste avant de rentrer dans le premier tour de boucle l’invariant est vrai.\nPassage dans la boucle = conservation ($\\rightarrow$ hérédité) :\non suppose que l’invariant est vrai au début d’un passage quelconque dans la boucle et on démontre que l’invariant reste vrai en fin de boucle.\nSortie de boucle = terminaison ($\\rightarrow$ conclusion) :\nl’invariant est toujours vrai (car il était vrai à la fin du dernier tour de boucle) mais la condition de boucle est devenue fausse.\nExemple : preuve de la correction de l\u0026rsquo;algorithme d\u0026rsquo;Euclide\ndef pgcd(a,b): while b != 0: a, b = b, a%b return a On note $a_k$ et $b_k$ les valeurs de a et b à la fin de la kème itération ($a_0$ et $b_0$ désignent les valeurs de a et b avant d’entrer dans la boucle).\nL\u0026rsquo;invariant de boucle est le $pgcd$ de a et b. En effet :\nInitialisation :\nelle est triviale puisque $a$ et $b$ n\u0026rsquo;ont pas encore été modifié ($pgcd(a_0,b_0)=pgcd(a,b)$). Conservation :\nsi $a=bq+r$, il est clair que tout diviseur commun de $a$ et $b$ est un diviseur commun de $b$ et $r$ et réciproquement. Notamment, $pgcd(a,b) = pgcd(b,r)$.\nCeci prouve que $pgcd(a_k,b_k) = pgcd(a_{k+1},b_{k+1})$. La quantité $pgcd(a_k,b_k)$ est donc bien un invariant de boucle. Terminaison :\nà la fin de la dernière itération (numérotée $f$), $b_f=0$ de sorte que $pgcd(a_0,b_0)=pgcd(a_f,b_f)=pgcd(a_f,0)=a_f.$\nEn renvoyant $a_f$, la fonction pgcd(a,b) renvoie donc bien le $pgcd$ de a et b. Algorithmes récursifs : La correction d\u0026rsquo;un algorithme récursif est généralement beaucoup plus simple à prouver que celle d\u0026rsquo;un itératif (c\u0026rsquo;est là une des principales qualités de la récursivité).\nEn effet, la propriété transmise des préconditions aux postconditions (jouant le rôle d\u0026rsquo;invariant de boucle) est souvent évidente voire tout à fait explicite puisqu\u0026rsquo;un algorithme récursif et une preuve par récurrence ont la même structure.\nReprenons l\u0026rsquo;exemple de la somme des entiers et démontrons par récurrence sa correction :\nsi n = 0, la somme vaut bien 0. supposons que sommerec(n-1) donne la somme des n-1 premiers entiers. Alors la somme des n premiers entiers vaudra sommerec(n-1) + n et c\u0026rsquo;est bien ce que retourne sommerec(n). Conclusion : pour tout n, sommerec(n) retourne la somme des n premiers entiers. On aurait pu se montrer plus technique en utilisant comme propriété héréditaire : $u_n=$sommerec(n) $=\\frac{n(n+1)}{2}$\nEn supposant la propriété vraie au rang n-1, sommerec(n) = n + sommerec(n-1) $=n+u_{n-1}$ $= n + \\frac{n(n-1)}{2} = \\frac{n(n+1)}{2}$\nConstruire un algorithme pour qu\u0026rsquo;il soit correct Expliciter l\u0026rsquo;invariant comme on a vu dans les bonnes pratiques en s\u0026rsquo;en servir comme guide permet de s\u0026rsquo;assurer en amont de la correction de l\u0026rsquo;algorithme ; on sait où on va.\nPar exemple, pour le tri par sélection, faire en sorte que l\u0026rsquo;invariant \u0026ldquo;la partie de la liste déjà inspectée est triée\u0026rdquo; soit toujours vrai nous assure de la correction future de l\u0026rsquo;algorithme ; en faisant en sorte que la partie non triée diminue bien à chaque tour, on finira fatalement par obtenir une liste entièrement triée.\nAutre exemple, pour consruire les méthodes liées à la jolie structure de données appelée tas (que l\u0026rsquo;on retrouvera dans le chapitre sur les graphes), on est guidé par la conservation de l\u0026rsquo;invariant \u0026ldquo;les clés des enfants doivent être supérieures à celles du parent\u0026rdquo; (voir la vidéo pour les détails).\nExercice : prouver la correction totale de l\u0026rsquo;algorithme de la division euclidienne vu dans les bonnes pratiques.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp2imbrication/",
	"title": "TP 2 : boucles imbriquées",
	"tags": [],
	"description": "",
	"content": " Algorithmes opérant sur une structure séquentielle par boucles imbriquées Cliquez sur cette invitation pour récupérer le repository du TP. Chercher un mot dans un texte Écrire une fonction cherche_mot naïve qui recherche si un mot est présent dans un texte en comparant chaque morceau du texte de la taille du mot au mot recherché.\nVous devrez vous assurez (grâce à des assertions) que le mot et le texte sont bien des chaînes de caractères et que le mot n\u0026rsquo;est pas plus long que le texte.\ndef cherche_mot(mot, texte): \u0026#39;\u0026#39;\u0026#39; cherche_mot(mot: string, texte: string) -\u0026gt; bool \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE Correction (cliquer pour afficher) def cherche_mot(mot,texte): assert type(mot) == str, \"'mot' n'est pas une chaîne de caractères\" assert type(texte) == str, \"'texte' n'est pas une chaîne de caractères\" n = len(texte) m = len(mot) assert n \u003e= m, \"'mot' plus grand que 'texte'...\" for i in range(n-m+1): if texte[i:i+m] == mot: return True return False Commentaire (cliquer pour afficher)\u0026nbsp; Imaginez que vous ayez oublié le +1 dans le range de la boucle. Vous devez être capable de déceler l'erreur en testant votre fonction.\nVos tests doivent consister à vérifier que votre fonction donne la réponse attendue sur différents exemples. Et en particulier, il faut toujours tester les extrémités d'un domaîne et les cas pathologiques lorsqu'il y en a (comme une division par zéro).\nIci par exemple, il était capital de tester que la fonction réponde bien True pour un mot au tout début du texte ou à la toute fin.\nSi la fonction bugue, il faut utiliser des print bien placés pour comprendre ce qui se passe. Une démarche plus systématique est détaillée ici.\nPar exemple, ici, on aurait pu écrire print(texte[i:i+m]) en première ligne de la boucle. # importation de la classique liste de mots de passe rockyou (cela prend quelques secondes) from urllib.request import urlopen url = \u0026#39;http://cordier-phychi.toile-libre.org/Info/github/rockyou.txt\u0026#39; rockyou = urlopen(url).read().decode(\u0026#39;latin-1\u0026#39;) print(f\u0026#34;Le fichier rockyou contient {len(rockyou.split())} mots de passe !\u0026#34;) Le fichier rockyou contient 14445388 mots de passe !\n# vous pouvez tester la présence de votre mot de passe dans la liste mot_de_passe = \u0026#39;...\u0026#39; cherche_mot(mot_de_passe,rockyou) Quel est le nombre minimum de comparaisons à faire pour s\u0026rsquo;assurer qu\u0026rsquo;un mot de 3 caractères est absent d\u0026rsquo;une chaîne de 10 caractères ? Attention, comparer deux mots ne compte pas que pour une seule comparaison !\nCorrection (cliquer pour afficher) Pour chaque morceau du texte de la taille du mot, il y a $m$ comparaisons réalisées ($m$ : taille du mot). Ici, $m=3$.\nEt combien y a-t-il de morceaux différents de taille $m$ dans un texte de taille $n$\u0026nbsp;? $n-m+1$.\nCela fait donc en tout $m\\times(n-m+1)=nm-m^2+m$ comparaisons, soit 24 ici. Traçons l\u0026rsquo;évolution du temps d\u0026rsquo;exécution de cherche_mot en fonction de la taille du texte pour une taille du mot fixe.\nfrom time import time from random import randint import matplotlib.pyplot as plt plt.style.use(\u0026#39;ggplot\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 5) I, T_in, T_ch = [], [], [] mot = \u0026#39;\u0026amp;\u0026#39;*100 for i in range(10000,500000,10000): texte = rockyou[:i] start = time() cherche_mot(mot,texte) stop = time() T_ch.append(stop-start) I.append(i) plt.figure(figsize = (15,5)) plt.plot(I,T_ch) plt.xlabel(\u0026#34;longeur du texte (longueur mot = moitié longueur texte)\u0026#34;) plt.ylabel(\u0026#34;temps d\u0026#39;exécution (s)\u0026#34;) plt.title(\u0026#34;Temps d\u0026#39;excution de \u0026#39;cherche_mot\u0026#39; en fonction de la taille du texte\u0026#34;) Sur le même modèle, vous allez tracer l\u0026rsquo;évolution du temps d\u0026rsquo;exécution de cherche_mot en fonction de la taille du mot pour une taille de texte fixe et pour des mots petits devant le texte.\nPour cela vous compléterez le code ci-dessous.\nI, T_ch_mot = [], [] texte = rockyou[:200000] for i in range(1000,20000,1000): # à compléter (i doit correspondre au nombre de caractères du mot) fig,ax = plt.subplots(figsize = (15,5)) ax.plot(I,T_ch_mot) ax.set(xlabel=\u0026#34;longueur du mot\u0026#34;, ylabel=\u0026#34;temps d\u0026#39;exécution (s)\u0026#34;) ax.set_title(\u0026#34;Temps d\u0026#39;excution de \u0026#39;cherche_mot\u0026#39; en fonction de la longueur du mot\u0026#34;) Code complété (cliquer pour afficher) I, T_ch_mot = [], [] texte = rockyou[:250000] for i in range(1000,12500,500): mot = 'f'*i # mot de i lettres start = time() cherche_mot(mot,texte) stop = time() T_ch_mot.append(stop-start) I.append(i) fig,ax = plt.subplots(figsize = (15,5)) ax.plot(I,T_ch_mot) ax.set(xlabel=\"longueur du mot\", ylabel=\"temps d'exécution (s)\") ax.set_title(\"Temps d'excution de 'cherche_mot' en fonction de la longueur du mot\") Pour des petits mots par rapport au texte et en appelant $n$ la longueur du texte et $m$ la longueur du mot, quelle fonction semble-t-elle le mieux modéliser l\u0026rsquo;évolution du temps d\u0026rsquo;exécution en fonction de $n$ et $m$ ?\nA : $a\\times m + b\\times n$ où $a$ et $b$ sont des constantes B : $a\\times m^2$ où $a$ est une constante C : $a\\times n^2$ où $a$ est une constante D : $a\\times m\\times n$ où $a$ est une constante Correction (cliquer pour afficher) Le premier graphique nous montre que pour une taille de mot $m$ fixée, le temps d'exécution semble proportionnel à la taille $n$ du texte.\nLe deuxième graphique nous montre que pour une taille de texte $n$ fixée, le temps d'exécution semble proportionnel à la taille $m$ du mot.\nOn peut donc supposé un temps d'exécution proportionnel à $n\\times m$ (réponse D). Chercher un doublon La fonction suivante cherche si un élément d\u0026rsquo;une liste se trouve en double et le cas échéant, le retourne.\ndef cherche_duplicata(liste): N = len(liste) for i in range(N): for j in range(N): if i != j and liste[i] == liste[j]: print(\u0026#39;Un élément en double a été trouvé :\u0026#39;) return liste[i] return \u0026#39;Pas de doublons trouvés 😞\u0026#39; liste_fruits = [\u0026#34;🍓\u0026#34;, \u0026#34;🍐\u0026#34;, \u0026#34;🍊\u0026#34;, \u0026#34;🍌\u0026#34;, \u0026#34;🍍\u0026#34;, \u0026#34;🍑\u0026#34;, \u0026#34;🍎\u0026#34;, \u0026#34;🍈\u0026#34;, \u0026#34;🍊\u0026#34;, \u0026#34;🍇\u0026#34;] a = cherche_duplicata(liste_fruits) print(a) Un élément en double a été trouvé :\n🍊\nCombien de fois la comparaison liste[i] == liste[j] est-elle opérée au maximum si la liste contient 200 éléments ?\nCorrection (cliquer pour afficher) Pour chacun des $N$ tours dans la boucle principale, on réalise $N-1$ fois la comparaison (on compare à tous les éléments sauf lui-même). Cela fait $N\\times(N-1)=N^2-N$.\nSoit ici, $39\\,800$ comparaisons. On peut aisément améliorer la fonction en évitant de doubler les comparaisons :\ndef cherche_duplicata_bis(liste): N = len(liste) for i in range(N-1): for j in range(i+1,N): if liste[i] == liste[j]: print(\u0026#39;Un élément en double a été trouvé :\u0026#39;) return liste[i] return \u0026#39;Pas de doublons trouvés 😞\u0026#39; liste_fruits = [\u0026#34;🍓\u0026#34;, \u0026#34;🍐\u0026#34;, \u0026#34;🍊\u0026#34;, \u0026#34;🍌\u0026#34;, \u0026#34;🍍\u0026#34;, \u0026#34;🍑\u0026#34;, \u0026#34;🍎\u0026#34;, \u0026#34;🍈\u0026#34;, \u0026#34;🍊\u0026#34;, \u0026#34;🍇\u0026#34;] a = cherche_duplicata(liste_fruits) print(a) Un élément en double a été trouvé :\n🍊\nCombien de comparaisons sont opérées au maximum avec cette nouvelle fonction si la liste contient 200 éléments ?\n# Pour vous aider à raisonner N = 10 for i in range(N-1) : L = [] for j in range(i+1,N) : L.append((i,j)) print(L) [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9)]\n[(1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9)]\n[(2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9)]\n[(3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9)]\n[(4, 5), (4, 6), (4, 7), (4, 8), (4, 9)]\n[(5, 6), (5, 7), (5, 8), (5, 9)]\n[(6, 7), (6, 8), (6, 9)]\n[(7, 8), (7, 9)]\n[(8, 9)]\nCorrection (cliquer pour afficher) Il y a $N-1$ comparaisons dans la première itération de la boucle principale, $N-2$ dans la deuxième, $N-3$ dans la troisième, etc.\nEt il y aura $N-1$ tours dans la boucle principale.\nCela donne : $\\sum_{i=1}^{N-1} (N-i)$ $= N(N-1) - (N-1)(1+N-1)/2$ $=N(N-1)/2$ $=N^2/2 - N/2$.\nEt donc ici : $19\\,900$ comparaisons from random import randint I, T_dup, T_dup_bis = [], [], [] for i in range(200,5000,200) : L = [i for i in range(i)] start = time() cherche_duplicata(L) stop1 = time() cherche_duplicata_bis(L) stop2 = time() I.append(i) T_dup.append(stop1-start) T_dup_bis.append(stop2-stop1) fig,axs = plt.subplots(3,figsize = (15,15)) axs[0].plot(I,T_dup) axs[0].set_title(\u0026#34;cherche_duplicata\u0026#34;) axs[1].plot(I,T_dup_bis,c=\u0026#39;#3388BB\u0026#39;,label=\u0026#34;cherche_duplicata_bis\u0026#34;) axs[1].set_title(\u0026#34;cherche_duplicata_bis\u0026#34;) axs[2].plot(I,T_dup,label=\u0026#34;cherche_duplicata\u0026#34;) axs[2].plot(I,T_dup_bis,c=\u0026#39;#3388BB\u0026#39;,label=\u0026#34;cherche_duplicata_bis\u0026#34;) axs[2].set_title(\u0026#34;Comparaison\u0026#34;) axs[2].legend() On constate que même si l\u0026rsquo;amélioration est visible entre les deux fonctions, le comportement général (la classe de complexité comme on le verra plus tard) est identique.\nCommentaire (cliquer pour afficher)\u0026nbsp; Ici, on peut résumer la complexité au comptage des comparaisons.\nLe premier algorithme opère $N(N-1)$ comparaisons et le deuxième $N(N-1)/2$.\nOn a bien divisé le nombre de comparaisons par deux mais la complexité est quadratique dans les deux cas (en $O(n^2)$ car le terme qui domine la croissance de la fonction donnant le nombre de comparaisons est dans les deux cas en $N^2$).\nCela traduit le fait que dans les deux cas, pour des grandes listes, si la taille de la liste est multipliée par $a$, alors le nombre de comparaisons est approximativement multiplié par $a^2$\u0026nbsp;! Intégration numérique def trapeze(f, a, b): return (f(a) + f(b))/2 * (b - a) def rect_gauche(f, a, b): return f(a)*(b-a) def integrale(f, a, b, n, methode): p = (b-a)/n s = 0 for i in range(n) : s += methode(f,a+i*p,a+(i+1)*p) return s def f(x) : return np.cos(x)*x**2 + 10 Commentaire (cliquer pour afficher)\u0026nbsp; Le code ci-dessus est dit modulaire dans le sens où plutôt qu'utiliser un gros bloc de code, l'algorithme est découpée en différentes fonctions.\nDeux gros avantages à ce type d'écriture\u0026nbsp;: la lecture et la compréhension du code sont facilitées\u0026nbsp;; le code est beaucoup plus facilement adaptable (facile d'ajouter ou changer la méthode d'intégration utilisée ou de modifier la fonction intégrée). import numpy as np import matplotlib.patches as patches a = -np.pi b = 3/2*np.pi x = np.linspace(a,b,2000) y = f(x) n_possibles = (6,10,20,50,200) fig,axs = plt.subplots(5,2,figsize=(20,20)) for k in range(5) : n = n_possibles[k] p = (b-a)/n I_rect = integrale(f,a,b,n,rect_gauche) I_trap = integrale(f,a,b,n,trapeze) for i in range(n) : rect = plt.Polygon(((a+i*p,0),(a+i*p,f(a+i*p)),(a+(i+1)*p,f(a+i*p)),(a+(i+1)*p,0),(a+i*p,0)),alpha=0.5,facecolor=\u0026#39;#9988DD\u0026#39;,edgecolor=\u0026#39;#9988DD\u0026#39;) trap = plt.Polygon(((a+i*p,0),(a+i*p,f(a+i*p)),(a+(i+1)*p,f(a+(i+1)*p)),(a+(i+1)*p,0),(a+i*p,0)),alpha=0.5,edgecolor=\u0026#39;#3388BB\u0026#39;) for j in range(2) : axs[k][j].plot(x,y,c=\u0026#39;#EE6666\u0026#39;) axs[k][0].add_patch(rect) axs[k][1].add_patch(trap) axs[k][0].text(0,4,s=f\u0026#39;I = {I_rect:.2f}\u0026#39;,fontsize=18,c=\u0026#39;w\u0026#39;,horizontalalignment=\u0026#39;center\u0026#39;) axs[k][1].text(0,4,s=f\u0026#39;I = {I_trap:.2f}\u0026#39;,fontsize=18,c=\u0026#39;w\u0026#39;,horizontalalignment=\u0026#39;center\u0026#39;) À comparer à : $$ \\int_{-\\pi}^{3\\pi/2}(x^2\\cos(x)+10)dx = 2+23\\pi-9\\frac{\\pi^2}{4}\\approx 52,05$$\nPour quelle valeur de $n$, la valeur de $I$ atteint-elle 52,0 (à 0,5 près) avec la méthode des rectangles à gauche ?\nVous appelerez cette valeur n_cible et votre code devra l\u0026rsquo;afficher.\nCorrection (cliquer pour afficher) Savoir tester une convergence, ou comme ici, trouver au bout de combien d'étapes un algorithme a convergé vers une valeur cible pour une imprécision donnée, est très important.\nCela se fait le plus fréquemment avec une boucle while. I = 0 n_cible = 1 while not(52+0.5 \u003e= I \u003e= 52-0.5): # 52,0 ± 0,5 I = integrale(f, a, b, n_cible, rect_gauche) n_cible += 1 print(n_cible) Cela donne $70$ étapes pour la méthode des rectangles à gauche alors qu'on voit sur le graphique qu'il n'a fallu qu'entre 10 et 20 étapes pour la méthode des trapèzes (remplacer rect_gauche par trapeze dans le code ci-dessus donne bien d'ailleurs $15$) "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/typesbase/",
	"title": "Types de base",
	"tags": [],
	"description": "",
	"content": "Types de base Les types de base en python (les catégories fondamentales des objets manipulés) sont :\nLes entiers int (en anglais, entier se dit integer).\nExemples : 1, 2, 1012, -18 etc. Leur précision est infinie et leur taille est illimitée en Python.\nLes flottants float. Ce sont des approximations de nombres réels. La méthode d\u0026rsquo;écriture en machine de ces nombres, équivalente à une écriture scientifique pour nombre binaire, explique leur nom : ce sont des nombres à virgule flottante.\nExemples : 3.58, -0.0398, 2e-7, 3e4 (les puissances de dix, notés e ou E renvoient toujours des nombres flottants). Leur précision est limitée à 53 bits, soit environ 16 chiffres significatifs en décimal.\nC\u0026rsquo;est le point . qui sert de démarcation entre la partie entière et la partie décimale et non la virgule ,.\nLes booléens bool. Ce sont des variables à deux états, True ou False, permettant de représenter des propositions logiques vraies ou fausses.\nOn peut convertir d\u0026rsquo;un type en l\u0026rsquo;autre en utilisant les fonctions natives int(), float() et bool().\nExemple :\n\u0026gt;\u0026gt;\u0026gt; int(5.8)\n5 int() donne la partie entière d\u0026rsquo;un nombre flottant.\n\u0026gt;\u0026gt;\u0026gt; float(5)\n5.0\n\u0026gt;\u0026gt;\u0026gt; bool(0)\nFalse\n\u0026gt;\u0026gt;\u0026gt; bool(5.8)\nTrue N\u0026rsquo;importe quel nombre non nul (entier ou flottant) est considéré comme vrai.\nOpérations sur les entiers (int) Les entiers sont stables pour les opérations suivantes (le résultat est un entier).\nAddition + \u0026gt;\u0026gt;\u0026gt; 2+3\n5\nSoustraction - \u0026gt;\u0026gt;\u0026gt; 2-3\n-1\nMultiplication * \u0026gt;\u0026gt;\u0026gt; 2*3\n6\nDivision entière // a//b donne le quotient de la division euclidienne de a par b.\n\u0026gt;\u0026gt;\u0026gt; 2//3\n0 Attention à ne pas confondre avec la division décimale /.\nSi on travaille avec des entiers, de précision infinie, il est contre-productif d\u0026rsquo;introduire des flottants en utilisant / plutôt que //.\nModulo % a%b donne le reste de la division euclidienne de a par b.\n\u0026gt;\u0026gt;\u0026gt; 2%3\n1 L\u0026rsquo;opérateur modulo sert énormément en informatique, notamment pour éviter de dépasser des valeurs (i%8 ne dépassera jamais 7, quoi que valle i).\nLes opérations suivent les règles de priorité habituelles, et on utilise les parenthèses pour les modifier :\n\u0026gt;\u0026gt;\u0026gt; 8//2*(2+2)\n16\nQue va donner 5*3%2 ? Et 5*(3%2) ?\nPuissance ** \u0026gt;\u0026gt;\u0026gt; 2**3\n8\nOn parle aussi d\u0026rsquo;opérateur d\u0026rsquo;exponentiation.\nLes puissances négatives retournent des flottants.\n\u0026gt;\u0026gt;\u0026gt; 2**(-3)\n0.125\nOpérations sur les flottants (float) Du moment qu\u0026rsquo;un des deux nombres est un flottant, les opérations +, - et * donnent des flottants.\nExemples :\n\u0026gt;\u0026gt;\u0026gt; 3-1.0\n2.0\n\u0026gt;\u0026gt;\u0026gt; 2e-3*500\n1.0\n\u0026gt;\u0026gt;\u0026gt; 2**(5/2)\n5.656854249492381\nLa précision limitée des flottants et le fait qu\u0026rsquo;ils soient définis en binaire peut donner des résultats surprenants.\nExemple :\n\u0026gt;\u0026gt;\u0026gt; 3*0.1\n0.30000000000000004\nLa division décimale / retourne un flottant même avec deux entiers, et même si le résultat est entier :\n\u0026gt;\u0026gt;\u0026gt; 10/5\n2.0\nOpérations sur les booléens (bool) Négation logique (not) Sert à nier une proposition :\nP ¬P F V V F a , b = True, False print(not a,not b) False True\nDisjonction logique (or) P Q P ∨ Q V V V V F V F V V F F F print(True or True,True or False,False or True, False or False) True True True False\nConjonction logique (and) P Q P ∧ Q V V V V F F F V F F F F print(True and True,True and False,False and True, False and False) True False False False\nnot est prioritaire devant and qui est prioritaire devant or.\nQue vaut False or not False and True ?\nCaractère paresseux des opérateurs or et and Lorsqu\u0026rsquo;on écrit a or b, si a est vrai, alors Python ne s\u0026rsquo;embête pas à évaluer b. Le résultat est nécessairement vrai (cf. la table de vérité), et c\u0026rsquo;est donc ce qui est retourné.\nTrue or qué_pasa True\nDe même, si a est faux, alors a and b retourne False sans évaluer b.\nCe comportement peut s\u0026rsquo;avérer utile pour éviter les erreurs.\nExemple : on veut tester si la première valeur d\u0026rsquo;une liste est positive. Appelons ce test Test. Si la liste est vide, l\u0026rsquo;expression Test va provoquer une erreur.\nOn ajoute alors un deuxième test, Test_vide, qui n\u0026rsquo;est vrai que si la liste est vide. En utilisant l\u0026rsquo;expression (non Test_vide) and Test, on s\u0026rsquo;assure de ne pas lever d\u0026rsquo;erreur en cas de liste vide.\nPour en savoir plus sur l\u0026rsquo;algèbre de Boole : Comparaisons Les différents comparateurs utilisables en Python sont :\ncomparateur signification == égal à != différent de \u0026gt; supérieur à \u0026lt; inférieur à \u0026gt;= supérieur ou égal à \u0026lt;= inférieur ou égal à Le résultat d’une comparaison est un booléen.\nNe pas confondre l\u0026rsquo;opérateur d\u0026rsquo;affectation = et l\u0026rsquo;opérateur de comparaison ==.\nLa précision finie des nombres flottants rend leur comparaison dangereuse :\n0.1**2 == 0.01 retourne False !\nSolution : utiliser un encadrement.\n0.1**2 \u0026gt; 0.01 - 1e-9 and 0.1**2 \u0026lt; 0.01 + 1e-9 renvoie bien True.\nLes opérateurs de comparaison sont prioritaires devant not, and et or.\nExemple : que vaut not 7.5 \u0026lt; 0.9 or 4 == 4 ?\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/projets/wordle/",
	"title": "Wordle",
	"tags": [],
	"description": "",
	"content": "Wordle Écrire un solveur du jeu Wordle qui propose un premier mot puis qui propose le mot suivant en fonction du motif coloré qu\u0026rsquo;on lui transmet en réponse au premier mot rentré, et ainsi de suite jusqu\u0026rsquo;à ce qu\u0026rsquo;il nous propose le mot du jour. Et le tout en moins de 6 essais.\nPour récupérer dans le code la liste des 2315 mots pouvant être solution :\nimport pandas as pd url1 = \u0026#39;https://gist.githubusercontent.com/cfreshman/a03ef2cba789d8cf00c08f767e0fad7b/raw/5d752e5f0702da315298a6bb5a771586d6ff445c/wordle-answers-alphabetical.txt\u0026#39; liste_solutions = pd.read_csv(url1,header=None) liste_solutions = liste_solutions[0].values.tolist() Et pour la liste des mots 10657 mots autorisés (ne comprenant pas les mots solutions) :\nurl2 = \u0026#39;https://gist.githubusercontent.com/cfreshman/cdcdf777450c5b5301e439061d29694c/raw/de1df631b45492e0974f7affe266ec36fed736eb/wordle-allowed-guesses.txt\u0026#39; liste_mots = pd.read_csv(url2,header=None) liste_mots = liste_mots[0].values.tolist() Mission supplémentaire : évaluer la qualité du solveur Pour cela, il faut tester le programme sur chacun des 2315 mots pouvant être solution en laissant le programme jouer tout seul et en vérifiant qu\u0026rsquo;il obtient le mot en au plus 6 essais.\nDonner le pourcentage de réussite. Donner le nombre d\u0026rsquo;essais moyen pour trouver la solution. Aide La démarche la plus efficace utilise la notion d\u0026rsquo;entropie de l\u0026rsquo;information :\nVidéo de Davide Louapre Explications supplémentaires de David Louapre. Une solution possible Disclaimer : cette solution n\u0026rsquo;est pas obtimale puisqu\u0026rsquo;elle n\u0026rsquo;utilise que les mots solutions (pour aller plus vite) ce qui nous prive d\u0026rsquo;un fort potentiel supplémentaire de discrimination.\nRemarquons aussi qu\u0026rsquo;une stratégie reposant sur la liste complète de mots sans connaître par avance l\u0026rsquo;ensemble des mots solutions (solution \u0026ldquo;sans triche\u0026rdquo; donc) ne serait pas forcément plus efficace (meilleure discrimination mais pour un choix bien plus grand). On va le tester à la fin.\nImport des modules et définition des fonctions dont on aura besoin :\nimport numpy as np import pandas as pd import csv import json def obtenir_motif(mot: str,solution: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; donne le motif coloré de la tentative \u0026#34;mot\u0026#34; pour un mot à trouvé valant \u0026#34;solution\u0026#34; exemple : si solution = \u0026#34;aroma\u0026#34; et mot = \u0026#34;raise\u0026#34;, alors la fonction retourne le motif \u0026#34;JJGGG\u0026#34; \u0026#34;\u0026#34;\u0026#34; motif_l = [0]*5 sol = list(solution) indices = list(range(5)) for i in indices[:]: if mot[i] == solution[i]: motif_l[i]=\u0026#39;V\u0026#39; sol.remove(mot[i]) indices.remove(i) for i in indices: if mot[i] in sol: motif_l[i] = \u0026#39;J\u0026#39; sol.remove(mot[i]) else: motif_l[i] = \u0026#39;G\u0026#39; motif = \u0026#39;\u0026#39; for s in motif_l: motif += s return motif def conv_motif_nb(motif: str) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34; considère le motif coloré constitué de 5 lettres valant \u0026#39;G\u0026#39;, \u0026#39;J\u0026#39; ou \u0026#39;V\u0026#39; comme un nombre écrit en base 3 avec \u0026#39;G\u0026#39; = 0, \u0026#39;J\u0026#39; = 1, et \u0026#39;V\u0026#39; = 2 la fonction retourne l\u0026#39;entier correspondant \u0026#34;\u0026#34;\u0026#34; nb = 0 rg = 0 for c in motif[::-1]: for i in range(3): if c==\u0026#39;GJV\u0026#39;[i]: nb += i*3**rg rg += 1 return nb def entropie(mot_test: str,liste_mots: list) -\u0026gt; tuple: \u0026#34;\u0026#34;\u0026#34; la liste en argument est la liste des mots restant possibles pour chaque motif possible, on crée une liste des mots donnant ce motif lorsqu\u0026#39;il est comparé au mot_test on calcul alors l\u0026#39;entropie de mot_test sur la distribution de ses motifs la fonction retourne à la fois l\u0026#39;entropie calculée et la liste liste_mots_par_motifs qui contient la liste des mots correspondant à chacun des motifs \u0026#34;\u0026#34;\u0026#34; n = len(liste_mots) liste_mots_par_motifs = [[] for _ in range(3**5)] for mot in liste_mots: liste_mots_par_motifs[conv_motif_nb(obtenir_motif(mot_test,mot))]+=[mot] res = 0 for L in liste_mots_par_motifs: X = len(L) if X: res += -X/n*np.log2(X/n) return res,liste_mots_par_motifs def entropie_depart(mot_test: str,liste_mots_depart: list) -\u0026gt; tuple: n = len(liste_mots_depart) liste_mots_par_motifs = [[] for _ in range(3**5)] for i in range(n) : liste_mots_par_motifs[conv_motif_nb(obtenir_motif(mot_test,liste_mots_depart[i]))]+=[i] res = 0 for L in liste_mots_par_motifs : X = len(L) if X != 0 : res += -X/n*np.log2(X/n) return res,liste_mots_par_motifs def resultats_depart(liste_depart: list) -\u0026gt; list: Resultats = [] for i in range(len(liste_depart)): s,liste_indices_mots_par_motifs = entropie_depart(liste_depart[i],liste_depart) Resultats.append((s,i,liste_indices_mots_par_motifs)) return Resultats def resultats(liste_depart: list,liste_mots_restants: list) -\u0026gt; list: Resultats = [] for mot in liste_depart: s,liste_mots_par_motifs = entropie(mot,liste_mots_restants) Resultats.append((s,mot,liste_mots_par_motifs)) return Resultats Le code suivant permet d\u0026rsquo;enregistrer la liste donnée par la fonction resultats_depart dans un fichier csv pour s\u0026rsquo;éviter de refaire ce premier long calcul à chaque fois qu\u0026rsquo;on lance le programme. Le fichier csv produit pèse 31,5 Mo (et plus d'1 Go avec tous les mots possibles\u0026hellip;).\n# Liste des mots solutions url = \u0026#39;https://gist.githubusercontent.com/cfreshman/a03ef2cba789d8cf00c08f767e0fad7b/raw/5d752e5f0702da315298a6bb5a771586d6ff445c/wordle-answers-alphabetical.txt\u0026#39; dataf = pd.read_csv(url,header=None) liste_mots_dep = dataf[0].values.tolist() Resultats = resultats_depart(liste_mots_dep[:]) with open(\u0026#39;liste_base.csv\u0026#39;,\u0026#39;w\u0026#39;) as f: write = csv.writer(f) write.writerows(Resultats) Maintenant, on peut jouer\u0026hellip;\nDemandons déjà quelles sont, d\u0026rsquo;après notre modèle, les 3 meilleures et les 3 pires ouvertures :\nRescla = sorted(Resultats,reverse=True) for i in range(3): print(Rescla[i][1].upper()) print(\u0026#39;-\u0026#39;*5) for i in range(1,4): print(Rescla[-i][1].upper()) RAISE\nSLATE\nCRATE\n-----\nFUZZY\nJAZZY\nMAMMA\nEn utilisant la liste complète des mots, on aurait obtenu :\nTARES\nLARES\nRALES\n-----\nQAJAQ\nXYLYL\nIMMIX\nÉcrivons maintenant le code nous permettant de vaincre le Wordle du jour :\n# on récupère les résultats du fichier csv dataf_result = pd.read_csv(\u0026#39;liste_base.csv\u0026#39;,header=None) liste_resultats = dataf_result.values.tolist() Resultats = [] for L1 in liste_resultats: L = [] a,b,c = L1 k = 0 c = json.loads(c) for L2 in list(c): L.append([]) for i in L2: L[k].append(liste_mots_dep[int(i)]) k += 1 Resultats.append((float(a),liste_mots_dep[int(b)],L)) # Et on récupère aussi la liste des mots solutions url = \u0026#39;https://gist.githubusercontent.com/cfreshman/a03ef2cba789d8cf00c08f767e0fad7b/raw/5d752e5f0702da315298a6bb5a771586d6ff445c/wordle-answers-alphabetical.txt\u0026#39; dataf = pd.read_csv(url,header=None) liste_mots_dep = dataf[0].values.tolist() # puis on lance la machine essais = 1 essai1 = max(Resultats)[1].upper() print(\u0026#34;\\n\u0026#34;) print(f\u0026#34;Tentez le mot \u0026#39;{essai1}\u0026#39;\u0026#34;) print() motif_obtenu = input(\u0026#34;puis entrez le motif obtenu\\nsous la forme d\u0026#39;un mot de 5 lettres\\nchoisies parmi \u0026#39;g\u0026#39;, \u0026#39;j\u0026#39; et \u0026#39;v\u0026#39; où\\n\u0026#39;g\u0026#39; désigne une lettre grise,\\n\u0026#39;j\u0026#39; une lettre jaune et\\n\u0026#39;v\u0026#39; une lettre verte\\n\\nmotif : \u0026#34;).upper() while True or essais \u0026lt;= 5: liste_mots = max(Resultats)[2][conv_motif_nb(motif_obtenu)] if len(liste_mots) == 1: print(\u0026#34;\\n\u0026#34;+\u0026#34; \u0026#34;*4+\u0026#34;-\u0026#34;*9) print(\u0026#39;--\u0026gt;\u0026#39;,end = \u0026#39; \u0026#39;) print(f\u0026#34;| {liste_mots[0].upper()} |\u0026#34;) print(\u0026#34; \u0026#34;*4+\u0026#34;-\u0026#34;*9+\u0026#34;\\n\u0026#34;) break Resultats = resultats(liste_mots_dep,liste_mots) nvessai = max(Resultats)[1].upper() print() print(f\u0026#34;Tentez le mot \u0026#39;{nvessai}\u0026#39;\u0026#34;) print() motif_obtenu = input(\u0026#34;motif : \u0026#34;).upper() essais += 1 Exemple :\nTentez le mot 'RAISE'\npuis entrez le motif obtenu\nsous la forme d'un mot de 5 lettres\nchoisies parmi 'g', 'j' et 'v' où\n'g' désigne une lettre grise,\n'j' une lettre jaune et\n'v' une lettre verte\nmotif : gjvgg\nTentez le mot 'CLOWN'\nmotif : ggjgg\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;---------\n--\u003e | AXIOM |\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;---------\nPour tester tous les mots et ainsi évaluer la stratégie :\nurl = \u0026#39;https://gist.githubusercontent.com/cfreshman/a03ef2cba789d8cf00c08f767e0fad7b/raw/5d752e5f0702da315298a6bb5a771586d6ff445c/wordle-answers-alphabetical.txt\u0026#39; liste = pd.read_csv(url,header=None) liste = liste[0].values.tolist() succes = 0 Distrib = [0]*6 nb_moy_tent = 0 count = 0 print(\u0026#34;Patience... Le premier calcul est un peu long\\n\u0026#34;) Res = resultats(liste[:],liste[:])[:] for mot_mystere in liste: essais = 1 conv_motif_nb Resultats = Res[:] motif_obtenu = obtenir_motif(\u0026#39;raise\u0026#39;,mot_mystere) if mot_mystere == \u0026#39;raise\u0026#39;: succes += 1 Distrib[0] += 1 nb_moy_tent += essais print(count,mot_mystere,essais) count += 1 continue while essais \u0026lt;= 6: liste_mots = max(Resultats)[2][conv_motif_nb(motif_obtenu)] Resultats = resultats(liste,liste_mots) motif_obtenu = obtenir_motif(max(Resultats)[1],mot_mystere) essais += 1 if motif_obtenu == \u0026#34;VVVVV\u0026#34;: succes += 1 Distrib[essais-1] += 1 nb_moy_tent += essais print(count,mot_mystere,essais) break if len(liste_mots) == 1: succes += 1 Distrib[essais-1] += 1 nb_moy_tent += essais print(count,mot_mystere,essais) break count += 1 print(f\u0026#34;Nombre de mots testés : {count}\u0026#34;) print(f\u0026#34;Nombre de mots trouvés en 6 tentatives ou moins : {succes}\u0026#34;) Moy = 0 for i in range(6): print(f\u0026#34;Nombre de mots trouvés en {i+1} essais : {Distrib[i]}\u0026#34;) Moy += (i+1)*Distrib[i] Moy /= succes print(f\u0026#34;Le mot a en moyenne été trouvé en {Moy:.2f} essais\u0026#34;) Nombre de mots testés : 2315\nNombre de mots trouvés en 6 tentatives ou moins : 2315\nNombre de mots trouvés en 1 essais : 1\nNombre de mots trouvés en 2 essais : 34\nNombre de mots trouvés en 3 essais : 843\nNombre de mots trouvés en 4 essais : 1290\nNombre de mots trouvés en 5 essais : 144\nNombre de mots trouvés en 6 essais : 3\nLe mot a en moyenne été trouvé en 3.67 essais\nEn utilisant tous les mots autorisés mais sans isoler le sous-ensemble solution (sans \u0026ldquo;triche\u0026rdquo;), les résultats sont moins bons : un mot n\u0026rsquo;est pas découvert (il faut 7 essais pour découvrir FERRY) et la moyenne est au-delà de 4 essais.\nNombre de mots testés : 2315\nNombre de mots trouvés en 6 tentatives ou moins : 2314\nNombre de mots trouvés en 1 essais : 0\nNombre de mots trouvés en 2 essais : 4\nNombre de mots trouvés en 3 essais : 320\nNombre de mots trouvés en 4 essais : 1430\nNombre de mots trouvés en 5 essais : 529\nNombre de mots trouvés en 6 essais : 31\nLe mot a en moyenne été trouvé en 4.11 essais\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/",
	"title": "Semestre 1",
	"tags": [],
	"description": "",
	"content": "Semestre 1 Les séances de travaux pratiques du premier semestre poursuivent les objectifs suivants :\nconsolider l’apprentissage de la programmation en langage Python qui a été entrepris dans les classes du lycée ; mettre en place un environnement de travail ; mettre en place une discipline de programmation : spécification précise des fonctions et programmes, annotations et commentaires, jeux de tests ; introduire les premiers éléments de complexité des algorithmes ; introduire des outils de validation : variants et invariants. Liste des TP : TP0 : tp introductif TP1 : recherche simple, dictionnaire, algos constants et linéaires TP2 : recherche d\u0026rsquo;un mot, d\u0026rsquo;un doublon, algos quadratiques, intégration numérique TP3 : utilisation de modules, fonctions statistiques, domaine de la science des données TP4 : recherche dichotomique, algos logarithmiques, recherche de racine TP5 : récursivité, tris récursifs, algorithme d\u0026rsquo;Euclide, dessiner des fractales TP6 : les algorithmes de tris, comparaisons TP7 : traitement d\u0026rsquo;image, matrices, utilisation de numpy. "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/complexite/",
	"title": "Complexité",
	"tags": [],
	"description": "",
	"content": "Complexité d\u0026rsquo;un algorithme Parmi les 3 questions qu\u0026rsquo;on peut se poser naturellement devant un algorithme (termine-t-il ? est-il correct ? combien de temps met-il ?), on a laissé la dernière en plan dans le chapitre précédent.\nLa question du temps mis par l\u0026rsquo;algorithme est le problème de la complexité de l\u0026rsquo;algorithme.\nL\u0026rsquo;objectif premier d\u0026rsquo;un calcul de complexité algorithmique est de pouvoir comparer l’efficacité d’algorithmes résolvant le même problème. Dans une situation donnée, cela permet donc d\u0026rsquo;établir lequel des algorithmes disponibles est le meilleur (du point de vue temps d\u0026rsquo;exécution).\ncomplexité en temps Réaliser un calcul de complexité en temps revient à décompter le nombre d’opérations élémentaires (affectation, calcul arithmétique ou logique, comparaison…) effectuées par l’algorithme.\nPour rendre ce calcul réalisable, on émettra l\u0026rsquo;hypothèse que toutes les opérations élémentaires sont à égalité de coût. En pratique ce n\u0026rsquo;est pas tout à fait exact, mais cette approximation est cependant raisonnable.\nOn pourra donc estimer que le temps d\u0026rsquo;exécution de l\u0026rsquo;algorithme est proportionnel au nombre d’opérations élémentaires.\nLa complexité $T(n)$ d\u0026rsquo;un algorithme va naturellement être fonction de la taille $n$ des données passées en entrée. Cette dépendance est logique, plus ces données seront volumineuses, plus il faudra d\u0026rsquo;opérations élémentaires pour les traiter.\nSouvent la complexité dépendra aussi de la donnée en elle même et pas seulement de sa taille. En particulier la façon dont sont réparties les différentes valeurs qui la constituent.\nRappelons-nous par exemple l\u0026rsquo;algorithme de recherche séquentielle d’un élément dans une liste non triée du cours \u0026ldquo;structures de données\u0026rdquo;. Le principe de l\u0026rsquo;algorithme est simple, on parcourt un par un les éléments jusqu\u0026rsquo;à trouver, ou pas, celui recherché. Ce parcours peut s’arrêter dès le début si le premier élément est \u0026ldquo;le bon\u0026rdquo;. Mais on peut également être amené à parcourir la liste entière si l’élément cherché est en dernière position, ou même n\u0026rsquo;y figure pas. Le nombre d\u0026rsquo;opérations élémentaires effectuées dépend donc non seulement de la taille de la liste, mais également de la répartition de ses valeurs.\nCette remarque nous conduit à préciser un peu notre définition de la complexité en temps. En toute rigueur, on devra en effet distinguer trois formes de complexité en temps :\nla complexité dans le meilleur des cas : c\u0026rsquo;est la situation la plus favorable, qui correspond par exemple à la recherche d\u0026rsquo;un élément situé à la première postion d\u0026rsquo;une liste, ou encore au tri d\u0026rsquo;une liste déjà triée. la complexité dans le pire des cas : c\u0026rsquo;est la situation la plus défavorable, qui correspond par exemple à la recherche d\u0026rsquo;un élément dans une liste alors qu\u0026rsquo;il n\u0026rsquo;y figure pas, ou encore au tri par ordre croissant d\u0026rsquo;une liste triée par ordre décroissant. la complexité en moyenne : on suppose là que les données sont réparties selon une certaine loi de probabilités. On calcule le plus souvent la complexité dans le pire des cas, car elle apporte une garantie (pas de mauvaises surprises en tablant sur le pire).\nDernière chose importante à prendre en considération, si la donnée est un nombre entier, la façon de le représenter influera beaucoup sur l’appréciation de la complexité.\nPar exemple, si $n=2020$, on peut considérer que la taille de $n$ est :\nsoit la valeur de $n$ en elle-même, façon la plus naturelle de voir les choses, c.-à-d. $2020$,\nsoit le nombre de chiffres que comporte l\u0026rsquo;écriture en binaire de $n$, c.-à-d. 11,\nsoit le nombre de chiffres que comporte l\u0026rsquo;écriture en décimal de $n$, c.-à-d. 4.\nVu la finalité informatique de nos algorithmes, nous devrions choisir le nombre de chiffres dans l\u0026rsquo;écriture binaire de l\u0026rsquo;entier, mais par souci de simplicité, on considèrera le plus souvent la valeur de l\u0026rsquo;entier comme taille.\nNéanmoins, lors de l\u0026rsquo;étude de la complexité des algorithmes arithmétiques (test de primalité, algorithme d\u0026rsquo;Euclide, etc.), la taille de l\u0026rsquo;entier est le paramètre important et il faudra donc considérer la taille de l\u0026rsquo;entrée $n$ comme étant $\\log_2(n)$.\nExemple : la fonction somme\n1def somme(L): 2 s = 0 3 for e in L: 4 s += e 5 return s Le calcul somme([1,2,3]) nécessite à priori 4 opérations (1 fois la ligne 2, et 3 fois la ligne 4). Toutefois, la notion d\u0026rsquo;opération élémentaire n\u0026rsquo;est pas précisément définie : on pourrait considérer par exemple que la ligne 4 fait non pas une, mais deux opérations élémentaires (une somme puis une affectation) et alors somme([1,2,3]) nécessiterait 7 opérations.\nCette imprécision est sans conséquence, car on estime la complexité \u0026ldquo;à la louche\u0026rdquo;. Pour définir formellement ce que signifie ce \u0026ldquo;à la louche\u0026rdquo;, nous introduisons les trois notations suivantes :\nÉtant donné deux fonctions $\\mathbb{N}\\rightarrow \\mathbb{R}^*_+$ $f$ et $g$ : $f(n)$ est un grand $\\mathcal{O}$ de $g(n)$ s\u0026rsquo;il existe une constante $k_2$ telle que pour tout $n$ assez grand $f(n)≤k_2\\cdot g(n)$ ;\non note $f(n) = \\mathcal{O}(g(n))$. Et on dit que $g$ domine $f$ asymptotiquement.\n$f(n)$ est un grand $\\Omega$ de $g(n)$ s\u0026rsquo;il existe une constante $k_1\u0026gt;0$ telle que pour tout $n$ assez grand $k_1\\cdot g(n)≤f(n)$ ;\non note $f(n) = \\Omega(g(n))$.\n$f(n)$ est un grand $\\Theta$ de $g(n)$ s\u0026rsquo;il existe deux constantes $k_1\u0026gt;0$ et $k_2$ telles que pour tout $n$ assez grand $k_1\\cdot g(n)≤f(n)≤k_2\\cdot g(n)$ ;\non note $f(n) = \\Theta(g(n))$.\n$f$ et $g$ sont asymptotiquement du même ordre de grandeur.\nComme on l\u0026rsquo;a dit, notre souhait est de connaître le nombre d\u0026rsquo;étapes que nécessitera l\u0026rsquo;algorithme dans le pire des cas, quitte à le surestimer. On veut par contre absolument éviter de le sous-estimer ; on se concentre alors sur la première notation, grand $O$ (correspondant à la majoration).\nEn effet, si on sait que $T(n)=O(g(n))$, on est alors assuré que le nombre d\u0026rsquo;étapes $T(n)$ ne sera asymptotiquement jamais plus grand que $g(n)$ (asymptotiquement signifiant en pratique \u0026ldquo;pour des $n$ suffisamment grands\u0026rdquo;).\nExemple : $T(n)=5n+3$\nDès $n\u0026gt;3$, $T(n)\u0026lt;6n$, ce qu\u0026rsquo;on réécrit $T(n)\u0026lt;6\\times g(n)$ avec $g(n)=n$, d\u0026rsquo;où\u0026rsquo; $T(n)=O(n)$.\nLes complexités algorithmiques sont exprimées comme des grands $\\mathcal{O}$ ou grands $\\mathcal{\\Theta}$ des fonctions de référence. Cela va nous permettre de les classer.\nDes algorithmes appartenant à une même classe sont alors considérés comme de complexité équivalente ; ils ont la même efficacité.\nLe tableau suivant récapitule les complexités de référence (rangées par ordre croissant) :\n$\\mathcal{O}$ Type de complexité $\\mathcal{O(1)}$ constant $\\mathcal{O}(\\ln(n))$ logarithmique $\\mathcal{O}(n)$ linéaire $\\mathcal{O}(n\\times\\ln(n))$ quasi-linéaire $\\mathcal{O}(n^2)$ quadratique $\\mathcal{O}(n^3)$ cubique $\\mathcal{O}(2^n)$ exponentiel $\\mathcal{O}(n!)$ factoriel Lors de la somme de deux complexités de types différents, la classe de plus grande complexité domine.\nPar exemple : $\\mathcal{O}(n)+\\mathcal{O}(n^2)=\\mathcal{O}(n^2)$.\nSi $T(n)$ est un grand $O$ d\u0026rsquo;une certaine fonction $g$, alors il sera un grand $O$ de toutes les fonctions $h$ qui dominent $g$ (toutes les fonctions appartenant à une classe de complexité supérieure). Laquelle de ces classes désigne la complexité de $T(n)$ ?\nOn choisit toujours la plus petite classe possible pour définir la classe de complexité de $T(n)$, car si on cherche bien à se prémunir contre les mauvaises surprises, cela ne sert à rien de s\u0026rsquo;assurer contre l\u0026rsquo;impossible (cela reviendrait à toujours répondre l\u0026rsquo;infini quand on nous demande une borne supérieure, c\u0026rsquo;est certes vrai mais pas très utile\u0026hellip;).\nMoralité, quand on parle de grand $O$, la plupart du temps, il s\u0026rsquo;agit en fait de grand $Θ$.\nDans l\u0026rsquo;exemple de $5n+3$, on a $T(n) = O(n)$, et par conséquent on a aussi $T(n)=O(n^2)$, $T(n)=O(n^3)$, etc.\nMais attention, quand on nous demande la complexité asymptotique au pire de $T(n)$, la réponse attendue est bien $O(n)$ !\nOrdres de grandeurs : en supposant qu\u0026rsquo;un système donné permette un milliard d\u0026rsquo;opérations par seconde (de type constant), on obtient les valeurs de temps d\u0026rsquo;exécution suivantes en fonction du type de complexité et de la taille des données :\ntaille des données $\\ln n$ $n$ $n\\ln n$ $n^2$ $n^3$ $2^n$ $n!$ $10^2$ $5$ ns $100$ ns $500$ ns $10$ μs $1$ ms $4.10^{13}$ ans $3.10^{141}$ ans $10^3$ $7$ ns $1$ μs $7$ μs $1$ ms $1$ s $10^4$ $9$ ns $10$ μs $90$ μs $100$ ms $17$ min $10^5$ $12$ ns $100$ μs $1,2$ ms $10$ s $12$ jours $10^6$ $14$ ns $1$ ms $14$ ms $17$ min $32$ ans Quelques relations utiles (valables pour toute constante $c$) :\n(1) $\\mathcal{O}(n+c)=\\mathcal{O}(n)$\n(2) $\\mathcal{O}(cn)=\\mathcal{O}(n)$\n(3) $\\mathcal{O}(n/c)=\\mathcal{O}(n)$\n(4) $\\mathcal{O}(c)=1$\n(5) $n\\times\\mathcal{O}(1)=\\mathcal{O}(n)$\nExemples :\nLe calcul de la somme des $n$ premiers entiers à l’aide d’une formule explicite (n*(n+1)//2) est de complexité constante. Ce même calcul réalisé de façon itérative grâce à la fonction somme() est de complexité linéaire. En effet, la taille de l\u0026rsquo;entrée est $n=$ len(L) et la complexité est en : $$T(n)=\\underbrace{\\mathcal{O}(1)}_\\text{ligne 2}+\\underbrace{n\\times \\underbrace{\\mathcal{O}(1)}_\\text{ligne 4}}_{\\text{for}}=\\mathcal{O}(n)$$ L\u0026rsquo;algorithme de recherche par dichotomie (TP4) est de complexité logarithmique puisque l\u0026rsquo;algorithme nécessite au pire $\\log_2 n$ passages dans la boucle et chaque instruction dans la boucle (comparaison, division euclidienne, affectations) se fait en temps constant $$T(n)=\\log_2(n)\\times \\mathcal{O}(1) = \\mathcal{O}(\\ln n)$$ Plus tordu : trouvons la complexité de la fonction neufs() suivante qui calcule naïvement le plus grand nombre de 9 consécutifs dans l\u0026rsquo;écriture en base 10 de $n$.\ndef neufs(n): L = [] while n!= 0: L.append(n%10) n //= 10 M = 0 for k in range(len(L)): i = k while i \u0026lt; len(L) and L[i]==9: i += 1 M = max(M, i - k) return M Chacune des instructions utilisées est en $\\mathcal{O}(1)$ (temps constant). On utilise bien max qui a une complexité linéaire, mais on ne l\u0026rsquo;utilise que sur 2 valeurs.\nOn passe dans le premier while une fois par chiffre de $n$ en base 10 (n//10 fait perdre un chiffre à $n$), soit environ $\\log_{10}(n)$ fois.\nLa liste L contient alors (à moins de 1 près) $\\log_{10}(n)$ valeurs. On passe dans le for $\\log_{10}(n)$ fois, et au pire le même nombre de fois dans le second while.\nLa complexité est donc $T(n)=\\underbrace{\\log_{10}(n) \\times \\mathcal{O}(1)}{\\text{premier while}}+\\underbrace{\\log{10}(n) \\times\\log_{10}(n) \\times\\mathcal{O}(1)}_{\\text{boucles imbriquées}}=\\mathcal{O}(\\ln ^2 n)$\nLa complexité sert essentiellement à comparer les algorithmes.\nOn peut aussi tenter de confirmer expérimentalement nos conclusions en mesurant le temps mis par la machine pour faire tourner l\u0026rsquo;algorithme. Grâce au module time, on va ainsi pouvoir vérifier empiriquement que l\u0026rsquo;algorithme de recherche par dichotomie est bien meilleur que l\u0026rsquo;algorithme de recherche naïf. On va aussi tenter d\u0026rsquo;en savoir plus sur l\u0026rsquo;opérateur natif in qui accomplit la même fonction.\nPour cela, on va mesurer le temps mis par les différentes méthodes pour chercher un nombre au hasard entre $0$ et $b$ dans une liste des $b$ premiers entiers. On moyenne ce temps en faisant $50\\,000$ essais avec des nombres à rechercher différents. Puis on multiplie $b$ par $2$ et on recommence :\nimport random import time b, m = 1, 50000 print(\u0026#39;\\n| n | tps algo naïf | tps algo dicho | tps \u0026#34;in\u0026#34; |\u0026#39;) print(\u0026#39;-\u0026#39;*54) for i in range(12): b *= 2 T = [i for i in range(0,b)] t1 = t2 = t3 = 0 for j in range(m): x = random.randint(0,b) d1 = time.time() #time() note la valeur de l\u0026#39;horloge (en s) recherche_naïve(x,T) f1 = time.time() d2 = time.time() recherche_dicho(x,T) f2 = time.time() d3 = time.time() x in T f3 = time.time() t1 += f1 - d1 #f1-d1 = laps de temps qu\u0026#39;a duré la recherche linéaire t2 += f2 - d2 #f2-d2 = laps de temps qu\u0026#39;a duré la recherche dicho t3 += f3 - d3 #f3-d3 = laps de temps qu\u0026#39;a duré la recherche avec \u0026#34;in\u0026#34; print(\u0026#39;| {:\u0026gt;4d} |{:^15.2E}|{:^16.2E}|{:^12.2E}|\u0026#39;.format(b,t1/m,t2/m,t3/m)) |\u0026nbsp;\u0026nbsp;\u0026nbsp;n\u0026nbsp;\u0026nbsp;|\u0026nbsp;tps algo naïf\u0026nbsp;|\u0026nbsp;tps algo dicho\u0026nbsp;|\u0026nbsp;\u0026nbsp;tps \"in\"\u0026nbsp;\u0026nbsp;|\n------------------------------------------------------\n|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;2\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;3.56E-07\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;6.81E-07\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;1.90E-07\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;4\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;4.04E-07\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;7.87E-07\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;2.12E-07\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;8\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;4.58E-07\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;8.58E-07\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;2.38E-07\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;\u0026nbsp;\u0026nbsp;16\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;5.86E-07\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;9.48E-07\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;2.80E-07\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;\u0026nbsp;\u0026nbsp;32\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;8.11E-07\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1.06E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;3.60E-07\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;\u0026nbsp;\u0026nbsp;64\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;1.30E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1.19E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;5.37E-07\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;\u0026nbsp;128\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;2.25E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1.33E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;8.83E-07\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;\u0026nbsp;256\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;4.18E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1.53E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;1.57E-06\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;\u0026nbsp;512\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;8.09E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;1.87E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;2.96E-06\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;1024\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;1.57E-05\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;2.14E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;5.70E-06\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;2048\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;3.09E-05\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;2.38E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;1.12E-05\u0026nbsp;\u0026nbsp;|\n|\u0026nbsp;4096\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;6.13E-05\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;2.63E-06\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;2.22E-05\u0026nbsp;\u0026nbsp;|\nin est plus rapide que l\u0026rsquo;algo de recherche naïf mais ils réagissent tous deux pareil à un changement d\u0026rsquo;échelle ; si on on multiplie n par 2, les deux algorithmes mettent 2 fois plus de temps. C\u0026rsquo;est ce qui nous montre qu\u0026rsquo;ils ont la même complexité ! Pour la recherche dichotomique en revanche, une multiplication du nombre de valeur par 2 ne se solde pas par un doublement du temps, mais par l\u0026rsquo;ajout d\u0026rsquo;un temps constant seulement. C\u0026rsquo;est typique d\u0026rsquo;une complexité logarithmique. On remarque que\nL\u0026rsquo;opérateur in semble de complexité linéaire. Derrière ces deux petits caractères se cache donc du code loin d\u0026rsquo;être de la complexité constante des opérations de base. Ce n\u0026rsquo;est pas la taille qui compte\u0026hellip;\nComplexité en espace La complexité en espace est quant à elle la taille de la mémoire nécessaire pour stocker les différentes structures de données utilisées lors de l\u0026rsquo;exécution de l\u0026rsquo;algorithme.\nOn considère pour simplifier qu\u0026rsquo;un type de base (un entier, un flottant, un caractère,\u0026hellip;) occupe une place en mémoire constante (complexité en $\\mathcal{O}(1)$).\nExemples : Pour la fonction somme(), on constate que si la liste L contient des entiers ou des flottants, chaque variable intermédiaire (e et s) contient un type de base, donc demande une place en mémoire en $\\mathcal{O}(1)$ et donc la complexité en mémoire au pire est en $\\mathcal{O}(1)$.\nPour la fonction neufs(), la complexité en mémoire vient de la variable L (toutes les autres variables demandent $\\mathcal{O}(1)$ en mémoire). Or cette variable va contenir environ $\\log_{10}(n)$ éléments d’où une complexité en mémoire de $\\mathcal{O}(\\log_{10}(n)) = \\mathcal{O}(\\ln(n))$.\nRetour sur les TP du premier semestre :\nTP 1 : quelle est la complexité des fonctions recherche, recherche_dico, max, maximum et max_2 ? TP 2 : quelle est la complexité de cherche_mot, cherche_duplicata et cherche_duplicata_bis ? TP 4 : quelle est la complexité de recherche_dicho_corr ? Et celle de racine en fonction du nombre de chiffres significatifs ? TP 6 : trier les algorithmes de tri en différentes catégories de complexité. Dans la vidéo suivante, on compare plusieurs algorithmes dont la mission est de trouver un doublon dans une liste. Quel est le meilleur ? Étudions leurs complexités en temps et en espace.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/projets/steganographie/",
	"title": "Stéganographie",
	"tags": [],
	"description": "",
	"content": "Stéganographie Première mission Dévoiler le message caché dans les 2 bits de poids faible de l\u0026rsquo;image fournie (dont l\u0026rsquo;adresse est https://info-tsi-vieljeux.github.io/cryptedimage.png).\nImportons d\u0026rsquo;abord les modules nécessaires :\nfrom PIL import Image import urllib.request # pour récupérer une image sur le web from IPython.display import display # pour afficher dans un notebook import numpy as np Ce petit code suffit pour dévoiler l\u0026rsquo;image cachée dans l\u0026rsquo;image :\ndef decache_image(image): image_decrypt = (image % 2**2) * 2**6 + 2**5 return image_decrypt image % 2**2 récupère les deux bits de poids faibles.\n* 2**6 permet de \u0026ldquo;dilater\u0026rdquo; les 4 valeurs $\\{0,1,2,3\\}\\rightarrow\\{0,64,128,192\\}$ + 2**5 permet de décaller les valeurs pour les centrer entre 0 et 255 $\\rightarrow\\{32,96,160,224\\}$. Pour l\u0026rsquo;afficher (sur un notebook type Colab) :\nfinal = decache_image(cache) affichage = Image.fromarray(comparaison) display(affichage) On peut vérifier que l\u0026rsquo;image obtenue est bien codée sur 2 bits avec le code suivant :\nprint(set(final.flatten())) {32, 224, 96, 160}\nflatten est une méthode de numpy permettant de transformer un tableau multidimensionnel en un tableau unidimensionnel (ici, le tableau image 3D devient donc un tableau 1D de longueur $l\\times L \\times 3$).\nset est une fonction native python permettant de convertir une séquence d\u0026rsquo;objets en une nouvelle structure, l\u0026rsquo;ensemble (en python, c\u0026rsquo;est le typeset). Son grand avantage est d\u0026rsquo;éliminer automatiquement tout doublon !\nDeuxième mission Il faut donc réussir à convertir l\u0026rsquo;image secrète en 6 bits (2 bits pour chaque pixel) et l\u0026rsquo;image servant de cache en 18 bits (6 bits pour chaque pixel) avant d\u0026rsquo;additionner les deux images, faisant en sorte que l\u0026rsquo;image à cacher corresponde aux deux bits de poids faible de l\u0026rsquo;image finale.\ndef cache_image(image1,image2): \u0026#34;\u0026#34;\u0026#34; cache_image(image1 : numpy.ndarray (H1,L1,3),image2 : numpy.ndarray (H2,L2,3)) -\u0026gt; numpy.ndarray (H1,L1,3) cache image2 dans image1 après l\u0026#39;avoir recadrée si besoin \u0026#34;\u0026#34;\u0026#34; H1,L1,_ = image1.shape H2,L2,_ = image2.shape hidden = np.copy(image2)[:H1,:L1,:3] # sans np.copy, le slicing rend image2 mutable hidden = (hidden.astype(np.uint16)//2**6).astype(np.uint8) image1 = image1//2**2 * 2**2 imagemix = image1[:,:,:3] # le :3 sert à retirer une éventuelle transparence, codée comme une 4e couleur h , l = max((H1-H2)//2,0), max((L1-L2)//2,0) imagemix[h:h+H2,l:l+L2] += hidden return imagemix Et pour faciliter l\u0026rsquo;utilisation d\u0026rsquo;url pour chaque image :\ndef cachageimage(): opener=urllib.request.build_opener() opener.addheaders=[(\u0026#39;User-Agent\u0026#39;,\u0026#39;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1941.0 Safari/537.36\u0026#39;)] urllib.request.install_opener(opener) # sans ce bazar, certains sites refusent la visite car le fouineur se présente pas comme un browser url1 = input(\u0026#34;url de l\u0026#39;image à afficher : \u0026#34;) urllib.request.urlretrieve(url1, \u0026#39;1\u0026#39;) url2 = input(\u0026#34;url de l\u0026#39;image à cacher : \u0026#34;) urllib.request.urlretrieve(url2, \u0026#39;2\u0026#39;) image1 = np.array(Image.open(\u0026#39;1\u0026#39;)) image2 = np.array(Image.open(\u0026#39;2\u0026#39;)) return cache_image(image1,image2) On obtient finalement : Et en \u0026ldquo;décachant\u0026rdquo; (pour vérifier) : "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp3data/",
	"title": "TP 3 : utilisation de modules",
	"tags": [],
	"description": "",
	"content": " L\u0026rsquo;idée de ce TP est de constater combien des modules/bibliothèques adaptés peuvent fournir des outils puissants et permettre un gain de temps gigantesque.\nOn va se placer dans un des champs les plus porteurs actuellement (et où python est très utilisé), l\u0026rsquo;analyse de données.\nCliquez sur cette invitation pour récupérer le repository du TP. Exploration d\u0026rsquo;un jeu de données Statistiques simples import pandas as pd # bibliothèques dédiée au traitement de jeux de données import matplotlib.pyplot as plt # bibliothèque graphique import seaborn as sns # bibliothèque graphique reposant sur matplotlib et dédiée plus particulièrement à la représentation de jeux de données import numpy as np # bibliothèque puissante permettant de gérer des tableaux multidimensionnels import plotly.express as px # libraire permettant des graphes interactifs import plotly.graph_objects as go # complémentaire à la première (seulement utile dans les cas complexes) Pour pouvoir être importé, un module doit avoir été préalablement installé. Les plus importants sont installés par défaut dans certaines distributions (comme Anaconda).\nLes gros modules sont généralement importés sous la forme import module as x où x est un raccourci pour le nom du module (np pour numpy ou plt pour matplotlib.pyplot). Se référer au cours Python pour les autres formes d\u0026rsquo;importation.\nPour obtenir de l\u0026rsquo;aide sur un module, on peut demander à Python (help(pd) par exemple pour avoir de l\u0026rsquo;aide sur pandas ou help(pd.read_csv) pour avoir de l\u0026rsquo;aide sur la fonction spécifique read_csv), mais il y a généralement beaucoup moins indigeste : l\u0026rsquo;aide en ligne des modules (pour Pandas par exemple).\n# paramètres par défaut pour les graphes plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 6) plt.rcParams[\u0026#39;font.family\u0026#39;] = \u0026#34;serif\u0026#34; plt.rcParams[\u0026#39;font.size\u0026#39;] = 13 sns.set_style(\u0026#34;white\u0026#34;) Le premier jeu de données qu\u0026rsquo;on va utiliser est issu du World Happiness report (une publication annuelle de l\u0026rsquo;ONU mesurant le degrés de bonheur de la population mondiale par pays à partir de sondages).\nurl = \u0026#34;https://raw.githubusercontent.com/Info-TSI-Vieljeux/s1-tp3/main/2020.csv\u0026#34; data_monde = pd.read_csv(url,sep=\u0026#34;;\u0026#34;,index_col=0) # data_monde est une dataframe Pandas # Une dataframe est une sorte de dictionnaire dont les clés sont les en-têtes des colonnes et dont les lignes sont indexées. data_monde Région du monde Score de bonheur Écart-type PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Score de bonheur en Distopie Pays Finland Western Europe 7.8087 0.031156 10.639267 0.954330 71.900825 0.949172 -0.059482 0.195445 1.972317 Denmark Western Europe 7.6456 0.033492 10.774001 0.955991 72.402504 0.951444 0.066202 0.168489 1.972317 Switzerland Western Europe 7.5599 0.035014 10.979933 0.942847 74.102448 0.921337 0.105911 0.303728 1.972317 Iceland Western Europe 7.5045 0.059616 10.772559 0.974670 73.000000 0.948892 0.246944 0.711710 1.972317 Norway Western Europe 7.4880 0.034837 11.087804 0.952487 73.200783 0.955750 0.134533 0.263218 1.972317 ... ... ... ... ... ... ... ... ... ... ... Central African Republic Sub-Saharan Africa 3.4759 0.115183 6.625160 0.319460 45.200001 0.640881 0.082410 0.891807 1.972317 Rwanda Sub-Saharan Africa 3.3123 0.052425 7.600104 0.540835 61.098846 0.900589 0.055484 0.183541 1.972317 Zimbabwe Sub-Saharan Africa 3.2992 0.058674 7.865712 0.763093 55.617260 0.711458 -0.072064 0.810237 1.972317 South Sudan Sub-Saharan Africa 2.8166 0.107610 7.425360 0.553707 51.000000 0.451314 0.016519 0.763417 1.972317 Afghanistan South Asia 2.5669 0.031311 7.462861 0.470367 52.590000 0.396573 -0.096429 0.933687 1.972317 153 rows × 10 columns\nPrécisions sur ces données :\nle score de bonheur est un score sur 10 correspondant à la moyenne des réponses des sondés (0 correspond à la pire vie possible et 10 à la meilleure) ce n\u0026rsquo;est pas le PIB par habitant mais son logarithme qui est utilisé pour ne pas avoir des valeurs sur des ordres de grandeur trop différents d\u0026rsquo;une colonne à l\u0026rsquo;autre entraide sociale : moyenne des réponses à la question binaire \u0026ldquo;en cas de difficultés, pouvez-vous compter sur de la famille ou des amis pour vous aider ?\u0026rdquo; (0 : non, 1 : oui) liberté des choix de vie : moyenne des réponses à la question binaire \u0026ldquo;êtes-vous satisfait ou non de votre liberté à choisir ce que vous voulez faire de votre vie ?\u0026rdquo; (0 : non, 1 : oui) générosité : moyenne des réponses à \u0026ldquo;Avez-vous donné à une association caritative le mois dernier ?\u0026rdquo; ajustée par rapport au PIB par habitant (valeur résiduelle) corruption perçue : moyenne des réponses à la question binaire \u0026ldquo;la corruption est-elle répandue dans le gouvernement ?\u0026rdquo; (0 : non, 1 : oui) On simplifie un peu le jeu de données en retirant la colonne \u0026lsquo;Écart-type\u0026rsquo; et \u0026lsquo;Score de bonheur en distopie\u0026rsquo; (score minimal obtenu).\ndata_monde.drop(columns=[\u0026#39;Écart-type\u0026#39;,\u0026#39;Score de bonheur en Distopie\u0026#39;], inplace=True) data_monde.head(3) Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Pays Finland Western Europe 7.8087 10.639267 0.954330 71.900825 0.949172 -0.059482 0.195445 Denmark Western Europe 7.6456 10.774001 0.955991 72.402504 0.951444 0.066202 0.168489 Switzerland Western Europe 7.5599 10.979933 0.942847 74.102448 0.921337 0.105911 0.303728 data_monde.tail(3) Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Pays Zimbabwe Sub-Saharan Africa 3.2992 7.865712 0.763093 55.61726 0.711458 -0.072064 0.810237 South Sudan Sub-Saharan Africa 2.8166 7.425360 0.553707 51.00000 0.451314 0.016519 0.763417 Afghanistan South Asia 2.5669 7.462861 0.470367 52.59000 0.396573 -0.096429 0.933687 Traçons un histogramme brut du jeu de données complet pour y voir plus clair (la librairie Seaborn rend cela très simple).\nsns.histplot(data=data_monde) La méthode describe s\u0026rsquo;appliquant à des dataframe pandas retourne un résumé statistique très pratique des données de chaque colonne :\ndata_monde.describe() Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue count 153.00000 153.000000 153.000000 153.000000 153.000000 153.000000 153.000000 mean 5.47324 9.295706 0.808721 64.445529 0.783360 -0.014568 0.733120 std 1.11227 1.201588 0.121453 7.057848 0.117786 0.151809 0.175172 min 2.56690 6.492642 0.319460 45.200001 0.396573 -0.300907 0.109784 25% 4.72410 8.350645 0.737217 58.961712 0.714839 -0.127015 0.683019 50% 5.51500 9.456313 0.829204 66.305145 0.799805 -0.033665 0.783122 75% 6.22850 10.265124 0.906747 69.289192 0.877709 0.085429 0.849151 max 7.80870 11.450681 0.974670 76.804581 0.974998 0.560664 0.935585 Pour confirmer certaines des valeurs, vous allez construire différentes fonctions :\nune fonction decompte qui retourne le nombre d\u0026rsquo;éléments d\u0026rsquo;une liste, une fonction moyenne qui retourne la moyenne des éléments d\u0026rsquo;une liste, une fonction mediane qui retourne la médiane des éléments d\u0026rsquo;une liste triée en ordre croissant. L\u0026rsquo;utilisation de fonctions statistiques déjà existantes est bien sûr prohibée.\ndef decompte(L): \u0026#34;\u0026#34;\u0026#34; decompte(L: liste) -\u0026gt; entier \u0026#34;\u0026#34;\u0026#34; # CODE def moyenne(L): \u0026#34;\u0026#34;\u0026#34; decompte(L: liste) -\u0026gt; flottant \u0026#34;\u0026#34;\u0026#34; # CODE def mediane(L): \u0026#34;\u0026#34;\u0026#34; decompte(L: liste) -\u0026gt; floattant ou entier (suivant les valeurs de L) \u0026#34;\u0026#34;\u0026#34; # CODE Correction (cliquer pour afficher) def decompte(L): return len(L) def moyenne(L): s = 0 for e in L: s += e return s/len(L) def mediane(L): N = decompte(L) return L[N//2] Calculez, pour les 3 formes d\u0026rsquo;importation du module, l\u0026rsquo;écart-type des éléments de la liste Liste_scores en utilisant la fonction stdev du module statistics.\nIl s\u0026rsquo;agit d\u0026rsquo;évaluer directement l\u0026rsquo;expresion (le nombre doit s\u0026rsquo;afficher sous la cellule sans utiliser de print).\nimport statistics # CODE from statistics import * # CODE import statistics as st # CODE Correction (cliquer pour afficher) import statistics statistics.stdev(Liste_scores) from statistics import * # Rq : on évite le plus souvent ce type d'importation qui peut générer des conflits de définition. stdev(Liste_scores) import statistics as st # C'est la forme la plus pratique si le module est souvent utilisé st.stdev(Liste_scores) Tracons maintenant un diagramme en batons des scores de bonheur des 60 premiers pays.\nfig,ax = plt.subplots(figsize=(20,4)) sns.barplot(ax = ax,x = data_monde.index[:60], y = data_monde[\u0026#39;Score de bonheur\u0026#39;].head(60)) plt.xticks(rotation=90) ax.set_xlabel(\u0026#39;\u0026#39;) On remarque que les pays sont classés par score de bonheur décroissant dans le jeu de données d\u0026rsquo;origine.\nMais on peut évidemment choisir un autre critère de classement si on le désire :\ndata_monde.sort_values(by=\u0026#34;PIB par habitant (log)\u0026#34;,ascending=True).head(10) Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Pays Burundi Sub-Saharan Africa 3.7753 6.492642 0.490326 53.400002 0.626350 -0.017552 0.606935 Central African Republic Sub-Saharan Africa 3.4759 6.625160 0.319460 45.200001 0.640881 0.082410 0.891807 Congo (Kinshasa) Sub-Saharan Africa 4.3110 6.694256 0.672159 52.900002 0.700794 0.083638 0.809404 Niger Sub-Saharan Africa 4.9096 6.842167 0.617435 53.500095 0.759772 0.013861 0.722530 Liberia Sub-Saharan Africa 4.5579 7.054380 0.709281 56.096313 0.735269 0.042273 0.856376 Malawi Sub-Saharan Africa 3.5380 7.062226 0.544007 57.592888 0.803223 0.021433 0.731701 Mozambique Sub-Saharan Africa 4.6236 7.069346 0.723874 54.205822 0.864452 0.032376 0.683019 Sierra Leone Sub-Saharan Africa 3.9264 7.268803 0.636142 50.865143 0.715315 0.088661 0.861331 Madagascar Sub-Saharan Africa 4.1656 7.281686 0.668196 59.105427 0.557574 -0.011824 0.817486 Gambia Sub-Saharan Africa 4.7506 7.321815 0.693169 55.012016 0.733163 0.343199 0.690718 data_monde.sort_values(by=\u0026#34;Corruption perçue\u0026#34;,ascending=False).head() Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Pays Bulgaria Central and Eastern Europe 5.1015 9.869319 0.937840 66.803978 0.745178 -0.143908 0.935585 Romania Central and Eastern Europe 6.1237 10.107584 0.825162 67.207237 0.842823 -0.197815 0.934300 Bosnia and Herzegovina Central and Eastern Europe 5.6741 9.455817 0.829204 67.808136 0.651353 0.098275 0.933769 Afghanistan South Asia 2.5669 7.462861 0.470367 52.590000 0.396573 -0.096429 0.933687 Kosovo Central and Eastern Europe 6.3252 9.204430 0.820727 63.885555 0.861536 0.190934 0.922328 data_monde.sort_values(by=\u0026#34;Générosité\u0026#34;,ascending=False).iloc[[45]] Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Pays Denmark Western Europe 7.6456 10.774001 0.955991 72.402504 0.951444 0.066202 0.168489 D\u0026rsquo;après la cellule précédente, le 46e (le 1er est à l\u0026rsquo;indice 0) meilleur score de générosité appartient au Danemark.\nQuel pays correspond à la 59e plus courte espérance de vie en bonne santé ?\nCorrection (cliquer pour afficher) On obtient son nom grâce à l'expression suivante\u0026nbsp;:\ndata_monde.sort_values(by=\"Espérance de vie en bonne santé\",ascending=True).iloc[[58]]\nIl s'agit de 'Russia'. On peut aussi aisément filtrer le jeu de données en fonction de n\u0026rsquo;importe quel critère :\ndata_monde[(data_monde[\u0026#34;Espérance de vie en bonne santé\u0026#34;]\u0026gt;60) \u0026amp; (data_monde[\u0026#34;Espérance de vie en bonne santé\u0026#34;]\u0026lt;61)] # Rq : pandas nécessite les opérateurs logiques bit à bit \u0026#39;\u0026amp;\u0026#39; (et) et \u0026#39;|\u0026#39; (ou) # plutôt que les opérateurs élément par élément \u0026#39;and\u0026#39; et \u0026#39;or\u0026#39; qui lèveraient une erreur. Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Pays Kenya Sub-Saharan Africa 4.5830 8.029776 0.702652 60.096931 0.829748 0.294682 0.831499 India South Asia 3.5733 8.849824 0.592201 60.215187 0.881445 0.057552 0.772043 Quel pays possède un score de bonheur inférieur à 5 malgré une valeur de corruption perçue inférieure à 0.5 ?\nCorrection (cliquer pour afficher) On obtient son nom grâce à l'expression suivante\u0026nbsp;:\ndata_monde[(data_monde[\"Score de bonheur\"]\u003c5) \u0026 (data_monde[\"Corruption perçue\"]\u003c0.5)]\nIl s'agit de 'Rwanda'. Pour récupérer l\u0026rsquo;ensemble des données d\u0026rsquo;un pays en particulier, on utilise :\ndata_monde.loc[\u0026#39;France\u0026#39;] Région du monde Western Europe Score de bonheur 6.6638 PIB par habitant (log) 10.584223 Entraide sociale 0.937104 Espérance de vie en bonne santé 73.801933 Liberté des choix de vie 0.825468 Générosité -0.130642 Corruption perçue 0.583521 Name: France, dtype: object Pour chaque variable mesurée (chaque colonne), on peut facilement tracer des histogrammes illustrant la répartition des valeurs.\nsns.displot(data_monde, x=\u0026#34;Score de bonheur\u0026#34;, bins=20, kde=True, height=4, aspect=3) # bins contrôle le nombre de classes On peut faciliter la lecture des graphes en les rendant interactif.\nOn utilise pour cela la bibliothèque Plotly express qui sait (comme seaborn) parler à une dataframe pandas.\nOn peut zoomer sur ces graphiques interactifs et obtenir des informations en survolant avec le curseur.\npx.histogram(data_monde,\u0026#39;Corruption perçue\u0026#39;,nbins=40,title=\u0026#34;Corruption perçue\u0026#34;) # Cette fois-ci, le nombre de classes est désigné par nbins. Modifez le graphe précedent pour répondre à cette question : combien la classe la plus peuplée de l\u0026rsquo;histogramme de l\u0026rsquo;espérence de vie en bonne santé compte-elle de valeurs si l\u0026rsquo;histogramme comporte 30 classes ?\nCorrection (cliquer pour afficher) On écrit maintenant\u0026nbsp;:\npx.histogram(data_monde,'Espérance de vie en bonne santé',nbins=30)\nEt on n'a plus qu'à survoler la classe la plus peuplée pour découvrir le nombre de valeurs qu'elle contient\u0026nbsp;: 29. Regroupement des données On remarque que le jeu de données contient une colonne catégorielle : \u0026ldquo;Région du monde\u0026rdquo;.\nCela va nous permettre d\u0026rsquo;explorer de possibles dynamiques régionales : est-ce que les pays d\u0026rsquo;une même zone ont des indicateurs semblables ?\npd.unique(data_monde[\u0026#34;Région du monde\u0026#34;]) # permet d\u0026#39;afficher une seule fois chacune des valeurs différentes de la colonne array(['Western Europe', 'North America and ANZ','Middle East and North Africa', 'Latin America and Caribbean','Central and Eastern Europe', 'East Asia', 'Southeast Asia','Commonwealth of Independent States', 'Sub-Saharan Africa','South Asia'], dtype=object)\nTraçons des diagrammes en boîte à moustaches représentant les scores de bonheur pour chacune des régions.\nConstruction des boîtes à moustaches (ou diagrammes en boîtes de Tukey) :\nLes frontières de la boites sont formées des premier Q1 et troisième quartile Q3 et la barre dans la boite correspond à la médiane (50% des valeurs sont donc dans la boîte).\nPour les moustaches, on calcule d\u0026rsquo;abord 1,5 fois la distance interquartile entre le premier et le troisième quartile (la longueur de la boîte) : L=1,5×(Q3-Q1). Si les valeurs ne s\u0026rsquo;étendent pas au-delà de Q1-L et Q3+L, on trace les moustaches aux valeurs min et max. Sinon, on trace les moustaches au niveau des valeurs précédant immédiatement la limite. Les valeurs au-delà sont représentées par des points et sont le plus souvent considérées comme des anomalies.\nÀ nouveau Seaborn rend cela très simple\u0026hellip;\nsns.set_style(\u0026#34;white\u0026#34;) fig, ax = plt.subplots(figsize=(12,8)) sns.boxplot(ax = ax, x=\u0026#34;Score de bonheur\u0026#34;, y=\u0026#34;Région du monde\u0026#34;, palette=\u0026#34;husl\u0026#34;, data=data_monde) sns.despine(offset=10, trim=True) ax.set_ylabel(\u0026#39;\u0026#39;) Traçons maintenant un graphe plus général représentant toutes les relations possibles entre deux axes du jeu de données pour voir si certaines combinaisons discriminent plus nettement les différentes régions.\n# Un peu long à s\u0026#39;exécuter (environ 30 s) g = sns.pairplot(data_monde, hue=\u0026#34;Région du monde\u0026#34;, corner=True) g._legend.set_bbox_to_anchor((0.6, 0.8)) On constate que les groupes régionaux sont relativement homogènes pour la plupart des critères.\nZoomons sur un de ces graphes :\nsns.set_style(\u0026#34;whitegrid\u0026#34;) sns.jointplot(data=data_monde,x=\u0026#34;PIB par habitant (log)\u0026#34;, y=\u0026#34;Score de bonheur\u0026#34;, hue=\u0026#34;Région du monde\u0026#34;, kind=\u0026#39;scatter\u0026#39;, height=8, legend=False) Une version interactive du même graphique permet de consulter les informations pour chaque point :\npx.scatter(data_monde,x=\u0026#39;PIB par habitant (log)\u0026#39;, y=\u0026#39;Score de bonheur\u0026#39;, hover_name=data_monde.index, color=\u0026#39;Région du monde\u0026#39;) Trouvez la région du monde représentée sur le graphe suivant (le graphe interactif permet de trouver la réponse facilement). Correction (cliquer pour afficher) Il s'agit de 'Latin America and Caribbean'. Allons maintenant au-delà de la proximité géographique pour regrouper les pays en 3 grands blocs socioéconomiques : \u0026ldquo;Nord\u0026rdquo;, \u0026ldquo;Sud\u0026rdquo;, \u0026ldquo;Intermédiaire\u0026rdquo;.\nconditions = [(data_monde[\u0026#39;Région du monde\u0026#39;] == \u0026#39;Western Europe\u0026#39;) | (data_monde[\u0026#39;Région du monde\u0026#39;] == \u0026#39;North America and ANZ\u0026#39;),(data_monde[\u0026#39;Région du monde\u0026#39;] == \u0026#39;South Asia\u0026#39;) | (data_monde[\u0026#39;Région du monde\u0026#39;] == \u0026#39;Sub-Saharan Africa\u0026#39;)] choix = [\u0026#39;\u0026#34;Nord\u0026#34;\u0026#39;, \u0026#39;\u0026#34;Sud\u0026#34;\u0026#39;] data_monde[\u0026#39;Groupe\u0026#39;] = np.select(conditions, choix, default=\u0026#39;Autres\u0026#39;) deux_gpes = data_monde[data_monde[\u0026#34;Groupe\u0026#34;].isin([\u0026#39;\u0026#34;Nord\u0026#34;\u0026#39;,\u0026#39;\u0026#34;Sud\u0026#34;\u0026#39;])] # Un peu long à s\u0026#39;exécuter (environ 30 s) sns.set_style(\u0026#34;white\u0026#34;) g = sns.PairGrid(data_monde, diag_sharey=False, hue=\u0026#34;Groupe\u0026#34;) g.map_upper(sns.scatterplot) g.map_lower(sns.kdeplot,common_norm=False) g.map_diag(sns.histplot,bins=20,kde=True) g.add_legend(title=\u0026#34;Grands groupes\u0026#34;,adjust_subtitles=True) L\u0026rsquo;homogénéité de ces 3 groupes saute aux yeux.\nCorrélations Les graphiques précédents mettent en évidence des corrélations assez fortes entre certaines grandeurs.\nCreusons un peu.\ng = sns.PairGrid(data_monde, y_vars=[\u0026#34;Score de bonheur\u0026#34;], x_vars=[\u0026#34;PIB par habitant (log)\u0026#34;, \u0026#34;Corruption perçue\u0026#34;], height=7, aspect=1.5) g.map(sns.regplot) On constate sur cet exemple que le score de bonheur est corrélé positivement avec le PIB par habitant et négativement avec le degré de corruption perçue.\nPour avoir un panorama complet, traçons la matrice de corrélation donnant, pour chaque couple de variable, la valeur du coefficient de corrélation $r$ (valeur entre -1 et 1 traduisant le degré de dépendance linéaire entre deux variables) :\nfig, ax = plt.subplots(figsize=(12,10)) cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True).reversed() # choix de la palette de couleurs sns.heatmap(data_monde.iloc[:,1:].corr(), cmap=cmap, center=0, annot=True, fmt=\u0026#34;.2f\u0026#34;, linewidth = 0.5, ax=ax) Citez les deux variables les moins corrélées entre elles (donner les noms exacts tels qu\u0026rsquo;ils apparaissent dans les données, attention à la casse). L\u0026rsquo;ordre des variables n\u0026rsquo;est pas important.\nCorrection (cliquer pour afficher) Voilà le test utiliser pour vérifier la réponse\u0026nbsp;: assert variable1 == \"Générosité\" or variable1 == \"Entraide sociale\" if variable1 == \"Générosité\": assert variable2 == \"Entraide sociale\" else: assert variable2 == \"Générosité\" Fin du TP3a\nUn chouïa d\u0026rsquo;apprentissage automatique\n(machine learning) On a vu qu\u0026rsquo;un regroupement des données en 3 grands groupes \u0026ldquo;Nord\u0026rdquo;, \u0026ldquo;Sud\u0026rdquo; et \u0026ldquo;Intermédiaire\u0026rdquo; semble plutôt cohérent.\nMais pourquoi pas laisser un algorithme décider lui-même de qui va le mieux ensemble ? Ensuite nous pourrons vérifier si cela recoupe notre découpage fait à la main.\nOn appelle cela un apprentissage non supervisé.\nNous allons utiliser l\u0026rsquo;algorithme des k-moyennes pour partitionner automatiquement nos données.\nIl consiste à placer chaque point de données dans un espace à $n$ dimensions où $n$ est le nombre de variables (les descripteurs) et chercher à les regrouper en clusters en fonction de leurs distances.\nChaque variable correspondant à un axe du repère.\nPour aider l\u0026rsquo;algorithme, on peut tenter de réduire la dimension de l\u0026rsquo;espace dans lequel chaque point de données est plongé en utilisant une analyse en composantes principales.\nL\u0026rsquo;idée est de déterminer les combinaisons des différentes variables expliquant le mieux la variance des données. Chaque nouvel axe ainsi formé (les composantes principales) explique une part décroissante mais complémentaire de la variance (sur la deuxième composante, les données sont moins étalées que sur la première, mais elles s\u0026rsquo;étalent dans une direction orthogonale, et ainsi de suite).\nProjeter les données sur les premières composantes permet de les étaler le plus possible. On peut ainsi réduire l\u0026rsquo;espace à n dimensions du départ à un espace de seulement 2 ou 3 dimensions expliquant la majorité de la variance des données.\nCommentaire (cliquer pour afficher)\u0026nbsp; Une vidéo pour ceux qui voudraient en savoir plus sur ce sujet. L\u0026rsquo;animation suivante montre comment serait sélectionné l\u0026rsquo;axe de la composante principale dans un espace à deux dimensions : il correspond à la position de la droite pour laquelle la distance cumulée de tous les points à la droite est la plus grande.\nLa bibliothèque Scikit-learn, destinée à l\u0026rsquo;apprentissage automatique, contient tout ce qu\u0026rsquo;il nous faut :\nfrom sklearn.decomposition import PCA # l\u0026#39;algorithme d\u0026#39;analyse en composantes principales (PCA en anglais) from sklearn.preprocessing import StandardScaler # pour centrer-réduire les données from sklearn.cluster import KMeans # l\u0026#39;algorithme des k-moyennes variables = data_monde.columns.values[1:-1] scaler = StandardScaler() X = scaler.fit_transform(data_monde[variables]) # chaque vecteur correspondant à chacune des variables est maintenant centré-réduit pca = PCA() components = pca.fit_transform(X) Quelle combinaison des variables de départ utilise la première composante ? Les quelqus lignes suivantes permettent de le déterminer.\ndata = data_monde.copy() # pour pouvoir revenir sur le graphe suivant même après ajout de colonnes à data_monde n_c = 1 # numéro de la composante principale à décrire px.bar(components.T, x=data.columns.values[1:-1], y=n_c-1, labels={f\u0026#34;{n_c-1}\u0026#34;: f\u0026#34;Composante Principale (CP) {n_c}\u0026#34;}) Quelle est le nom de la variable participant le plus à la composante principale n°34 ?\nCorrection (cliquer pour afficher) La 'Générosité'. Représentons le pourcentage de variance expliquée par chacune des composantes :\nexp_var_cumul = np.cumsum(pca.explained_variance_ratio_) fig = px.bar(x=range(1, exp_var_cumul.shape[0] + 1),y=pca.explained_variance_ratio_,labels={\u0026#34;x\u0026#34;: \u0026#34;composante\u0026#34;, \u0026#34;y\u0026#34;: \u0026#34;% variance expliquée\u0026#34;}) fig.add_scatter(x=list(range(1, exp_var_cumul.shape[0] + 1)), y=exp_var_cumul, name=\u0026#34;\u0026#34;, showlegend=False) Les trois premières composantes expliquent plus de 80% de la variance !\nPlaçons les données dans un espace réduit à ces 3 dimensions :\npx.scatter_3d(components, x=0, y=1, z=2, color=data_monde[\u0026#39;Groupe\u0026#39;], labels={\u0026#39;0\u0026#39;: \u0026#39;CP 1\u0026#39;, \u0026#39;1\u0026#39;: \u0026#39;CP 2\u0026#39;, \u0026#39;2\u0026#39;: \u0026#39;CP 3\u0026#39;}, hover_name=data_monde.index) On constate à nouveau que nos 3 groupes discriminent plutôt très bien nos données même si quelques chevauchements existent.\nC\u0026rsquo;est le moment d\u0026rsquo;utiliser l\u0026rsquo;algorithme des k-moyennes pour essayer de former 3 groupes homogènes :\n# on ne garde que les 3 premières composantes principales pca = PCA(n_components = 3) pca.fit(X) score_pca = pca.transform(X) kmeans_pca = KMeans(n_clusters=3,init=\u0026#39;k-means++\u0026#39;,random_state=42) kmeans_pca.fit(score_pca) data_monde[\u0026#34;Cluster\u0026#34;]=kmeans_pca.labels_.astype(str) data_monde.head(3) Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Groupe Cluster Pays Finland Western Europe 7.8087 10.639267 0.954330 71.900825 0.949172 -0.059482 0.195445 \"Nord\" 2 Denmark Western Europe 7.6456 10.774001 0.955991 72.402504 0.951444 0.066202 0.168489 \"Nord\" 2 Switzerland Western Europe 7.5599 10.979933 0.942847 74.102448 0.921337 0.105911 0.303728 \"Nord\" 2 fig = px.scatter_3d(components, x=0, y=1, z=2, color=data_monde[\u0026#39;Cluster\u0026#39;], labels={\u0026#39;0\u0026#39;: \u0026#39;CP 1\u0026#39;, \u0026#39;1\u0026#39;: \u0026#39;CP 2\u0026#39;, \u0026#39;2\u0026#39;: \u0026#39;CP 3\u0026#39;}, color_discrete_sequence=px.colors.qualitative.Bold, hover_name=data_monde.index) fig.update_layout(legend_title = \u0026#34;Cluster\u0026#34;) Les 3 clusters créés reproduisent à peu de chose près les 3 groupes \u0026ldquo;Nord\u0026rdquo;, \u0026ldquo;Sud\u0026rdquo;, \u0026ldquo;Intermédiaire\u0026rdquo; construits à la main.\nÀ quel cluster correspondent approximativement les pays du groupe \u0026ldquo;Sud\u0026rdquo; ?\nCorrection (cliquer pour afficher) Au cluster \"1\". Mais l\u0026rsquo;accord n\u0026rsquo;est pas parfait !\nCitez un pays qui appartient au groupe \u0026ldquo;Nord\u0026rdquo; mais qui n\u0026rsquo;appartient pas au cluster lui correspondant.\nCorrection (cliquer pour afficher) Un des pays suivant : \"Spain\", \"Italy\", \"Cyprus\", \"North Cyprus\", \"Portugal\", \"Greece\".\nOn remarque qu'il s'agit exclusivement de pays du sud de l'Europe. Nous allons voir dans la prochaine partie du TP comment représenter ces données sur une carte pour y voir plus clair.\nFin du TP3b\nUn peu de géographie Le module suivant va permettre d\u0026rsquo;ajouter à nos données le code à 3 lettres (SO 3166-1 alpha-3) de chaque pays.\nMais pourquoi donc ? plotly express permet de tracer la carte d\u0026rsquo;un pays directement à partir de ce petit code de 3 lettres !\nimport country_converter as coco iso3 = coco.convert(names=data_monde.index, to=\u0026#39;ISO3\u0026#39;, not_found=None) data_monde[\u0026#34;code\u0026#34;] = iso3 data_monde.head() Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Groupe Cluster code Pays Finland Western Europe 7.8087 10.639267 0.954330 71.900825 0.949172 -0.059482 0.195445 \"Nord\" 2 FIN Denmark Western Europe 7.6456 10.774001 0.955991 72.402504 0.951444 0.066202 0.168489 \"Nord\" 2 DNK Switzerland Western Europe 7.5599 10.979933 0.942847 74.102448 0.921337 0.105911 0.303728 \"Nord\" 2 CHE Iceland Western Europe 7.5045 10.772559 0.974670 73.000000 0.948892 0.246944 0.711710 \"Nord\" 2 ISL Norway Western Europe 7.4880 11.087804 0.952487 73.200783 0.955750 0.134533 0.263218 \"Nord\" 2 NOR fig = px.choropleth(data_monde, locations = \u0026#34;code\u0026#34;, color = \u0026#34;Score de bonheur\u0026#34;, projection = \u0026#34;orthographic\u0026#34;, color_continuous_scale = \u0026#34;Spectral_r\u0026#34;, hover_name = data_monde.index, hover_data = {\u0026#34;code\u0026#34; : False}) fig.update_geos( showland = True, landcolor = \u0026#34;LightGrey\u0026#34;, showocean = True, oceancolor = \u0026#34;LightBlue\u0026#34;, showlakes = True, lakecolor = \u0026#34;LightBlue\u0026#34;, showframe = False) fig.update_layout(margin={\u0026#34;r\u0026#34;:0,\u0026#34;t\u0026#34;:0,\u0026#34;l\u0026#34;:0,\u0026#34;b\u0026#34;:0}) fig.show() On est maintenant paré pour représenter les 3 clusters obtenus par l\u0026rsquo;algo des k-moyennes du tp3b.\ndata_monde[\u0026#34;Cluster\u0026#34;] = [f\u0026#39;n°{cluster}\u0026#39; for cluster in data_monde[\u0026#34;Cluster\u0026#34;].astype(\u0026#39;int64\u0026#39;) if cluster != \u0026#39;nan\u0026#39;] data_monde.head(1) Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Groupe Cluster code Pays Finland Western Europe 7.8087 10.639267 0.95433 71.900825 0.949172 -0.059482 0.195445 \"Nord\" n°2 FIN fig = px.choropleth(data_monde, locations = \u0026#34;code\u0026#34;, color = \u0026#34;Cluster\u0026#34;, projection = \u0026#34;natural earth\u0026#34;, color_discrete_sequence = px.colors.qualitative.Set2, hover_name = data_monde.index, hover_data = {\u0026#34;code\u0026#34; : False} ) #fig.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=True) fig.update_layout(margin = {\u0026#34;r\u0026#34;:0,\u0026#34;t\u0026#34;:0,\u0026#34;l\u0026#34;:0,\u0026#34;b\u0026#34;:0}) fig.update_geos(showframe = False) fig.show() Terminons en fabriquant une carte régionale.\nfor reg in pd.unique(data_monde[\u0026#34;Région du monde\u0026#34;]): print(reg) Western Europe\nNorth America and ANZ\nMiddle East and North Africa\nLatin America and Caribbean\nCentral and Eastern Europe\nEast Asia\nSoutheast Asia\nCommonwealth of Independent States\nSub-Saharan Africa\nSouth Asia\nregion = data_monde[data_monde[\u0026#34;Région du monde\u0026#34;] == \u0026#34;Middle East and North Africa\u0026#34;] fig = px.choropleth(region, locations = \u0026#34;code\u0026#34;, color = \u0026#34;Score de bonheur\u0026#34;, projection = \u0026#34;natural earth\u0026#34;, color_continuous_scale = \u0026#34;Temps\u0026#34;, hover_name = region.index, hover_data = {\u0026#34;code\u0026#34; : False} ) fig.update_geos(fitbounds = \u0026#34;locations\u0026#34;, visible = True) fig.update_layout(margin = {\u0026#34;r\u0026#34;:0,\u0026#34;t\u0026#34;:0,\u0026#34;l\u0026#34;:0,\u0026#34;b\u0026#34;:0}) fig.update_geos(showframe = False, resolution = 50) fig.show() Modifiez les cellules qui précèdent pour que le graphique ci-dessus affiche la carte du score de générosité des pays d\u0026rsquo;Asie du sud-est.\nCorrection (cliquer pour afficher) Voilà les lignes modifiées\u0026nbsp;: region = data_monde[data_monde[\"Région du monde\"] == \"Southeast Asia\"] fig = px.choropleth(region, locations=\"code\", color=\"Générosité\", projection=\"natural earth\", color_continuous_scale=\"Temps\", hover_name = region.index, hover_data ={\"code\" : False} ) fig.update_geos(fitbounds=\"locations\", visible=True) fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}) fig.update_geos(showframe = False, resolution=50) fig.show() De quelle couleur est le Vietnam sur cette carte ?\nCorrection (cliquer pour afficher) vert Fin du TP3c\nSérie temporelle Utilisons un nouveau jeu de données comprenant des relevés de consommation électrique allemands entre 2006 et 2018 :\nurl = \u0026#34;http://cordier-phychi.toile-libre.org/Info/github/elec_allemagne.csv\u0026#34; serie_temp = pd.read_csv(url,sep=\u0026#34;,\u0026#34;) serie_temp.drop(columns=\u0026#34;Wind+Solar\u0026#34;,inplace=True) serie_temp Date Consumption Wind Solar 0 2006-01-01 1069.18400 NaN NaN 1 2006-01-02 1380.52100 NaN NaN 2 2006-01-03 1442.53300 NaN NaN 3 2006-01-04 1457.21700 NaN NaN 4 2006-01-05 1477.13100 NaN NaN ... ... ... ... ... 4378 2017-12-27 1263.94091 394.507 16.530 4379 2017-12-28 1299.86398 506.424 14.162 4380 2017-12-29 1295.08753 584.277 29.854 4381 2017-12-30 1215.44897 721.247 7.467 4382 2017-12-31 1107.11488 721.176 19.980 4383 rows × 4 columns\nPetit toilettage des données : on transforme les valeurs de la colonne des dates en un type date reconnu par pandas et on les utilise comme index.\nserie_temp[\u0026#39;Date\u0026#39;] = pd.to_datetime(serie_temp[\u0026#39;Date\u0026#39;]) serie_temp = serie_temp.set_index(\u0026#39;Date\u0026#39;) serie_temp.head() Consumption Wind Solar Date 2006-01-01 1069.184 NaN NaN 2006-01-02 1380.521 NaN NaN 2006-01-03 1442.533 NaN NaN 2006-01-04 1457.217 NaN NaN 2006-01-05 1477.131 NaN NaN On francise ensuite les noms de colonne\u0026hellip;\nserie_temp.columns = [\u0026#34;Consommation\u0026#34;,\u0026#34;Vent\u0026#34;,\u0026#34;Solaire\u0026#34;] serie_temp.head() Consommation Vent Solaire Date 2006-01-01 1069.184 NaN NaN 2006-01-02 1380.521 NaN NaN 2006-01-03 1442.533 NaN NaN 2006-01-04 1457.217 NaN NaN 2006-01-05 1477.131 NaN NaN Et enfin, on ajoute des colonnes \u0026ldquo;jour\u0026rdquo;, \u0026ldquo;mois\u0026rdquo; et \u0026ldquo;année\u0026rdquo;.\nserie_temp[\u0026#39;jour\u0026#39;] = serie_temp.index.day_name() serie_temp[\u0026#39;mois\u0026#39;] = serie_temp.index.month serie_temp[\u0026#39;année\u0026#39;] = serie_temp.index.year serie_temp[\u0026#34;date\u0026#34;] = serie_temp.index serie_temp[\u0026#34;date\u0026#34;] = serie_temp[\u0026#34;date\u0026#34;].dt.date # pour aider Colab qui a des soucis avec les dates serie_temp.head() Consommation Vent Solaire jour mois année date Date 2006-01-01 1069.184 NaN NaN Sunday 1 2006 2006-01-01 2006-01-02 1380.521 NaN NaN Monday 1 2006 2006-01-02 2006-01-03 1442.533 NaN NaN Tuesday 1 2006 2006-01-03 2006-01-04 1457.217 NaN NaN Wednesday 1 2006 2006-01-04 2006-01-05 1477.131 NaN NaN Thursday 1 2006 2006-01-05 px.line(serie_temp[[\u0026#34;Consommation\u0026#34;,\u0026#34;Vent\u0026#34;,\u0026#34;Solaire\u0026#34;]]) On constate d\u0026rsquo;importantes variations saisonnières.\nzoom = serie_temp[serie_temp[\u0026#39;année\u0026#39;]==2016] fig1 = px.line(zoom,\u0026#39;date\u0026#39;,\u0026#39;Consommation\u0026#39;) fig2 = px.scatter(zoom,\u0026#39;date\u0026#39;,\u0026#39;Consommation\u0026#39;,color=\u0026#39;jour\u0026#39;) fig = go.Figure() fig.add_traces([fig1.data[0],*[fig2.data[i] for i in range(7)]]) Une variabilité hebdomadaire se superpose à la tendance saisonnière.\nGrâce à la méthode des dataframe pandas groupby, on peut facilement grouper les donner de manière à obtenir les statistiques qui nous intéressent.\nExemple : trouvons combien d\u0026rsquo;électricité d\u0026rsquo;origine éolienne a été produite chaque mois en 2016.\nserie_temp[serie_temp[\u0026#39;année\u0026#39;]==2016].groupby(\u0026#34;mois\u0026#34;)[\u0026#34;Vent\u0026#34;].sum() mois\n1 9264.588\n2 9814.294\n3 6030.177\n4 5910.504\n5 6089.484\n6 3369.069\n7 4651.582\n8 4742.343\n9 4222.315\n10 5585.248\n11 8076.232\n12 9252.290\nName: Vent, dtype: float64\nSur le modèle précédent, déterminez le jour de la semaine où l\u0026rsquo;Allemagne a consommé le plus d\u0026rsquo;électricité en moyenne en 2016 (vous pourrez utilisez la méthode mean à la place de sum).\nCorrection (cliquer pour afficher) Il suffit d'écrire la ligne suivante\u0026nbsp;:\nserie_temp[serie_temp['année']==2016].groupby(\"jour\")[\"Consommation\"].mean()\nEt on constate alors que le mercredi est le jour où les allemands ont le plus consommé en moyenne en 2016. Commentaire (cliquer pour afficher)\u0026nbsp; On retrouve une philosophie proche des fonctions d'agrégations en SQL. Traçons une boîte à moustaches de la répartition des 3 variables mois par mois :\nfig, axes = plt.subplots(3, 1, figsize=(15, 10), sharex=True) for var, ax in zip([\u0026#39;Consommation\u0026#39;, \u0026#39;Solaire\u0026#39;, \u0026#39;Vent\u0026#39;], axes): sns.boxplot(data=serie_temp, x=\u0026#39;mois\u0026#39;, y=var, ax=ax) ax.set_ylabel(\u0026#39;GWh\u0026#39;) ax.set_title(var) if ax != axes[-1]: ax.set_xlabel(\u0026#39;\u0026#39;) On observe que :\nles trois graphes présentent bien une variabilité saisonnière ; la consommation électrique est plus forte en hiver ainsi que la production éolienne (même si l\u0026rsquo;écart est moins marqué) et la production solaire est beaucoup plus importante en été. beaucoup de valeurs se retrouvent à l\u0026rsquo;extérieur des moustaches supérieures pour la production éolienne, ce qui est probablement dû à des périodes de fort vent. Regardons maintenant jour par jour :\nserie_temp[\u0026#34;date\u0026#34;]=(serie_temp.index.strftime(\u0026#39;%d %B\u0026#39;)) px.box(serie_temp,x=\u0026#39;jour\u0026#39;, y=\u0026#39;Consommation\u0026#39;,hover_data={\u0026#34;date\u0026#34;}) Pourquoi y a-t-il autant de points au-delà des moustaches les jours de semaine ?\nCorrection (cliquer pour afficher) À cause des jours fériés. "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/typesstruct/",
	"title": "Types structurés",
	"tags": [],
	"description": "",
	"content": "Types structurés Les types structurés (chaînes, tuiles, listes, dictionnaires, ensembles) sont des objets composés ; ils contiennent eux-mêmes d\u0026rsquo;autres objets.\nCertains de ces objets composites sont en plus indicés. Comme leur nom l\u0026rsquo;indique, on peut parcourir les éléments présents d\u0026rsquo;une structure indicée à l\u0026rsquo;aide d\u0026rsquo;un indice (un nombre entier étiquetant l\u0026rsquo;indice). Les structures indicés sont donc ordonnées, ce sont des séquences. L\u0026rsquo;indice commence toujours à 0.\nEt donc si la structure contient n éléments, le dernier indice est n-1.\nStructures indicées immuables (chaînes, tuples) Une structure est dite immuable si on ne peut pas modifier les éléments qu\u0026rsquo;elle contient une fois qu\u0026rsquo;elle est construite.\nIl y a deux structures de ce type en Python : les chaînes de caractères (type string) et les tuples (type tuple).\nLes chaînes de caractères sont des séquences de caractères (du texte) définies par des apostrophes ', des guillemets \u0026quot;, des triples apostrophes ''' ou des triples guillemets \u0026quot;\u0026quot;\u0026quot; ('abc', \u0026quot;abc\u0026quot;,'''abc''',\u0026quot;\u0026quot;\u0026quot;abc\u0026quot;\u0026quot;\u0026quot; ).\nLes chaînes de caractères peuvent être constituées de tous les caractères possibles, y compris des emojis 👍. Les guillemets \u0026quot;\u0026quot; permettent d\u0026rsquo;utiliser des apostrophes ' dans la chaîne sans que cela ne la ferme (\u0026quot;C'est bon\u0026quot;).\nLes triples apostrophes ''' ou guillemets \u0026quot;\u0026quot;\u0026quot; permettent d\u0026rsquo;écrire des chaînes sur plusieurs lignes (on utilise de telles chaînes pour les signatures des fonctions).\nL\u0026rsquo;espace est un caractère comme un autre !\nLes tuples sont des ensembles d\u0026rsquo;objets (pas forcément du même type) placés entre parenthèses (pas obligatoires) et séparés par des virgules comme (3.2, 'abc', True). len La fonction native len() permet d\u0026rsquo;obtenir le nombre d\u0026rsquo;éléments présents dans la structure, c\u0026rsquo;est-à-dire sa longueur (len est l\u0026rsquo;\u0026lsquo;abréviation de length).\nlen(\u0026#39;abc\u0026#39;) 3\nlen((3.2, \u0026#39;abc\u0026#39;, True)) 3\nMême si le deuxième élément du tuple du dernier exemple est lui-même composé, len le considère comme un (et un seul) des éléments du tuple.\nDe même, si un tuple contient un autre tuple imbriqué, il ne comptera que pour un seul élément pour len :\nlen((\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,(1,2,3),18)) 4\nAccès par indice d\u0026rsquo;un élément On place l\u0026rsquo;indice de l\u0026rsquo;élément qui nous intéresse entre crochets pour le récupérer :\nS = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39; n = len(S) print(\u0026#39;de\u0026#39;,S[0],\u0026#39;à\u0026#39;,S[n-1]) de a à z\ns[n] provoque l\u0026rsquo;erreur classique IndexError: string index out of range.\nSi $n$ est le nombre d\u0026rsquo;éléments de la structure (donné par len), alors l\u0026rsquo;indice doit être un entier inférieur ou égal à $n-1$.\nSi une structure indicée se trouve enchassée au sein d\u0026rsquo;une autre structure indicée, on peut aussi accéder à ses éléments :\nT = (1,\u0026#39;abcd\u0026#39;,2) len(T[1]) 4\nT[1][3] d\nAutre source d\u0026rsquo;erreur : on ne peut pas modifier la valeur d\u0026rsquo;un élément dans une structure immuable.\nT = (1,2,3) T[2] = 4 TypeError: 'tuple' object does not support item assignment\n\u0026#39;abc\u0026#39;[1] = \u0026#39;d\u0026#39; TypeError: 'str' object does not support item assignment\nConcaténation + L\u0026rsquo;opérateur + permet de concaténer deux structures du même type.\n\u0026#39;abc\u0026#39;+\u0026#39;de\u0026#39; 'abcde'\n(1,\u0026#39;b\u0026#39;,2.2) + (True,1/5) (1, 'b', 2.2, True, 0.2)\nLa longueur de la structure résultante vaut la somme des longueurs des deux tructures concaténées.\nRépétition * L\u0026rsquo;opérateur * permet de répéter une structure.\n\u0026#39;abc\u0026#39;*2 abcabc\nOn peut combiner * et + :\n(\u0026#39;z\u0026#39;*5 + \u0026#39; \u0026#39;)*3 zzzzz zzzzz zzzzz Tranches On peut extraire plusieurs éléments d\u0026rsquo;une structure indicée en une seule fois grâce au découpage en tranches (slicing en anglais). On utilise les crochets comme pour l\u0026rsquo;indexation mais on utilise maintenant 2 ou 3 indices séparés par :. La tranche va du premier indice (inclu) jusqu\u0026rsquo;au deuxième indice (exclu).\nS = \u0026#39;0123456789\u0026#39; S[1:4] '123'\nCette règle d\u0026rsquo;exclusion du deuxième indice permet d\u0026rsquo;avoir une épaisseur de tranche (len(S[i:j])) valant la différence entre les deux indices (j-i).\nSi on omet le premier indice ([:j]), on part du début. Si on omet le second ([i:]), on va jusqu\u0026rsquo;au bout.\nS[:4],S[5:] ('0123', '56789')\nUn troisième indice installe un pas dans la découpe :\nS[::2],S[1::4] ('02468', '159')\nEt si le troisième indice est négatif, il permet de parcourir la séquence en sens inverse :\nS[::-1],S[8:0:-2] ('9876543210', '8642')\nAppartenance in On peut tester l\u0026rsquo;appartenance d\u0026rsquo;un élément ou d\u0026rsquo;une tranche à une structure composée grâce au mot clé in :\n\u0026#39;b\u0026#39; in (5,\u0026#39;a\u0026#39;,12.5) False\n\u0026#39;567\u0026#39; in S True\nListes Une liste (type list) est une collection d\u0026rsquo;objets placés entre crochets et séparés par des virgules.\nExemple : L = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\nComme avec les chaînes de caractères et les tuples :\non accède à un élément via son indice :\nL[3] renvoie 0.3. on obtient le nombre d\u0026rsquo;éléments d\u0026rsquo;une liste grâce à la fonction len :\nlen(L) retourne 9 ; on peut concaténer deux listes avec +:\n[5,6]+[7,8] donne [5,6,7,8] ; on peut extraire par tranche des éléments :\nL[1:6] donne [0.1,0.2,0.3,0.4,0.5] ; on peut tester la présence d\u0026rsquo;un élément grâce au mot clé in :\n0.1 in L renvoie True et 1 in L renvoie False. Mais contrairement aux chaînes de caractères et aux tuples, les listes ne sont pas immuables. On peut donc réaffecter des éléments.\nEn reprenant la liste L précédente, si on écrit L[2] = 'a', L devient [0.0,0.1,'a',0.3,0.4,0.5,0.6,0.7,0.8].\nCréation d\u0026rsquo;une liste par duplication : L\u0026rsquo;opérateur * permet de créer une liste répétant un élément.\nPar exemple, pour créer une liste L de 10 zéros, il suffit d\u0026rsquo;écrire L = [0]*10.\npar append successifs : On initialise une liste vide ([]), puis on la garnit élément par élément grâce à la méthode append.\nExemple :\nL = [] for i in range(10): L.append(i/10) L [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\npar compréhension La construction par compréhension d\u0026rsquo;une liste est une méthode concise et élégante. L\u0026rsquo;idée est d\u0026rsquo;intégrer les boucles et enventuelles conditions dans une seule expression entre crochets pour aboutir à une définition plus directe de la liste.\nExemples :\nL1 = [i/10 for i in range(9)] L2 = [k**2 if (k%2==0) else k**3 for k in range(9)] print(f\u0026#34;{L1 = }\u0026#34;) print(f\u0026#34;{L2 = }\u0026#34;) L1 = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\nL2 = [0, 1, 4, 27, 16, 125, 36, 343, 64]\nCopie d\u0026rsquo;une liste Si on copie une liste en l\u0026rsquo;affectant à un nouveau nom, alors toute modification de l\u0026rsquo;ancienne liste se répercutera sur la nouvelle (et inversement). Les deux noms pointent en réalité vers le même espace mémoire. En effet, lorsqu\u0026rsquo;on affecte une liste à un nom de variable via =, ce n\u0026rsquo;est pas la liste mais sa référence (son adresse mémoire) qui est assignée à la variable. Et donc lorsqu\u0026rsquo;on affecte la liste à une nouvelle variable, c\u0026rsquo;est une copie de la référence et non des valeurs qui est faite.\nL_originelle = [\u0026#39;🍓\u0026#39;, \u0026#39;🍇\u0026#39;, \u0026#39;🍊\u0026#39;] L_copie = L_originelle L_originelle[1] = \u0026#39;?\u0026#39; print(L_originelle,L_copie) ['🍓', '?', '🍊'] ['🍓', '?', '🍊']\nAucune différence !\nSi on veut que la liste copiée conserve ses éléments tels qu\u0026rsquo;ils étaient au moment de la copie, on peut soit utiliser une \u0026ldquo;copie par tranche\u0026rdquo;, en affectant une tranche complète (avec [:]) de la liste, soit utiliser la méthode copy(), soit utiliser la fonction list.\nL_originelle = [\u0026#39;🍓\u0026#39;, \u0026#39;🍇\u0026#39;, \u0026#39;🍊\u0026#39;] L_copie_1 = L_originelle[:] L_copie_2 = L_originelle.copy() L_copie_3 = list(L_originelle) L_originelle[1] = \u0026#39;?\u0026#39; print(L_originelle,L_copie_1,L_copie_2,L_copie_3) ['🍓', '?', '🍊'] ['🍓', '🍇', '🍊'] ['🍓', '🍇', '🍊'] ['🍓', '🍇', '🍊']\n'?' ne se retrouve pas dans les copies !\nMais ces deux copies n\u0026rsquo;en restent pas moins superficielles. En effet, si la liste originelle contient des éléments mutables (comme une autre liste), alors seule l\u0026rsquo;adresse de ceux-ci est copiée, et s\u0026rsquo;ils sont modifiés, la copie aussi le sera :\nL = [\u0026#39;🍋\u0026#39;,\u0026#39;🍑\u0026#39;,[\u0026#39;🍈\u0026#39;,\u0026#39;🍒\u0026#39;],\u0026#39;🍏\u0026#39;] L_copie = L[:] L.append(\u0026#39;🥥\u0026#39;) L[2].append(\u0026#39;🍌\u0026#39;) print(L_copie) ['🍋', '🍑', ['🍈', '🍒', '🍌'], '🍏']\n'🥥' ne se retrouve pas dans la copie, mais 🍌 y est bien\u0026hellip;\nRetirer un élément La méthode pop() permet de retirer le dernier élément d\u0026rsquo;une liste.\nL = [\u0026#39;🥥\u0026#39;, \u0026#39;🍐\u0026#39;, \u0026#39;🍋\u0026#39;, \u0026#39;🍒\u0026#39;] print(f\u0026#34;{L.pop() = }\u0026#34;) print(f\u0026#34;{L = }\u0026#34;) L.pop() = '🍒'\nL = ['🥥', '🍐', '🍋']\nComme on le voit, pop retourne l\u0026rsquo;élément retiré (c\u0026rsquo;est une expression), et une fois que pop a été utilisé, l\u0026rsquo;élément a disparu.\nSi on veut retirer un autre élément que le dernier et qu\u0026rsquo;on connaît son indice i, on peut utiliser pop(i), mais on peut aussi utiliser le slicing (L[i:i+1]=[]) ou encore le mot clé del (del L[i]).\nL1 = [\u0026#39;🥥\u0026#39;, \u0026#39;🍐\u0026#39;, \u0026#39;🍋\u0026#39;, \u0026#39;🍒\u0026#39;] L2 = [\u0026#39;🥥\u0026#39;, \u0026#39;🍐\u0026#39;, \u0026#39;🍋\u0026#39;, \u0026#39;🍒\u0026#39;] L3 = [\u0026#39;🥥\u0026#39;, \u0026#39;🍐\u0026#39;, \u0026#39;🍋\u0026#39;, \u0026#39;🍒\u0026#39;] # Si on veut retirer la poire L1.pop(1) L2[1:2]=[] del L3[1] print(L1) print(L2) print(L3) ['🥥', '🍋', '🍒']\n['🥥', '🍋', '🍒']\n['🥥', '🍋', '🍒']\nEt si plutôt que l\u0026rsquo;indice de l\u0026rsquo;élément à retirer, on veut utiliser sa valeur, on emploie la méthode remove.\nL = [\u0026#39;🥥\u0026#39;, \u0026#39;🍐\u0026#39;, \u0026#39;🍋\u0026#39;, \u0026#39;🍒\u0026#39;] # Si on veut retirer la poire L.remove(\u0026#39;🍐\u0026#39;) print(L) ['🥥', '🍋', '🍒']\nDictionnaires Petite présentation\nUn dictionnaire (type dict) est une collection d\u0026rsquo;objets, comme une liste ou un tuple, mais au lieu d\u0026rsquo;indicer les objets s\u0026rsquo;y trouvant (appelés valeurs) par un nombre, on utilise une clé.\nLes dictionnaires sont l\u0026rsquo;implémentation en Python des tables de hachage.\nUne clé peut être n\u0026rsquo;importe quel objet immuable, mais il s\u0026rsquo;agit le plus souvent d\u0026rsquo;une chaîne de caractères.\nPour créer un dictionnaire, on utilise la syntaxe {clé1 : valeur1, clé2 : valeur2, ...}.\nExemple où les clés sont des prénoms et les valeurs, des notes :\nnote = {\u0026#39;Giselle\u0026#39; : 7.5, \u0026#39;Alphonse\u0026#39; : 12, \u0026#39;Dudule\u0026#39; : 7.5, \u0026#39;Berthe\u0026#39; : 16.5} Chaque valeur peut être récupérée grâce à la clé comme s\u0026rsquo;il s\u0026rsquo;agisait d\u0026rsquo;un indice : note['Dudule'] donne 7.5\nAjouter une clé à un dictionnaire On peut ajouter une entrée au dictionnaire en écrivant simplement dico[nouvelleClé]=valeur.\nnote[\u0026#39;Raoul\u0026#39;] = 14 # ajoute la note de Raoul au dictionnaire note print(note) {'Giselle': 7.5, 'Alphonse': 12, 'Dudule': 7.5, 'Berthe': 16.5, 'Raoul': 14}\nOn peut partir d\u0026rsquo;un dictionnaire vide {} et le construire ainsi étape par étape :\ncoef = {} # dictionnaire vide coef[\u0026#39;maths\u0026#39;] = 9 coef[\u0026#39;physique\u0026#39;] = 10 coef[\u0026#39;philo\u0026#39;] = 9 print(coef) {'maths': 9, 'physique': 10, 'philo': 9}\nComme les listes, les dictionnaires sont des objets mutables.\nnote[\u0026#39;Berthe\u0026#39;] = 18 # modifie la note de Berthe dans le dictionnaire note print(note) {'Giselle': 7.5, 'Alphonse': 12, 'Dudule': 7.5, 'Berthe': 18, 'Raoul': 14}\nChaque clé doit être unique, mais les valeurs peuvent être identiques (comme les notes de Dudule et Giselle).\nTenter d\u0026rsquo;accéder à une clé qui ne figure pas dans le dictionnaire se solde par une erreur.\nprint(note[\u0026#39;Gourmandine\u0026#39;]) # la clé Gourmandine n\u0026#39;existe pas KeyError: 'Gourmandine'\nPour y échapper, on peut tester la présence d\u0026rsquo;une clé grâce à in.\nExemple : à partir d\u0026rsquo;une liste de 12 éléments pris au hasard parmi les entiers de 1 à 10, fabriquons un dictionnaire qui compte les occurrences de chacun des 10 entiers :\nfrom random import randint L = [] for i in range(12): L = L+[randint(1,10)] effectifs = {} for e in L: if not e in effectifs: effectifs[e] = 1 else: effectifs[e] = effectifs[e]+1 print(effectifs) {5: 3, 10: 1, 9: 1, 4: 1, 8: 1, 6: 2, 1: 3}\nSans la condition, effectifs[e]+1 aurait levé une KeyError car le dictionnaire n\u0026rsquo;a initialement aucune entrée et donc effectifs[e] n\u0026rsquo;est pas défini.\nRetirer une clé On peut retirer une clé d\u0026rsquo;un dictionnaire grâce au mot clé del.\ndel note[\u0026#39;Alphonse\u0026#39;] print(note) {'Giselle': 7.5, 'Dudule': 7.5, 'Berthe': 18, 'Raoul': 14}\nSi on utilise del sur une clé inexistante, une erreur KeyError est là encore produite.\nParcourir un dictionnaire Les méthodes keys et values permettents de récupérer les clés et valeurs d\u0026rsquo;un dictionnaire sous forme d\u0026rsquo;itérables, ce qui peut s\u0026rsquo;avérer pratique pour un tracé, par exemple.\nimport matplotlib.pyplot as plt clés = effectifs.keys() valeurs = effectifs.values() plt.bar(clés, valeurs) plt.show() La méthode items regroupe clés et valeurs au sein de tuples (clé,valeur).\nfor clé, valeur in effectifs.items(): print(\u0026#39;nombre de\u0026#39;,clé,\u0026#39;:\u0026#39;,valeur) nombre de 5 : 3\nnombre de 10 : 1\nnombre de 9 : 1\nnombre de 4 : 1\nnombre de 8 : 1\nnombre de 6 : 2\nnombre de 1 : 3\nLes dictionnaires sont des ensemble de paires clé-valeur qui n\u0026rsquo;ont aucun ordre particulier. Les dictionnaires ne sont donc pas des séquences.\nComme pour les listes, une affectation d\u0026rsquo;un dictionnaire existant à une nouvelle variable n\u0026rsquo;en copie que la référence. Toute modification de l\u0026rsquo;un se retrouve dans l\u0026rsquo;autre.\nEt si on veut conserver invariante les valeurs copiées, on peut ici aussi utiliser la méthode copy().\ninfos = {\u0026#39;prénom\u0026#39;: \u0026#39;Russell\u0026#39;, \u0026#39;nom\u0026#39;: \u0026#39;Bell\u0026#39;, \u0026#39;alias\u0026#39;: \u0026#39;Stringer\u0026#39;, \u0026#39;notes\u0026#39;: [13,18,7]} infos_copie = infos.copy() infos[\u0026#39;prénom\u0026#39;] = infos.pop(\u0026#39;alias\u0026#39;) infos[\u0026#39;notes\u0026#39;][:] = [\u0026#39;abs\u0026#39;] print(infos) print(infos_copie) {'prénom': 'Stringer', 'nom': 'Bell', 'notes': ['abs']}\n{'prénom': 'Russell', 'nom': 'Bell', 'alias': 'Stringer', 'notes': ['abs']}\nOn remarque que le remplacement du prénom par l\u0026rsquo;alias et la suppression de l\u0026rsquo;alias n\u0026rsquo;ont pas été répercutés sur la copie, par contre la modification de la liste de notes, objets mutable, oui.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/",
	"title": "Semestre 2",
	"tags": [],
	"description": "",
	"content": "Semestre 2 On consolide certains concepts rencontrés pendant les TP du semestre 1 :\nles bonnes pratiques en programmation la correction et la terminaison d\u0026rsquo;un algorithme (TP8) la complexité (TP8) Puis on développe deux nouveaux chapitres :\nla représentation des nombres (TP9) les graphes (TP10) "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/projets/ieee754/",
	"title": "IEEE-754",
	"tags": [],
	"description": "",
	"content": "IEEE-754 Réaliser un convertisseur permettant de donner l\u0026rsquo;écriture d\u0026rsquo;un flottant sous la forme d\u0026rsquo;un mot binaire de 64 bits suivant la norme IEEE-754 (cf. cours sur le codage des nombres). Réaliser aussi le convertisseur inverse, du mot 64 bits au nombre décimal. Pour vérifier Nombre à convertir en mot machine 64 bits : Conversion\nMot machine 64 bits à convertir en nombre décimal : Conversion\nUne solution possible La fonction suivante convertit la partie fractionnaire du nombre n en binaire et donne ainsi son développement binaire (équivalent d\u0026rsquo;un dévelopement décimal).\nTous les nombres auront nécessairement un développement binaire fini (et seront donc des fractions dyadiques) puisque le flottant donné en argument a lui même une écriture fini (il est codé sur 64 bits !).\ndef conv_fract(n): n = abs(n) n = n-int(n) count = 0 s = \u0026#39;\u0026#39; n *= 2 eps = 1e-9 while count \u0026lt; 64: print(n) if n \u0026gt;= 1: s += \u0026#39;1\u0026#39; if not 1-eps \u0026lt; n \u0026lt; 1+eps: n = (n-1)*2 else: # fin du développement binaire break else: s += \u0026#39;0\u0026#39; n *= 2 count += 1 return s La méthode consiste à multiplié par 2 lorsque le nombre est inférieur à 1 et à retirer 1 lorsqu\u0026rsquo;il dépasse.\nOn constate sur l\u0026rsquo;enchaînement des résultats intermédiaires que le chiffre avant la virgule correspond au développement binaire du nombre :\n\u003e\u003e\u003e conv_fract(0.1)\n0.2\n0.4\n0.8\n1.6\n1.2000000000000002\n0.40000000000000036\n0.8000000000000007\n1.6000000000000014\n1.2000000000000028\n0.4000000000000057\n0.8000000000000114\n1.6000000000000227\n1.2000000000000455\n0.40000000000009095\n0.8000000000001819\n1.6000000000003638\n1.2000000000007276\n0.4000000000014552\n0.8000000000029104\n1.6000000000058208\n1.2000000000116415\n0.40000000002328306\n0.8000000000465661\n1.6000000000931323\n1.2000000001862645\n0.40000000037252903\n0.8000000007450581\n1.6000000014901161\n1.2000000029802322\n0.4000000059604645\n0.800000011920929\n1.600000023841858\n1.2000000476837158\n0.40000009536743164\n0.8000001907348633\n1.6000003814697266\n1.2000007629394531\n0.40000152587890625\n0.8000030517578125\n1.600006103515625\n1.20001220703125\n0.4000244140625\n0.800048828125\n1.60009765625\n1.2001953125\n0.400390625\n0.80078125\n1.6015625\n1.203125\n0.40625\n0.8125\n1.625\n1.25\n0.5\n1.0\n'00011001100110011001100110011001100110011001100110011010001100110011001100110011001100110011001100110011001101'\nUn code possible pour obtenir l\u0026rsquo;écriture du nombre sur 64 bits via la norme IEEE-754.\ndef conv_iee(n: float) -\u0026gt; str: s = \u0026#39;\u0026#39; if n \u0026lt; 0: s += \u0026#39;1\u0026#39; else: s += \u0026#39;0\u0026#39; n = abs(n) if n \u0026gt; 1: mantisse_str = bin(int(n))[3:] # on enlève le 1er 1 mantisse_str += conv_fract(n)[:52-len(mantisse_str)] exp = len(bin(int(n))[2:])-1 + 1023 exp_str = bin(exp)[2:] s += (11-len(exp_str))*\u0026#39;0\u0026#39;+ exp_str else: if n == 0: exp = 0 exp_str = \u0026#39;0\u0026#39;*11 s += exp_str mantisse_str = \u0026#39;0\u0026#39;*52 else: dvlpt = \u0026#34;0\u0026#34;+conv_fract(n) exp = 0 while dvlpt[exp] == \u0026#34;0\u0026#34;: exp += 1 exp = exp*(-1) + 1023 exp_str = bin(exp)[2:] s += (11-len(exp_str))*\u0026#39;0\u0026#39; + exp_str # on ajoute des 0 à gauche pour compléter à 11 caractères mant = conv_fract(n) mantisse_str = \u0026#34;\u0026#34; test = True for i in range(len(mant)): if not test or mant[i] != \u0026#34;0\u0026#34;: # on enlève les 0 qui précèdent le 1er 1 mantisse_str += mant[i] test = False mantisse_str = mantisse_str[1:] # on enlève le 1er 1 if len(mantisse_str) \u0026lt; 52: mantisse_str += (52-len(mantisse_str))*\u0026#39;0\u0026#39; s += mantisse_str s = s[0]+\u0026#34; \u0026#34;+s[1:12]+\u0026#34; \u0026#34;+s[12:] return s Enfin, code d\u0026rsquo;un convertisseur d\u0026rsquo;un mot machine 64 bits vers sa valeur décimale :\ndef deconv(s: str) -\u0026gt; float: mot = \u0026#39;\u0026#39; for c in s: if c != \u0026#39; \u0026#39;: mot += c if int(mot) == 0: return 0 exp = int(mot[1:12],2) - 1023 nombre = 2**exp mantisse = mot[12:] for c in mantisse: exp -= 1 nombre += int(c)*2**exp if mot[0] == \u0026#34;1\u0026#34;: nombre *= -1 return nombre "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/structcontr/",
	"title": "Strucutres de contrôle",
	"tags": [],
	"description": "",
	"content": "Structures de contrôle Instruction d\u0026rsquo;affectation Définition Lorsqu\u0026rsquo;un objet est créé dans un programme Python, une certaine place en mémoire lui est allouée. Cette place est repérée par une adresse dont la valeur peut être obtenue grâce à la fonction id().\nid(3.7) 4387417928\nIl est beaucoup plus pratique de pouvoir récupérer une valeur en mémoire grâce à un petit nom plutôt que par son adresse. C\u0026rsquo;est à ça que servent les variables. Une variable est liée à un objet grâce à une affectation et identifie cet objet pour les calculs suivants. Une affectation est une instruction (pas de retour).\nEn Python, une affectation s\u0026rsquo;opère avec le symbole =.\nEn pseudocode, on utilise généralement := ou ← pour les affectations.\nLa variable est un tiroir avec une étiquette. Et comme on l\u0026rsquo;a vu, en Python, pas besoin de choisir un tiroir correspondant au type d\u0026rsquo;objet qu\u0026rsquo;il va contenir, c\u0026rsquo;est l\u0026rsquo;interpréteur qui s\u0026rsquo;en charge pour nous (le typage est dynamique).\na = 3 b = -2 a * b -6\nSi on veut pouvoir utiliser le résultat de a * b pour des calculs ultérieurs, il faut lui aussi le stocker en mémoire.\nc = a * b c -6\nOn peut interroger le type d\u0026rsquo;une variable avec la fonction type() :\nc = 3,2 type(c) \u0026lt;class 'tuple'\u0026gt;\nInstruction plutôt qu\u0026rsquo;expression Le fait que l\u0026rsquo;affectation soir une instruction plutôt qu\u0026rsquo;une expression est un choix d\u0026rsquo;écriture du langage (en C, l\u0026rsquo;affectation est une expression).\nD\u0026rsquo;ailleurs, Python 3.8 a introduit l\u0026rsquo;opérateur := (dit le walrus opérator ou opérateur de morse du fait de sa ressemblance à un morse\u0026hellip;) permettant justement une expression d\u0026rsquo;affectation au sein d\u0026rsquo;une expression plus large. L\u0026rsquo;intérêt est de permettre de raccourcir l\u0026rsquo;écriture ou d\u0026rsquo;éviter les répétitions dans certains cas.\nL\u0026rsquo;opérateur de morse n\u0026rsquo;est pas à connaître, mais il va nous permettre, dans les deux exemples suivants, de bien faire la différence entre une instruction et une expression.\nif (n := len(a)) \u0026gt; 5: print(f\u0026#34;La liste est trop grande ({n} élements alors qu\u0026#39;on en attend 5 au plus)\u0026#34;) Montrer que sans :=, on aurait soit une répétition, soit une ligne en plus.\nAutre exemple :\nwhile (choix := input(\u0026#39;Entrer q ou p : \u0026#39;)) != \u0026#39;q\u0026#39;: if choix == \u0026#39;p\u0026#39;: print(\u0026#34;Salut !\u0026#34;) Comment aurait-on dû écrire ce code sans := ?\nRéaffectation Une affectation ne retourne rien mais a un effet sur la mémoire : l\u0026rsquo;adresse de la variable est modifiée à chaque nouvelle affectation. C\u0026rsquo;est ce qui rend possible les réaffectations à partir de la variable elle-même.\nid(a) 4304751488\nid(a+1) 4304751520\na = a + 1 id(a) 4304751520\nCes types de réaffectation sont si fréquents qu\u0026rsquo;il existe une notation raccourcie : +=, -=, *=, /=, //=, %=.\nAinsi, a += 1 équivaut à a = a + 1 et b /= 5 équivaut à b = b/5.\nAffectation parallèle Comment faire si on veut permuter les valeurs auxquelles sont liées deux variables ? Dès qu\u0026rsquo;on écrit a = b, la valeur initiale de a est perdue. Et si on commence par b = a, c\u0026rsquo;est la valeur initiale de b qui est perdue. Il faudrait donc utiliser une variable temporaire et écrire : tmp = a, a = b et b = tmp.\nMais l\u0026rsquo;affectation parallèle de Python va nous permettre d\u0026rsquo;être plus élégants. Il suffit en effet d\u0026rsquo;une petite ligne :\na = \u0026#39;haut\u0026#39; b = \u0026#39;bas\u0026#39; a , b = b , a print(a,b) bas haut\nL\u0026rsquo;affectation parallèle repose sur le dépaquetage (unpacking) de tuples.\nEn effet, des objets séparés par des virgules forment un tuple (pas besoin de parenthèses). Donc a,b,c = 1,2,3 correspond au dépaquetage du tuple (1,2,3) sur les 3 variables a, b et c.\nNoms de variable Règles sur les noms de variables :\nils sont sensibles à la casse (minuscule ou majuscule) ils peuvent contenir n\u0026rsquo;importe quelles lettres ou chiffres et le tiret-bas \u0026ldquo;_\u0026rdquo; mais ne doivent pas commencer par un chiffre. certains noms sont interdits (attention en particulier à lambda) : and assert break class continue def del elif else except finally for from global if import in is lambda nonlocal not or pass print raise return try while yield\nIl est important pour la lisibilité de son code de donner les noms les plus explicites possibles aux variables. Les rapports de jury le répète tous les ans\u0026hellip;\nRapport 2019 de l\u0026rsquo;épreuve de Centrale par exemple :\nDes noms de variables explicites aident à la compréhension du code. De trop nombreux candidats utilisent des noms de variables quelconques (a, b, c\u0026hellip;) ce qui nuit à la compréhension du programme. La clarté du programme (en particulier le choix des noms de variables) ainsi que la présence de commentaires opportuns sont prises en compte dans l’évaluation.\nInstuction conditionnelle Les instructions conditionnelles permettent de rediriger le flot d\u0026rsquo;exécution d\u0026rsquo;un programme en proposant des alternatives.\nif,elif,else La structure if ... elif ... else permet d\u0026rsquo;exécuter des instructions seulement si une condition, donnée par le résultat d\u0026rsquo;un ou plusieurs tests logiques, est vérifiée.\nif \u0026lt;expression logique 1\u0026gt; :\n\u0026lt;bloc d\u0026rsquo;instructions 1\u0026gt;\nelif \u0026lt;expression logique 2\u0026gt; :\n\u0026lt;bloc d\u0026rsquo;instructions 2\u0026gt;\n\u0026hellip;\nelse :\n\u0026lt;bloc d\u0026rsquo;instructions\u0026gt;\nSi l\u0026rsquo;\u0026lt;expression logique 1\u0026gt; est évaluée comme vraie, le \u0026lt;bloc d\u0026rsquo;instructions 1\u0026gt; est exécuté ; dans le cas contraire, si l\u0026rsquo;\u0026lt;expression logique 2\u0026gt; est évaluée comme vraie, le \u0026lt;bloc d\u0026rsquo;instructions 2\u0026gt; est exécuté, et ainsi de suite ; et si aucune des expressions logiques précédentes n\u0026rsquo;est vraie, le bloc d\u0026rsquo;instructions faisant suite au else: est exécuté.\nPar exemple :\nfor x in range(10): if x\u0026lt;= 3: print(x,\u0026#39;est inférieur ou égal à 3\u0026#39;) elif x \u0026gt; 5: print(x,\u0026#39;est plus grand que 5\u0026#39;) else: print(x,\u0026#39;doit être 4 ou 5\u0026#39;) 0 est inférieur ou égal à 3 1 est inférieur ou égal à 3 2 est inférieur ou égal à 3 3 est inférieur ou égal à 3 4 doit être 4 ou 5 5 doit être 4 ou 5 6 est plus grand que 5 7 est plus grand que 5 8 est plus grand que 5 9 est plus grand que 5 Python reconnaît comme vrai n\u0026rsquo;importe quel type de donnée (même pas besoin d\u0026rsquo;expression logique) du moment qu\u0026rsquo;il ne s\u0026rsquo;agit ni de l\u0026rsquo;entier 0, du décimal 0., de la chaîne de caractères vide '', du tuple vide (), de la liste vide [], ou encore de la valeur None.\nExemple :\nDans le calendrier grégorien, une année est bissextile si elle est divisible par 4 sauf si elle est aussi divisible par 100 à l\u0026rsquo;exception des années divisibles par 400 qui sont bien bissextiles.\nLe programme suivant détermine si une année est bissextile :\nannée = 2022 if not année % 400: est_bissextile = True elif not année % 100: est_bissextile = False elif not année % 4: est_bissextile = True else: est_bissextile = False s = \u0026#39;est une\u0026#39; if est_bissextile else \u0026#34;n\u0026#39;est pas une\u0026#34; print(\u0026#34;L\u0026#39;année\u0026#34;, année , s ,\u0026#34;année bissextile.\u0026#34;) L'année 2022 n'est pas une année bissextile.\nBoucle while Une boucle while ou \u0026ldquo;tant que\u0026rdquo; permet de répéter une suite d\u0026rsquo;instructions tant qu\u0026rsquo; une condition est respectée.\nLa suite d\u0026rsquo;instructions répétées devra être indentée et forme alors le corps de la boucle.\nLes boucles while sont dangereuses ! Rien ne dit en effet que la condition sera un jour fausse et la boucle peut donc tourner indéfiniment.\nLes boucles infinis posent le problème de la terminaison d\u0026rsquo;un programme.\ni = 0 while i \u0026lt; 10: i += 1 print(i,end =\u0026#39;.\u0026#39;) print(\u0026#39;\\nLa boucle est finie...\u0026#39;) 1.2.3.4.5.6.7.8.9.10. La boucle est finie... Le compteur i est initialisé à 0 et comme 0 est inférieur à 10, la boucle while démarre. À chaque itération, i est incrémenté de 1 et sa valeur affichée. Puis i atteint 10 et à l\u0026rsquo;itération suivante i \u0026lt; 10 devient faux, la boucle s\u0026rsquo;arrête et l\u0026rsquo;éxécution reprend après la boucle.\nUn exemple plus intéressant :\nimplémentons l\u0026rsquo;algorithme d\u0026rsquo;Euclide permettant de déterminer le plus grand diviseur commun de deux entiers.\na , b = 1920 , 1080 print(f\u0026#39;pgcd({a},{b}) = \u0026#39;,end = \u0026#39;\u0026#39;) while b: a , b = b, a % b print(a) pgcd(1920,1080) = 120\nLa boucle continue jusqu\u0026rsquo;à ce que b divise a. À chaque itération, b prend la valeur du reste de la division euclidienne de a par b et a prend l\u0026rsquo;ancienne valeur de b.\nwhile b est équivalent à while b != 0 puisque la valeur 0 est évaluée comme fausse.\nbreak L\u0026rsquo;instruction break, placée dans le bloc d\u0026rsquo;instructions d\u0026rsquo;une boucle, met immédiatement fin à cette boucle lorsqu\u0026rsquo;arrive son tour d\u0026rsquo;être exécutée.\nL\u0026rsquo;exécution reprend à l\u0026rsquo;instruction suivant la boucle.\nx = 0 while True: x += 1 if not (x % 15 or x % 25): break print(x,\u0026#39;est divisible à la fois par 15 et 25.\u0026#39;) 75 est divisible à la fois par 15 et 25.\nLa condition du while est ici littéralement toujours vraie donc la seule sortie possible de la boucle passe par une exécution de l\u0026rsquo;instruction break, ce qui ne peut arriver que si x est à la fois divisible par 15 et 25 (c\u0026rsquo;est une pratique risquée !).\nDe la même manière, pour trouver l\u0026rsquo;indice de la première occurrence d\u0026rsquo;un nombre négatif dans une liste :\nliste = [5, 2, 99, 0, 100, -2, 37, 43, -124] for i, a in enumerate(liste): if a \u0026lt; 0: break print(\u0026#34;L\u0026#39;élément d\u0026#39;indice\u0026#34;,i,\u0026#34;valant\u0026#34;,a,\u0026#34;est le premier élément négatif.\u0026#34;) L'élément d'indice 5 valant -2 est le premier élément négatif.\nAprès la sortie de la boucle, les variables i et a gardent les valeurs qu\u0026rsquo;elles ont au moment de l\u0026rsquo;instruction break.\nreturn L\u0026rsquo;instruction return permet elle aussi de s\u0026rsquo;échapper d\u0026rsquo;une boucle.\nEn effet, l\u0026rsquo;utilisation du return a pour effet de sortir du corps d\u0026rsquo;une fonction donc à fortiori, si une boucle est utilisée dans la définition de cette fonction, le return permet aussi d\u0026rsquo;en sortir.\ndef vol(i): t = 0 while(1): if not i%2: i //= 2 elif i != 1: i = 3*i+1 else: return t t += 1 vol(27) renvoie alors 111.\nBoucle for Une boucle for se différencie d\u0026rsquo;une boucle while en ce que le nombre d\u0026rsquo;itérations est connu à l\u0026rsquo;avance.\nLa structure d\u0026rsquo;une telle boucle est en effet :\nfor \u0026lt;élément\u0026gt; in \u0026lt;itérable\u0026gt; :\n\u0026lt;bloc d\u0026rsquo;instructions\u0026gt;\nL\u0026rsquo;itérable est une collection d\u0026rsquo;éléments et le bloc d\u0026rsquo;instructions est alors répété autant de fois que l\u0026rsquo;itérable contient d\u0026rsquo;éléments.\nPassons en revue quelques itérables.\nrange range permet d\u0026rsquo;itérer sur une suite arithmétique d\u0026rsquo;entiers :\nfor i in range(5): print(i,end=\u0026#34;.\u0026#34;) 0.1.2.3.4.\nL\u0026rsquo;itération sur range(n) va de $0$ à $n-1$ par pas de 1.\nOn peut spécifier un point de départ et un pas différents en les passant en argument : range(depart,fin,pas).\nfor i in range(5,10): print(i,end=\u0026#34;.\u0026#34;) 5.6.7.8.9.\nfor i in range(0,100,20): print(i,end=\u0026#34;.\u0026#34;) 0.20.40.60.80.\nune chaîne de caractères Itérer sur une chaîne de caractères décompose la chaîne caractère par caractère :\nfor car in \u0026#39;abc😱\u0026#39;: print(car*2,end=\u0026#39; \u0026#39;) aa bb cc 😱😱 une liste, un tuple On peut de même parcourir une liste ou un tuple élément par élément.\nL = [(\u0026#39;🙈\u0026#39;,\u0026#39;🙊\u0026#39;,\u0026#39;🙉\u0026#39;),(\u0026#39;🌖\u0026#39;,\u0026#39;🌗\u0026#39;,\u0026#39;🌘\u0026#39;),] s = \u0026#39;\u0026#39; i = 1 for tuple in L: for element in tuple: s += element*i i += 1 print(s) 🙈🙊🙊🙉🙉🙉🌖🌖🌖🌖🌗🌗🌗🌗🌗🌘🌘🌘🌘🌘🌘\nun dictionnaire Pour pacourir uniquement les clés d\u0026rsquo;un dictionnaire, on peut utiliser la méthode keys :\nDico = {\u0026#39;pwd_1\u0026#39; : \u0026#39;123456\u0026#39;, \u0026#39;pwd_2\u0026#39; : \u0026#39;qwerty\u0026#39;, \u0026#39;pwd_3\u0026#39; : \u0026#39;password\u0026#39;} for cle in Dico.keys(): print(cle,\u0026#39;-\u0026gt;\u0026#39;,Dico[cle]) pwd_1 -\u0026gt; 123456\npwd_2 -\u0026gt; qwerty\npwd_3 -\u0026gt; password\nEt grâce à la méthode items, on peut déballer clés et valeurs associées dans un tuple :\nfor cle,valeur in Dico.items(): print(cle,\u0026#39;-\u0026gt;\u0026#39;,valeur) pwd_1 -\u0026gt; 123456\npwd_2 -\u0026gt; qwerty\npwd_3 -\u0026gt; password\nConstruisons par exemple un nouveau dictionnaire inversant clés et valeurs :\nDico = {\u0026#39;$\u0026#39; : \u0026#39;dollar\u0026#39;, \u0026#39;€\u0026#39; : \u0026#39;euro\u0026#39;, \u0026#39;¥\u0026#39; : \u0026#39;yen\u0026#39;, \u0026#39;£\u0026#39; : \u0026#39;livre\u0026#39;} Dico_inv = {} for cle,valeur in Dico.items(): Dico_inv[valeur] = cle print(Dico_inv) {'dollar': '$', 'euro': '€', 'yen': '¥', 'livre': '£'}\nDernier exemple, modifions une à une chaque valeur d\u0026rsquo;un dictionnaire :\ndico_notes = {\u0026#39;Kurt\u0026#39; : 19, \u0026#39;Kris\u0026#39; : 11, \u0026#39;Dave\u0026#39; : 13, \u0026#39;Pat\u0026#39; : 10, \u0026#39;Courtney\u0026#39; : 15} for eleve,note in dico_notes.items(): dico_notes[eleve] = note+1 print(dico_notes) {'Kurt': 20, 'Kris': 12, 'Dave': 14, 'Pat': 11, 'Courtney': 16} Définition d\u0026rsquo;une fonction Une fonction est un ensemble d\u0026rsquo;instructions auxquelles on accède par un raccourci : le nom de la fonction. Elles se comportent comme des sous-programmes à l\u0026rsquo;intérieur du programme principal. Et comme tout programme, elles peuvent agir sur des données, les entrées, et fournir de nouvelles données, les sorties.\nLa signature d\u0026rsquo;une fonction résume ces points clés : son nom, les différents arguments et leurs types, les différentes sorties et leur type. nom(arg_1:type, arg_2:type, etc) -\u0026gt; sortie_1:type, sortie_2:type, etc\nOn définit une fonction grâce au mot clé def en suivant la structure suivante :\ndef nom(arguments séparés par des virgules) :\n\u0026lt; corps de la fonction contenant les différentes instructions \u0026gt;\nLa définition d\u0026rsquo;une fonction est une instruction.\ndef addition(a,b): c = a+b print(c) On appelle une fonction en utilisant son nom et en affectant chaque argument dans les parenthèses qui suivent son nom.\nLes instructions du corps de la fonction sont alors exécutée une par une et si des variables correspondant aux nom des arguments (on parle alors d\u0026rsquo;arguments formels) sont rencontrées, ce sont les valeurs utilisées lors de l\u0026rsquo;appel (les arguments effectifs) qui les remplacent.\naddition(5,2) 7 On utilise aussi le terme \u0026ldquo;paramètre\u0026rdquo; pour désigner les arguments formels, c\u0026rsquo;est-à-dire les variables qui entrent dans la définition de la fonction. Et on réserve alors le terme argument aux valeurs données à ces variables au moment de l\u0026rsquo;appel.\nDans l\u0026rsquo;exemple, a et b sont alors les paramètres (= arguments formels) et 5 et 2 sont les arguments (= arguments effectifs).\nMalgré ce que l\u0026rsquo;affichage peut laisser croire, la fonction précédente ne retourne rien !\nLa valeur de c est prisonnière du corps de la fonction, elle n\u0026rsquo;est pas accessible dans le code principal. C\u0026rsquo;est une variable locale.\nSi on veut pouvoir accéder à c ailleurs que dans la fonction, il faut l\u0026rsquo;extirper en utilisant un return.\nIl ne faut ainsi pas confondre print et return !\nLe return transforme l\u0026rsquo;appel de la fonction en expression puisqu\u0026rsquo;une valeur est retournée.\nLe print n\u0026rsquo;a qu\u0026rsquo;un effet de bord. La valeur est affichée mais inutilisable. L\u0026rsquo;appel de la fonction n\u0026rsquo;est alors qu\u0026rsquo;une instruction et on nomme procédure une telle fonction.\nAinsi, addition(5,2) + 7 va lever une erreur : TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'.\nEn effet, comme addition ne retourne rien, Python la considère de type NoneType et ne comprend pas pourquoi on cherche à additionner quelque chose à rien.\nArrangeons cela grâce à un return :\ndef addition(a,b): c = a+b return c Maintenant, addition(5,2) + 7 retourne gentiment 12.\nDès que l\u0026rsquo;instruction return est rencontrée lors de l\u0026rsquo;appel de la fonction le flot d\u0026rsquo;exécution du code de la fonction est interrompu et reprend à la ligne suivant l\u0026rsquo;appel.\ndef demo(): print(\u0026#34;Ligne exécutée car avant le return\u0026#34;) return print(\u0026#34;Ligne non exécutée car après le return\u0026#34;) demo() Ligne exécutée car avant le return\nL\u0026rsquo;exemple précédent nous montre aussi qu\u0026rsquo;une fonction n\u0026rsquo;a pas nécessairement d\u0026rsquo;argument et qu\u0026rsquo;un return peut ne rien retourner (il ne sert alors qu\u0026rsquo;à interrompre l\u0026rsquo;exécution).\nComme on l\u0026rsquo;a vu précédemment, un return, à l\u0026rsquo;instar d\u0026rsquo;un break, peut donc interrompre une boucle dans le corps d\u0026rsquo;une fonction.\nL\u0026rsquo;appel d\u0026rsquo;une fonction est la valeur qu\u0026rsquo;elle retourne, qu\u0026rsquo;il s\u0026rsquo;agisse d\u0026rsquo;un entier, d\u0026rsquo;une liste, d\u0026rsquo;un dictionnaire, etc.\nUne fonction peut retourner plusieurs variables séparées par des virgules. L\u0026rsquo;appel est alors un tuple qui peut être déballé.\ndef somme_moyenne(liste): s = 0 for e in liste: s += e m = s/len(liste) return s,m L = [1,2,3,4] print(type(somme_moyenne(L))) a,b = somme_moyenne(L) print(\u0026#34;somme :\u0026#34;,a,\u0026#34;et moyenne :\u0026#34;,b) print(somme_moyenne(L)[1]) \u0026lt;class 'tuple'\u0026gt;\nsomme : 10 et moyenne : 2.5\n2.5\nUne fonction peut aussi ne pas avoir d\u0026rsquo;argument :\ndef HelloWorld(): print(\u0026#39;\\x4B\\x49\\x4C\\x4C\\n\\x41\\x4C\\x4C\\n\\x48\\x55\\x4D\\x41\\x4E\u0026#39;) "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp4dicho/",
	"title": "TP 4 : algorithmes dichotomiques",
	"tags": [],
	"description": "",
	"content": " Algorithmes dichotomiques Cliquez sur cette invitation pour récupérer le repository du TP. Recherche dichotomique L\u0026rsquo;algorithme de recherche mis au point dans le tp1 compte dans le pire des cas autant d\u0026rsquo;étapes que l\u0026rsquo;ensemble scruté contient d\u0026rsquo;éléments.\nPeut-on faire mieux ?\nDans le cas, d\u0026rsquo;un ensemble ordonné trié, la réponse est oui. On peut même faire beaucoup mieux !\nImaginons que l\u0026rsquo;on cherche une carte dans un jeu trié en ordre croissant. L\u0026rsquo;idée est de regarder d\u0026rsquo;abord au milieu du paquet. Si la carte du milieu est plus petite (repectivement plus grande) que la carte cherchée, on en déduit que celle-ci ne peut être que dans la deuxième partie (respectivement dans la première partie) du paquet (si elle est bien présente).\nOn peut alors se débarrasser de la moitié des cartes environ et on recommence la manœuvre avec les cartes restantes.\nVoilà ci-dessous une tentative d\u0026rsquo;implémentation de cet algorithme :\ndef recherche_dicho(L,x): n = len(L) g, d = 0, n-1 while g \u0026lt; d: i = (g + d)//2 if x \u0026lt; L[i]: d = i - 1 elif x \u0026gt; L[i]: g = i + 1 else: return True return False Commentaire (cliquer pour afficher)\u0026nbsp; Attention à ne pas confondre avec recherche_dico du TP1, il ne s'agit pas ici de dictionnaires, mais de dichotomie... Testez cet algorithme et constatez qu\u0026rsquo;il contient une erreur.\nRecopier ci-dessous une liste triée et un élément à rechercher qui mettent en échec l\u0026rsquo;algorithme.\nCorrection (cliquer pour afficher) On peut trouver de telles listes sans réfléchir en utilisant le code suivant\u0026nbsp;: from random import randint for k in range(20): L = [randint(1,10) for i in range(5)] L = sorted(L) x = randint(1,10) a = recherche_dicho(L,x) b = x in L if not ((not a and not b) or (a and b)): print(a,b,x,L) Si on donne la liste [2, 5, 7, 7, 8] en argument, la fonction renverra False si on lui demande de rechercher 5. Corrigez l\u0026rsquo;algorithme recherche_dicho_corr en ajoutant un seul caractère.\nAttention, tout autre ajout, même un espace, rendra faux l\u0026rsquo;exercice.\nCorrection (cliquer pour afficher) Il suffit d'ajouter un = dans la condition de la boucle while\u0026nbsp;:\nwhile g \u003c= d: Commentaire (cliquer pour afficher)\u0026nbsp; Voyons pourquoi ça ne marche pas sans la correction dans le cas du contre-exemple donné\u0026nbsp;:\nrecherche_dicho([2, 5, 7, 7, 8],5) initialisation : $g\\leftarrow 0$, $d\\leftarrow 5$ itération 1 : $i\\leftarrow 2$, L[i] vaut $7$ et donc, $d\\leftarrow 1$ (on est dans le if) itération 2 : $i\\leftarrow 0$, L[0] vaut $2$ et donc, $g\\leftarrow 1$ (on est dans le elif) Sans la correction, on sort de la boucle while à ce moment. La fonction retourne donc à tort False.\nAvec la correction, on fait un nouveau tour dans la boucle\u0026nbsp;: itération 3 : $i\\leftarrow 1$, L[1] vaut $5$ et on est donc dans le else $\\Rightarrow$ la fonction retourne True La figure suivante est un arbre binaire décrivant tous les chemins possibles que prend l\u0026rsquo;algorithme à partir d\u0026rsquo;une liste de 16 éléments (en vert, le nombre d\u0026rsquo;éléments restant).\nCet algorithme peut se montrer bien plus rapide que la recherche simple du TP1.\nRéouvrons la liste de mots de passe du TP2 mais en la transformant en liste de mots plutôt qu\u0026rsquo;en long texte.\n# importation de la classique liste de mots de passe rockyou (cela prend quelques secondes) from urllib.request import urlopen url = \u0026#39;http://cordier-phychi.toile-libre.org/Info/github/rockyou.txt\u0026#39; rockyou = urlopen(url).read().decode(\u0026#39;latin-1\u0026#39;).split() rockyou = sorted(rockyou) print(len(rockyou),\u0026#39;mots de passe\u0026#39;) 14445388 mots de passe\ndef trouve_indice(L, x): \u0026#39;\u0026#39;\u0026#39; trouve_indice(L: liste, x: type des éléments de L) -\u0026gt; soit un entier, soit un booléen postcondition: renvoie l\u0026#39;indice d\u0026#39;un éléments x lorsqu\u0026#39;il est présent dans la liste L et renvoie False lorsqu\u0026#39;il est absent \u0026#39;\u0026#39;\u0026#39; for indice, element in enumerate(L): if element == x: return indice return False Rq : enumerate est une fonction native plutôt pratique (mais en rien indispensable et d\u0026rsquo;ailleurs pas au programme).\nCommentaire (cliquer pour afficher)\u0026nbsp; Ce n'est pas bien dur de réécrire la fonction sans utiliser enumerate\u0026nbsp;: def trouve_indice(L, x): for i in range(len(L)): if L[i] == x: return i return False from time import time from random import randint import matplotlib.pyplot as plt plt.style.use(\u0026#39;seaborn\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 6) Indice, T_ch = [], [] liste_noms = [\u0026#39;567890\u0026#39;,\u0026#39;billgates\u0026#39;,\u0026#39;dollars\u0026#39;,\u0026#39;jklmno\u0026#39;,\u0026#39;pupuce\u0026#39;,\u0026#39;zorro\u0026#39;] for nom in liste_noms: start = time() i = trouve_indice(rockyou,nom) stop = time() Indice.append(i) T_ch.append(stop-start) print(f\u0026#34;{stop -start:.2e} s pour trouver \u0026#39;{nom}\u0026#39; qui est à la position {i}\u0026#34;) plt.plot(Indice,T_ch,\u0026#39;--\u0026#39;) plt.plot(Indice,T_ch,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) plt.xlabel(\u0026#34;Position dans la liste\u0026#34;) plt.ylabel(\u0026#34;Temps pour trouver le nom (s)\u0026#34;) 1.84e-01 s pour trouver '567890' qui est à la position 2612528\n3.93e-01 s pour trouver 'billgates' qui est à la position 5584305\n4.85e-01 s pour trouver 'dollars' qui est à la position 6925245\n6.32e-01 s pour trouver 'jklmno' qui est à la position 8867150\n8.32e-01 s pour trouver 'pupuce' qui est à la position 11949039\n1.01e+00 s pour trouver 'zorro' qui est à la position 14416270\nComment semble évoluer le temps de recherche en fonction de la position dans la liste ?\nCorrection (cliquer pour afficher) Le temps de recherche semble évoluer linéairement en fonction de la position dans la liste (durée $\\propto$ position). Avec l\u0026rsquo;algorithme de recherche dichotomique, on obtient :\nT_ch = [] liste_noms = [\u0026#39;567890\u0026#39;,\u0026#39;billgates\u0026#39;,\u0026#39;dollars\u0026#39;,\u0026#39;jklmno\u0026#39;,\u0026#39;pupuce\u0026#39;,\u0026#39;zorro\u0026#39;] for i,nom in zip(Indice,liste_noms): start = time() recherche_dicho_corr(rockyou,nom) stop = time() T_ch.append(stop-start) print(f\u0026#34;{stop -start:.2e} s pour trouver {nom} qui est à la position {i}\u0026#34;) plt.plot(Indice,T_ch,\u0026#39;--\u0026#39;) plt.plot(Indice,T_ch,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) for i in range(len(liste_noms)) : plt.text(Indice[i]+max(Indice)/100,T_ch[i],liste_noms[i]) plt.xlabel(\u0026#34;Position dans la liste (s)\u0026#34;) plt.ylabel(\u0026#34;Temps pour trouver le nom\u0026#34;) plt.savefig(\u0026#39;graph.png\u0026#39;,dpi=600) 1.41e-05 s pour trouver 567890 qui est à la position 2612528\n1.41e-05 s pour trouver billgates qui est à la position 5584305\n1.10e-05 s pour trouver dollars qui est à la position 6925245\n2.19e-05 s pour trouver jklmno qui est à la position 8867150\n1.12e-05 s pour trouver pupuce qui est à la position 11949039\n1.41e-05 s pour trouver zorro qui est à la position 14416270\nOn constate que l\u0026rsquo;algorithme dichotomique met beaucoup moins de temps et qu\u0026rsquo;il ne semble pas dépendre clairement de la position de l\u0026rsquo;élément.\nTentons de comparer le comportement des deux algorithmes quand la longueur de la liste augmente.\nQuel que soit l\u0026rsquo;algorithme de recherche, la pire situation possible correspond à la recherche d\u0026rsquo;un élément absent de la liste.\nSe placer dans ce pire des cas permet une comparaison plus sûre des algorithmes ; on sait à quoi s\u0026rsquo;attendre !\nMesurer un temps dépend de trop de paramètres (processeur, utilisation de la mémoire par le système, etc.).\nUne information plus universelle est le nombre d\u0026rsquo;étapes de l\u0026rsquo;algorithme.\nPlus précisément, concentrons sur le nombre de comparaisons entre l\u0026rsquo;élément recherché x et les éléments de la liste L.\nOn a construit ci-dessous la fonction trouve_indice_etapes dont la description est donnée :\ndef trouve_indice_etapes(L,x): \u0026#34;\u0026#34;\u0026#34; trouve_indice_etapes(liste: list, valeur: type des éléments de la liste) -\u0026gt; bool, int postcondition: retourne à la fois un booléen qui traduit la présence ou non de l\u0026#39;élément et un entier correspondant au nombre de comparaisons effectuées entre x et les éléments de L \u0026#34;\u0026#34;\u0026#34; nb_comp = 0 for indice, element in enumerate(L): nb_comp += 1 if element == valeur: return True,nb_comp return False,nb_comp À vous de jouer pour construire sur le même modèle recherche_dicho_etapes :\ndef recherche_dicho_etapes(L,x) : \u0026#34;\u0026#34;\u0026#34; recherche_dicho_etapes(liste: list, valeur: type des éléments de la liste) -\u0026gt; bool, int postcondition: doit retourner à la fois un booléen qui traduit la présence ou non de l\u0026#39;élément et un entier correspondant au nombre de comparaisons effectuées entre x et les éléments de L \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Correction (cliquer pour afficher) Il faut faire très attention aux endroits où l'on place les incrémentations de nbcomp dans le code de recherche_dicho.\nÀ chaque itération, il peut y avoir soit 1 comparaison (en passant par le if), soit 2 (en passant par le elif ou le else). def recherche_dicho_etapes(L,x) : n = len(L) nb_comp = 0 g, d = 0, n-1 while g \u003c= d: i = (g + d)//2 nb_comp += 1 # toujours au moins 1 comparaison (celle du if) if x \u003c L[i]: d = i - 1 # pas d'incrémentation car déjà comptée elif x \u003e L[i]: g = i + 1 nb_comp += 1 # on ajoute la comparaison du elif else: nb_comp += 1 # la comparaison du elif a été faite et elle s'est avérée fausse return True,nb_comp return False,nb_comp Maintenant, comparons :\nimport pandas as pd NB_elts, NB_comp = [], [] nom = \u0026#39;???#!!!\u0026#39; liste_longueurs = [10*2**i for i in range(1,19)] for longueur in liste_longueurs: start = time() nb_comp = trouve_indice_etapes(rockyou[:longueur],nom)[1] stop = time() NB_elts.append(longueur) NB_comp.append(nb_comp) d = {\u0026#39;taille\u0026#39; : NB_elts,\u0026#39;# comparaisons\u0026#39;: NB_comp} tableau = pd.DataFrame(data=d) display(tableau) fig, axs = plt.subplots(2,figsize=(15,12)) axs[0].plot(NB_elts,NB_comp,\u0026#39;--\u0026#39;) axs[0].plot(NB_elts,NB_comp,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) axs[1].semilogx(NB_elts,NB_comp,\u0026#39;--\u0026#39;) axs[1].semilogx(NB_elts,NB_comp,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) axs[0].set(xlabel=\u0026#39;Longueur de la liste\u0026#39;, ylabel=\u0026#39;Nb de comparaisons\u0026#39;) axs[1].set(xlabel=\u0026#39;Longueur de la liste (axe logarithmique)\u0026#39;, ylabel=\u0026#39;Nb de comparaisons\u0026#39;) taille # comparaisons 0 20 20 1 40 40 2 80 80 3 160 160 4 320 320 5 640 640 6 1280 1280 7 2560 2560 8 5120 5120 9 10240 10240 10 20480 20480 11 40960 40960 12 81920 81920 13 163840 163840 14 327680 327680 15 655360 655360 16 1310720 1310720 17 2621440 2621440 NB_elts, NB_comp = [], [] nom = \u0026#39;???#!!!\u0026#39; liste_longueurs = [10*2**i for i in range(1,19)] for longueur in liste_longueurs: start = time() nb_comp = recherche_dicho_etapes(rockyou[:longueur],nom)[1] stop = time() NB_elts.append(longueur) NB_comp.append(nb_comp) d = {\u0026#39;taille\u0026#39; : NB_elts,\u0026#39;# comparaisons\u0026#39;: NB_comp} tableau = pd.DataFrame(data=d) display(tableau) fig, axs = plt.subplots(2,figsize=(15,12)) axs[0].plot(NB_elts,NB_comp,\u0026#39;--\u0026#39;) axs[0].plot(NB_elts,NB_comp,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) axs[1].semilogx(NB_elts,NB_comp,\u0026#39;--\u0026#39;) axs[1].semilogx(NB_elts,NB_comp,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) axs[0].set(xlabel=\u0026#39;Longueur de la liste\u0026#39;, ylabel=\u0026#39;Nb de comparaisons\u0026#39;) axs[1].set(xlabel=\u0026#39;Longueur de la liste (axe logarithmique)\u0026#39;, ylabel=\u0026#39;Nb de comparaisons\u0026#39;) taille # comparaisons 0 20 5 1 40 6 2 80 7 3 160 8 4 320 9 5 640 10 6 1280 11 7 2560 12 8 5120 13 9 10240 14 10 20480 15 11 40960 16 12 81920 17 13 163840 18 14 327680 19 15 655360 20 16 1310720 21 17 2621440 22 Commentaire (cliquer pour afficher)\u0026nbsp; Dans le cas de la recherche linéaire, le nombre de comparaisons est proportionnel à la taille de la liste alors que dans le cas de la recherche dichotomique, le nombre de comparaisons est proportionnel au logarithme de la taille de la liste\u0026nbsp;! Recherche dichotomique d\u0026rsquo;une racine On cherche à appliquer la méthode de la dichotomie (découpage en deux systématique d\u0026rsquo;un intervalle) à la recherche d\u0026rsquo;une racine.\nPlus précisément, on souhaite déterminer une approximation d’une racine (ou zéro) sur un intervalle $[a, b]$, avec une précision $ε$, d’une fonction continue et monotone $f$ sur cet intervalle et telle que $f(a)$ et $f(b)$ sont de signes opposés ($f(a)f(b)≤0)$. Elle consiste à comparer le signe de l’image $f\\left(\\frac{a + b}{2}\\right)$ du milieu de l’intervalle $[a, b]$ avec le signe de $f(a)$ et $f(b)$ pour réduire l’intervalle de recherche de manière itérative.\nPour déterminer $x_0$, racine de la fonction $f$, strictement monotone sur l’intervalle $[a, b]$, avec une précision $ε,$ on procède comme suit :\nOn détermine le milieu de l’intervalle $m = \\frac{a+b}{2}$ ; On compare le signe de $f(m)$ avec celui de $f(a)$ et $f(b)$ pour déterminer dans quel intervalle $[a, m]$ ou $[m, b]$ se trouve la racine $x_0$ ; On affecte à $a$ (resp. $b$) la valeur de $m$ si la racine se trouve entre $m$ et $b$ (resp. $a$) ; On itère tant que $|a − b| \u0026gt; ε$, (ε est la précision définie initialement), et on renvoie $m$. There should have been a video here but your browser does not seem to support it. Construisez une fonction racine prenant en argument une fonction f, les bornes d\u0026rsquo;un intervalle a et b, et une précision eps et retournant la racine ainsi que le nombre d\u0026rsquo;itérations nécessaires. Vous vous assurerez grâce à un assert qu\u0026rsquo;au moins une racine existe bel et bien dans l\u0026rsquo;intervalle choisi et vous sécuriserez la boucle while en ajoutant une condition empèchant l\u0026rsquo;algorithme d\u0026rsquo;utiliser plus de 100 itérations.\ndef racine(f,a,b,eps) : \u0026#34;\u0026#34;\u0026#34; racine(f: fonction, a: flottant, b: flottant, eps: flottant) -\u0026gt; racine: flottant, nbiter: entier précondition: f doit être une fonction n\u0026#39;ayant qu\u0026#39;un argument (un flottant) et ne retournant qu\u0026#39;un flottant. \u0026#34;\u0026#34;\u0026#34; ### BEGIN SOLUTION Correction (cliquer pour afficher) def racine(f,a,b,eps): assert f(a)*f(b)\u003c0 nbiter = 1 nbitermax = 100 m = (a + b)/ 2 while abs(a - b) \u003e eps and nbiter \u003c nbitermax: # condition de convergence + non-dépassement d'un nombre limite d'iterations m = (a + b)/ 2 if f(a) * f(m) \u003c 0: b = m else: a = m nbiter += 1 return m, nbiter Comment évolue l\u0026rsquo;accroissement du nombre d\u0026rsquo;iterations en fonction de l\u0026rsquo;accroissement du nombre de chiffres significatifs obtenus pour la racine ?\nCorrection (cliquer pour afficher) Traçons cette évolution grâce au code suivant\u0026nbsp;: def f(x): return x**2-2 Leps, Let = [], [] for i in range(1,15): eps = 10**(-i) Leps.append(1+i) nb_etapes = racine(f,1,2,eps)[1] Let.append(nb_etapes) plt.plot(Leps,Let,'--') plt.plot(Leps,Let,'o',c='C2') plt.xlabel(\"Nombre de chiffres significatifs\") plt.ylabel(\"Nombre d'étapes\") On obtient :\ni+1 correspond bien ici au nombre de chiffres significatifs souhaités puisque la solution, 1,414..., ne contient qu'un seul chiffre avant la virgule.\nOn constate que l'accroissement du nombre d'itérations semble proportionnel à l'accroissement du nombre de chiffres significatifs souhaité. "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/tp8correc/",
	"title": "TP 8 : correction et complexité",
	"tags": [],
	"description": "",
	"content": " TP 8 : correction et complexité Cliquez sur cette invitation pour récupérer le repository du TP. Multiplication égyptienne Considérons le code suivant, qui implémente un ancien algorithme égyptien.\na et b sont supposés être des entiers positifs.\ndef multegy(a, b): p = 0 while a \u0026gt; 0: if a%2 == 1: p += b b *= 2 a //= 2 return p Qui est le variant de boucle permettant de prouver que multegy termine toujours ?\na : a b : b c : p d : autre réponse Correction (cliquer pour afficher) a est une suite d'entiers positifs strictement décroissante, c'est donc un variant de boucle. Détaillez l\u0026rsquo;éxécution de multegy(23,5) en affectant à a_i, b_i, p_i, les valeurs rencontrées en début de chaque itération.\nCorrection (cliquer pour afficher) def multegy(a, b): p = 0 i = 0 while a \u003e 0: print(f\"itération {i} : {a = }, {b = }, {p = }\") if a%2 == 1: p += b b *= 2 a //= 2 i += 1 print(f\"itération {i} : {a = }, {b = }, {p = }\") return p multegy(23,5) Ce code affiche\u0026nbsp;:\nitération 0 : a = 23, b = 5, p = 0\nitération 1 : a = 11, b = 10, p = 5\nitération 2 : a = 5, b = 20, p = 15\nitération 3 : a = 2, b = 40, p = 35\nitération 4 : a = 1, b = 80, p = 35\nitération 5 : a = 0, b = 160, p = 115 Construisons la preuve de l\u0026rsquo;algorithme :\non va montrer que $a\\times b + p$ est un invariant de boucle et l\u0026rsquo;utiliser pour prouver que l\u0026rsquo;algorithme retourne bien le produit entre $a$ et $b$.\nNotons $a_k$, $b_k$, $p_k$, les valeurs de $a$, $b$ et $p$ après la ke itération et supposons $a_k\\times b_k + p_k = cste$.\ninitialisation : pour $k=0$, $a_0=a$, $b_0=b$ et $p_0=0$. D\u0026rsquo;où $a_0\\times b_0+p_0=a\\times b$ conservation : à la boucle $k+1$, deux cas se présentent : si $a$ est impair : $a_{k+1} = X$, $b_{k+1} = Y$ et $p_{k+1}= Z$.\nD\u0026rsquo;où $a_{k+1}\\times b_{k+1} + p_{k+1} = a_k\\times b_k - b_k +p_k+ b_k = a_k\\times b_k+p_k$ si $a$ est pair : $a_{k+1} = \\frac{a_k}{2}$, $b_{k+1} = b_k\\times 2$ et $p_{k+1}=p_k$.\nD\u0026rsquo;où $a_{k+1}\\times b_{k+1} + p_{k+1} = a_k\\times b_k + p_k$\nPar conséquent, $a_k\\times b_k + p_k$ est bien un invariant pour tout $k$. terminaison : en sortie de boucle (itération $f$), $a_f = 0$, donc $a_f\\times b_f+p_f = p_f$. Or comme l\u0026rsquo;invariant est\u0026hellip; invariant, il garde toujours la valeur qu\u0026rsquo;il possède en entrée (pour $k=0$) : d\u0026rsquo;où $p_f = a\\times b$. Et comme la fonction retourne $p_f$, cqfd. Que vallent X,Y et Z ?\na : $a_k$, $b_k$, $p_k+b_k$ b : $\\frac{a_k-1}{2}$, $b_k\\times 2$, $p_k+b_k$ c : $\\frac{a_k+1}{2}$, $b_k\\times 2$, $p_k$ Correction (cliquer pour afficher) $\\displaystyle X = \\frac{a_k+1}{2}$, $Y = b_k\\times 2$, $Z = p_k+b_k$ Quelle est la complexité de multegy (en supposant chacun des calculs comme élémentaire) ?\na : $O(a)$ b : $O(a\\times b)$ c : $O(a\\log b)$ d : $O(\\log a)$ e : $O(b)$ Correction (cliquer pour afficher) Il y aura autant de tours dans la boucle while que le nombre de fois qu'on peut diviser a par 2 (division euclidienne) avant d'arriver sur 0. Ce nombre est en $O(\\log a)$.\nEt à chaque tour, il y a soit $c$ étapes, soit $c+1$ où $c$ est une constante.\nLa complexité globale reste donc en $O(\\log a)$. Deux fonctions de recherche def cherche(s, m): for k in range(len(s) - len(m) + 1): b = True for i in range(len(m)): if s[k + i] != m[i]: b = False if b: return True return False def cherche2(s, m): for k in range(len(s) - len(m) + 1): if s[k:k + len(m)] == m: return True return False Quelle est la complexité de la fonction cherche ? Et celle de cherche2 ?\nAppelons len(s) n et len(m) p.\na : les deux en $O(n\\times p)$ b : cherche en $O(n\\times p)$ et cherche2 en en $O(n)$ c : une autre réponse Correction (cliquer pour afficher) Les deux sont en $O(n\\times p)$.\nIl ne faut pas simplement compter les imbrications de boucles (même si c'est souvent suffisant)\u0026nbsp;; dans le cas de cherche2, $m$ étapes sont cachées dans la comparaison s[k:k + len(m)] == m puisque l'interprète python ne peut faire autrement que de comparer les caractères un par un pour s'assurer que les deux chaînes sont bien les mêmes. Exécuter le code suivant peut vous aider à confirmer votre réponse.\nimport time from random import randint abc = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39; def motdenlettres(n): mot = \u0026#39;\u0026#39; for i in range(n): mot += abc[randint(0,25)] return mot print(\u0026#39;-\u0026#39;*30) print(\u0026#39;| n | p | cherche2 |\u0026#39;) print(\u0026#39;-\u0026#39;*30) for j in range(2,6): n = 10**5*2**j s = motdenlettres(n) for k in range(3): p = 10**4*2**k m = motdenlettres(p) d = time.time() cherche2(s,m) f = time.time() t = f - d print(f\u0026#39;|{n:^9d}|{p:^8d}|{t:^10.2E}|\u0026#39;) print(\u0026#39;-\u0026#39;*30) ------------------------------\n|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;p\u0026nbsp;\u0026nbsp;\u0026nbsp;|\u0026nbsp;cherche2\u0026nbsp;|\n------------------------------\n|\u0026nbsp;400000\u0026nbsp;\u0026nbsp;|\u0026nbsp;10000\u0026nbsp;\u0026nbsp;|\u0026nbsp;2.04E-01\u0026nbsp;|\n|\u0026nbsp;400000\u0026nbsp;\u0026nbsp;|\u0026nbsp;20000\u0026nbsp;\u0026nbsp;|\u0026nbsp;4.65E-01\u0026nbsp;|\n|\u0026nbsp;400000\u0026nbsp;\u0026nbsp;|\u0026nbsp;40000\u0026nbsp;\u0026nbsp;|\u0026nbsp;9.72E-01\u0026nbsp;|\n------------------------------\n|\u0026nbsp;800000\u0026nbsp;\u0026nbsp;|\u0026nbsp;10000\u0026nbsp;\u0026nbsp;|\u0026nbsp;4.20E-01\u0026nbsp;|\n|\u0026nbsp;800000\u0026nbsp;\u0026nbsp;|\u0026nbsp;20000\u0026nbsp;\u0026nbsp;|\u0026nbsp;8.94E-01\u0026nbsp;|\n|\u0026nbsp;800000\u0026nbsp;\u0026nbsp;|\u0026nbsp;40000\u0026nbsp;\u0026nbsp;|\u0026nbsp;2.06E+00\u0026nbsp;|\n------------------------------\n|\u0026nbsp;1600000\u0026nbsp;|\u0026nbsp;10000\u0026nbsp;\u0026nbsp;|\u0026nbsp;8.25E-01\u0026nbsp;|\n|\u0026nbsp;1600000\u0026nbsp;|\u0026nbsp;20000\u0026nbsp;\u0026nbsp;|\u0026nbsp;1.85E+00\u0026nbsp;|\n|\u0026nbsp;1600000\u0026nbsp;|\u0026nbsp;40000\u0026nbsp;\u0026nbsp;|\u0026nbsp;4.20E+00\u0026nbsp;|\n------------------------------\n|\u0026nbsp;3200000\u0026nbsp;|\u0026nbsp;10000\u0026nbsp;\u0026nbsp;|\u0026nbsp;1.66E+00\u0026nbsp;|\n|\u0026nbsp;3200000\u0026nbsp;|\u0026nbsp;20000\u0026nbsp;\u0026nbsp;|\u0026nbsp;3.64E+00\u0026nbsp;|\n|\u0026nbsp;3200000\u0026nbsp;|\u0026nbsp;40000\u0026nbsp;\u0026nbsp;|\u0026nbsp;8.30E+00\u0026nbsp;|\n------------------------------\nCommentaire (cliquer pour afficher) On constate bien sur le tableau que pour un $n$ fixé, le temps de calcul de cherche2 semble proportionnel à $p$, et que pour un $p$ fixé, il semble proportionnel à $n$... Quelle est la complexité au meilleur de la fonction cherche ?\na : $O(n)$ b : $O(p)$ c : $O(1)$ Correction (cliquer pour afficher) Le meilleur des cas possible correspond à un mot à cherché placé au tout début du texte. Il faudra alors $p$ comparaisons (la longueur du mot) avant de sortir de la fonction.\nD'où $O(p)$ au meilleur. On peut déterminer ce que fait la fonction cherche en mettant en lumière deux invariants, un pour chaque boucle.\nLa boucle interne a pour invariant \u0026ldquo;b équivaut à s[k:k+i]==m[:i]\u0026rdquo;.\nEt la boucle externe a pour invariant \u0026ldquo;s[j:j+len(m)] != m pour tout j\u0026lt;k\u0026rdquo; car s\u0026rsquo;il y avait égalité, on serait sorti de la boucle avec le return True.\nOn en conclut que si la boucle n’est jamais interrompue par le return True alors m n’est pas un sous-mot de s.\nSi la boucle est interrompue, d’après l’invariant de la boucle intérieure, on a trouvé m dans s.\nCommentaire (cliquer pour afficher) Vous trouverez des exemples de calcul de complexité et une démonstration de correction dans la section recensant les défis algorithmiques ( le défi est souvent de réussir à diminuer la classe de complexité en passant d'un algo naïf à un algo plus malin). "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/concours-blanc/",
	"title": "DS",
	"tags": [],
	"description": "",
	"content": "DS Énoncé TSI1 2022 (durée 2h) : Le fichier pdf\nCorrection : Énoncé TSI2 2022 (durée 3h) : Le fichier pdf\nCorrection : Notebook Colab\nRésultat de PageRank pour le graphe du DS : Résultat pour un web de 100 pages : "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/nombre/",
	"title": "Les nombres en machine",
	"tags": [],
	"description": "",
	"content": "Représentation des nombres Comment un nombre est-il représenté à l\u0026rsquo;intérieur d\u0026rsquo;un ordinateur ?\nL\u0026rsquo;espace pour représenter un nombre en machine est limité. Si cette limitation n\u0026rsquo;a pas trop d\u0026rsquo;impact pour les entiers (surtout en Python !) elle devient très handicapante pour représenter les réels.\nLa représentation machine d\u0026rsquo;un nombre est appelée mot machine. Sa taille est généralement aujourd\u0026rsquo;hui de 64 bits.\nLes différentes bases Une écriture en base $b$ utilise $b$ chiffres différents :\n0, 1, 2, 3, 4, 5, 6, 7, 8 et 9 pour la base décimale 0 et 1 pour la base binaire 0, 1, 2, 3 pour la base 4 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E et F pour la base hexadécimale Un nombre $a$ écrit dans une basse $b$ se note $(a_n a_{n-1}\\cdots a_0)_b$ avec $(a_n a_{n-1}\\cdots a_0)_b = a_n\\times b^n + a_{n-1} \\times b^{n-1}+ \\cdots + a_0 = \\sum\\limits_{i=0}^{n} a_i\\,b^i$\nConversions La conversion d’une base à une autre n’est pas un objectif de formation d\u0026rsquo;après le B.O. Néanmoins, la comparaison et les pièges des algorithmes qui suivent dépassent le simple enjeu de la conversion. Moralité, pas besoin d\u0026rsquo;apprendre par cœur ces algorithmes, mais leur étude est conseillée.\nPour convertir un nombre d\u0026rsquo;une base $b\u0026lt;10$ vers la base 10 : Il suffit de calculer la somme précédente (si $b\u0026gt;10$, il faut en plus donner la valeur des nouveaux chiffres).\nComparaison de deux algorithmes :\nAlgorithme classique : def convbvers10(a: str, b: int) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34; Convertit a de la base b à la base 10 le nombre à convertir a doit être passé en argument sous la forme d\u0026#39;une chaine de caractères \u0026#39;a_n...a_0\u0026#39; b, la base, est un entier inférieur à 10. La fonction retourne un entier en base 10. \u0026#34;\u0026#34;\u0026#34; s = 0 n = len(a)-1 for e in a: s += int(e)*b**n n -= 1 return s convbvers10(\u0026#39;100101101\u0026#39;,2) 301\nconvbvers10(\u0026#39;10231\u0026#39;,4) 301\nMéthode de Horner (qui utilise des multiplications imbriquées) : $a = ((((a_nb+a_{n-1})b+a_{n-2})b+\\cdots)b+a_1)b+a_0$\nImplémentée en Python, cela donne :\ndef convbvers10_Horner(a: str, b: int) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34; Convertit a de la base b à la base 10 en utilisant la méthode de Horner le nombre à convertir a doit être passé en argument sous la forme d\u0026#39;une chaine de caractères \u0026#39;a_n...a_0\u0026#39; b, la base, est un entier inférieur à 10. La fonction retourne un entier en base 10. \u0026#34;\u0026#34;\u0026#34; s = 0 for i in range(0,len(a)): s = s*b + int(a[i]) return s convbvers10_Horner(\u0026#39;100101101\u0026#39;,2) 301\nLequel de ces deux algorithmes est le plus eficace ?\nla fonction Python native int() permet aussi de convertir un nombre écrit dans une base $b$ vers la base décimale en ajoutant $b$ en argument.\nint(\u0026#39;10231\u0026#39;,4) 301\nPour convertir de la base 10 vers la base $b$ : On peut remarquer que le quotient de la division euclidienne de $a=(a_n a_{n-1}\\cdots a_0)_b$ par $b$ vaut $(a_n a_{n-1}\\cdots a_1)_b$ et que le reste vaut $a_0$. De même, le quotient de la division euclidienne de $(a_n a_{n-1}\\cdots a_1)_b$ par $b$ vaut $(a_n a_{n-1}\\cdots a_2)_b$ et le reste vaut $a_1$. Et on continue tant que le quotient est non nul. On obtient ainsi la décomposition de $a$ dans la base $b$.\nUn algorithme en découle naturellement :\ndef conv10versb(a,b) : \u0026#34;\u0026#34;\u0026#34; Arguments : nombre à convertir et base cible la fonction retourne une chaîne de caractère correspondant au nombre a dans la base b. \u0026#34;\u0026#34;\u0026#34; s = \u0026#39;\u0026#39; while a \u0026gt; 0: s = str(a%b) + s # le dernier terme est ajouté à gauche de la chaîne ! a //= b return s conv10versb(301,2) '100101101'\nles fonctions Python natives bin() et hex() permettent de convertir directement un nombre de la base 10 vers les bases respectives 2 et 16 (ces fonctions retournent des chaînes de caractères).\nbin(301,2) '0b100101101'\nUsages des différentes bases La base binaire : C\u0026rsquo;est la base naturelle de l\u0026rsquo;ordinateur. Avec ses deux caractères (0 et 1), c\u0026rsquo;est la seule que peut adresser directement un ordinateur dont la nature même n\u0026rsquo;est qu\u0026rsquo;interrupteurs, passant ou non. Chaque bit est un chiffre binaire.\nEn base 2, les calculs sont facilités et la plupart des algorithmes scolaires des opérations de base marchent, voir sont simplifiés.\nPrenons l\u0026rsquo;exemple de la multiplication : chaque 1 du second facteur décale le premier facteur d\u0026rsquo;autant de rangs que son propre rang dans le second facteur, puis on additionne entre eux tous les différents termes obtenus (on utilisera cette méthode dans l\u0026rsquo;algorithme de multiplication égyptienne du TP8) .\nEn Python, on peut écrire un nombre directement en base 2 si on le précède des caractères 0b.\na = 0b1011011 b = 0b1011 a*b bin(a*b) '0b1111101001'\nLa base hexadécimale : La base 16 joue un rôle particulier en informatique. Pour quelle raison ? L’écriture binaire d’un nombre présente l’inconvénient d’être très longue. Une base plus élevée est à cet égard préférable. Le choix de la base 10 pourrait paraître naturel, mais malheureusement, convertir un nombre de la base 10 à la base 2 ou inversement n’est pas simple. En revanche, nous allons voir que passer de la base 2 à la base 16 est naturel.\nPour écrire un nombre en base 16, nous avons besoin d’un caractère pour chacun des entiers de 0 à 15 ; on complète donc les chiffres de 0 à 9 par les lettres a, b, c, d, e et f.\nAinsi, $(\\text{a})_{16} = 10$, $(\\text{b})_{16} = 11$, $(\\text{c})_{16} = 12$, $(\\text{d})_{16} = 13$, $(\\text{e})_{16} = 14$, $(\\text{f})_{16} = 15$.\nSachant que $2^4 = 16$, tout nombre écrit en base 2 à l’aide de 4 chiffres s’écrit en base 16 à l’aide d’un seul chiffre :\nAussi, pour convertir un nombre quelconque de la base 2 à la base 16, il suffit de regrouper les chiffres qui le composent par paquet de 4 et convertir chacun de ces paquets en un chiffre en base 16.\nPar exemple $(1100\\,0111\\,1110\\,1011)_2$ = $(\\text{c}7\\text{eb})_{16}$.\nUn octet (8 bits) est donc représenté par au plus deux caractères hexadécimaux, ce qui explique l\u0026rsquo;intérêt de cette base (les octets, unité de mémoire, sont partout en informatique).\nExemple : une couleur peut être définie par trois octets représentant ses composantes RVB. Ci-dessous, chaque mot de 3 octets sert aussi à coder la couleur en HTML :\nff0000 00ff00 0000ff aa00aa 777777 a3850e 07ab98 (code HTML du dernier mot : \u0026lt;font color=#07ab98\u0026gt; 07ab98 \u0026lt;/font\u0026gt;)\n$256^3 = 16\\,777\\,216$ couleurs différentes sont ainsi accessibles.\nChoix couleur : Comme pour les nombres binaires, Python permet d\u0026rsquo;écrire directement en base 16 si on précède le nombre des caractères 0x.\n0xd 13\nbin(0xd) '0b1101'\nhex(0b11110111) '0xf7'\nLa plus \u0026ldquo;efficace\u0026rdquo; des bases est la base ternaire, suivie de près par la base binaire (où la notion d\u0026rsquo;efficacité est définie dans l\u0026rsquo;article en lien).\nCodage des nombres entiers en machine Nombres entiers naturels Les entiers naturels sont essentiellement utilisés pour représenter les adresses en mémoire.\nUn mot machine de n bits permet de représenter tous les nombres naturels compris entre 0 et $2^n − 1$. Ainsi, un octet permet de coder les entiers allant de $0 = (00)_{16} = (0000\\,0000)_2$ à $255 = (\\text{ff})_{16} = (1111\\,1111)_2$, et 64 bits (soit 8 octets) tous les nombres allant de $0 = (0000\\,0000\\,0000\\,0000)_{16}$ à $2^{64}−1 = (\\text{ffff}\\,\\text{ffff}\\,\\text{ffff}\\,\\text{ffff})_{16}$.\nNombres entiers relatifs Il faut un bit supplémentaire pour coder le signe. Le premier bit, 0 pour un nombre positif et 1 pour un nombre négatif, est donc réservé.\nAinsi, le plus grand entier relatif représentable sur n bits vaut $2^{n-1}-1$. Pour un processeur 64 bits, cela correspond à $2^{63}-1=(7\\text{fff}\\,\\text{ffff}\\,\\text{ffff}\\,\\text{ffff})_{16}$\n2**63-1 9223372036854775807\ncodage binaire naturel signé La méthode paraissant la plus simple pour coder les nombres relatifs est alors le codage binaire naturel signé : on place le bit de signe devant la valeur absolue de l\u0026rsquo;entier codé normalement sur $n-1$ bits. Par exemple, sur 4 bits, 3 est codé par le mot 0011 et -3 par 1011.\nSimple, oui, mais cela pose 2 problèmes :\nil y a 2 représentations de 0 (les mots 0000 et 1000 sur 4 bits), les opérations arithmétiques ne sont pas faciles (l\u0026rsquo;addition \u0026ldquo;normale\u0026rdquo; de 3 et -3 codés ainsi sur 4 bits donnerait 1110, soit -6\u0026hellip;). complément à 2 La solution qui a été adoptée pour éviter ces problèmes est le complément à 2 :\nCe codage découle du problème posé par l\u0026rsquo;addition précédente : comment faire pour que l\u0026rsquo;addition de 2 nombres opposés vaille 0 ? La solution est d\u0026rsquo;utiliser l\u0026rsquo;absence du bit $n+1$ dans un codage à $n$ bits. Par exemple, à 4 bits, si on additionne $5$ ($0101$) avec $11$ ($1011$), on obtient $16$ ($\\color{red}{1}\\color{green}{0000}$) qui devient $0$ ($\\color{green}{0000}$) puisqu\u0026rsquo;il n\u0026rsquo;y a pas de 5e bit. Il suffit donc d\u0026rsquo;associer 11 à -5, et de la même façon, 8 à -8, 9 à -7, 10 à -6, 12 à -4, 13 à -3, 14 à -2, et 15 à -1.\nDe manière générale, pour un codage sur n bits, les $2^{n-1}$ premiers entiers, tous commençants par 0, sont les entiers positifs et on associe les $2^{n-1}$ entiers suivants, commençant par 1, donc négatifs, de façon à ce qu\u0026rsquo;il complète chaque entier positif à la puissance de 2 supérieure, $2^n$ (d\u0026rsquo;où \u0026ldquo;complément à 2\u0026rdquo;).\nLes nombres négatifs sont donc placés au-dessus plutôt qu\u0026rsquo;en dessous et on peut visualiser ça comme un enroulement sur un cercle des nombres positifs et négatifs.\nEn pratique, si on veut le mot codant -3, il suffit d\u0026rsquo;inverser chaque bit du codage de 3 et d\u0026rsquo;ajouter 1 :\n$0011 \\rightarrow 1100$\n$1100+1 = 1101$\ndonc $-3 \\rightarrow 1101$\nDépassement de capacité : On remarque qu\u0026rsquo;avec ce type de codage, un dépassement de capacité (ou overflow en anglais) ne lèvera pas d\u0026rsquo;erreur, mais aboutira à des valeurs aberrantes.\nSupposons par exemple que l\u0026rsquo;on veuille additionner 5 et 7 sur un codage 4 bits. On obtiendra\u0026hellip; -4 !\nC\u0026rsquo;est un bug de ce type, un overflow, qui a fait exploser la fusée Ariane 5 lors de son vol inaugural (le vol 501) causant la perte de la fusée et de sa charge utile (4 satellites). Ce bug est un des plus coûteux de l\u0026rsquo;histoire (370 millions d\u0026rsquo;euros).\nC\u0026rsquo;est au niveau de la plateforme inertielle (ensemble des capteurs, accéléromètres et gyroscopes, permettant de guider la fusée), héritée de la fusée précédente Ariane 4, que le bug apparut. Plus précisément, c\u0026rsquo;est le capteur d\u0026rsquo;accélération horizontale qui fut débordé pendant sa phase de calibrage (lors des premières 40 s du vol). Codée sur 8 bits, la valeur d\u0026rsquo;accélération maximum représentable était donc de $2^7-1=127$, ce qui était suffisant pour Ariane 4 (valeur max : 64). Mais plus puissante et avec une trajectoire de décollage différente, Ariane 5 engendre des accélérations horizontales qui peuvent être jusqu\u0026rsquo;à 5 fois plus fortes pendant la phase de décollage (valeur max : 300). Cela aboutit à une valeur absurde que le guidage essaya de compenser\u0026hellip; boom.\nEt comble de la frustration : ce calibrage en début de vol était devenu inutile pour Ariane 5.\nQu\u0026rsquo;en est-il de Python ?\nContrairement à la plupart des langages, Python n\u0026rsquo;alloue pas de taille à priori aux entiers. Par conséquent, ils peuvent dépasser la taille maximale adressable par le processeur et sont donc de précision arbitraire, la seule limite étant la taille totale de la RAM.\n2**200 1606938044258990275541962092341162602522202993782792835301376\nSi cela facilité pas mal les opérations arithmétiques sur les grands nombres, cela complique l\u0026rsquo;étude de la complexité, car si un entier prend plusieurs mots mémoires, la plupart de ses manipulations ne sont plus des étapes élémentaires.\nD\u0026rsquo;autre part, certain package très utilisé, et particulièrement NumPy, utilisent des entiers de précision fixée.\nimport numpy as np a = np.array(2**63-1) a.dtype dtype('int64')\nAjouter 1 à a va causer un overflow sans lever d\u0026rsquo;erreurs :\nb = a+1 b -9223372036854775808\na + b -1\nExemple :\nC\u0026rsquo;est bien en utilisant Numpy qu\u0026rsquo;on a été confronté au TP7 au problème du dépassement de capacité. Chaque couleur d\u0026rsquo;une image étant codée sur un octet dans un tableau Numpy, certaines opérations pouvaient provoquer un dépassement et donner des résultats bizarres.\nRevenons sur la conversion d\u0026rsquo;une image couleur avec une profondeur de 24 bits (un octet par couleur) en une image 6 bits (2 bits pour chaque couleur).\nAvec cette méthode, on a bien une image de 6 bits de profondeur mais elle paraît assombrie par rapport à l\u0026rsquo;originale.\nL\u0026rsquo;idée est alors de décaler toutes les valeurs de $2^5$, mais cela provoque un dépassement de capacité !\nPour corriger cela, on peut convertir le tableau en 16 bits avant de lui ajouter $2^5$ puis le reconvertir à la fin en 8 bits :\nimageconvertie = (imageoriginale.astype(np.uint16) // 2**6 * 2**6 + 2**5).astype(np.uint8) Codage des nombres réels en machine Écriture finie ou infinie Un nombre décimal $x$ est un nombre pouvant s\u0026rsquo;écrire sous la forme $\\frac{x}{10^n}$. Son développement décimal s\u0026rsquo;obtient en décomposant $x$ sur les puissances de 10 positives et négatives d\u0026rsquo;exposants allant au maximum jusqu\u0026rsquo;à -n : $\\frac{5}{8}=0,625=\\frac{625}{10^3} = \\frac{6}{10^1}+ \\frac{2}{10^2} + \\frac{5}{10^3}$. Mais la plupart des nombres ne possède pas un développement décimal fini ($\\frac{1}{3}=0,33333\\cdots$ par exemple).\nL\u0026rsquo;équivalent binaire des nombres décimaux correspond aux nombres dyadiques. Ainsi, $\\frac{5}{8}=\\frac{5}{2^3}$ est un nombre dyadique et son développement dyadique s\u0026rsquo;écrit : $\\frac{5}{8}=\\frac{1\\times 2^2+0\\times 2^1+1\\times 2^0}{8}=\\frac{1}{2^1}+\\frac{0}{2^2}+\\frac{1}{2^3}=(0,101)_2$\nComme pour les décimaux, la plupart des nombres ne possèdent pas un développement dyadique fini, mais cela ne correspond pas aux mêmes nombres ! C\u0026rsquo;est le cas par exemple de $0,1$ : $\\frac{1}{10} = (0,0001\\,1001\\,1001\\,1001\\cdots)_2$.\nLa représentation de $0,1$ sera donc nécessairement tronquée par la machine :\n0.1**2 0.010000000000000002\n0.1**2 == 0.01 False\nConclusion : il faut réserver les tests d\u0026rsquo;égalité aux entiers ! Pour les flottants, il faut se restreindre à tester des inégalités.\nAu lieu de vérifier l\u0026rsquo;égalité entre deux flottants, on se borne donc à vérifier qu\u0026rsquo;ils sont suffisamment proches en se fixant un écart minimal faible ($\\varepsilon = 10^{-10}$ par exemple).\nExemple :\nabs(0.1**2 - 0.01) \u0026lt; 1e-10 True\nÉcriture binaire de la partie fractionnaire d\u0026rsquo;un nombre Pour convertir en binaire la partie fractionnaire d\u0026rsquo;un nombre en base 10, rien de plus simple :\non multiplie la partie décimale par 2, si ça dépasse 1, on retire 1 au nombre obtenu, et on ajoute 1 à l\u0026rsquo;écriture binaire sinon, on garde la nombre obtenu, et on ajoute 0 à l\u0026rsquo;écriture binaire puis on recommence en multipliant par 2 le nombre obtenu précédemment. Exemple avec 0,625 :\nL\u0026rsquo;écriture binaire commence par \u0026ldquo;0,\u0026quot;\n$0,625\\times 2 = \\textcolor{red}{1},25$ $\\rightarrow$ \u0026ldquo;$0,\\color{red}1$\u0026rdquo; (on garde $1,25-1 = 0,25$)\n$0,25\\times 2 = \\textcolor{blue}{0},5$ $\\rightarrow$ \u0026ldquo;$0,1\\color{blue}0$\u0026quot;\n$0,5\\times 2 = \\textcolor{red}1$ et comme $1-1=0$, on a fini $\\rightarrow$ \u0026ldquo;$0,10\\color{red}1$\u0026rdquo;\nExemple avec 0,1 :\n$0,1\\times 2 = \\textcolor{blue}{0},2$ $\\rightarrow$ \u0026ldquo;$0,\\color{blue}0$\u0026quot;\n$0,2\\times 2 = \\textcolor{blue}{0},4$ $\\rightarrow$ \u0026ldquo;$0,0\\color{blue}0$\u0026quot;\n$0,4\\times 2 = \\textcolor{blue}{0},8$ $\\rightarrow$ \u0026ldquo;$0,00\\color{blue}0$\u0026quot;\n$0,8\\times 2 = \\textcolor{red}{1},6$ $\\rightarrow$ \u0026ldquo;$0,000\\color{red}1$\u0026rdquo;\t(et on garde $1,6-1 = 0,6$)\n$0,6\\times 2 = \\textcolor{red}{1},2$ $\\rightarrow$ \u0026ldquo;$0,0001\\color{red}1$\u0026rdquo; (on garde $1,2-1 = 0,2$)\n$0,2\\times 2 = \\textcolor{blue}{0},4$ $\\rightarrow$ \u0026ldquo;$0,00011\\color{blue}0$\u0026quot;\n$0,4\\times 2 = \\textcolor{blue}{0},8$ $\\rightarrow$ \u0026ldquo;$0,000110\\color{blue}0$\u0026quot;\n\u0026hellip;\nÉcrire une fonction fractbin(n: float, c: int) -\u0026gt; :str qui donne l\u0026rsquo;écriture fractionnaire en binaire d\u0026rsquo;un nombre décimal n avec c chiffres après la virgule.\nNombres en virgule flottante Nous connaissons la notation scientifique qui normalise tous les nombres décimaux avec une mantisse comprise entre 1 et 9,999… et une puissance de dix restituant la grandeur du nombre.\nLes nombres en virgule flottante (ou au format flottant) peuvent être vus comme l\u0026rsquo;équivalent informatique de la notation scientifique.\nLa notation flottante comprend trois composantes :\nle signe s, la mantisse m, l\u0026rsquo;exposant e de la puissance de b. Un nombre $x$ s\u0026rsquo;écrit donc $x=s\\times m\\times b^e$ où $b$ est la base.\nEn faisant varier l\u0026rsquo;exposant, on fait « flotter » la virgule.\nLe format flottant est le format privilégié pour représenter les nombres décimaux en machine (la base est alors 2 bien sûr).\nNorme IEEE-754 La norme elle-même n\u0026rsquo;est pas à connaître, mais son principe permet de comprendre comment les mots machines correspondant aux flottants sont construits.\nCette norme est actuellement le standard pour la représentation des nombres à virgule flottante en binaire.\nPour une architecture 64 bits, le signe est codé sur 1 bit, l\u0026rsquo;exposant sur 11 et la mantisse sur 52. Le format est alors dit double précision pour le distinguer du simple précision stocké sur 32 bits.\nComme le premier chiffre significatif d\u0026rsquo;un nombre binaire est nécessairement 1, ce 1 n\u0026rsquo;est pas inclus dans les 52 bits de la mantisse. Les 52 bits permettent donc 53 bits de précision grâce à ce bit caché. On dit alors que le flottant est normalisé.\nExemple : comment est représenté le nombre décimal $13256,625$ ?\n$13256,625 = (11001111001000,101)_2 = 1,1001111001000101\\times 2^{13}$\nDonc l\u0026rsquo;exposant vaut 13, et comme on l\u0026rsquo;a dit, on omet le premier 1 dans la mantisse qui s\u0026rsquo;écrit donc :\n$\\color{blue}1001111001000101000000000000000000000000000000000000$ (les 16 bits après le premier 1 de l\u0026rsquo;écriture binaire de $13256,625$ suivis de 36 zéros).\nL\u0026rsquo;exposant est représenté avec un décalage : on lui ajoute $2^{10}-1=1023$.\nCela permet de stocker des exposants allant de $-1022$ à $1023$ sur des valeurs toutes positives allant de $1$ à $2046$.\nDans notre cas, l\u0026rsquo;exposant est représenté avec la valeur $13+1023=1036=10000001100$\nAu final, la représentation au format flottant 64 bits normalisé de $13256,625$ est :\n$\\color{teal}{0}\\;\\color{magenta}{10000001100}\\;\\color{blue}{1001111001000101000000000000000000000000000000000000}$\nElle est exacte.\nPar contre, la représentation de $0,1$ est, elle, tronquée :\n$\\color{teal}{0}\\;\\color{magenta}{01111111011}\\;\\color{blue}{1001100110011001100110011001100110011001100110011010}$\nEn décimal, ce nombre correspond à $0,100000000000000005551115123126$.\nLes soucis des flottants En général, les 53 bits (en incluant le bit caché) permettent 15 chiffres significatifs en décimal ($\\log_{10} 2^{53} = 15,95$).\nTout calcul impliquant un nombre de chiffres plus grands sera sujet à une erreur d\u0026rsquo;arrondi.\nLa limite supérieure de l\u0026rsquo;erreur d\u0026rsquo;approximation relative causée par l\u0026rsquo;arrondi est appelée epsilon de la machine $\\varepsilon$.\nPour Python :\nimport sys eps = sys.float_info.epsilon eps 2.220446049250313e-16\nCette valeur est logiquement $2^{-52}$, la dernière position de la mantisse.\nConséquence de ces arrondis : lors de l\u0026rsquo;addition de deux nombres à l\u0026rsquo;écart relatif très important, il peut y avoir absorption du petit par le grand !\nL\u0026rsquo;addition de flottants n\u0026rsquo;est plus associative.\n(1 + 2.**53) - 2.**53 0.0\n1 + (2**53 - 2**53) 1\nExplication : $1+2^{53} = (1, \\underbrace{000\\cdots000}_\\text{52 zéros}\\,\\color{red}{1}\\color{black}{)_2 \\times 2^{53}} \\Rightarrow$ Le dernier 1 se voit tronqué.\nEt c\u0026rsquo;est pour ça que le code suivant termine !\nx = 1.0 p = 0 while x != x+1: x *= 2 p += 1 print(x) print(p) 9007199254740992.0\n53\nDe plus, la multiplication de flottants n\u0026rsquo;est en général pas distributive.\na, b, c = 100, 0.1, 0.2 a*b + a*c 30.0\na*(b+c) 30.000000000000004\nBeaucoup de calculs en flottants entraînent la perte de chiffres significatifs.\nLes cas les plus spectaculaires intervenant lorsqu\u0026rsquo;on soustrait deux nombres très proches.\nPrenons, pour simplifier, l\u0026rsquo;exemple de flottants décimaux dont la mantisse s\u0026rsquo;écrit sur 6 bits et représentons le calcul dont la forme exacte est :\n$1,2345432 - 1,23451 = 0,0000332$\nNotre système hypothétique est obligé de tronquer le premier terme $1,2345432 \\rightarrow 1,23454$.\nLe résultat de la soustraction donne alors :\n$1,23454 - 1,23451 = 0,00003$ On n\u0026rsquo;a plus qu\u0026rsquo;un seul chiffre significatif alors que le résultat exact avec ses 3 chiffres significatifs pouvait très bien être représenté par notre système à mantisse de 6 bits.\nOn parle alors de catastrophic cancellation.\nMême si les 15 chiffres significatifs des flottants double précision semblent beaucoup, des opérations répétées entraînent une cascade d\u0026rsquo;arrondis qui peuvent aboutir à des résultats dramatiques comme le montre l\u0026rsquo;exemple du missile patriot du TP.\nUne autre conséquence de la manière dont les flottants sont gérés est l\u0026rsquo;existence de valeur minimale et maximale stockable.\nLes calculs bayésiens, par exemple, requièrent de fréquentes multiplications entre petites probabilités. Mais en dessous d\u0026rsquo;une certaine valeur, un soupassement de capacité ou underflow amène le programme à afficher zéro.\nP = 1 for i in range(1,101): if (i\u0026lt;6 or P\u0026lt;1e-306): print(P) elif i == 10: print(\u0026#39;...\u0026#39;) P *= 5e-4 1\n0.0005\n2.5e-07\n1.25e-10\n6.250000000000001e-14\n...\n1.0097419586828971e-307\n5.0487097934146e-311\n2.5243548965e-314\n1.2621776e-317\n6.31e-321\n5e-324\n0.0\nOn voit que la précision est progressivement abaissée avec l\u0026rsquo;affichage de nombres dits subnormaux (ce processus est appelé \u0026ldquo;gradual underflow\u0026rdquo;) avant l\u0026rsquo;affichage de zéro.\\\nLe plus petit nombre qui peut être représenté avec une précision complète est :\nsys.float_info.min 2.2250738585072014e-308\nDe l\u0026rsquo;autre côté, on a la possibilité d\u0026rsquo;un dépassement de capacité ou overflow. Le plus grand nombre affichable est :\nsys.float_info.max 1.7976931348623157e+308\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/projets/bacon/",
	"title": "Nombre de Bacon",
	"tags": [],
	"description": "",
	"content": "Nombre de Bacon On part d\u0026rsquo;un ensemble de 250 films populaires. Pour chaque film, on a la liste des acteurs qui y jouent.\nÀ partir de ces informations, on peut créer un graphe où les sommets sont les films et les acteurs et où une arête lie un acteur à un film dans lequel il joue.\nLe graphe obtenu est biparti car il n\u0026rsquo;y a pas d\u0026rsquo;arête entre les acteurs, ni entre les films, seulement entre sommets de catégories différentes.\nCe graphe va nous permettre de tester l\u0026rsquo;effet « petits mondes » qui consiste à obtenir des distances faibles entre deux sommets quelconques lorsque les graphes sont suffisamment interconnectés. Le graphe est alors gros mais peu large (petit diamètre) !\nLe « nombre de Bacon » d\u0026rsquo;un acteur est le chiffre caractérisé par le degré de séparation qu\u0026rsquo;il a avec Kevin Bacon. C\u0026rsquo;est une application du nombre d\u0026rsquo;Erdős au secteur du cinéma. Plus le chiffre est grand, plus l\u0026rsquo;acteur en question est éloigné de Bacon.\nLe nombre de Bacon de Kevin Bacon lui-même est 0 Le nombre de Bacon d\u0026rsquo;un acteur A ayant tourné directement avec Kevin Bacon est 1 Si le plus nombre de Bacon d\u0026rsquo;un acteur avec qui A a tourné est N, le Bacon number de A est N + 1. Première mission : Créer une fonction qui donne le nombre de Bacon d\u0026rsquo;un acteur A et qui affiche la chaîne \u0026ldquo;acteur A - film A - acteur B - film B - \u0026hellip; - Kevin Bacon\u0026rdquo; sur notre jeu de données restreint.\nPour cela, il faudra d\u0026rsquo;abord créer la matrice d\u0026rsquo;adjacence du graphe ayant pour sommets tous les films et acteurs et dont les arêtes lient un acteur au film dans lequel il joue.\nPuis l\u0026rsquo;idée est d\u0026rsquo;utiliser un parcours en largeur avec une reconstruction de chemin.\nLignes de code pour récupérer les données du fichier dans une liste data (chaque élément de data est une ligne du fichier texte) :\nimport requests response = requests.get(\u0026#34;http://cs.oberlin.edu/~gr151/imdb/imdb.top250.txt\u0026#34;) data = response.text.split(\u0026#39;\\n\u0026#39;) Seconde mission : Toujours grâce à un parcours en largeur, vous recenserez les différents domaines connexes du graphe.\nEnsuite, vous calculerez la distance moyenne d\u0026rsquo;un acteur avec les autres acteurs de son domaine, dans le plus gros des domaines.\n\u0026lt;div style=\u0026quot;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\u0026quot;\u0026gt; \u0026lt;iframe allow=\u0026quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\u0026quot; allowfullscreen=\u0026quot;allowfullscreen\u0026quot; loading=\u0026quot;eager\u0026quot; referrerpolicy=\u0026quot;strict-origin-when-cross-origin\u0026quot; src=\u0026quot;https://www.youtube.com/embed/QCj7VijRkiM?autoplay=0\u0026amp;controls=1\u0026amp;end=0\u0026amp;loop=0\u0026amp;mute=0\u0026amp;start=0\u0026quot; style=\u0026quot;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\u0026quot; title=\u0026quot;YouTube video\u0026quot; \u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; Une solution pour la première mission : Récupération des données :\nimport requests response = requests.get(\u0026#34;http://cs.oberlin.edu/~gr151/imdb/imdb.top250.txt\u0026#34;) data = response.text.split(\u0026#39;\\n\u0026#39;) Fabrication du graphe et de la liste des acteurs :\nLA = {} Acteurs = {} Films = {} for ligne in data[:-1]: acteur,film = ligne.split(\u0026#39;|\u0026#39;) if acteur[-3:] == \u0026#39;(I)\u0026#39;: acteur = acteur[:-4] if acteur not in Acteurs: # utiliser un dictionnaire permet de ne pas passer en O(n^2) Acteurs[acteur] = True if film not in Films: # idem Films[film] = True if acteur not in LA: LA[acteur] = [film] else: LA[acteur] += [film] if film not in LA: LA[film] = [acteur] else: LA[film] += [acteur] print(f\u0026#34;{len(Films)} films où jouent {len(Acteurs)} acteurs.\u0026#34;) 250 films où jouent 12465 acteurs.\nParcours en largeur avec mémorisation des prédécesseurs pour reconstituer ensuite le chemin le plus court :\nfrom collections import deque def parcours_largeur(G,depart,cible): file = deque() file.append((depart,depart)) Parents = {depart : None} Vus_sommet = {} while file: sommet,parent = file.popleft() if not sommet in Vus_sommet: for v in G[sommet]: file.append((v,sommet)) Parents[sommet] = parent Vus_sommet[sommet] = True if sommet == cible: return Parents return None # depart et cible ne sont pas connectés Reconstruction du chemin entre les deux acteurs :\ndef chemin(parents,cible,depart,chem): if cible == depart: return chem chem.append(parents[cible]) return chemin(parents,parents[cible],depart,chem) def rec_chem(parents,cible,depart): chem = [cible] chemin(parents,cible,depart,chem) return chem[::-1] Et au final, le nombre de Bacon n\u0026rsquo;est autre que la moitié de la distance entre Francis Bacon et l\u0026rsquo;autre acteur (ce qui revient au nombre de films qui les séparent) :\ndepart = \u0026#39;Kevin Bacon\u0026#39; cible = \u0026#39;Marilyn Monroe\u0026#39; if cible not in Acteurs: print(f\u0026#34;Pas de {cible} dans la liste...\u0026#34;) else: parents = parcours_largeur(LA,depart,cible) ch = rec_chem(parents,cible,depart) for i in range(0,len(ch)-2,2): print(ch[i]+\u0026#34; - \u0026#34;+ch[i+1]+\u0026#34; - \u0026#34;+ch[i+2]) print(f\u0026#34;distance : {(len(ch)-1)//2}\u0026#34;) Kevin Bacon - Mystic River (2003) - Laurence Fishburne\nLaurence Fishburne - Apocalypse Now (1979) - Marlon Brando\nMarlon Brando - On the Waterfront (1954) - Nehemiah Persoff\nNehemiah Persoff - Some Like It Hot (1959) - Marilyn Monroe\ndistance : 4\nUne solution pour la seconde mission : Le code suivant permet de créer une liste de listes où chaque sous liste est un des domaines connexes.\ndef domaines_connexes(G): Domaines = [] Vus_tous = {} for s in G: if s not in Vus_tous: file = deque() file.append(s) Vus = {} while file: sommet = file.popleft() if not sommet in Vus: file += G[sommet] Vus[sommet] = True Vus_tous[sommet] = True Domaines.append(list(Vus.keys())) assert len(Vus_tous) == len(G) # check qu\u0026#39;on a bien vu tout le monde return Domaines Vérification :\n\u0026gt;\u0026gt;\u0026gt; DOM = domaines_connexes(LA) \u0026gt;\u0026gt;\u0026gt; for i in range(len(DOM)): ... print(f\u0026#34;Taille domaine {i} : {len(DOM[i])}\u0026#34;) Taille domaine 0 : 12035\nTaille domaine 1 : 108\nTaille domaine 2 : 32\nTaille domaine 3 : 33\nTaille domaine 4 : 86\nTaille domaine 5 : 31\nTaille domaine 6 : 150\nTaille domaine 7 : 47\nTaille domaine 8 : 22\nTaille domaine 9 : 49\nTaille domaine 10 : 13\nTaille domaine 11 : 51\nTaille domaine 12 : 38\nTaille domaine 13 : 7\nTaille domaine 14 : 13\nRetirons ensuite du graphe et de la liste des acteurs, tous les sommets qui ne sont pas dans le domaine 0 :\nLA0 = LA.copy() Acteurs0 = Acteurs.copy() Films0 = Films.copy() for i in range(1,len(DOM)): for s in DOM[i]: del LA0[s] if s in Acteurs: del Acteurs0[s] if s in Films: del Films0[s] print(f\u0026#34;Il y a {len(Films0)} films et {len(Acteurs0)} acteurs dans le plus gros domaine connexe.\u0026#34;) Il y a 233 films et 11802 acteurs dans le plus gros domaine connexe.\nComme on n\u0026rsquo;a plus besoin de reconstituer un chemin, écrivons une version simplifiée du parcours en largeur permettant de calculer la distance entre deux acteurs le plus vite possible.\ndef BFS0(G,depart,cible): file = deque() file.append((depart,0)) Vus_sommet = {} while file: sommet,dist = file.popleft() for v in G[sommet]: if v == cible: return (dist+1)//2 if not v in Vus_sommet: Vus_sommet[v] = True file.append((v,dist+1)) Une fonction permettant de trouver la distance moyenne d\u0026rsquo;un acteur aux autres :\ndef distMoy(acteur,G,listeActeurs): \u0026#34;\u0026#34;\u0026#34; précondition : G est connexe, acteur et listeActeurs appartiennent à G \u0026#34;\u0026#34;\u0026#34; listact = list(Acteurs0.keys()) listact.remove(acteur) distMoy = 0 nbPaires = 0 for cible in listact: dist = BFS0(G,acteur,cible) distMoy += dist nbPaires += 1 distMoy = distMoy/nbPaires return distMoy Y a plus qu\u0026rsquo;à :\nActeur = \u0026#34;Tom Cruise\u0026#34; if Acteur not in Acteurs0: print(f\u0026#34;{Acteur} n\u0026#39;est pas présent dans la liste\u0026#34;) else: print(f\u0026#34;La distance entre {Acteur} et un autre acteur du domaine 0 est en moyenne de {distMoy(Acteur,LA0,Acteurs0):.2f}.\u0026#34;) La distance entre Tom Cruise et un autre acteur du domaine 0 est en moyenne de 3.32.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp5recu/",
	"title": "TP 5 : fonctions récursives",
	"tags": [],
	"description": "",
	"content": " Fonctions récursives Cliquez sur cette invitation pour récupérer le repository du TP. import numpy as np import matplotlib.pyplot as plt from matplotlib.patches import Rectangle plt.style.use(\u0026#39;seaborn\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (10, 10) fig, ax = plt.subplots() ax.set_aspect(1) couleurs = plt.rcParams[\u0026#39;axes.prop_cycle\u0026#39;].by_key()[\u0026#39;color\u0026#39;] Visualisation des appels récursifs Installons un module permettant de représenter sous forme de graphe les différents appels récursifs d\u0026rsquo;une fonction.\n%%capture !pip install recursionvisualisation==0.2 On construit une fonction récursive somme(n) qui retourne la somme des n premiers entiers et on utilise un décorateur (fonction qui modifie le comportement d\u0026rsquo;autres fonctions) pour visualiser les différents appels récursifs faits par somme.\nfrom recursionvisualisation import viz, CallGraph cg = CallGraph() @viz(cg) # décorateur def somme(n): if n \u0026lt; 1: return 0 return n + somme(n - 1) print(f\u0026#39;somme(5) = {somme(5)}\u0026#39;) cg.render() somme(5) = 15 On observe l\u0026rsquo;empilement des appels successifs de somme jusqu\u0026rsquo;à ce que le cas de base soit touché. Ces appels forment une pile d\u0026rsquo;exécution (ou pile d\u0026rsquo;appels, \u0026ldquo;call stack\u0026rdquo; en anglais).\nLe cas de base correspond à la première valeur retournée (0 ici) et donc au premier appel retiré de la pile. Tous les appels précédents sont restés en attente.\nOn remonte ensuite chronologiquement la pile des appels avec à chaque fois une nouvelle valeur retournée, jusqu\u0026rsquo;à l\u0026rsquo;appel initial, appelé appel terminal.\nCombien l\u0026rsquo;expression somme(100) va-t-elle provoquer d\u0026rsquo;appels de la fonction somme ?\nCorrection (cliquer pour afficher) 101 Les choses se compliquent si plusieurs appels récursifs sont faits dans la définition de la fonction.\nLe nombre d\u0026rsquo;appels progresse maintenant exponentiellement mais pas la taille de la pile d\u0026rsquo;exécution qui correspond au nombre de niveaux (à la profondeur de l\u0026rsquo;arbre).\ncg = CallGraph() @viz(cg) def fib(n): if n \u0026lt; 2: return n return fib(n-1) + fib(n-2) print(f\u0026#39;{fib(5) = }\u0026#39;) cg.render() fib(5) = 5 Comme on le voit ci-dessus, fib(5) fait 15 appels à la fonction mais la pile ne dépasse jamais 6 appels en attente.\nEn effet, fib(5) appelle fib(4) qui appelle fib(3)qui appelle fib(2) qui appelle fib(1). Comme fib(1) est un des deux cas de base possible, il retourne la valeur 1 et est retiré de la pile. Le dernier appel en attente de la pile est alors fib(2), on y retourne.\nfib(2) fait son deuxième appel : fib(0). fib(0) étant l\u0026rsquo;autre cas de base, il retourne une valeur (0) et est retiré de la pile. fib(2) peut maintenant elle aussi retourner une valeur (1+0) et est à son tour retirée de la pile.\nLe dernier appel en attente est dorénavant fib(3) qui fait maintenant son deuxième appel : fib(1). fib(1) retourne 1 et est retiré de la liste, fib(2) retourne 2 (1+1) et est retirée à son tour, et on remonte à fib(4) qui fait son deuxième appel, fib(2), qui elle-même appelle fib(1), etc.\nQuelle sera la taille maximale de la pile d\u0026rsquo;exécution de fib(100) ?\nCorrection (cliquer pour afficher) 100 Commentaire (cliquer pour afficher)\u0026nbsp; Par contre, le nombre d'appels est bien plus grand (cf. vidéo). Deux tris récursifs Construisons les deux tris récursifs présentés dans la vidéo.\nTri insertion Écrire la fonction insertion qui insert au bon endroit un nombre dans une liste triée afin qu\u0026rsquo;elle reste triée.\ndef insertion(element,Ltriee): \u0026#34;\u0026#34;\u0026#34; insertion(element: nombre, Ltriee: liste de nombres) -\u0026gt; Lsortie: liste de nombres insertion insert \u0026#39;nombre\u0026#39; au bon endroit dans \u0026#39;Ltriee\u0026#39; et retourne cette nouvelle liste. préconditions: \u0026#39;element\u0026#39; est un entier ou un flottant, \u0026#39;Ltriee\u0026#39; est une liste de nombres triée en ordre croissant postconditions: \u0026#39;Lsortie\u0026#39; est triée dans l\u0026#39;ordre croissant (et len(Lsortie)==len(Ltriee)+1) \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Exemple : insertion(5,[-12,1e-2,0,3,18]) doit renvoyer [-12,1e-2,0,3,5,18] .\nCorrection (cliquer pour afficher) def insertion(element,Ltriee): i = 0 while i \u003c len(Ltriee) and element \u003e Ltriee[i]: #inverser les deux conditions provoque une erreur (caractère paresseux de and) i += 1 Lsortie = Ltriee[:i]+[element]+Ltriee[i:] return Lsortie Combien d\u0026rsquo;itérations sont nécessaires dans le pire des cas pour insérer un élément dans une liste de longueur n ?\nA : $n$ B : $2n$ C : $n^2$ Correction (cliquer pour afficher) $n$ Ajouter le cas de base à la fonction tri_insertion :\ndef tri_insertion(liste) : n = len(liste) ### VOTRE CODE else : element = liste[0] reste = liste[1:] return insertion(element,tri_insertion(reste)) # si pas de return dans le else alors tous les appels de tri_insertion avec un len \u0026gt; 1 sont de type None !!! Correction (cliquer pour afficher) def tri_insertion(liste) : n = len(liste) if n == 1 or n == 0 : # cas de base return liste else : element = liste[0] reste = liste[1:] return insertion(element,tri_insertion(reste)) Combien d\u0026rsquo;appels à tri_insertion sont faits au sein de tri_insertion(L) quand L à une taille n ?\nA : $n-1$ B : $2^n$ C : $\\log_2(n)$ Correction (cliquer pour afficher) $n-1$ Tri fusion Écrire la fonction fusion qui fusionne deux listes triées en une seule liste triée.\ndef fusion(Ltrie1,Ltrie2): \u0026#34;\u0026#34;\u0026#34; fusion(Ltrie1: liste de nombres, Ltrie2: liste de nombres) -\u0026gt; liste_sortie: liste de nombres fusion retourne une seule liste ordonnée à partir de deux sous-listes ordonnées. préconditions: Ltrie1 et Ltrie2 sont triées dans l\u0026#39;ordre croissant. postconditions: \u0026#39;Lfus\u0026#39; est triée dans l\u0026#39;ordre croissant (et len(Lfus)==len(Ltrie1)+len(Ltrie2)). \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Exemple : fusion([-12,3.5,18],[-2,15]) doit renvoyer [-12,-2,3.5,15,18].\nCorrection (cliquer pour afficher) def fusion(Ltrie1,Ltrie2) : if Ltrie1 == []: return Ltrie2 elif Ltrie2 == []: return Ltrie1 elif Ltrie1[0] \u003c= Ltrie2[0]: return [Ltrie1[0]] + fusion(Ltrie1[1:],Ltrie2) else: return [Ltrie2[0]] + fusion(Ltrie1,Ltrie2[1:]) Compléter la définition de tri_fusion pour le rendre opérant. Il faut que chaque appel récursif concerne approximativement une moitié de la liste.\ndef tri_fusion(L): n = len(L) if n == 1: return L else: L = fusion(trifusion(L[...]),trifusion(L[...])) return L Correction (cliquer pour afficher) Un découpage en deux parties approximativement égales de la liste est obtenu par L[:n//2] et L[n//2:].\nOn écrit donc\u0026nbsp;:\nL = fusion(trifusion(L[:n//2]),trifusion(L[n//2:])) Supposons que la longueur de la liste L soit une puissance de 2.\nAu niveau de récursivité $j$ (à l\u0026rsquo;appel initial de tri_fusion(L), $j=0$, pour les deux appels à tri_fusion au sein de tri_fusion(L), $j=1$, etc.), on a décomposé le problème initial en \u0026hellip; fusions, chacune opérant sur des sous-listes de taille \u0026hellip; .\nPar quoi faut-il compléter les pointillés respectivement ?\nA : $2^j$ et $2^j$ B : $n/2^j$ et $n/2^j$ C : $2^j$ et $n/2^j$ D : $n/2^j$ et $2^j$ Correction (cliquer pour afficher) On a décomposé le problème initial en $2^j$ fusions, chacune opérant sur des sous-listes de taille $n/2^j$. Algorithme d\u0026rsquo;Euclide Un des plus vieux algorithmes connus, l\u0026rsquo;algorithme d\u0026rsquo;Euclide, suit un raisonnement récursif et s\u0026rsquo;écrit donc naturellement de cette façon.\nPrincipe de l\u0026rsquo;algorithme : le plus grand commun divisieur (pgcd) entre deux nombres a et b est le même que celui entre b et le reste de la division euclidienne de a par b ($a\\pmod b$). Algébriquement, cela donne $\\text{pgcd}(a,b)=\\text{pgcd}(b,a\\pmod b)$.\nOn a donc ainsi réduit le problème initial en un problème plus simple, ce qui permet d\u0026rsquo;appliquer la technique algorithmique diviser pour régner.\nÉcrivez une fonction récursive pgcd permettant de calculer le pgcd entre deux nombres (n\u0026rsquo;oubliez pas le cas de base qu\u0026rsquo;il vous faudra déterminer).\ndef pgcd(a,b): \u0026#34;\u0026#34;\u0026#34; pgcd(a: int,b: int) -\u0026gt; int \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Correction (cliquer pour afficher) def pgcd(a,b): if b == 0: return a else: return pgcd(b,a%b) pgcd(1080,480) 120\nCommentaire (cliquer pour afficher)\u0026nbsp; Une petite vidéo sur l'algorithme d'Euclide\u0026nbsp;:\nUne utilité géométrique du pgcd : le pavage d\u0026rsquo;un rectangle par les plus grands carrés possibles.\nax.clear() a = 1080 b = 480 ax.set_xlim([0, a]) ax.set_ylim([0, b]) ax.add_patch(Rectangle((0,0), a, b, color=\u0026#39;white\u0026#39;)) # Le côté du plus gros carré pavant le rectangle de longueur a et largeur b vaut pgcd(a,b) ! for i in range(a//pgcd(a,b)) : # a//pgcd(a,b) : nombre de carrés dans la longueur for j in range(b//pgcd(a,b)) : # b//pgcd(a,b) : nombre de carrés dans la largeur ax.add_patch(Rectangle((pgcd(a,b)*i, pgcd(a,b)*j), pgcd(a,b), pgcd(a,b),color=couleurs[(i+j)%2])) fig Commentaire (cliquer pour afficher)\u0026nbsp; Une vidéo un peu chargée sur la complexité de l'algorithme d'Euclide\u0026nbsp;:\nDessins récursifs def dessine_cercle(centre,rayon) : theta = np.linspace(0, 2*np.pi, 100) # permet d\u0026#39;avoir 100 valeurs entre 0 et 2pi x0,y0 = centre x = rayon*np.cos(theta)+x0 y = rayon*np.sin(theta)+y0 ax.plot(x, y) ax.fill(x, y) return fig ax.clear() dessine_cercle((4,6),5) # cercle de centre (4,6) et de rayon 5 def cercles(centre,rayon) : dessine_cercle(centre,rayon) if rayon \u0026gt; 0.1 : cercles(centre,rayon*0.9) return fig ax.clear() cercles((10,10),20) Définir une fonction récursive dessin qui affiche l\u0026rsquo;image ci-dessous avec l\u0026rsquo;appel dessin((0,0),20).\ndef dessin(centre,rayon): ### VOTRE CODE return fig Correction (cliquer pour afficher) def dessin(centre,rayon): dessine_cercle(centre,rayon) if rayon \u003e 1: x,y = centre dessin((x+rayon/2,y),rayon/2) dessin((x-rayon/2,y),rayon/2) return fig # La figure qui s\u0026#39;affiche en exécutant cette cellule doit être identique à l\u0026#39;image précédente. ax.clear() dessin((0,0),20) L-système (système de Lindenmayer) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (7, 7) ax.clear() Pour tracer une ligne brisée allant du point $\\left(0;0\\right)$ au point $\\left(2;0\\right)$ en passant par le point $\\left(1;1\\right)$ avec matplotlib, on peut faire l\u0026rsquo;appel suivant à plot :\nax.plot([0, 1, 2], [0, 1, 0]) # [0, 1, 2] sont les valeurs des x # et [0, 1, 0] sont les valeurs des y fig Comme c\u0026rsquo;est plus courant de penser en termes de coordonnées, on va construire une fonction dessine_points qui permet de tracer des lignes joignant une liste de points donnés sous le format (x,y).\nComplétez la définition de dessine_points ci-dessous.\ndef dessine_points(liste_points): \u0026#34;\u0026#34;\u0026#34; précondition: liste_points est une liste de tuples contenant chacun deux nombres (x1,y1),(x2,y2),etc. \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE ax.plot(X,Y) return fig Correction (cliquer pour afficher) def dessine_points(liste_points): X = [M[0] for M in liste_points] Y = [M[1] for M in liste_points] ax.plot(X,Y) return fig # les instructions suivantes doivent afficher le même graphe que plus haut. ax.clear() dessine_points([(0,0),(1,1),(2,0)]) Le \u0026ldquo;graphisme tortue\u0026rdquo; est un style de graphique où on commande le crayon en vue subjective ; on bouge un curseur (la tortue) sur le plan cartésien en retenant systématiquement sa position et sa direction actuelles (où est la tortue et vers où elle est tournée).\nDans la suite, on va faire en sorte de pouvoir envoyer trois ordres à la tortue codés chacun par un caractère :\n'A' : avance d\u0026rsquo;une certaine longueur dans ta direction actuelle '+' : tourne dans le sens des aiguilles d\u0026rsquo;une montre d\u0026rsquo;un certain angle sans avancer '-' : tourne dans le sens inverse des aiguilles d\u0026rsquo;une montre d\u0026rsquo;un certain angle sans avancer On va donc devoir convertir une suite de consignes comme 'A+A-A+A-A' en une liste de points.\nfrom math import pi, sin, cos Compléter la définition de consigne_vers_points de façon à ce que le nouveau point (x_new,y_new) corresponde à une tortue ayant avancé de la distance D dans la direction actuelle depuis (x_old,y_old) (il manque seulement la définition de y_new).\ndef consigne_vers_points(consigne,angle): \u0026#34;\u0026#34;\u0026#34; consigne_vers_points(consigne: string) -\u0026gt; liste_de_points: list precondition: angle est donné en radian postcondition: liste_de_points est une liste de tuples contenant chacun deux nombres \u0026#34;\u0026#34;\u0026#34; liste_de_points = [(0,0)] # point de départ D = 1 # distance de laquelle la tortue avance à chaque F direction = 0 # direction initiale de la tortue (vers la droite) for c in consigne: x_old,y_old = liste_de_points[-1] if c == \u0026#39;A\u0026#39;: # création de x_new et y_new x_new = x_old + D*cos(direction) ### VOTRE CODE liste_de_points.append((x_new,y_new)) elif c == \u0026#39;+\u0026#39;: direction -= angle elif c == \u0026#39;-\u0026#39;: direction += angle return liste_de_points Correction (cliquer pour afficher) Il manque la définition de y_new\u0026nbsp;:\ny_new = y_old + D*sin(direction) L\u0026rsquo;exécution des deux lignes suivantes doit afficher le graphe ci-dessous.\nax.clear() dessine_points(consigne_vers_points(\u0026#39;A-A+A--A-A\u0026#39;,pi/4)) Donner la consigne et l\u0026rsquo;angle permettant de tracer le triangle équilatéral suivant (votre consigne ne devra comprendre que 5 caractères !) : ax.clear() consigne = \u0026#39;...\u0026#39; angle = 0 dessine_points(consigne_vers_points(consigne,angle)) Correction (cliquer pour afficher) consigne = 'A-A-A' angle = 2*pi/3 Ajoutons un jeu de règles capables de transformer une chaîne de caractères.\nImaginons la séquence \u0026lsquo;abca\u0026rsquo; et les règles suivantes :\n'a' -\u0026gt; 'b' 'b' -\u0026gt; 'aba' Alors la séquence \u0026lsquo;abca\u0026rsquo; transformée par la règle devient \u0026lsquo;babacb\u0026rsquo; (\u0026lsquo;c\u0026rsquo; n\u0026rsquo;étant pas touché par la règle, il n\u0026rsquo;est pas modifié).\nConstruisez une fonction transformation prenant en argumant une chaîne de caractères appelée axiome et une règle donnée sous la forme d\u0026rsquo;un dictionnaire et retournant la séquence transformée.\nPour la règle de notre exemple, le dictionnaire serait {'a':'b','b':'aba'}.\ndef transformation(axiome,regle): \u0026#34;\u0026#34;\u0026#34; transformation(axiome: string, regle: dictionnary) -\u0026gt; nvelle_chaine: string \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE axiome = \u0026#39;abca\u0026#39; regle = {\u0026#39;a\u0026#39;:\u0026#39;b\u0026#39;,\u0026#39;b\u0026#39;:\u0026#39;aba\u0026#39;} transformation(axiome,regle) Doit donner 'babacb'.\nCorrection (cliquer pour afficher) def transformation(axiome,regle): nvelle_chaine = '' for car in axiome: if car in regle: nvelle_chaine += regle[car] else: nvelle_chaine += car return nvelle_chaine Faisons maintenant en sorte de pouvoir appliquer la transformation à elle-même :\nsi le niveau de récursivité vaut zéro, on retourne juste l\u0026rsquo;axiome, sinon, on retourne le résultat de la transformation appliquée non plus sur l\u0026rsquo;axiome, mais sur la transformation de l\u0026rsquo;axiome par la règle, et on diminue le niveau d\u0026rsquo;une unité (il faut nécessairement faire en sorte d\u0026rsquo;atterrir sur le cas de base). Complétez la définition de la fonction ci-dessous et testez-la dans la cellule suivante (il ne manque que l\u0026rsquo;appel récursif).\ndef transformation_recu(axiome,regle,niveau): \u0026#34;\u0026#34;\u0026#34; transformation_recu(axiome: string, regle: dictionnary, niveau: int) -\u0026gt; nvelle_chaine: string precondition: niveau doit être un entier positif ! \u0026#34;\u0026#34;\u0026#34; if niveau \u0026gt; 0 : return transformation_recu(...,...,...) else : nvelle_chaine = axiome return nvelle_chaine Correction (cliquer pour afficher) On complète les arguments de transformation_recu\u0026nbsp;:\ntransformation_recu(transformation(axiome,regle),regle,niveau-1) axiome = \u0026#39;aba\u0026#39; regle = {\u0026#39;a\u0026#39;:\u0026#39;b\u0026#39;,\u0026#39;b\u0026#39;:\u0026#39;aba\u0026#39;} for i in range(6): print(transformation_recu(axiome,regle,i)) #doit s\u0026#39;afficher : #aba #babab #abababababa #babababababababababab #abababababababababababababababababababababa #babababababababababababababababababababababababababababababababababababababababababab À partir d\u0026rsquo;un axiome, d\u0026rsquo;une règle de transformation, et de l\u0026rsquo;application récursive de la transformation sur l\u0026rsquo;axiome, on obtient une consigne permettant de faire dessiner des fractales à la tortue !\nPour le flacon de Koch, on part d\u0026rsquo;un triangle équilatéral comme axiome (construit à partir d\u0026rsquo;un angle de π/3 pour les virages de la tortue), et pour chaque segment de droite, on suit la règle de transformation représentée dans le schéma suivant.\nÀ vous de déterminer l\u0026rsquo;axiome et la bonne règle.\naxiome = \u0026#39;...\u0026#39; regle_Koch = {\u0026#39;A\u0026#39;:\u0026#39;...\u0026#39;} Correction (cliquer pour afficher) axiome = 'A--A--A' regle_Koch = {'A':'A+A--A+A'} ax.clear() dessine_points(consigne_vers_points(transformation_recu(axiome,regle_Koch,5),pi/3)) Autre exemple : comment construire une surface 2D à partir d\u0026rsquo;une courbe 1D avec la courbe de Hilbert.\naxiome = \u0026#39;L\u0026#39; regle_Hilbert = {\u0026#39;L\u0026#39;:\u0026#39;-RA+LAL+AR-\u0026#39;,\u0026#39;R\u0026#39;: \u0026#39;+LA-RAR-AL+\u0026#39;} ax.clear() dessine_points(consigne_vers_points(transformation_recu(axiome,regle_Hilbert,6),pi/2)) Autre exemple : un triangle de Sierpinski.\naxiome = \u0026#34;YA\u0026#34; regle = {\u0026#34;X\u0026#34;:\u0026#34;YA+XA+Y\u0026#34;, \u0026#34;Y\u0026#34;:\u0026#34;XA-YA-X\u0026#34;} angle = pi/3 ax.clear() dessine_points(consigne_vers_points(transformation_recu(axiome,regle,7),angle)) Et enfin, une jolie courbe du dragon.\naxiome = \u0026#34;AX\u0026#34; regle = {\u0026#34;X\u0026#34;:\u0026#34;X+YA+\u0026#34;, \u0026#34;Y\u0026#34;:\u0026#34;-AX-Y\u0026#34;} angle = pi/2 ax.clear() dessine_points(consigne_vers_points(transformation_recu(axiome,regle,16),angle)) En donnant de la mémoire à la tortue, on va pouvoir dessiner des branches.\nPour cela, il faut ajouter deux nouvelles consignes à consigne_vers_points_branche :\n'[' : qui ajoute à une liste (la \u0026ldquo;mémoire\u0026rdquo;), la position actuelle de la tortue. ']' : qui permet à la tortue de retourner à la dernière position en mémoire. Voici une implémentation possible d\u0026rsquo;une fonction consigne_vers_points_branche intégrant ces deux nouvelles consignes :\ndef consigne_vers_points_branche(consigne,angle): liste_de_points = [(0,0)] D = 1 direction = pi/2 memoire = [] for c in consigne: x_old,y_old = liste_de_points[-1] if c == \u0026#39;A\u0026#39;: x_new = x_old+D*cos(direction) y_new = y_old+D*sin(direction) liste_de_points.append((x_new,y_new)) elif c == \u0026#39;+\u0026#39;: direction -= angle elif c == \u0026#39;-\u0026#39;: direction += angle elif c == \u0026#39;[\u0026#39;: memoire.append(((x_old,y_old),direction)) elif c == \u0026#39;]\u0026#39;: souvenir = memoire.pop() x_new,y_new = souvenir[0] direction = souvenir[1] liste_de_points.append((float(\u0026#39;nan\u0026#39;),float(\u0026#39;nan\u0026#39;))) liste_de_points.append((x_new,y_new)) return liste_de_points ax.clear() dessine_points(consigne_vers_points_branche(\u0026#39;A[-A]+A\u0026#39;, pi/4)) Reproduisez la figure suivante en définissant la bonne consigne et le bon angle :\nax.clear(ax.clear(`ax.clear(ax.clear(`) consigne = \u0026#39;...\u0026#39; angle = 0 dessine_points(consigne_vers_points_branche(consigne, angle)) draw_circle = plt.Circle((0.5, 2.7), 0.3) ax.add_artist(draw_circle) fig Correction (cliquer pour afficher) consigne = '+A[++++A]-A[A][--A]++A' angle = pi/6 Et en utilisant la récursivité, on peut désormais dessiner de jolis arbres :\naxiome = \u0026#39;P\u0026#39; regle = {\u0026#39;A\u0026#39;: \u0026#39;AA\u0026#39;, \u0026#39;P\u0026#39;: \u0026#39;A[+PA-[P]--P][---P]\u0026#39;} angle = pi*0.11 ax.clear() dessine_points(consigne_vers_points_branche(transformation_recu(axiome,regle,8),angle)) "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/projets/",
	"title": "Projets",
	"tags": [],
	"description": "",
	"content": "Divers projets\net défis algorithmiques Défis Présentation et solutions\nProjets Projet Doomsday Projet Wordle Projet Stéganographie Projet IEEE-754 Projet nombre de Bacon Projet Nim Projet oracle Tournoi d\u0026rsquo;Axelrod "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/projets/nim/",
	"title": "Nim",
	"tags": [],
	"description": "",
	"content": "Jeu de Nim Présentation du jeu et de l\u0026rsquo;algorithme de Bouton :\nMission : Coder une IA qui joue un coup gagnant lorsqu\u0026rsquo;elle est est en position gagnante (en suivant l\u0026rsquo;algorithme de Bouton) et qui joue aléatoirement si elle est sur une position perdante.\nJouer contre une telle IA.\nUn code solution possible : # exemple de plateau : [1,3,5,7] from random import randint def tourIA(plateau): nimSomme = 0 for nb in plateau: nimSomme ^= nb if nimSomme == 0: # position perdante ligne = randint(0,len(plateau)-1) while plateau[ligne] == 0: ligne = randint(0,len(plateau)-1) nbjetons = randint(1,plateau[ligne]) plateau[ligne] -= nbjetons print(f\u0026#34;l\u0026#39;IA en prend {nbjetons} sur la ligne {ligne+1}\u0026#34;) print(plateau) else: compteur = 0 for i in range(len(plateau)): if plateau[i] != 0: ligne = i compteur += 1 if compteur == 1: # s\u0026#39;il ne reste qu\u0026#39;une seule ligne non vide, c\u0026#39;est fini print(f\u0026#34;l\u0026#39;IA en prend {plateau[ligne]} sur la ligne {ligne+1}.\\nLe plateau est vide, vous avez perdu...\u0026#34;) plateau[i] = 0 print(plateau) else: i = 0 while (plateau[i]^nimSomme) \u0026gt; plateau[i]: # on cherche une ligne permettant d\u0026#39;obtenir à nouveau nimSomme=0 i += 1 vieux = plateau[i] plateau[i] = nimSomme^plateau[i] print(f\u0026#34;l\u0026#39;IA en prend {vieux-plateau[i]} sur la ligne {i+1}\u0026#34;) print(plateau) "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp6tri/",
	"title": "TP 6 : algorithmes de tri",
	"tags": [],
	"description": "",
	"content": " Algorithmes de tri Cliquez sur cette invitation pour récupérer le repository du TP. Tous ces algos de tri semblent faire correctement le boulot. Qu'est-ce qui les différencie\u0026nbsp;? Trier c\u0026rsquo;est partir d\u0026rsquo;une structure de données désordonnée et la remettre en ordre.\nLes tris sont omniprésents en informatique et Tim Roughgarden (auteur d\u0026rsquo;Algorithms illuminated) en parle même comme de la \u0026ldquo;mère de tous les problèmes algorithmiques\u0026rdquo;.\nPlusieurs stratégies existent. On va en passer certaines en revue et essayer de trier les algorithmes de tri.\nTris par comparaison La plupart des algorithmes de tri sont dits par comparaison car ils reposent sur des comparaisons deux à deux des éléments de la liste.\nOn a déjà rencontré deux algorithmes de tri par comparaison dans le TP sur la récursivité : le tri par insertion et le tri fusion.\nTri fusion def fusion(L1,L2) : \u0026#34;\u0026#34;\u0026#34; fusion(L1:list,L2:list)-\u0026gt;Lfus:list fusion retourne une seule liste ordonnée à partir de deux sous-listes ordonnées préconditions : L1 et L2 sont triée dans l\u0026#39;ordre croissant postconditions : \u0026#39;Lfus\u0026#39; est triée dans l\u0026#39;ordre croissant (et len(Lfus)==len(L1)+len(L2)) \u0026#34;\u0026#34;\u0026#34; if L1 == [] : return L2 if L2 == [] : return L1 if L1[0] \u0026lt;= L2[0] : # devient instable si \u0026lt; au lieu de \u0026lt;= ! return [L1[0]] + fusion(L1[1:],L2) else : return [L2[0]] + fusion(L1,L2[1:]) def tri_fusion(L) : n = len(L) if n \u0026lt;= 1 : return L else : return fusion(tri_fusion(L[:n//2]),tri_fusion(L[n//2:])) Combien de comparaisons entre deux éléments de la liste effectue l\u0026rsquo;algorithme de tri fusion pour ordonner [1,2,3,4,5,6,7,8] et [8,7,6,5,4,3,2,1] ?\nA : 0 et 8 B : 8 et 16 C : 12 et 12 D : 16 et 8 Vous pouvez trouver la réponse à la main, mais vous pouvez aussi intégrer à fusion une variable globale nb_comp qui est incrémentée à chaque comparaison entre deux éléments de la liste.\nPensez à systématiquement réinitialiser nb_comp à 0 avant chaque appel de tri_fusion, car sinon la valeur continue à courir. C\u0026rsquo;est un des dangers de l\u0026rsquo;utilisation de variables globales dans les fonctions.\nCorrection (cliquer pour afficher) Incorporation d'un compteur de comparaisons dans fusion\u0026nbsp;: def fusion(L1,L2): global nbcomp if L1 == []: return L2 if L2 == []: return L1 if L1[0] \u003c= L2[0]: nbcomp += 1 return [L1[0]] + fusion(L1[1:],L2) else: nbcomp += 1 return [L2[0]] + fusion(L1,L2[1:]) nbcomp = 0 L1 = [1,2,3,4,5,6,7,8] tri_fusion(L1) print(f'nombre de comparaisons pour trier la liste {L1} : {nbcomp}') nbcomp = 0 L2 = [8,7,6,5,4,3,2,1] tri_fusion(L2) print(f'nombre de comparaisons pour trier la liste {L2} : {nbcomp}') S'affiche alors\u0026nbsp;:\nnombre de comparaisons pour trier la liste [1, 2, 3, 4, 5, 6, 7, 8] : 12\nnombre de comparaisons pour trier la liste [8, 7, 6, 5, 4, 3, 2, 1] : 12\nC'était donc la réponse C. Tri par insertion On va écrire une version itérative de l\u0026rsquo;algorithme de tri par insertion.\nSon principe : on compare chacun des éléments i de la liste donnée en argument (à partir du deuxième) à ceux qui le précèdent en remontant la liste un par un (i-1,i-2,etc.). Tant qu\u0026rsquo;un des éléments qui précèdent est plus grand que l\u0026rsquo;élément i, on les permute, jusqu\u0026rsquo;à ce que l\u0026rsquo;élément i soit à la bonne place.\nConstruisez d\u0026rsquo;abord une fonction permute(L,i,j) qui permute les éléments i et j d\u0026rsquo;une liste L.\ndef permute(L,i,j): \u0026#34;\u0026#34;\u0026#34; permute(L: list,i: int,j: int) -\u0026gt; None préconditions: 0 \u0026lt; i,j \u0026lt; len(L) \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE On remarque que la fonction ne retourne rien (de manière assez paradoxale, il y a un objet python correspondant à \u0026ldquo;rien\u0026rdquo; qui s\u0026rsquo;appelle None), mais elle aura bien un effet sur la liste du fait de son caractère mutable.\nOn dit alors que la fonction a un effet de bord (traduction bizarre de side effect qui signifie que la fonction a un effet en-dehors de son environnement local).\nEt pour ce qui est de la liste, on dit qu\u0026rsquo;elle a été modifiée en place, sans avoir eu besoin d\u0026rsquo;en créer une copie.\nCorrection (cliquer pour afficher) def permute(L,i,j): assert -len(L) \u003c= i \u003c len(L) and -len(L) \u003c= j \u003c len(L) L[i], L[j] = L[j], L[i] # Tester tous les cas particulier auxquels vous pensez qui pourraient mettre votre fonction en défaut L = [1,2,3] permute(L,0,2) L Puis complétez la fonction tri_insertion en utilisant permute.\ndef tri_insertion(L): \u0026#34;\u0026#34;\u0026#34; tri_insertion(L: list) -\u0026gt; None \u0026#34;\u0026#34;\u0026#34; for i in range(1,len(L)): j = i X = L[i] while j \u0026gt; 0 and L[j-1] \u0026gt; X: ### VOTRE CODE j -= 1 Correction (cliquer pour afficher) def tri_insertion(L): for i in range(1,len(L)): j = i X = L[i] while j \u003e 0 and L[j-1] \u003e X: permute(L,j,j-1) j -= 1 Commentaire (cliquer pour afficher) Comme permute, tri_insertion ne retourne rien, mais la liste est bien finalement triée.\nRien ne nous empêche d'ailleurs d'ajouter un return L à la fin du code si on veut que la fonction retourne la liste. La cellule de tests suivante permet de comparer le résultat de la fonction tri_insertion à la fonction native de tri sort sur 1000 listes de 10 nombres tirés au hasard entre -5 et 5. Si pas d\u0026rsquo;AssertionError, a priori votre fonction\u0026hellip; fonctionne.\nfrom random import randint for i in range(1000): L_desord = [randint(-5,5) for i in range(10)] L_desord_copie1 = L_desord[:] # attention à ne pas juste écrire L_desord_copie1 = L_desord (copie superficielle) ! L_desord_copie2 = L_desord[:] L_desord_copie1.sort() tri_insertion(L_desord_copie2) assert L_desord_copie1==L_desord_copie2, f\u0026#34;y a un problème avec {L_desord} :\\ndonne {L_desord_copie2}\\nau lieu de {L_desord_copie1}\u0026#34; Combien de comparaisons entre deux éléments de la liste effectue l\u0026rsquo;algorithme de tri insertion pour ordonner [1,2,3,4,5,6,7,8] et [8,7,6,5,4,3,2,1] ?\nA : 7 et 28 B : 0 et 7 C : 28 et 28 D : 5 et 35 Correction (cliquer pour afficher) Incorporation d'un compteur de comparaisons dans tri_insertion (on modifie un peu le code sans changer sa logique pour que le décompte soit plus évident)\u0026nbsp;: def tri_insertion(L): global nbcomp for i in range(1,len(L)): j = i X = L[i] while j \u003e 0: nbcomp += 1 if L[j-1] \u003e X: permute(L,j,j-1) j -= 1 else: break nbcomp = 0 L1 = [1,2,3,4,5,6,7,8] tri_insertion(L1[:]) print(f'nombre de comparaisons pour trier la liste {L1} : {nbcomp}') nbcomp = 0 L2 = [8,7,6,5,4,3,2,1] tri_insertion(L2[:]) print(f'nombre de comparaisons pour trier la liste {L2} : {nbcomp}') S'affiche alors\u0026nbsp;:\nnombre de comparaisons pour trier la liste [1, 2, 3, 4, 5, 6, 7, 8] : 7\nnombre de comparaisons pour trier la liste [8, 7, 6, 5, 4, 3, 2, 1] : 28\nC'était donc la réponse A. Combien de comparaisons entre deux éléments de la liste demande le tri par insertion d\u0026rsquo;une liste de 200 éléments rangés en ordre inverse ?\nCorrection (cliquer pour afficher) On est ici dans le pire des cas possibles pour tri_insertion (liste en ordre inversé)\u0026nbsp;:\npour la $i^e$ des $n-1$ itérations dans la boucle principale, il y a $i$ tours dans le while avec à chaque fois une comparaison.\nLe nombre de comparaisons est donc donné par\u0026nbsp;:\n$\\sum_{i=1}^{n-1} i = n(n-1)/2$, soit ici $200\\times 199/2 = 19900$ Tri par sélection Principe : parmi les éléments de la liste, on cherche le plus petit, et on le permute avec le premier élément. Puis on recommence avec tous les éléments restants (tous moins le premier) : on cherche le plus petit et on le permute avec le deuxième élément. On recommence jusqu\u0026rsquo;à épuiser la liste\nfonction tri_selection(liste L)\nn ← longueur(L)\npour i de 0 à n - 2\nmin ← i\npour j de i + 1 à n - 1\nsi L[j] \u0026lt; L[min], alors min ← j\nfin pour\nsi min ≠ i, alors échanger L[i] et L[min]\nfin pour\nfin fonction\nTraduisez le pseudocode ci-dessus en python.\ndef tri_selection(L): ### VOTRE CODE Correction (cliquer pour afficher) def tri_selection(L): n = len(L) for i in range(n-1): min = i for j in range(i+1,n): if L[j] \u003c L[min]: min = j if min != i: permute(L,i,min) Combien de comparaisons entre deux éléments de la liste effectue l\u0026rsquo;algorithme de tri par sélection pour ordonner [1,2,3,4,5,6,7,8] et [8,7,6,5,4,3,2,1] ?\nA : 7 et 28 B : 0 et 7 C : 28 et 28 D : 5 et 35 Correction (cliquer pour afficher) Incorporation d'un compteur de comparaisons dans tri_selection\u0026nbsp;: def tri_selection(L): global nbcomp n = len(L) for i in range(n-1): min = i for j in range(i+1,n): nbcomp += 1 if L[j] \u003c L[min]: min = j if min != i: permute(L,i,min) nbcomp = 0 L1 = [1,2,3,4,5,6,7,8] tri_selection(L1[:]) print(f'nombre de comparaisons pour trier la liste {L1} : {nbcomp}') nbcomp = 0 L2 = [8,7,6,5,4,3,2,1] tri_selection(L2[:]) print(f'nombre de comparaisons pour trier la liste {L2} : {nbcomp}') S'affiche alors\u0026nbsp;:\nnombre de comparaisons pour trier la liste [1, 2, 3, 4, 5, 6, 7, 8] : 28\nnombre de comparaisons pour trier la liste [8, 7, 6, 5, 4, 3, 2, 1] : 28\nC'était donc la réponse C. Le tri par sélection ressemble beaucoup au tri par insertion. Dans les deux, après k traversées de la liste, les k premiers éléments sont triés. Cependant la différence fondamentale entre les deux algorithmes est le sens dans lequel ces tris s\u0026rsquo;opèrent ; le tri par insertion trie de la fin vers le début alors que le tri par sélection trie du début vers la fin.\nConséquence : dans le tri par sélection, les k premiers éléments de la liste en cours de tri sont les plus petits de la liste entière alors que dans le tri par insertion, ce sont seulement les k premiers éléments d\u0026rsquo;origine qui sont triés.\nLe tri par sélection doit toujours inspecter tous les éléments restant pour trouver le plus petit, tandis que le tri par insertion ne requiert qu\u0026rsquo;une seule comparaison quand le (k+1)e élément est plus grand que le ke ; lorsque c\u0026rsquo;est fréquent (si la liste est déjà partiellement triée), le tri par insertion est bien plus efficace. En moyenne, le tri par insertion nécessite de comparer et décaler la moitié des éléments seulement, ce qui correspond donc à la moitié des comparaisons que le tri par sélection doit faire.\nDans le pire des cas pour le tri par insertion (liste triée en sens inverse), les deux tris opèrent autant d\u0026rsquo;opérations l\u0026rsquo;un que l\u0026rsquo;autre, mais le tri par insertion va nécessiter plus de permutations puisqu\u0026rsquo;il décale toujours d\u0026rsquo;une position voisine à l\u0026rsquo;autre. Le dernier élément d\u0026rsquo;une liste renversée, par exemple, va devoir traverser toute la liste en échangeant sa place avec chacun des éléments qui le précèdent, alors qu\u0026rsquo;avec le tri par sélection, il n\u0026rsquo;y a jamais au plus qu\u0026rsquo;une permutation par élément.\nEn général, le tri par insertion va écrire dans la liste $O(n^2)$ fois (chaque permutation écrit dans la liste), alors que le tri par sélection va écrire seulement $O(n)$ fois. Pour cette raison, le tri par sélection peut être préférable au tri par insertion lorsque l\u0026rsquo;écriture sur la mémoire est significativement plus coûteuse que la lecture (comme sur les EEPROM ou sur les mémoires flash). Ce point est illustré dans l\u0026rsquo;animation interactive du début car limiter les permutations y correspond à limiter les déplacements, ce qui donne l\u0026rsquo;illusion d\u0026rsquo;un algorithme plus rapide.\nTri à bulles Le tri à bulles est surtout à visée pédagogique, il ne sert quasiment jamais réellement. Il tire son nom du fait qu\u0026rsquo;on pousse vers la fin de la liste, de proche en proche, des éléments de plus en plus grands, comme une bulle qui grossit en remontant à la surface.\ndef tri_a_bulles(L): n = len(L) for i in range(n-1): for j in range(n-i-1): if L[j] \u0026gt; L[j+1]: permute(L,j,j+1) return L Combien de comparaisons effectue l\u0026rsquo;algorithme de tri à bulles pour ordonner [1,2,3,4,5,6,7,8] et [8,7,6,5,4,3,2,1] ?\nA : 7 et 28 B : 0 et 7 C : 28 et 28 D : 5 et 35 Correction (cliquer pour afficher) Incorporation d'un compteur de comparaisons dans tri_selection\u0026nbsp;: def tri_a_bulles(L): global nbcomp n = len(L) for i in range(n-1): for j in range(n-i-1): nbcomp += 1 if L[j] \u003e L[j+1]: permute(L,j,j+1) nbcomp = 0 L1 = [1,2,3,4,5,6,7,8] tri_a_bulles(L1[:]) print(f'nombre de comparaisons pour trier la liste {L1} : {nbcomp}') nbcomp = 0 L2 = [8,7,6,5,4,3,2,1] tri_a_bulles(L2[:]) print(f'nombre de comparaisons pour trier la liste {L2} : {nbcomp}') S'affiche alors\u0026nbsp;:\nnombre de comparaisons pour trier la liste [1, 2, 3, 4, 5, 6, 7, 8] : 28\nnombre de comparaisons pour trier la liste [8, 7, 6, 5, 4, 3, 2, 1] : 28\nC'était donc la réponse C. Combien de comparaisons demande le tri à bulles d\u0026rsquo;une liste de 200 éléments rangés en ordre inverse ?\nCorrection (cliquer pour afficher) $19\\,900$ comme pour les autres tris vus jusqu'ici. Tri rapide Le tri rapide n\u0026rsquo;est pas toujours le plus rapide\u0026hellip; Mais il peut l\u0026rsquo;être (surtout sur les grandes listes) !\nC\u0026rsquo;est un algorithme récursif utilisant une partition de la liste à trier.\nSon avantage sur le tri fusion est d\u0026rsquo;être un tri en place.\nDésavantage : il est instable.\nfrom random import randint def partition(L, g, d): p = L[g] i = g+1 for j in range(g+1,d+1): if L[j] \u0026lt; p: permute(L,i,j) i += 1 permute(L,g,i-1) return i-1 def tri_rapide_gd(L, g, d): if g \u0026lt; d: pivot = randint(g,d) permute(L,pivot,g) pivot = partition(L, g, d) tri_rapide(L, g, pivot-1) tri_rapide(L, pivot+1, d) return L Pour ne pas s\u0026rsquo;embêter avec g et d, on peut encapsuler tri_rapide_gd dans une nouvelle fonction dont le seul rôle est d\u0026rsquo;initialiser g et d.\ndef tri_rapide(L): g = 0 d = len(L)-1 tri_rapide_gd(L, g, d) La figure précédente permet de supposer que la complexité dans le pire des cas du tri fusion est égale à sa complexité dans le meilleur des cas et à la complexité en moyenne du tri rapide.\nSur la vidéo qui suit, des danseurs hongrois exécutent une implémentation classique du tri rapide utilisant systématiquement le premier élément comme pivot (et non un élément tiré au hasard) et où la partition marche un peu différemment : le chapeau rouge (élément comparé au pivot) est donné au voisin le plus proche du pivot et quand le pivot récupère le chapeau rouge, il est à la bonne place.\nCommentaire (cliquer pour afficher) Un des défis de la section Projets du site propose d'implémenter cette variante danse hongroise du tri rapide.\nLa fonction de partition à base de chapeau rouge et chapeau noir diffère pas mal de celle écrite plus haut. En levant la contrainte d\u0026rsquo;un tri en place, on escamote lâchement la réelle difficulté et on peut maintenant s\u0026rsquo;affranchir de la fonction de partition, ce qui permet un code bien plus court et clair.\nOn va visualiser les différents appels récursifs d\u0026rsquo;un tel code grâce au module introduit dans le TP précédent.\nfrom recursionvisualisation import viz, CallGraph cg = CallGraph() @viz(cg) def triRapide(elements): if len(elements) \u0026lt;= 1: return elements else: pivot = elements[0] plusPetit = triRapide([e for e in elements[1:] if e \u0026lt;= pivot]) plusGrand = triRapide([e for e in elements[1:] if e \u0026gt; pivot]) return plusPetit + [pivot] + plusGrand print(triRapide(\u0026#34;hanniballecter\u0026#34;)) cg.render() ['a', 'a', 'b', 'c', 'e', 'e', 'h', 'i', 'l', 'l', 'n', 'n', 'r', 't'] Placer le pivot en premier élément a un inconvénient : triRapide devient très lent avec les listes déjà triées (ou quasi triées).\nQuelle sera la taille de la pile d\u0026rsquo;exécution si on donne en argument à triRapide une liste déjà triée de 500 éléments ?\nCorrection (cliquer pour afficher) $500$\nEn effet, le pivot serait sans cesse placé en première position donnant un appel récursif sur une liste vide et l'autre sur une liste avec un élément en moins.\nÉlément par élément, on arrive au cas de base sur le deuxième appel après avoir retiré 499 éléments, ce qui fait 500 appels avec l'appel initial.\nOn peut s\u0026rsquo;en convaincre en dessinant un arbre plus petit :\ntriRapide([1,2,3,4,5]) cg.render() Les tris par comparaison n\u0026rsquo;ont que faire de la nature des éléments de la liste à trier du moment qu\u0026rsquo;on peut les comparer entre eux. On peut ainsi trier tout aussi bien des chaînes de caractères que des flottants.\nPar contre, si les éléments de la liste sont contraints d\u0026rsquo;une façon ou d\u0026rsquo;une autre, on peut essayer de tirer parti de la situation.\nTris non comparatifs Tri par dénombrement (ou par comptage) Si la liste à trier n\u0026rsquo;est constituée que d\u0026rsquo;entiers positifs, on peut mettre au point un tri très rapide n\u0026rsquo;utilisant aucune comparaison : le tri par dénombrement (counting sort).\nPrincipe : on construit un histogramme des valeurs de la liste à trier L dans une liste intermédiaire L_eff.\nSi m est la plus grande valeur des éléments de la liste à trier, alors la taille de L_eff doit valoir m+1. Et on initialise toutes ses valeurs à zéros. Chaque valeur L[i] de la liste à trier est donc aussi un indice de la liste L_eff ! On parcourt ensuite la liste à trier et on incrémente de 1 la valeur de l\u0026rsquo;élément L_eff[L[i]] de la liste intermédiaire. On obtient bien ainsi les effectifs pour chaque valeur de la liste à trier. Il suffit enfin de parcourir L_eff depuis le début et pour chaque élément L_eff[i] non nul, d\u0026rsquo;ajouter à une nouvelle liste L_sortie autant de fois i que la valeur de L[i]. Plus qu\u0026rsquo;à retourner L_sortie. Implémentez la fonction tri_par_denombrement telle qu\u0026rsquo;elle est décrite ci-dessus.\ndef tri_par_denombrement(L,m): \u0026#34;\u0026#34;\u0026#34; tri_par_denombrement(L: list,m: int) -\u0026gt; L_sortie: list m est la valeur maximum des éléments de L \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Correction (cliquer pour afficher) def tri_par_denombrement(L,m): L_eff = [0]*(m+1) # liste des effectifs L_sortie = L.copy() # liste triée n = len(L) for i in range(n): j = L[i] L_eff[j] += 1 k = 0 for i in range(m): for j in range(L_eff[i]): L_sortie[k] = i k += 1 return L_sortie Le nombre d\u0026rsquo;étapes de tri_denombrement peut s\u0026rsquo;écrire en fonction du nombre d\u0026rsquo;éléments n de la liste comme (on considérera que m est une constante) :\nA : $a$ B : $a\\times n + b$ C : $a\\times n^2+b\\times n + c$ D : $a\\times n^3+b\\times n^2 + c\\times n + d$ Correction (cliquer pour afficher) $a\\times n + b$ 1re ligne : m+1 étapes 2e ligne : n étapes 3e ligne : 1 étape 4e ligne - 6e ligne (boucle for) : 2n étapes (2 étapes par itération) 7e ligne : 1 étape 8e ligne - 11e ligne (boucles for imbriquées) : 2n étapes (il y aura en tout n tours dans la boucle intérieur puisqu'on parcourt l'ensemble des effectifs et il s'y trouve deux étapes) Comparer les tris Essayons maintenant de classer ces tris suivant différents critères.\nCommençons par ce qui est souvent le plus critique : leur complexité en temps. À quoi doit-on s\u0026rsquo;attendre lorsque la taille de la liste à trier prend un facteur d\u0026rsquo;échelle ?\nComplexité en temps Le graphe suivant présente le temps mis par les différents algorithmes pour trier des listes de taille croissante.\nOn peut classer ces algorithmes en 3 catégories de complexité temporelle :\nles tris par insertion, sélection et à bulles sont de complexité quadratique ($O(n^2)$) les tris fusion et rapide sont quasilinéaires ($O(n\\log n)$) le tri par dénombrement est linéaire ($O(n)$) Pour des petites listes (et lorsque des tris non comparatifs ne sont pas applicables), le tri par insertion est en moyenne plus rapide que les autres alors que pour des grandes listes, c\u0026rsquo;est le tri rapide qui domine.\nComplexité en espace : en place ou non ? L\u0026rsquo;algorithme a-t-il besoin d\u0026rsquo;utiliser une liste intermédiaire pour opérer son tri ou parvient-il à écrire directement sur la liste d\u0026rsquo;origine ? Dans ce dernier cas, les tri est dit en place.\nDans la liste suivante, affectez à chaque variable correspondant à un algorithme de tri le caractère 'O' si son tri se fait en place ou 'X' sinon.\n# Retirer la mauvaise réponse triinsertion = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; tiselection = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; triabulles = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; trifusion = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; trirapide = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; tridenombrement = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; Correction (cliquer pour afficher) Seuls le tri fusion et le tri par dénombrement ne sont pas en place (le tri rapide l'est même si on a aussi vu une implémentation plus simple qui ne l'était pas).\nStabilité Un algorithme de tri est stable s\u0026rsquo;il conserve l\u0026rsquo;ordre relatif de départ entre deux valeurs égales.\nDans l\u0026rsquo;animation suivante, un algorithme est stable si les deux barres noires et blanches restent toujours dans le même ordre après et avant le tri.\nOn compte le nombre de fois que les caractères \u0026lsquo;r\u0026rsquo;, \u0026lsquo;c\u0026rsquo;, \u0026lsquo;q\u0026rsquo; et \u0026lsquo;p\u0026rsquo; apparaissent dans cette phrase :\n\u0026lsquo;r\u0026rsquo; : 6 \u0026lsquo;c\u0026rsquo; : 5 \u0026lsquo;q\u0026rsquo; : 2 \u0026lsquo;p\u0026rsquo; : 5 On crée à partir de ces données le tuple (('r',6),('c',5),('q',2),('p',5)).\nSi on trie ce tuple selon le premier élément de chacune des paires qu\u0026rsquo;il contient (tri alphabétique), tous les tris donnent le même résultat :\n(('c',5),('p',5),('q',2),('r',6))\nMais si maintenant, on part de ce tuple trié et qu\u0026rsquo;on le trie en fonction des effectifs, les algorithmes ne sont pas tous d\u0026rsquo;accords !\nPour vous en convaincre triez à la main (('c',5),('p',5),('q',2),('r',6)) selon le deuxième élément de chacun des tuples en suivant l\u0026rsquo;algorithme du tri à bulle, puis en suivant l\u0026rsquo;algorithme de tri insertion.\nNotez ci-dessous les tuples obtenus.\n# tuple obtenu avec le tri à bulle (modifiez le tuple pour qu\u0026#39;il corresponde à ce que vous avez trouvé) T1 = ((\u0026#39;c\u0026#39;,5),(\u0026#39;p\u0026#39;,5),(\u0026#39;q\u0026#39;,2),(\u0026#39;r\u0026#39;,6)) # tuple obtenu avec le tri insertion (modifiez le tuple pour qu\u0026#39;il corresponde à ce que vous avez trouvé) T2 = ((\u0026#39;c\u0026#39;,5),(\u0026#39;p\u0026#39;,5),(\u0026#39;q\u0026#39;,2),(\u0026#39;r\u0026#39;,6)) On dit alors que le tri insertion n\u0026rsquo;est pas stable car il ne conserve pas nécessairement l\u0026rsquo;ordre de deux éléments égaux.\ntris instables : le tri sélection et le tri rapide.\ntris stables : le tri insertion, le tri à bulle et le tri fusion Un tri instable peut sans trop de peine être rendu stable, il suffit de garder la trace de l\u0026rsquo;ordre initial pour les éléments égaux, mais cela a un coût !\nL\u0026rsquo;instabilité du tri par sélection peut être éliminée en utilisant une fonction intermédiaire minimum cherchant l\u0026rsquo;indice du plus petit des éléments restant à trier et en ajoutant successivement les éléments trouvés dans une nouvelle liste tout en les retirant de la première liste (on détricote la liste de départ pour retricoter à l\u0026rsquo;endroit la liste triée). Mais l\u0026rsquo;algorithme n\u0026rsquo;est alors plus en place ! On a troqué l\u0026rsquo;instabilité contre de la place mémoire.\nDonnez le code de minimum et tri_selection_stable (avec une contrainte supplémentaire : le bloc de code de tri_selection_stable ne devra pas dépasser 4 lignes). Pour retirer un élément d\u0026rsquo;une liste, vous pouvez regarder ici.\ndef minimum(L): \u0026#34;\u0026#34;\u0026#34; minimum(L: list) -\u0026gt; imin: int imin est l\u0026#39;indice du plus petit élément de la liste et s\u0026#39;il y a plusieurs minimaux, imin est le plus petit des indices \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE # le bloc de code de tri_selection_stable ne devra pas dépasser 4 lignes pour être considéré comme juste. def tri_selection_stable(L) : ### VOTRE CODE Correction (cliquer pour afficher) def minimum(L): imin = 0 for i in range(1,len(L)): if L[i] \u003c L[imin]: imin = i return imin def tri_selection_stable(L): L_sortie = [] for i in range(len(L)): L_sortie.append(L.pop(minimum(L))) return L_sortie On pouvait réduire à 2 lignes avec une construction par compréhension de L_sortie. Commentaire (cliquer pour afficher) Il existe un wiki dédié à l'explication des dessins de xkcd. "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/tp9nombre/",
	"title": "TP 9 : nombres en machine",
	"tags": [],
	"description": "",
	"content": " TP9 : nombres Cliquez sur cette invitation pour récupérer le repository du TP. Exo 1 : nombres palindromiques Déterminer grâce à un code Python le plus petit nombre supérieur ou égal à $10,000$ dont l\u0026rsquo;écriture est palindromique (se lisant pareil dans les deux sens) à la fois en base 10 et en base 2.\n### VOTRE CODE Correction (cliquer pour afficher) a = False b = False i = 10000 while not (a and b): str_i_10 = str(i) str_i_2 = bin(i)[2:] a = str_i_10 == str_i_10[::-1] # i palindromique en base 10 b = str_i_2 == str_i_2[::-1] # i palindromique en base 2 i += 1 print(str_i_10,str_i_2) Saffiche alors\u0026nbsp;:\n15351 11101111110111 # Affectez votre réponse (l\u0026#39;écriture en base 10 du nombre entier trouvé) à la variable nb nb = 3 Correction (cliquer pour afficher) $15\\,351$ Exo 2 : missiles Patriot Une batterie de missiles Patriot détecte les missiles ennemis et les intercepte avec un contre-missile. La batterie mesure le temps pour prévoir le déplacement des missiles ennemis.\nElle dispose d’un compteur (un entier) que nous appellerons c qui compte le nombre de dixièmes de secondes écoulés depuis sa mise en marche. Le temps écoulé t est calculé par l’opération t=c*0.1. Nous nous intéressons à l’erreur de calcul commise lors de cette multiplication.\nD’après un rapport du General Accounting Office, le logiciel du Patriot utilise des nombres à virgule fixe stockés dans un registre de 24 bits.\nLa représentation en virgule fixe utilisée est le format $Q1.23$ où seulement 1 bit est utilisé pour la partie entière et 23 bits le sont pour la partie fractionnaire.\nLa partie fractionnaire d\u0026rsquo;un réel ${x}=x-\\lfloor x\\rfloor$ est stockée sur les 23 bits en la transformant en l\u0026rsquo;entier $\\lfloor {x}\\times 2^{23}\\rfloor$ (où $\\lfloor\\rfloor$ est la partie entière), les chiffres au delà du 23ème après la virgule sont donc tronqués.\nÉcrivez en base 2 le nombre 0,1 en ne gardant que 24 chiffres (23 après la virgule). On notera $z$ le nombre obtenu.\nVous pourrez vous aidez du code suivant (après l\u0026rsquo;avoir modifié de manière adéquate) pour déterminer la réponse ou utiliser la dernière phrase de l\u0026rsquo;énoncé (mais attention alors au petit piège).\na = 2.7 avt = bin(int(a))[2:] + \u0026#39;,\u0026#39; n = a - int(a) apres = \u0026#39;\u0026#39; while len(apres)\u0026lt;9 : n *= 2 if n \u0026gt; 1 : apres += \u0026#39;1\u0026#39; n -= 1 else : apres += \u0026#39;0\u0026#39; print(avt+apres) 10,101100110\n# Affectez à la variable z la chaîne de caractères correspondant à l\u0026#39;écriture binaire demandée : z = \u0026#39;0,...\u0026#39; Correction (cliquer pour afficher) a = 0.1 avt = bin(int(a))[2:] + ',' n = a - int(a) apres = '' while len(apres)\u003c23: n *= 2 if n \u003e 1: apres += '1' n -= 1 else: apres += '0' print(avt+apres) Saffiche alors\u0026nbsp;:\n0,00011001100110011001100 Commentaire (cliquer pour afficher) On aurait aussi pu obtenir l'écriture en moins de lignes en utilisant bin sur $\\lfloor 0,1\\times2^{23} \\rfloor$ (ce qui revient à décaler la virgule de 23 rangs en binaire)\u0026nbsp;: a = bin(int(0.1*2**23))[2:23] # mais attention, il manque des zéros avant ! z = '0,'+'0'*(23-len(a))+a On note $\\varepsilon = |0,1 − z|$. La batterie de missiles Patriot fait une erreur de $\\varepsilon$ en approximant 0,1.\nFaites calculer par Python la valeur de $\\varepsilon$ et affectez cette valeur à une variable epsilon.\n# Vous affecterez la valeur à la variable epsilon epsilon = Correction (cliquer pour afficher) z = '0,00011001100110011001100' eps = abs(0.1*2**23-int(z[2:],2))/2**23 Début février 1991, l’armée israélienne a empiriquement constaté qu’au bout de 8h, la précision des missiles est significativement réduite. Puis, le 25 février 1991, six batteries de missiles Patriot (un bataillon) ont été déployées à Dhahran, en Arabie Saoudite, pendant 100h.\nNous noterons $e_8$ et $e_{100}$ l’erreur commise sur $t$ par la batterie au bout de 8h puis au bout de 100h.\nCalculez des deux erreurs précédentes.\n# Vous affecterez les valeurs aux variables e_8 et e_100 e_8 = e_100 = Correction (cliquer pour afficher) e8 = eps*8*3600*10 e100 = eps*100*3600*10 Un Scud a une vitesse de croisière de 1676 m/s (Mach 5).\nPendant une durée $e_{100}$, de quelle distance $d$ (en m) se déplace un Scud ?\n# Vous affecterez la valeur à la variable d d = Correction (cliquer pour afficher) d = e100*1676 Suite à cette imprécision, un Scud irakien ne fut pas intercepté et causa 28 morts parmi les soldats américains.\nExo 3 : overflows Les 3 \u0026ldquo;évènements\u0026rdquo; suivant correspondent au même bug : un dépassement de capacité d\u0026rsquo;entiers (signés ou non) codés sur 32 bits.\nLa FAA (Federal Aviation Administration) publie en 2015 une Airworthiness Directive ou AD (notification technique que les compagnies aériennes sont obligées de suivre) concernant un bug dans le logiciel des Boeing 787 : \u0026ldquo;This AD was prompted by the determination that a Model 787 airplane that has been powered continuously for 248 days can lose all alternating current (AC) electrical power due to the generator control units (GCUs) simultaneously going into failsafe mode.\u0026rdquo; Le logiciel mesure le temps depuis sa mise en route en incrémentant un compteur toutes les centisecondes. D\u0026rsquo;après les informations fournies et vos réflexions, au bout de combien de centisecondes exactement, la capacité du compteur se trouve dépassée, expliquant le bug ?\n# Vous affecterez la valeur entière à la variable nb_centi nb_centi = Correction (cliquer pour afficher) On cherche un nombre de centisecondes correspondant à 248 jours.\nComme 231 cs correspondent à 248,6 jours, on peut supposer que le nombre de cs est codé en 32 bits signés. En 2004, l\u0026rsquo;oubli d\u0026rsquo;un technicien de rebooter un serveur a provoqué une immense pagaille dans le ciel californien. En effet, le 14 septembre, les aiguilleurs du ciel des aéroports du sud californien ont perdu le contact vocal avec 400 avions pendant plus de 3 heures, heureusement sans graves conséquences (grâce à la réaction rapide des contrôleurs qui ont tout de suite utilisé leurs portables pour contacter d\u0026rsquo;autres centres de contrôle aérien). La maintenance de routine du système de communication consistait à le rebooter tous les 30 jours. Ce système mesure le temps depuis sa mise en route en incrémentant un compteur toutes les millisecondes. D\u0026rsquo;après les informations fournies et vos réflexions, au bout de combien de millisecondes exactement, la capacité du compteur s\u0026rsquo;est trouvée dépassée, expliquant le bug ?\n# Vous affecterez la valeur entière à la variable nb_milli nb_milli = Correction (cliquer pour afficher) On cherche un nombre de millisecondes dépassant les 30 jours (mais pas trop).\nComme 232 ms correspondent à 49,7 jours. On peut supposer que le nombre de ms est codé en 32 bits non signés. Le bug de l\u0026rsquo;an 2038 concerne les horloges des systèmes unix 32 bits dont le temps 0, appelé epoch, est le 1 janvier 1970 à 00:00:00 UT.\nimport time time.gmtime(0) time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=1, tm_isdst=0 Cela montre que les serveurs hébergeant Colab tournent sous Unix.\nAu bout de combien de secondes exactement le problème lié au bug de 2038 se pose ?\n# Vous affecterez la valeur entière à la variable nb_sec = Correction (cliquer pour afficher) On cherche un nombre de secondes correspondant à 68 ans.\nComme 231 s correspondent à 68,05 années. On peut supposer que le nombre de secondes est codé en 32 bits signés. Les overflows peuvent aussi avoir des conséquences plus sympatiques comme la machine à sous d\u0026rsquo;un casino qui a décidé un jour d\u0026rsquo;imprimer un ticket de 42 949 672,96 $ !! Malheureusement pour le gagnant, le casino a refusé de payer sous prétexte que la machine indiquait un prix maximum de 10 000 $ et le tribunal a finalement donné raison au casino\u0026hellip;\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_3/",
	"title": "Semestre 3",
	"tags": [],
	"description": "",
	"content": "Semestre 3 Algorithmique numérique\n$\\rightarrow$ TP11 Extrait du programme :\nBases de données\n$\\rightarrow$ TP12 Extrait du programme :\nDictionnaires et algorithmes pour l\u0026rsquo;intelligence artificielle\n$\\rightarrow$ TP13 Extrait du programme :\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/graphes/",
	"title": "Graphes",
	"tags": [],
	"description": "",
	"content": "Les graphes Quelques points et des traits pour les relier suffisent pour créer un graphe. Cette grande simplicité est pourtant à l\u0026rsquo;origine d\u0026rsquo;un foisonnement mathématiques impressionnant.\nUn peu d\u0026rsquo;histoire L\u0026rsquo;acte de naissance de la théorie des graphes date d\u0026rsquo;une petite énigme à laquelle s\u0026rsquo;attelaient sans succès les habitants de Königsberg. Comment un voyageur pouvait traverser les sept ponts sans jamais passer deux fois sur le même pont ? Euler résout le problème et fonda du même coup la théorie des graphes ! Un graphe permet d\u0026rsquo;extraire l\u0026rsquo;essence du problème : les arêtes sont les ponts et les sommets (ou nœuds) sont les zones accessibles depuis ces ponts (séparées par les bras de rivière).\nLa forme précise des lignes reliant les points n\u0026rsquo;a pas d\u0026rsquo;importance : elles ne font qu\u0026rsquo;indiquer l\u0026rsquo;existance de laison entre ces points (cela illustre le caractère topologique et non géométrique du problème). Euler compris alors que ce qu\u0026rsquo;on appelerait ensuite un chemin eulérien (un chemin reliant chaque sommet en ne passant qu\u0026rsquo;une fois par chaque arête) n\u0026rsquo;est possible que si le graphe ne compte pas plus de deux sommets d\u0026rsquo;où partent un nombre impair d\u0026rsquo;arêtes. Or dans le cas de Königsberg, il part un nombre impair d\u0026rsquo;arêtes de chacun des sept sommets ! Un chemin eulérien y est donc impossible.\nLorsqu\u0026rsquo;on trace un chemin eulérien sur un graphe, trois types de sommets se présentent : un sommet peut être soit un point de départ, soit un point d\u0026rsquo;arrivée, soit un point traversé (on y arrive puis on en repart). Et pour ces derniers, on aura toujours un nombre pair d\u0026rsquo;arêtes (autant d\u0026rsquo;arrivées que de départs)\u0026hellip;\nCe premier pas d\u0026rsquo;Euler eut lieu en 1737, il fallut attendre ensuite plus de cent ans pour que Kirchhoff réutilise des graphes pour déterminer les intensités circulant dans les différentes branches d\u0026rsquo;un circuit électrique ; il met alors au point la notion d\u0026rsquo;arbre, des graphes sans boucle, en 1847.\nDix ans plus tard, c\u0026rsquo;est au tour de la chimie de s\u0026rsquo;attaquer aux graphes. En 1857, Cayley s\u0026rsquo;intéresse aux différentes structures possibles (isomères) d\u0026rsquo;une molécule ayant $n$ atomes de carbone et $2n+2$ atomes d\u0026rsquo;hydrogène (un alcane). Cela revient à trouver tous les arbres à $3n+2$ éléments tels que de chaque élément (chaque sommet) partent exactement une ou quatre arêtes (symbolisant les liaisons chimiques).\nEn 1869, enfin, les mathématiciens redécouvrent les graphes, par la voix de Jordan qui, sans connaître les travaux de Cayley, retrouve ses résultats.\nLes jeux ne sont pas en reste : en 1859, le mathématicien et physicien irlandais William Hamilton invente \u0026ldquo;The Icosian Game\u0026rdquo;, dont le but est de visiter une et une seule fois tous les sommets d\u0026rsquo;un dodécaèdre régulier. Un tel chemin est depuis appelé hamiltonien.\nApparemment voisin du problème du chemin eulérien (visiter une et une seule fois chaque arête), le problème du chemin hamiltonien est en réalité beaucoup plus difficile.\nPour ce qui est du jeu que vous pouvez tester ci-dessous, une règle supplémentaire impose que la fin du chemin soit adjacente à son début. En rejoignant le point de départ, on formerait alors un cycle et on appelle ainsi cycle hamiltonnien un cycle passant par tous les sommets (pour pimenter les choses, un premier joueur choisit 5 sommets voisins les uns des autres et le deuxième joueur doit alors trouver les 15 restants ; c\u0026rsquo;est ça le jeu original d\u0026rsquo;Hamilton1 , et il a prouvé que la victoire est alors toujours possible pour le deuxième joueur).\nLe deuxième moitié du 20e siècle et l\u0026rsquo;avènement de l\u0026rsquo;informatique voit la théorie des graphes prendre son véritable essor : c\u0026rsquo;est en effet l\u0026rsquo;outil idéal pour décrire les réseaux complexes modernes.\nLes réseaux sont partout : les réseaux sociaux et les réseaux de communication, mais on trouve aussi des réseaux dans des champs scientifiques très différents comme en biologie, logistique, linguistique, économie, etc.\nLa théorie des graphes donne un langage commun à la description de ces réseaux.\nVocabulaire Graphes non orientés Un graphe $G$ est un ensemble de sommets (ou nœuds) S (notés $s_i$) et d\u0026rsquo;arêtes A (notées $\\{s_i,s_j\\}$) reliant deux à deux ces sommets. On note un tel graphe : $G = (S,A)$.\nQuelques exemples dans des champs variés :\nRéseau Sommets Arêtes transport aérien aéroports vols plans routiers carrefours tronçons de routes réseau génétique gènes facteurs de transcription cerveau neurones synapses colonie de fourmis jonctions traces de phéromones appels téléphoniques numéro appel réseau de citation auteur citation Est représenté ci-dessus le graphe $G=(S,A)$ avec $S=\\{1,2,3,4,5,6\\}$ et $A=\\{\\{1,2\\},\\{1,5\\},\\{2,5\\},\\{3,3\\},\\{4,6\\}\\}$\nUne boucle est une arête reliant un sommet à lui-même.\nExemple : il y a une boucle sur le sommet $3$.\nL\u0026rsquo;ensemble des sommets adjacents (joints par une arête) au sommet $s_i$, autrement dit les voisins du sommet $s_i$, se note : $Adj(s_i)=\\{s_j \\in S,\\{ s_i,s_j \\}\\in A\\}$.\nExemple : $Adj(2)=\\{1,5\\}$\nUn graphe non orienté est dit simple s\u0026rsquo;il ne comporte pas de boucle et jamais plus d\u0026rsquo;une arête entre deux sommets.\nLe graphe ci-dessus n\u0026rsquo;est donc pas simple.\nOn appelle ordre d\u0026rsquo;un graphe le nombre de ses sommets ($card(S)$ ou plus simplement $|S|$).\nExemple : pour le graphe ci-dessus $|S|=6$\nOn appelle taille d\u0026rsquo;un graphe le nombre de ses arêtes ($card(A)$ ou $|A|$).\nExemple : pour le graphe ci-dessus $|A|=5$\nGraphes orientés Les arêtes d\u0026rsquo;un graphe non orienté sont symétriques, elles se parcourent indifféremment dans les deux sens, mais ce n\u0026rsquo;est pas toujours très pertinent. Considérons les exemples suivants :\nSupposons que l\u0026rsquo;on veuille modéliser un plan routier. On associe naturellement un carrefour à un sommet et une rue à une arête. Mais on a besoin en plus d\u0026rsquo;une notion de direction pour représenter les rues à sens unique. Pour modéliser des relations sociales, une arête entre Alice et Bob modélise un lien, mais comment représenter le fait que Bob connaisse Alice, mais que l\u0026rsquo;inverse soit faux ? Dans un réseau d\u0026rsquo;ordinateur, en particulier sans fil, le lien entre deux nœuds est généralement non symétrique dans le sens où un message peut être envoyé de A vers B, mais pas l\u0026rsquo;inverse. Pour modéliser ce type de situation, on utilise des graphes orientés.\nDans un graphe orienté, les sommets sont reliés par des arcs que l\u0026rsquo;on peut identifier à des couples de sommets (un couple a un ordre) : au couple $(a,b)$ correspond un arc d\u0026rsquo;origine $a$ et d\u0026rsquo;extrémité $b$.\nL\u0026rsquo;arc $a = (s_i,s_j)$ est dit sortant en $s_i$ et incident ou entrant en $s_j$, et $s_j$ est un successeur de $s_i$, tandis que $s_i$ est un prédécesseur de $s_j$.\nL\u0026rsquo;ensemble des successeurs d\u0026rsquo;un sommet $s_i \\in S$ est noté $Succ(s_i) = \\{s_j \\in S,(s_i,s_j) \\in A\\}$.\nL\u0026rsquo;ensemble des prédécesseurs d\u0026rsquo;un sommet $s_i \\in S$ est noté $Pred(s_i) = \\{s_j \\in S,(s_j,s_i) \\in A\\}$.\nUn graphe orienté permet, par exemple, de résumer les relations dans un chi-fou-mi (ici dans la variante puits montrant bien que jouer \u0026ldquo;pierre\u0026rdquo; est sans intérêt, ou encore dans la variante pierre-feuille-ciseaux-lézard-spock de The Big Bang Theory). Pour \u0026ldquo;pierre-feuille-ciseaux-puits\u0026rdquo;, le graphe $G(S,A)$ a pour sommets $S=\\{pierre,feuille,ciseaux,puits\\}$ et pour arêtes $A=\\{(ciseaux,feuille),(feuille,puits),(feuille,pierre),(puits,pierre),(puits,ciseaux),(pierre,ciseaux)\\}$.\nDegré d\u0026rsquo;un sommet Dans un graphe non-orienté, le degré d\u0026rsquo;un sommet $s$ est le nombre d\u0026rsquo;arêtes incidentes à ce sommet (une boucle comptant pour 2).\nDans le cas d\u0026rsquo;un graphe simple, on aura $d(s) = |Adj(s)|$ (nombre de sommets adjacents).\nDans un graphe orienté, le degré sortant d\u0026rsquo;un sommet $s$, noté $d_+(s)$, est le nombre d\u0026rsquo;arcs partant de $s$ (de la forme $(s,v)$ avec $s,v \\in S$).\nDans le cas d\u0026rsquo;un graphe simple, on aura $d_+(s) = |Succ(s)|$ (nombre de successeurs).\nDe même, le degré entrant d\u0026rsquo;un sommet $s$, noté $d_−(s)$, est le nombre d\u0026rsquo;arcs arrivant en $s$ (de la forme $(v, s)$ avec $s,v \\in S$).\nDans le cas d\u0026rsquo;un graphe simple, on aura $d_−(s) = |Pred(s)|$ (nombre de prédécesseurs).\nLe degré d\u0026rsquo;un sommet $s$ d\u0026rsquo;un graphe orienté est donc la somme des degré entrant et sortant : $d(s) = d_+(s) + d_−(s)$.\nExemple : $d_+(puits)=2$ et $d_-(puits)=1$, d\u0026rsquo;où $d(puits) = d_+(puits) + d_−(puits)=2+1=3$\nPour tout graphe, la somme des degrés de chaque sommet est le double du nombre d\u0026rsquo;arêtes. $$\\sum_{s \\in S} d(s) = 2*|A|$$\n$d(puits)=d(feuille)=d(ciseaux)=d(pierre)=3$ d\u0026rsquo;où $\\sum_{s \\in S} d(s) = 12$. Et on a bien $|A|=6$. Et pour un graphe orienté, la somme des degrés entrant vaut la somme des degrés sortants et est aussi égal au nombre d\u0026rsquo;arêtes. $$\\sum_{s \\in S} d_+(s) = \\sum_{s \\in S} d_-(s) = |A|$$\n$d_+$ $d_-$ puits 2 1 feuille 2 1 ciseaux 1 2 pierre 1 2 $\\sum_{s \\in S} d_+(s) =\\sum_{s \\in S} d_-(s) =|A|=6$\nOn en déduit que pour tout graphe, il y a un nombre pair de sommets à degré impair.\nLe degré d\u0026rsquo;un sommet est un concept simple, mais fécond, utilisé dans des contextes très différents. Dans un réseau social, le degré d\u0026rsquo;un sommet traduit l\u0026rsquo;importance d\u0026rsquo;une personne dans le groupe. Dans un réseau de communication comme Internet, on apprend beaucoup sur l\u0026rsquo;organisation réelle du réseau à partir de la distribution obtenue en ordonnant les sommets par leurs degrés.\nChemin, chaîne, cycle et circuit Cas des graphes orientés Soit $G = (S, A)$ un graphe orienté.\nUn chemin d\u0026rsquo;un sommet $u$ vers un sommet $v$ est une séquence $\u0026lt; s_0,s_1,s_2,\u0026hellip;,s_k \u0026gt;$ de sommets tels que $u = s_0$, $v = s_k$ et $(s_{i−1},s_i) \\in A$ pour tout $i \\in \\{1,\u0026hellip;,k\\}$.\nOn dira que le chemin contient les sommets $s_0,s_1,\u0026hellip;,s_k$ et les arcs $(s_0,s_1),(s_1,s_2),\u0026hellip;,(s_{k−1},s_k)$.\nLa longueur du chemin est le nombre d\u0026rsquo;arcs dans le chemin, c\u0026rsquo;est-à-dire $k$.\nS\u0026rsquo;il existe un chemin de $u$ à $v$, on dira que $v$ est accessible à partir de $u$.\nUn chemin $\u0026lt; s_0,s_1,\u0026hellip;,s_k \u0026gt;$ forme un circuit si $s_0 = s_k$ et si le chemin comporte au moins un arc ($k ≥ 1$).\nUne boucle est un circuit de longueur $1$.\n$\u0026lt;6,3,2,1\u0026gt;$ est un chemin du graphe. $\u0026lt;1,5,3,2,1\u0026gt;$ est un circuit. Cas des graphes non orientés Si $G = (S, A)$ est un graphe non orienté, on parlera de chaîne au lieu de chemin, et de cycle au lieu de circuit.\nDans le cas d\u0026rsquo;un cycle, toutes les arêtes doivent être distinctes.\nUn graphe sans cycle est dit acyclique.\nUn arbre est est un graphe acyclique et connexe.\nLa ligne A du RER forme un arbre, mais pas la ligne C.\nDistance dans un graphe La notion de longueur de chemin nous permet ensuite de définir la notion de distance dans un graphe.\nSoit un graphe $G=(S,A)$. La distance d\u0026rsquo;un sommet à un autre est la longueur du plus court chemin/chaîne entre ces deux sommets, ou $\\infty$ s\u0026rsquo;il n\u0026rsquo;y a pas un tel chemin/chaîne :\n$$ \\forall x,y \\in S,d(x,y)=\\left\\lbrace \\begin{array}{ll} k \\; \u0026amp;\\text{si le plus court chemin de x vers y est de longueur k}\\\\ \\infty \u0026amp;\\text{sinon}\\end{array}\\right. $$\nLe diamètre d\u0026rsquo;un graphe est la plus grande distance entre deux sommets.\nExemple : dans le graphe orienté ci-dessus $d(2,3)=2$, $d(3,2)=1$, $d(6,1)=3$ et $d(3,6)=\\infty$.\nDans ce graphe taureau, le diamètre vaut 3 (distance entre les deux cornes).\nConnexité Un graphe non orienté est connexe si chaque sommet est accessible à partir de n\u0026rsquo;importe quel autre (pour tout couple de sommets distincts $(s_i,s_j) \\in S^2$, il existe une chaîne entre $s_i$ et $s_j$).\nLe graphe comportant les sommets $1,2,3,4$ n\u0026rsquo;est pas connexe mais celui comportant les sommets $5,6,7,8$ l\u0026rsquo;est !\nReprésentation d\u0026rsquo;un graphe Listes d\u0026rsquo;adjacence Soit le graphe $G = (S,A)$ d\u0026rsquo;ordre $n$. On suppose que les sommets de $S$ sont numérotés de $1$ à $n$. La représentation par listes d\u0026rsquo;adjacence de $G$ consiste en un tableau $T$ de $n$ listes (un par sommet) :\nPour chaque sommet $s_i \\in S$, la liste d\u0026rsquo;adjacence $T[s_i]$ est une liste de tous les sommets $s_j$ tels qu\u0026rsquo;il existe un arc $(s_i,s_j) \\in A$ ou une arête $\\{s_i,s_j\\} \\in A$.\nAutrement dit, pour chaque sommet, on liste ses voisins accessibles.\nDans chaque liste d\u0026rsquo;adjacence, les sommets sont généralement ordonnés arbitrairement.\nPour l\u0026rsquo;implémentation Python, on peut soit utiliser des listes imbriquées, soit un dictionnaire.\nExemple : # Avec un dictionnaire T = {1:[1,3],2:[1,3,4],3:[],4:[1,2,3,4]} # Avec des listes imbriquées T = [[1,3],[1,3,4],[],[1,2,3,4]] L\u0026rsquo;avantage du dictionnaire est qu\u0026rsquo;il n\u0026rsquo;impose pas d\u0026rsquo;avoir une correspondance entre le numéro du sommet et la position dans la liste d\u0026rsquo;adjacence (dans le cas de listes imbriquées T[0] sera toujours la liste correspondant au premier sommet, T[1], celle du deuxième, etc.).\nTaille mémoire nécessaire: si le graphe G est orienté, la somme des longueurs des listes d\u0026rsquo;adjacence est égale au nombre d\u0026rsquo;arcs de $A$, puisque l\u0026rsquo;existence d\u0026rsquo;un arc $(s_i,s_j)$ se traduit par la présence de $s_j$ dans la liste d\u0026rsquo;adjacence de $T[s_i]$.\nEn revanche, si le graphe n\u0026rsquo;est pas orienté, la somme des longueurs de toutes les listes d\u0026rsquo;adjacence est égale à deux fois le nombre d\u0026rsquo;arêtes du graphe, puisque si $\\{s_i,s_j\\}$ est une arête, alors $s_i$ appartient à la liste d\u0026rsquo;adjacence de $T[s_j]$, et vice versa.\nPar conséquent, la liste d\u0026rsquo;adjacence d\u0026rsquo;un graphe ayant $n$ sommets et $m$ arcs ou arêtes nécessite de l\u0026rsquo;ordre de $O(n + m)$ emplacements mémoire.\nOpérations sur les listes d\u0026rsquo;adjacence : pour tester l\u0026rsquo;existence d\u0026rsquo;un arc $(s_i, s_j)$ ou d\u0026rsquo;une arête $\\{s_i, s_j \\}$, on doit parcourir la liste d\u0026rsquo;adjacence de $T[s_i]$ jusqu\u0026rsquo;à trouver $s_j$.\nEn revanche, le calcul du degré d\u0026rsquo;un sommet, ou l\u0026rsquo;accès à tous les successeurs d\u0026rsquo;un sommet, est très efficace : il suffit de parcourir la liste d\u0026rsquo;adjacence associée au sommet. D\u0026rsquo;une façon plus générale, le parcours de l\u0026rsquo;ensemble des arcs/arêtes nécessite le parcours de toutes les listes d\u0026rsquo;adjacence, et prendra un temps de l\u0026rsquo;ordre de $m$, où $m$ est le nombre d\u0026rsquo;arcs/arêtes.\nLe calcul des prédécesseurs d\u0026rsquo;un sommet n\u0026rsquo;est pas pratique avec cette représentation. Il nécessite le parcours de toutes les listes d\u0026rsquo;adjacences de $T$.\nSi l\u0026rsquo;on a besoin de connaître les prédécesseurs d\u0026rsquo;un sommet, une solution est de maintenir, en plus de la liste d\u0026rsquo;adjacence des successeurs, la liste d\u0026rsquo;adjacence des prédécesseurs.\nMatrice d\u0026rsquo;adjacence Soit le graphe $G = (S,A)$ d\u0026rsquo;ordre $n$. On suppose que les sommets de $S$ sont numérotés de $1$ à $n$. La représentation par matrice d\u0026rsquo;adjacence de $G$ consiste en une matrice booléenne $M=(m_{i,j})$ de taille $n\\times n$ telle que $m_{i,j} = 1$ si $ (i,j) \\in A$, et $m_{i,j} = 0$ sinon.\nLa matrice d\u0026rsquo;adjacence d\u0026rsquo;un graphe non orienté sera toujours symétrique, mais pas nécessairement celle d\u0026rsquo;un graphe orienté.\nImplémentation Python :\nM = [[1,0,1,0],[1,0,1,1],[0,0,0,0],[1,1,1,1]] # pour savoir si un arc joint le sommet 1 au sommet 3 M[0][2] # pour savoir si un arc joint le sommet 3 au sommet 1 M[2][0] Taille mémoire nécessaire : La matrice d\u0026rsquo;adjacence d\u0026rsquo;un graphe ayant $n$ sommets nécessite de l\u0026rsquo;ordre de $O(n^2)$ emplacements mémoire.\nSi le nombre d\u0026rsquo;arcs est très inférieur à $n^2$ (on parle alors de graphe creux), cette représentation est loin d\u0026rsquo;être optimale.\nOpérations sur les matrices d\u0026rsquo;adjacence :\nle test de l\u0026rsquo;existence d\u0026rsquo;un arc ou d\u0026rsquo;une arête avec une représentation par matrice d\u0026rsquo;adjacence est immédiat (il suffit de tester directement la case correspondante de la matrice).\nEn revanche, connaître le degré d\u0026rsquo;un sommet nécessite le parcours de toute une ligne (ou toute une colonne) de la matrice. D\u0026rsquo;une façon plus générale, le parcours de l\u0026rsquo;ensemble des arcs/arêtes nécessite la consultation de la totalité de la matrice, et prendra un temps de l\u0026rsquo;ordre de $n^2$.\nApplication : Combien y a-t-il de chemins menant d\u0026rsquo;un sommet à un autre en exactement $n$ coups ?\nOn cherche donc les chemins de longueur $n$ entre deux sommets $i$ et $j$.\nSoit $M = (m_{i,j})$ la matrice d\u0026rsquo;adjacence d\u0026rsquo;un graphe $G(S,A)$. $M$ est donc aussi le nombre de chemin de $i$ à $j$ de longueur $1$ (une seul arête), que l\u0026rsquo;on va noter $m_{i,j}(1)$.\nL\u0026rsquo;idée est alors de découper le chemin de longueur $n$ en un chemin de longueur $n-1$ suivi d\u0026rsquo;un chemin de longueur $1$. Le nombre $m_{i,j}(n)$ de chemins de longueur $n$ est ainsi donné par : $$ m_{i,j}(n)=\\sum_{k=1}^{|S|}m_{i,k}(n-1)\\times m_{k,j}(1)$$ Pour $ m_{i,j}(2) $, on obtient $m_{i,j}(n)=\\sum_{k=1}^{|S|}m_{i,k}(1)\\times m_{k,j}(1)$ qui n\u0026rsquo;est autre que $M^2$ (on reconnaît en effet la formule du produit matriciel).\nEt par une récurrence immédiate, pour des chemins de longueur $n$, il suffit de calculer $M^n$.\nExemple : combien y a-t-il de chemins de longueur 4 entre les sommets 1 et 3 du graphe représenté ci-dessous. La matrice d\u0026rsquo;adjacence du graphe vaut $M = \\begin{pmatrix}1\u0026amp;1\u0026amp;0\\\\0\u0026amp;0\u0026amp;1\\\\1\u0026amp;1\u0026amp;0\\end{pmatrix}$. Utilisons Python pour calculer $M^4$ :\nimport numpy as np # librairie très utile pour les calculs sur matrices from numpy.linalg import matrix_power M = [[1,1,0],[0,0,1],[1,1,0]] M = np.array(M) # on convertit M en tableau numpy M4 = matrix_power(M,4) print(f\u0026#34;Il y a {M4[2][0]} chemins de longueur 4 du sommet 3 au sommet 1.\u0026#34;) Il y a 3 chemins de longueur 4 du sommet 3 au sommet 1. Quelques comparaisons liste d\u0026rsquo;adjacence matrice d\u0026rsquo;adjacence Déterminer le degrés d\u0026rsquo;un sommet (graphe non orienté) O(1) O(n) Determiner liste des successeurs / degrés sortant O(1) O(n) Determiner liste des prédécesseurs / degrés entrant O(m) O(n) Déterminer si un sommet S est relié directement à un autre O(|Succ(S)|) O(1) Parcours d\u0026rsquo;un graphe Pour déterminer si un sommet est accessible depuis un autre sommet, il faut pouvoir parcourir méthodiquement l\u0026rsquo;ensemble du graphe.\nAlgorithme de parcours en largeur (BFS) Une première méthode, l\u0026rsquo;algorithme de parcours en largeur (breadth-first BFS), consiste à partir d\u0026rsquo;un nœud, d\u0026rsquo;explorer tous ses successeurs, puis les successeurs de chacun de ses successeurs, etc., jusqu\u0026rsquo;à ce qu\u0026rsquo;il n\u0026rsquo;y ait plus de sommets.\nCela revient à inspecter le graphe par couche concentrique de plus en plus éloignées du nœud source.\nPour implémenter un tel algorithme, la structure de données adaptée est la file.\nLes files (queues en anglais) sont des structures dynamiques (les éléments sont enfilés ou défilés) où, à l\u0026rsquo;instar d\u0026rsquo;une file d\u0026rsquo;attente à une caisse, c\u0026rsquo;est le premier arrivé qui est le premier retiré (FIFO pour \u0026ldquo;first in first out\u0026rdquo;). Les files sont utilisées par exemple lorsqu\u0026rsquo;il y a une possibilité d\u0026rsquo;encombrement (pour une imprimante partagée par exemple).\nL\u0026rsquo;idée est de placer chaque nouveau successeur au bout d\u0026rsquo;une file (enfiler), puis de retirer un à un (défiler) les premiers arrivés (donc les plus proches du sommet de départ) lorsqu\u0026rsquo;ils sont à leur tour inspectés.\nPour l\u0026rsquo;implémentation des files, on pourrait utiliser des listes python en ajoutant toujours les éléments à la fin et les retirant au début, mais ce n\u0026rsquo;est pas très efficace. En effet, l\u0026rsquo;ajout d\u0026rsquo;un élément en début de liste à un coût linéaire (proportionnel à la taille de la liste). On aimerant pourtant tirer partie de la structure particulièrement simple des files où seule deux positions (première et dernière) nous intéressent\u0026hellip;\nComme souvent en python, un module dédié, ici collecions.deque, va nous venir en aide. Il implément efficacement les files en permettant un enfilage et un défilage en temps constant.\nG = {\u0026#34;Bob\u0026#34; : [\u0026#34;Alice\u0026#34;,\u0026#34;Dave\u0026#34;,\u0026#34;Charlie\u0026#34;], \u0026#34;Alice\u0026#34; : [\u0026#34;Elisa\u0026#34;], \u0026#34;Charlie\u0026#34; : [\u0026#34;Elisa\u0026#34;,\u0026#34;Hector\u0026#34;], \u0026#34;Dave\u0026#34; : [\u0026#34;Farid\u0026#34;,\u0026#34;Gus\u0026#34;], \u0026#34;Elisa\u0026#34; : [], \u0026#34;Farid\u0026#34; : [], \u0026#34;Gus\u0026#34; : [], \u0026#34;Hector\u0026#34; : [] } from collections import deque # préconditions: on a besoin d\u0026#39;un graphe G(S,A) représenté par une liste d\u0026#39;adjacence implémentée par un dictionnaire et d\u0026#39;un sommet s de S # postconditions : un sommet est accessible depuis s si et seulement si il est marqué comme \u0026#34;vu\u0026#34; def parcours_largeur(G,depart): file = deque() file.append(depart) Vus = {s : False for s in G} Sommets = [] while file: # tant que la file n\u0026#39;est pas vide sommet = file.popleft() # méthode de la classe deque permettant de défiler (équivaut à pop(0) sur une liste) if not Vus[sommet]: # évite ici d\u0026#39;avoir 2 Elisa, mais ça peut être bien pire file += G[sommet] Vus[sommet] = True Sommets.append(sommet) return Sommets parcours_largeur(G,\u0026quot;Bob\u0026quot;) renvoie ['Bob', 'Alice', 'Dave', 'Charlie', 'Elisa', 'Farid', 'Gus', 'Hector']. Si on ne marque pas les sommets vus (ici grâce au dictionnaire Vus), on se retrouve avec une boucle infinie dès qu\u0026rsquo;il y a un circuit ou un cycle (le simple graphe 🦉⇆🐘 par exemple).\nExemples d\u0026rsquo;applications du parcours en largeur :\nutilisé par les robots d\u0026rsquo;exploration des moteurs de recherche pour construire l\u0026rsquo;index des pages web, recherche dans les réseaux sociaux, recherche d\u0026rsquo;un nœud voisin accessible dans les réseaux peer-to-peer. Algorithme de parcours en profondeur (DFS) L\u0026rsquo;idée de l\u0026rsquo;algorithme de parcours en profondeur (depth-first search DFS) est d\u0026rsquo;explorer jusqu\u0026rsquo;au bout chaque chaîne de successeurs du nœud source avant de passer à la suivante.\nOn n\u0026rsquo;explore alors plus par couches concentriques mais par branches.\nLa structure de données dynamique adaptée est cette fois-ci la pile.\nLes piles (stacks en anglais) sont des structures dynamiques (des éléments sont ajoutés = empilés, ou retirés = dépilés) ayant la propriété que l’élément extrait est celui qui y a été introduit le plus récemment (\u0026ldquo;dernier entré, premier sortie\u0026rdquo; ou LIFO \u0026ldquo;last in first out\u0026rdquo; en anglais). C\u0026rsquo;est l\u0026rsquo;équivalent informatique d\u0026rsquo;une pile d\u0026rsquo;assiettes. Cette structure est par exemple utilisée dans la fonction \u0026ldquo;annuler\u0026rdquo; (CTR-Z) d\u0026rsquo;un logiciel ou encore dans le traitement des fonctions récursives.\ndef parcours_profondeur(G,depart): pile = deque() pile.append(depart) Vus = {s : False for s in G} Sommets = [] while pile: sommet = pile.pop() if not Vus[sommet]: pile += G[sommet] Vus[sommet] = True Sommets.append(sommet) return Sommets parcours_profondeur(G,\u0026quot;Bob\u0026quot;) renvoie ['Bob', 'Charlie', 'Hector', 'Elisa', 'Dave', 'Gus', 'Farid', 'Alice'].\nExemples d\u0026rsquo;applications du parcours en profondeur :\ntrouver un chemin entre deux sommets, détection de cycles dans un graphe, utilisé dans le tri topologique, trouver la sortie d\u0026rsquo;un labyrinthe. La complexité des deux algorithmes est en $O(n+m)$ où $n =|S|$ et $m = |A|$.\nEn effet, la pile ou la file voit passer tous les successeurs ou adjoints de chaque sommet, ce qui correspond aux m arcs pour les successeurs et 2m pour les arêtes qui sont parcourues dans les deux sens. Comme chaque ajout et enlèvement de sommet se fait en $O(1)$, l\u0026rsquo;enfilement et défilement complet ainsi que l\u0026rsquo;empilement et dépilement complet sont en $O(m)$.\nEn plus de ces opérations, on modifie Vus et on construit Sommets, ce qui représente $O(n)$ nouvelles opérations.\nQue deviendrait la complexité si on remplaçait l\u0026rsquo;utilisation d\u0026rsquo;un dictionnaire par celle d\u0026rsquo;une liste pour vérifier qu\u0026rsquo;un sommet a déjà été traîté (on utiliserait alors if sommet not in Sommets plutôt que if not Vus[sommet]) ? Que deviendrait la complexité sans l\u0026rsquo;utilisation de la classe deque fournissant une vraie file/pile ? Structures de données On remarque que les deux algorithmes de parcours d\u0026rsquo;un graphe (BFS et DFS) ne diffèrent que par la structure de données utilisée. Et loin d\u0026rsquo;être anodin, ce passage de la file à la pile change complètement le principe du parcours !\nCela illustre bien que la conception d\u0026rsquo;un algorithme est intimement liée aux structures de données envisagées.\nUne structure de donnée est une façon d\u0026rsquo;organiser les données de telle sorte que certaines opérations sur ces données (les primitives) soient très rapides. Une structure de données est donc spécialisée dans ces quelques opérations.\nLors de la conception d\u0026rsquo;un algorithme, l\u0026rsquo;identification des différentes opérations à effectuer va guider le choix de la structure de données adaptée.\nPar exemple, l\u0026rsquo;algorithme de recherche en largeur doit gérer un ensemble où le premier élément ajouté doit toujours être le premier retiré (logique FIFO) $\\rightarrow$ utilisation d\u0026rsquo;une file qui gère l\u0026rsquo;ajout d\u0026rsquo;un élément à la fin d\u0026rsquo;une file d\u0026rsquo;attente et l\u0026rsquo;extraction au début en temps constant (elle est optimisée pour ça, mais en contrepartie, elle ne sait faire que ça).\nL\u0026rsquo;algorithme de recherche en profondeur suit lui la logique LIFO $\\rightarrow$ utilisation d\u0026rsquo;une pile.\nDernier exemple : l\u0026rsquo;algorithme de Dijkstra (décrit plus loin) a besoin à chaque itération d\u0026rsquo;ajouter un élément à un ensemble et d\u0026rsquo;en retirer le plus petit élément $\\rightarrow$ la file de priorité est la structure spécialisée dans ses opérations (dans quels autres algorithmes le tas pourrait-il être utilisé avantageusement ?).\nNous n\u0026rsquo;avions pas réellement besoin de la classe deque pour implémenter efficacement la pile. En effet, si insérer un élément au début d\u0026rsquo;une liste python de taille $n$ a bien un coût linéaire ($O(n)$) et ralentit donc l\u0026rsquo;exécution par rapport à l\u0026rsquo;utilisation d\u0026rsquo;une file, retirer un élément à la fin (via pop) se fait en temps constant ($O(1)$).\nEn pratique, on a utilisé dans les deux codes exactement le même objet, présent dans le module standard collections : deque().\ndeque() (qui se prononce comme deck) est l\u0026rsquo;implémentation d\u0026rsquo;une file d\u0026rsquo;attente à double extrémité (double-ended queue). Elle permet d\u0026rsquo;ajouter et retirer efficacement (en temps constant) des éléments aux deux extrémités. On peut donc bien à la fois s\u0026rsquo;en servir comme une file ou comme une pile.\nOn peut aussi utiliser deque() comme une liste python normale, mais l\u0026rsquo;accès d\u0026rsquo;un élément via son indice est alors inefficace (il ne se fait pas en temps constant). C\u0026rsquo;est la contrepartie de l\u0026rsquo;optimisation des opérations sur les extrémités\u0026hellip;\nPour optimiser l\u0026rsquo;ajout et l\u0026rsquo;enlèvement aux extrémités, l\u0026rsquo;objet deque() utilise une liste doublement chaînée (chaque élément est stocké en mémoire avec deux pointeurs : un vers l\u0026rsquo;élément précédent et un vers le suivant).\nLa dernière note permet de pointer la distinction entre une structure de données abstraite (ou plutôt type de données abstrait TDA) et son implémentation :\nUne liste doublement chaînée peut implémenter à la fois le TDA file ou pile.\nUn tas (arbre binaire presque complet ordonné) permet d\u0026rsquo;implémenter le TDA file de priorité.\nGraphes pondérés Dans de nombreuses situations, les arêtes d\u0026rsquo;un graphe ne sont pas toutes équivalentes. On ajoute alors l\u0026rsquo;information du \u0026ldquo;coût\u0026rdquo; que cela représente d\u0026rsquo;emprunter telle ou telle arête. On appelle poids ces valeurs ajoutées aux arêtes/arcs.\nPar exemple, pour modéliser un réseau ferroviaire, on peut attribuer à chaque arête modélisant les jonctions entre deux gares la distance correspondante. Et pour un réseau de communication, le poids d\u0026rsquo;une arête correspondra plutôt au temps nécessaire pour transférer un message de taille élémentaire.\nOn obtient alors un graphe pondéré.\nOn utilise par exemple des graphes pondérés, plus particulièrement des arbres de probabilité (où chaque branche est affublée d\u0026rsquo;une probabilité) pour calculer des probabilités conditionnelles.\nExemple : Très souvent (particulièrement pour les réseaux de communication), l\u0026rsquo;information ajoutée au graphe est un temps ou une distance et se pose alors le problème de l\u0026rsquo;optimisation d\u0026rsquo;un trajet entre deux sommets.\nLe poids d\u0026rsquo;un chemin est la somme des poids des arcs empruntés.\nLa distance entre deux sommets (dans un graphe pondéré) correspond au chemin de poids minimum entre ces deux sommets.\nProblème du plus court chemin Pas au programme de TSI mais plus prudent d\u0026rsquo;en avoir entendu parler pour l\u0026rsquo;épreuve de Centrale qui jusqu\u0026rsquo;à maintenant était commune aux autres sections.\nSi le graphe considéré n\u0026rsquo;est pas pondéré, l\u0026rsquo;algorithme de parcours en largeur, moyennant quelques adaptations, est tout à fait capable de faire le travail.\nAlgorithme de parcours en largeur Comme l\u0026rsquo;algorithme de parcours en largeur examine le graphe en couches concentriques depuis le sommet de départ, lorsqu\u0026rsquo;il parvient au sommet cible, on est sûr que le nombre d\u0026rsquo;arcs est minimal.\nIl suffit alors de joindre à la liste des sommets examinés, la liste des chemins permettant de parvenir à chacun de ces sommets (en incrémentant à chaque tour chacun des chemins du sommet correspondant de la nouvelle couche).\ndef recherche_largeur(G,depart,arrivee): file = [(depart,[depart])] # on remplace la file des sommets par une file de tuples (sommet,chemin) Vus = {s : False for s in G} while file: sommet,chemin = file.pop(0) # pop(0) fait la même chose que le popleft des deque if sommet == arrivee: return chemin # si l\u0026#39;arrivée est atteinte, on retourne le chemin correspondant if not Vus[sommet]: for s in G[sommet]: nv_chemin = chemin+[s] file.append((s,nv_chemin)) Vus[sommet] = True return False # si l\u0026#39;arrivée n\u0026#39;est pas atteinte, on renvoie Faux G = {\u0026#34;Minimes\u0026#34; : {\u0026#34;Tasdon\u0026#34;,\u0026#34;Hôpital\u0026#34;}, \u0026#34;Hôpital\u0026#34; : {\u0026#34;Verdun\u0026#34;}, \u0026#34;Verdun\u0026#34; : {\u0026#34;Stade\u0026#34;}, \u0026#34;Tasdon\u0026#34; : {\u0026#34;Cognehors\u0026#34;, \u0026#34;Lafond\u0026#34;}, \u0026#34;Cognehors\u0026#34; : {\u0026#34;Verdun\u0026#34;}, \u0026#34;Lafond\u0026#34; : {\u0026#34;Mireuil\u0026#34;}, \u0026#34;Mireuil\u0026#34; : {\u0026#34;Stade\u0026#34;}, \u0026#34;Stade\u0026#34; : {} } recherche_largeur(G,\u0026quot;Minimes\u0026quot;,\u0026quot;Stade\u0026quot;) retourne bien le chemin comportant le moins d\u0026rsquo;arêtes : ['Minimes', 'Hôpital', 'Verdun', 'Stade'].\nMais si on ajoute des poids, l\u0026rsquo;algorithme de recherche en largeur devient inefficace puisqu\u0026rsquo;il se borne à donner la même réponse (les pondérations sont nulle part prises en compte !).\nG_pond = {\u0026#34;Minimes\u0026#34; : {\u0026#34;Tasdon\u0026#34;: 5,\u0026#34;Hôpital\u0026#34;: 4}, \u0026#34;Hôpital\u0026#34; : {\u0026#34;Verdun\u0026#34;: 21}, \u0026#34;Verdun\u0026#34; : {\u0026#34;Stade\u0026#34;: 4}, \u0026#34;Tasdon\u0026#34; : {\u0026#34;Cognehors\u0026#34;: 7, \u0026#34;Lafond\u0026#34;: 7}, \u0026#34;Cognehors\u0026#34; : {\u0026#34;Verdun\u0026#34;: 8}, \u0026#34;Lafond\u0026#34; : {\u0026#34;Mireuil\u0026#34;: 5}, \u0026#34;Mireuil\u0026#34; : {\u0026#34;Stade\u0026#34;: 3}, \u0026#34;Stade\u0026#34; : {} } recherche_largeur(G_pond,\u0026quot;Minimes\u0026quot;,\u0026quot;Stade\u0026quot;) retourne à nouveau ['Minimes', 'Hôpital', 'Verdun', 'Stade'] alors qu\u0026rsquo;il y a maintenant des chemins plus rapides !\nAlgorithme de Dijkstra L\u0026rsquo;algorithme de Dijkstra va permettre de dépasser les limites du parcours en largeur grâce à un score attribué à chaque sommet (au départ, tous les scores sont fixés à l\u0026rsquo;infini sauf celui du sommet de départ, fixé à zéro). En sortie de l\u0026rsquo;algorithme, chaque score vaudra la distance entre le sommet et le sommet de départ.\nComme avec les parcours en largeur et en profondeur, la distinction principale réside dans la sélection du prochain sommet ajouté à Vus ; il s\u0026rsquo;agit maintenant de celui ayant le plus petit score parmi les sommets non déjà inspectés.\nOn appelle algorithme glouton un algorithme dont la logique consiste à choisir à chaque itération un objet de valeur maximale ou minimale.\nDijkstra est donc un exemple d\u0026rsquo;algorithme glouton.\nÀ chaque sommet ajouté $s$, on met à jour les scores de chaque successeur $s_+$ en gardant la valeur minimale entre le score qu\u0026rsquo;il avait précédemment et la somme entre le score de $s$ et le poids de l\u0026rsquo;arc $(s,s_+)$ (c\u0026rsquo;est l\u0026rsquo;étape de relaxation des arêtes) : $\\text{score}(s_+)=\\min\\left(\\text{score}(s_+),\\text{score}(s)+p((s,s_+))\\right)$\nEt en gardant à chaque mise-à-jour du score la trace du nouveau prédécesseur, on obtient un algorithme capable de fournir les distances et les plus courts chemins entre le sommet de départ et tous les autres.\nIdée clé de l\u0026rsquo;algo : si un chemin entre deux sommets est le plus court alors tout chemin intermédiaire entre des sommets présents sur le chemin principal est aussi le plus court entre ces sommets. Cela permet de construire le chemin le plus court de proche en proche.\nCe n\u0026rsquo;est plus vrai s\u0026rsquo;il y a une arête négative : un plus court chemin n\u0026rsquo;a alors plus à être composé des tronçons les plus courts entre les sommets intermédiaires.\nMoralité, la correction partielle de l\u0026rsquo;algorithme de Dijkstra suppose que tous les poids des arêtes du graphe sont positifs.\n# préconditions : un graphe orienté ￼pondéré G(S,A) avec des poids positifs pour chaque arc représenté par une liste d’adjacence grâce à un dictionnaire, un sommet s_0 de S # postcondition : pour chaque sommet ￼s_i de S le score trouvé correspond bien à la distance entre s_0 et s_i (d(s_0,s_i)) def sommet_suivant(scores,nonvus): \u0026#34;\u0026#34;\u0026#34; retourne le sommet de nonvus au plus bas score \u0026#34;\u0026#34;\u0026#34; plus_bas_score = float(\u0026#34;inf\u0026#34;) sommet_choisi = None for sommet in nonvus: score = scores[sommet] if score \u0026lt; plus_bas_score: plus_bas_score = score sommet_choisi = sommet return sommet_choisi def Dijkstra(G,depart): # on construit Scores et Preds dans lesquels on mettra à jour les scores calculés et les prédecesseurs des sommets examinés Scores = {} Preds = {} # initialisation for s in G: Scores[s] = float(\u0026#34;inf\u0026#34;) Preds[s] = None Scores[depart] = 0 NonVus = list(G.keys()) # liste pour stocker les sommets examinés sommet = depart while sommet is not None: score = Scores[sommet] Succ = G[sommet] for n in Succ: nv_score = score + Succ[n] if Scores[n] \u0026gt; nv_score: Scores[n] = nv_score Preds[n] = sommet NonVus.remove(sommet) sommet = sommet_suivant(Scores,NonVus) return Preds,Scores preds,scores = Dijkstra(G_pond,\u0026#34;Minimes\u0026#34;) print(preds) print(scores) # Ce qui s\u0026#39;affiche : {\u0026#39;Minimes\u0026#39;: None, \u0026#39;Hôpital\u0026#39;: \u0026#39;Minimes\u0026#39;, \u0026#39;Verdun\u0026#39;: \u0026#39;Cognehors\u0026#39;, \u0026#39;Tasdon\u0026#39;: \u0026#39;Minimes\u0026#39;, \u0026#39;Cognehors\u0026#39;: \u0026#39;Tasdon\u0026#39;, \u0026#39;Lafond\u0026#39;: \u0026#39;Tasdon\u0026#39;, \u0026#39;Mireuil\u0026#39;: \u0026#39;Lafond\u0026#39;, \u0026#39;Stade\u0026#39;: \u0026#39;Mireuil\u0026#39;} {\u0026#39;Minimes\u0026#39;: 0, \u0026#39;Hôpital\u0026#39;: 4, \u0026#39;Verdun\u0026#39;: 20, \u0026#39;Tasdon\u0026#39;: 5, \u0026#39;Cognehors\u0026#39;: 12, \u0026#39;Lafond\u0026#39;: 12, \u0026#39;Mireuil\u0026#39;: 17, \u0026#39;Stade\u0026#39;: 20} La complexité de cette implémentation de l\u0026rsquo;algorithme de Dijkstra est en $O(n^2)$ où $n=|S|$ est le nombre de sommets du graphe.\nEn effet, deux actions sont réalisées dans la boucle principale qui parcourt chaque sommet :\nLa recherche du sommet non validé ayant un score minimal et sa validation. Elle se fait via la fonction sommet_suivant qui est en $O(n)$. La mise à jour des scores des sommets. Elle se fait en temps constant mais concerne tous les successeurs du sommet étudié. On obtient : $$\\sum_{u\\in S}\\left(T(\\text{obtenir le sommet min et le retirer})+\\left(\\sum_{v\\in Succ(u)}T(\\text{mettre à jour le score})\\right)\\right) = O(n^2+m) = O(n^2)$$\nComme évoqué plus haut, on peut améliorer la complexité en utilisant une structure de données adaptée au problème : la file de priorité implémentée par un tas.\nL\u0026rsquo;idée est d\u0026rsquo;optimiser le choix du prochain sommet inspecté, celui au plus bas score parmi les sommets pas encore validés. En effet, réinspecter systématiquement toute la liste des sommets restants (c\u0026rsquo;est ce que fait la fonction sommet_suivant) gaspille de l\u0026rsquo;information. C\u0026rsquo;est sur ce point que le tas vient à la rescousse :\nle tas est une structure de données de type arbre qui permet de retrouver directement l\u0026rsquo;élément que l\u0026rsquo;on veut traiter en priorité. Le tas garde en permanence le sommet de plus bas score en son sommet avec un coût logarithmique.\nConséquence : si on remplace la fonction sommet_suivant par un tas et ses opérations dédiées d\u0026rsquo;ajout et d\u0026rsquo;extraction, on passe d\u0026rsquo;une complexité linéaire à une complexité logarithmique pour cette opération.\nimport heapq # module implémentant un tas (heap en anglais) def Dijkstra_tas(G, depart): Scores = {sommet: float(\u0026#39;infinity\u0026#39;) for sommet in G} Preds = {sommet: None for sommet in G} Scores[depart] = 0 tas = [(0, depart)] # liste de tuples contenant le score et le sommet associé # le score correspond alors à la priorité du tas while tas: score_actuel, sommet_actuel = heapq.heappop(tas) # on retire le sommet prioritaire du tas if score_actuel == Scores[sommet_actuel]: # permet de vérifier que le sommet correspond bien à la dernière mise-à-jour score_voisins = G[sommet_actuel] for voisin in score_voisins: score = score_actuel + score_voisins[voisin] if score \u0026lt; Scores[voisin]: Scores[voisin] = score Preds[voisin] = sommet_actuel heapq.heappush(tas, (score, voisin)) # on ajoute le score et le sommet au tas # le même sommet peut être ajouté plusieurs fois avec des scores différents return Preds,Scores Grâce au tas, la complexité de Dijkstra est maintenant en $O(m\\log n)$ où $n =|S|$ et $m = |A|$.\nEn effet, le tas contient $O(m)$ éléments (les voisins mis-à-jour), donc les opérations heappop et heappush sont en $O(\\log m)=O(\\log n)$.\nComme un graphe simple contient au plus $\\binom{n}{2}=\\frac{n(n-1)}{2}$ arêtes et le double pour les arcs, on en déduit que $O(m)=O(n^2)$.\nEt donc $O(\\log m)=O(2\\log n)=O(\\log n)$.\nOn entre au pire $m$ fois dans la boucle while, mais la boucle for n\u0026rsquo;est exécutée que $n$ fois car la condition score_actuel \u0026lt;= Scores[sommet_actuel] nous assure de ne traiter qu\u0026rsquo;une seule fois chaque sommet. $$\\sum_{O(m)}T(\\text{retirer la racine du tas})+\\sum_{u \\in S}\\left(\\sum_{v\\in Succ(u)}\\left(T(\\text{mettre à jour le score})+T(\\text{placer dans le tas})\\right)\\right)= O(m\\log n+m\\log n) = O(m \\log n)$$\nCette implémentation n\u0026rsquo;est réellement avantageuse que si le graphe est creux (pour ne pas avoir $|A|$ de l\u0026rsquo;ordre de $|S|^2$). Mais même si le tas contient au pire de l\u0026rsquo;ordre de $|A|$ éléments, c\u0026rsquo;est en pratique quasiment jamais le cas puisqu\u0026rsquo;il faudrait qu\u0026rsquo;à chaque arête parcourue lors de l\u0026rsquo;inspection des voisins, il y ait mise à jour du score d\u0026rsquo;un sommet (pour provoquer son ajout au tas).\nOn verra dans le TP comment encore améliorer les choses grâce à l\u0026rsquo;utilisation d\u0026rsquo;une heuristique. On passe alors de l\u0026rsquo;algorithme de Dijkstra à l\u0026rsquo;algorithme A* (A star ou A étoile).\nDans une lettre de 1856, Hamilton écrit : \u0026ldquo;I have found that some young persons have been much amused by trying a new mathematical game which the Icosion furnishes, one person sticking five pins in any consectutive points [\u0026hellip;] and the other player then aiming to insert, which by the theory in this letter can always be done, fifteen other pins, in cyclical succession, so as to cover all the other points, and to end in immediate proximity to the pin wherewith his antagonist had begun.\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/projets/oracle/",
	"title": "Oracle",
	"tags": [],
	"description": "",
	"content": "L\u0026rsquo;oracle d\u0026rsquo;Aaronson Un petit projet tout gentil pour la fin\u0026hellip;\nL\u0026rsquo;oracle d\u0026rsquo;Aaronson est un petit programme capable de prédire si une personne va taper \u0026ldquo;g\u0026rdquo; ou \u0026ldquo;h\u0026rdquo; sur son clavier avec une précision généralement supérieure à 60%.\nL\u0026rsquo;idée du programme de base :\nPour chaque mot possible de 5 lettres (\u0026ldquo;g\u0026rdquo; ou \u0026ldquo;h\u0026rdquo;) entré par l\u0026rsquo;utilisateur, on tient à jour dans un registre la lettre que l\u0026rsquo;utilisateur tape tout de suite après. Il suffit ensuite de générer une prédiction pour les 5 dernières lettres qui ont été entrées en regardant quelle lettre est majoritairement donnée après ce mot. Écrire le programme. Comment pourrait-on l\u0026rsquo;améliorer ? L\u0026rsquo;oracle en action "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/tp10graphes/",
	"title": "TP 10 : les graphes",
	"tags": [],
	"description": "",
	"content": " TP10 : les graphes Cliquez sur cette invitation pour récupérer le repository du TP. Le dessin ci-dessus peut se représenter par (choisir la bonne réponse) :\na : un graphe orienté b : un graphe non orienté Correction (cliquer pour afficher) Un graphe orienté. Le degré du sommet C vaut :\na : 2 b : 3 c : 5 Correction (cliquer pour afficher) 5 Le distance de F à C vaut :\na : 1 b : 3 c : $\\infty$ Correction (cliquer pour afficher) Comme il n'y a pas de chemin allant de F à C, la distance est dite par convention infinie. En transformant les arcs en arêtes, quel serait le diamètre du graphe ?\na : 4 b : 5 c : $\\infty$ Correction (cliquer pour afficher) Le diamètre d'un graphe est la plus grande des distances entre deux sommets.\nIci, il vaut 4. Listes et matrices d\u0026rsquo;adjacence Construire le graphe G_la correspondant au dessin du haut sous la forme d\u0026rsquo;une liste d\u0026rsquo;adjacence en utilisant un dictionnaire (sur le modèle du cours).\nLes sommets devront s\u0026rsquo;appeler \u0026quot;A\u0026quot;,\u0026quot;B\u0026quot;,\u0026quot;C\u0026quot;,\u0026quot;D\u0026quot;,\u0026quot;E\u0026quot; et \u0026quot;F\u0026quot;.\nCorrection (cliquer pour afficher) G_la = {\"A\":[\"B\"], \"B\":[\"C\"], \"C\":[\"B\",\"D\",\"F\"], \"D\":[\"C\",\"E\"], \"E\":[\"F\"], \"F\":[]} Construire maintenant le graphe G_ma correspondant au dessin ci-dessus sous la forme d\u0026rsquo;une matrice d\u0026rsquo;adjacence (en suivant le modèle donné dans le cours).\nCorrection (cliquer pour afficher) G_ma = [[0,1,0,0,0,0], [0,0,1,0,0,0], [0,1,0,1,0,1], [0,0,1,0,1,0], [0,0,0,0,0,1], [0,0,0,0,0,0]] Manipulation d\u0026rsquo;un graphe Ajouter un sommet à un graphe Construire une fonction qui ajoute un sommet S à un graphe G orienté. Le graphe G est représenté par une liste d\u0026rsquo;adjacence et on donne en argument de la fonction la liste des prédécesseurs et des successeurs du sommet S ($Pred(S)$ et $Succ(S)$).\ndef ajouteSommet(G,S,pred,succ): \u0026#34;\u0026#34;\u0026#34; ajouteSommet(G: dict,S: str,pred: list,succ: list) -\u0026gt; G: dict préconditions: G est un graphe dont certains des sommets font partie de la liste pred et certains de la liste succ. S est le nom d\u0026#39;un sommet n\u0026#39;appartenenat pas à G. G est modélisé par une liste d\u0026#39;adjacence utilisant un dictionnaire. pred et succ sont les listes des prédécesseurs et des successeurs de S. postcondition: la fonction retourne le graphe mis à jour (muté) avec le sommet S ajouté. \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Correction (cliquer pour afficher) def ajouteSommet(G,S,pred,succ): G[S] = succ for sp in pred: G[sp].append(S) return G Le graphe de gauche est modélisé ci-dessous par une liste d\u0026rsquo;adjacence :\nGraphe = {\u0026#39;A\u0026#39; : [\u0026#39;E\u0026#39;,\u0026#39;D\u0026#39;], \u0026#39;B\u0026#39; : [\u0026#39;D\u0026#39;], \u0026#39;C\u0026#39; : [\u0026#39;B\u0026#39;], \u0026#39;D\u0026#39; : [\u0026#39;C\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;E\u0026#39; : [], \u0026#39;F\u0026#39; : [\u0026#39;B\u0026#39;]} On souhaite lui ajouter le sommet 'G'.\nCompléter au préalable les listes Pred et Succ contenant les prédécesseurs et les successeurs de 'G'.\nPred = [] Succ = [] Correction (cliquer pour afficher) Pred = ['B'] Succ = ['A','C'] Testez ensuite votre fonction ajouteSommet pour vérifier que le graphe est modifié comme souhaité.\nCorrection (cliquer pour afficher) ajouteSommet(Graphe,'G',Pred,Succ) donne alors\u0026nbsp;:\n{'A': ['E', 'D'],\n\u0026nbsp;'B': ['D', 'G'],\n\u0026nbsp;'C': ['B'],\n\u0026nbsp;'D': ['C', 'E'],\n\u0026nbsp;'E': [],\n\u0026nbsp;'F': ['B'],\n\u0026nbsp;'G': ['A', 'C']}\nRetirer un sommet à un graphe On souhaite maintenant construire la fonction retireSommet permettant de retirer un sommet d\u0026rsquo;un graphe.\nElle prend en argument le graphe et un sommet du graphe.\nVous utiliserez un assert pour vous assurer que le sommet passé en argument appartient bien augraphe.\ndef retireSommet(G,S): \u0026#34;\u0026#34;\u0026#34; retireSommet(G: dict,S: str) -\u0026gt; G: dict préconditions: G est un graphe et S est un de ses sommets. G est modélisé par une liste d\u0026#39;adjacence utilisant un dictionnaire postcondition: la fonction retourne le graphe mis à jour (muté) avec le sommet S en moins \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Correction (cliquer pour afficher) def retireSommet(G,S): assert S in G del G[S] for liste in G.values(): if S in liste: liste.remove(S) return G Reprenons le graphe précédent avant l\u0026rsquo;ajout du sommet 'G'.\nGraphe = {\u0026#39;A\u0026#39; : [\u0026#39;E\u0026#39;,\u0026#39;D\u0026#39;], \u0026#39;B\u0026#39; : [\u0026#39;D\u0026#39;], \u0026#39;C\u0026#39; : [\u0026#39;B\u0026#39;], \u0026#39;D\u0026#39; : [\u0026#39;C\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;E\u0026#39; : [], \u0026#39;F\u0026#39; : [\u0026#39;B\u0026#39;]} Testez ensuite votre fonction retireSommet pour vérifier que le graphe est modifié comme souhaité.\nUtilisation d\u0026rsquo;un module pour visualiser import networkx as nx from IPython.display import Image import pandas as pd Construisons la matrice d\u0026rsquo;adjacence d\u0026rsquo;un graphe non-orienté complet.\nmatrice = [[0, 3, 2, 2, 1, 6, 4, 2, 6, 5], [3, 0, 6, 6, 4, 3, 6, 5, 4, 5], [2, 6, 0, 6, 2, 3, 1, 1, 2, 6], [2, 6, 6, 0, 4, 3, 2, 2, 4, 6], [1, 4, 2, 4, 0, 3, 6, 1, 6, 2], [6, 3, 3, 3, 3, 0, 6, 2, 6, 6], [4, 6, 1, 2, 6, 6, 0, 4, 2, 5], [2, 5, 1, 2, 1, 2, 4, 0, 4, 2], [6, 4, 2, 4, 6, 6, 2, 4, 0, 2], [5, 5, 6, 6, 2, 6, 5, 2, 2, 0]] Construisez à votre tour une matrice $10\\times 10$ M semblable à la précédente en tirant chaque élément au hasard parmi la liste [1,2,3,4,5,6] grâce à la fonction choice du module random (choice(L) retourne un des éléments de L choisi au hasard).\nCette matrice devra n\u0026rsquo;avoir que des 0 dans sa diagonale et être symétrique.\nAttention: le nom de la matrice doit être M.\nfrom random import choice n = 10 # nombre de sommets # VOTRE CODE Correction (cliquer pour afficher) M = [[choice([1,2,3,4,5,6]) for i in range(n)] for j in range(n)] for i in range(n): M[i][i] = 0 for j in range(i): M[j][i] = M[i][j] Si vous avez réussi à construire M vous pourrez utilisez votre matrice par la suite.\nOn transforme ensuite la matrice en dataframe pandas (pandas est un module de gestion de données très riche déjà utilisé dans le tp3 et un dataframe est un tableau à deux dimensions) qui sera reconnue par networkx et on lui ajoute des lettres en en-tête de ligne et de colonne pour nommer les sommets.\nabc = \u0026#39;ABCDEFGHIJKLMNOPQRSTUVWXYZ\u0026#39; labels = list(abc[:n]) M_df = pd.DataFrame(matrice, index=labels, columns=labels) print(M_df) A B C D E F G H I J A 0 3 2 2 1 6 4 2 6 5 B 3 0 6 6 4 3 6 5 4 5 C 2 6 0 6 2 3 1 1 2 6 D 2 6 6 0 4 3 2 2 4 6 E 1 4 2 4 0 3 6 1 6 2 F 6 3 3 3 3 0 6 2 6 6 G 4 6 1 2 6 6 0 4 2 5 H 2 5 1 2 1 2 4 0 4 2 I 6 4 2 4 6 6 2 4 0 2 J 5 5 6 6 2 6 5 2 2 0 G_complet = nx.from_pandas_adjacency(M_df) # obtention du graphe networkx à partir de la dataframe weights = [G_complet[u][v][\u0026#39;weight\u0026#39;]*3 for u,v in G_complet.edges()] # liste des poids (*3) # Tracé options = {\u0026#34;font_size\u0026#34;: 20, \u0026#34;font_weight\u0026#34;:\u0026#34;bold\u0026#34;, \u0026#34;node_size\u0026#34;: 1000, \u0026#34;node_color\u0026#34;: \u0026#34;#34A5DA\u0026#34;, \u0026#34;edge_color\u0026#34;: weights, # couleur en fonction des poids \u0026#34;width\u0026#34;: weights, # épaisseur des arêtes en fonction des poids \u0026#34;edge_cmap\u0026#34;: plt.cm.Set3, \u0026#34;with_labels\u0026#34;: True, \u0026#34;font_color\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;linewidths\u0026#34;: 5, } pos = nx.shell_layout(G_complet) fig = plt.figure(figsize=(12, 12)) nx.draw(G_complet,pos=pos,**options) labels = nx.get_edge_attributes(G_complet,\u0026#39;weight\u0026#39;) nx.draw_networkx_edge_labels(G_complet, pos=pos,edge_labels=labels) plt.show() Transformez la matrice matrice en une liste d\u0026rsquo;adjacence G_la n\u0026rsquo;utilisant que des dictionnaires.\nG_la devra ressembler à :\n{\u0026#39;A\u0026#39;: {\u0026#39;B\u0026#39;: 3, \u0026#39;C\u0026#39;: 2, \u0026#39;D\u0026#39;: 2, \u0026#39;E\u0026#39;: 1, \u0026#39;F\u0026#39;: 6, \u0026#39;G\u0026#39;: 4, \u0026#39;H\u0026#39;: 2, \u0026#39;I\u0026#39;: 6, \u0026#39;J\u0026#39;: 5}, \u0026#39;B\u0026#39;: {\u0026#39;A\u0026#39;: 3, \u0026#39;C\u0026#39;: 6, \u0026#39;D\u0026#39;: 6, \u0026#39;E\u0026#39;: 4, \u0026#39;F\u0026#39;: 3, \u0026#39;G\u0026#39;: 6, \u0026#39;H\u0026#39;: 5, \u0026#39;I\u0026#39;: 4, \u0026#39;J\u0026#39;: 5}, \u0026#39;C\u0026#39;: {\u0026#39;A\u0026#39;: 2, \u0026#39;B\u0026#39;: 6, \u0026#39;D\u0026#39;: 6, \u0026#39;E\u0026#39;: 2, \u0026#39;F\u0026#39;: 3, \u0026#39;G\u0026#39;: 1, \u0026#39;H\u0026#39;: 1, \u0026#39;I\u0026#39;: 2, \u0026#39;J\u0026#39;: 6}, \u0026#39;D\u0026#39;: {\u0026#39;A\u0026#39;: 2, \u0026#39;B\u0026#39;: 6, \u0026#39;C\u0026#39;: 6, \u0026#39;E\u0026#39;: 4, \u0026#39;F\u0026#39;: 3, \u0026#39;G\u0026#39;: 2, \u0026#39;H\u0026#39;: 2, \u0026#39;I\u0026#39;: 4, \u0026#39;J\u0026#39;: 6}, \u0026#39;E\u0026#39;: {\u0026#39;A\u0026#39;: 1, \u0026#39;B\u0026#39;: 4, \u0026#39;C\u0026#39;: 2, \u0026#39;D\u0026#39;: 4, \u0026#39;F\u0026#39;: 3, \u0026#39;G\u0026#39;: 6, \u0026#39;H\u0026#39;: 1, \u0026#39;I\u0026#39;: 6, \u0026#39;J\u0026#39;: 2}, \u0026#39;F\u0026#39;: {\u0026#39;A\u0026#39;: 6, \u0026#39;B\u0026#39;: 3, \u0026#39;C\u0026#39;: 3, \u0026#39;D\u0026#39;: 3, \u0026#39;E\u0026#39;: 3, \u0026#39;G\u0026#39;: 6, \u0026#39;H\u0026#39;: 2, \u0026#39;I\u0026#39;: 6, \u0026#39;J\u0026#39;: 6}, \u0026#39;G\u0026#39;: {\u0026#39;A\u0026#39;: 4, \u0026#39;B\u0026#39;: 6, \u0026#39;C\u0026#39;: 1, \u0026#39;D\u0026#39;: 2, \u0026#39;E\u0026#39;: 6, \u0026#39;F\u0026#39;: 6, \u0026#39;H\u0026#39;: 4, \u0026#39;I\u0026#39;: 2, \u0026#39;J\u0026#39;: 5}, \u0026#39;H\u0026#39;: {\u0026#39;A\u0026#39;: 2, \u0026#39;B\u0026#39;: 5, \u0026#39;C\u0026#39;: 1, \u0026#39;D\u0026#39;: 2, \u0026#39;E\u0026#39;: 1, \u0026#39;F\u0026#39;: 2, \u0026#39;G\u0026#39;: 4, \u0026#39;I\u0026#39;: 4, \u0026#39;J\u0026#39;: 2}, \u0026#39;I\u0026#39;: {\u0026#39;A\u0026#39;: 6, \u0026#39;B\u0026#39;: 4, \u0026#39;C\u0026#39;: 2, \u0026#39;D\u0026#39;: 4, \u0026#39;E\u0026#39;: 6, \u0026#39;F\u0026#39;: 6, \u0026#39;G\u0026#39;: 2, \u0026#39;H\u0026#39;: 4, \u0026#39;J\u0026#39;: 2}, \u0026#39;J\u0026#39;: {\u0026#39;A\u0026#39;: 5, \u0026#39;B\u0026#39;: 5, \u0026#39;C\u0026#39;: 6, \u0026#39;D\u0026#39;: 6, \u0026#39;E\u0026#39;: 2, \u0026#39;F\u0026#39;: 6, \u0026#39;G\u0026#39;: 5, \u0026#39;H\u0026#39;: 2, \u0026#39;I\u0026#39;: 2}} Correction (cliquer pour afficher) G_la = {} for i in range(n): D = {} for j in range(n): if matrice[i][j] != 0: D[abc[j]] = matrice[i][j] G_la[abc[i]] = D Une application concrète des graphes : l\u0026rsquo;arbre couvrant minimal Supposons que chaque sommet du graphe précédent représente les nœuds d\u0026rsquo;un réseau que l\u0026rsquo;on souhaite relier à moindre coût. Ces sommets peuvent être des villes que l\u0026rsquo;on veut relier électriquement, des champs à irriguer, des serveurs à relier, etc. Les différents poids des arêtes matérialisent la difficulté ou le coût de la liaison entre les deux sommets.\nComment trouver facilement le moyen de relier tout le monde en minimisant les coûts ? Il faut trouver un arbre couvrant minimal du graphe.\nUn arbre couvrant est un arbre (graphe sans cycle) qui rejoint tous les sommets d\u0026rsquo;un graphe connexe.\nUn arbre couvrant minimal est un arbre couvrant dont la somme des poids des arêtes est minimale.\nChercher une solution par force brute devient rapidement impossible quand le nombre de sommets du graphe augmente. La formule de Cayley nous dit qu\u0026rsquo;il y aura $n^{n-2}$ arbres couvrants d\u0026rsquo;un graphe complet connexe comportant n sommets (avec seulement 100 sommets, cela fait plus de possibilités que le nombre d\u0026rsquo;atomes dans l\u0026rsquo;univers).\nQuelle serait donc le type de complexité d\u0026rsquo;une exploration par force brute de tous les arbres couvrants ?\na : logarithmique en n b : polynomiale en n c : exponentielle en n Correction (cliquer pour afficher) Pire qu'exponentielle en fait, mais on classe généralement tout ça ($n!$, $,n^n$, etc.) sous l'étiquette exponentielle car c'est quoiqu'il arrive trop lent. Grâce à l\u0026rsquo;algorithme de Prim, on peut trouver un arbre couvrant minimal d\u0026rsquo;un graphe connexe pondéré en temps raisonable !\nMais commençons d\u0026rsquo;abord par construire une fonction qui vérifie si un graphe est connexe ou non.\nPour cela, on va utiliser l\u0026rsquo;algorithme de parcours en profondeur (Deep-First Search) sur le graphe à tester en partant d\u0026rsquo;un sommet quelconque et vérifier que tous les sommets sont visités.\nfrom collections import deque def parcours_profondeur(G,depart): pile = deque() pile.append(depart) Vus = [] while pile : sommet = pile.pop() if not sommet in Vus : pile += G[sommet] Vus.append(sommet) return Vus Construisez la fonction verifConnexe qui vérifie si un graphe est connexe ou non.\nVous utiliserez la fonction parcours_profondeur dans votre code.\nVous pourrez ensuite tester ci-dessous si votre fonction fait le travail sur les deux listes d\u0026rsquo;adjacence G_la et Gt_nc.\nDans le premier cas, le graphe est évidemment connexe, et on a construit le deuxième pour qu\u0026rsquo;il ne le soit pas.\ndef verifConnexe(G): \u0026#34;\u0026#34;\u0026#34; verifConnexe(G: dict) -\u0026gt; bool précondition: G est un graphe sous la forme d\u0026#39;une liste d\u0026#39;adjacence représentée par un dictionnaire comme ci-dessus postcondition: la fonction retourne True si le graphe est connexe, False sinon \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Correction (cliquer pour afficher) def verifConnexe(G): depart = list(G.keys())[0] Sommets = parcours_profondeur(G,depart) if len(Sommets) == len(G): return True else: return False # Construction d\u0026#39;un graphe G_nc non connexe G_nc = nx.Graph() G_nc.add_nodes_from([i for i in range(1,9)]) color_map = [\u0026#39;red\u0026#39; if node \u0026lt;=4 else \u0026#39;green\u0026#39; for node in G_nc] G_nc.add_edges_from([(1, 2), (1, 3),(2,4),(1,4),(5,7),(6,7),(5,8),(7,8)]) posi = nx.kamada_kawai_layout(G_nc) options = {\u0026#34;node_size\u0026#34;: 200, \u0026#34;node_color\u0026#34;: color_map, \u0026#34;edge_color\u0026#34;: color_map, \u0026#34;linewidths\u0026#34;: 1, \u0026#34;width\u0026#34;: 1, \u0026#34;with_labels\u0026#34;: False, } G_nc_la = nx.to_dict_of_dicts(G_nc) nx.draw(G_nc,posi,**options) print(\u0026#39;G_la est connexe :\u0026#39;,verifConnexe(G_la)) print(\u0026#39;G_nc_la est connexe :\u0026#39;,verifConnexe(G_nc_la)) G_la est connexe : True\nG_nc_la est connexe : False\nImplémentons maintenant une version lente (quadratique) de l\u0026rsquo;algorithme de Prim.\nComme Dijkstra, Prim est un algorithme glouton. À chaque itération, il se jette sur l\u0026rsquo;arête de poids le plus faible permettant de traverser la frontière entre l\u0026rsquo;ensemble des sommets déjà inspectés et l\u0026rsquo;ensemble des autres. Une fois l\u0026rsquo;arête choisie, on ajoute le sommet non inspecté qu\u0026rsquo;elle relie à l\u0026rsquo;ensemble des sommets inspectés.\nIntégrez à l\u0026rsquo;algorithme ci-dessous une assertion testant si le graphe donné en argumant est bien connexe et ajoutez une variable cout à l\u0026rsquo;algorithme qui enregistre le coût de l\u0026rsquo;arbre final retourné et qui devra elle aussi être retournée.\nLa sortie doit donc devenir : return A, cout\ndef Prim(G): \u0026#34;\u0026#34;\u0026#34; Prim(G : dict) -\u0026gt; A : liste de tuples , cout : nombre G est donné sous la forme d\u0026#39;une liste d\u0026#39;adjacence implémenté par un dictionnaire A est une liste d\u0026#39;arêtes représentées par un tuple (A,B) où A et B sont les deux sommets délimitant l\u0026#39;arête cout est le coût de l\u0026#39;arbre A (somme des pondération des arêtes constituant A) postcondition : A doit être un arbre couvrant minimal \u0026#34;\u0026#34;\u0026#34; inf = float(\u0026#39;inf\u0026#39;) NX = list(G.keys()) # un dictionnaire n\u0026#39;est pas ordonné donc pas indiçable d\u0026#39;où la transformation en liste S0 = NX[0] X = [S0] NX.remove(S0) A = [] while NX != []: # invariant : A est un arbre couvrant minimal de X Min = inf for S1 in X: for S2 in NX: if G[S1].get(S2,inf) \u0026lt; Min: # get(clé,v0) renvoie la valeur liée à la clé si la clé existe et v0 sinon (permet d\u0026#39;éviter les \u0026#34;key error\u0026#34;) Min = G[S1][S2] # là, on sait que S2 est bien un voisin de S1 Fmin = S2 Dmin = S1 X.append(Fmin) NX.remove(Fmin) A.append((Dmin,Fmin)) return A Correction (cliquer pour afficher) def Prim(G): assert verifConnexe(G) # assertion demandée inf = float('inf') NX = list(G.keys()) S0 = NX[0] X = [S0] NX.remove(S0) A = [] cout = 0 # initialisation du cout while NX != []: Min = inf for S1 in X: for S2 in NX: if G[S1].get(S2,inf) \u003c Min: Min = G[S1][S2] Fmin = S2 Dmin = S1 X.append(Fmin) NX.remove(Fmin) A.append((Dmin,Fmin)) cout += Min # incrémentation du cout return A,cout Traçons maintenant l\u0026rsquo;arbre couvrant minimal trouvé par Prim.\nA,cout = Prim(G_la) H = nx.Graph() for S in abc[:n]: H.add_node(S) for S1,S2 in A: H.add_edge(S1,S2,weight=10) F = nx.compose(G_complet,H) weights = [5 if F[u][v][\u0026#39;weight\u0026#39;]==10 else 0 for u,v in F.edges()] options = {\u0026#34;font_size\u0026#34;: 20, \u0026#34;font_weight\u0026#34;:\u0026#34;bold\u0026#34;, \u0026#34;node_size\u0026#34;: 1000, \u0026#34;node_color\u0026#34;: \u0026#34;#34A5DA\u0026#34;, \u0026#34;edge_color\u0026#34;: weights, \u0026#34;width\u0026#34;: weights, \u0026#34;edge_cmap\u0026#34;: plt.cm.bwr, \u0026#34;with_labels\u0026#34;: True, \u0026#34;font_color\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;linewidths\u0026#34;: 1, } fig = plt.figure(figsize=(12, 12)) nx.draw(F,pos=pos,**options) plt.show() print(f\u0026#34;Coût de l\u0026#39;arbre : {cout}\u0026#34;) Coût de l'arbre : 15\nEt voilà ! En deux coups de cuillère à pot, on a trouvé un arbre couvrant minimal sans s\u0026rsquo;infliger l\u0026rsquo;inspection systématique des $10^8$ arbres couvrants possibles\u0026hellip;\nLien entre structures de données et graphes, exemple du tas Le tas est une structure de données permettant d\u0026rsquo;implémenter une file de priorité dont le rôle est d\u0026rsquo;obtenir rapidement le plus petit élément d\u0026rsquo;un ensemble.\nOn peut se représenter un tas par un arbre binaire presque complet ordonné.\nPour implémenter un tas, on retranscrit l\u0026rsquo;arbre binaire sous la forme d\u0026rsquo;une liste.\nEn vous aidant de la vidéo ci-dessus, choisir parmi les listes suivantes celle qui peut représenter un tas :\na : [3,5,8,5,13,7,9,6,12,15,18,11,12,10] b : [3,5,8,5,13,11,11,6,12,15,18,11,11,12,10] c : [3,5,8,5,13,11,9,6,12,15,18,11,12] Correction (cliquer pour afficher) a : le parent à la position 3 a un enfant plus petit que lui (position 6) b : le parent à la position 7 a un enfant plus petit que lui (position 15) c : tout va bien Construire une fonction plusPetitEnfant qui retourne la position du petit enfant d\u0026rsquo;un élément dans le tas.\nLa fonction prend en argument le tas (représenté sous la forme d\u0026rsquo;une liste) et la position du parent.\nLa fonction retourne la position du plus petit enfant.\nSi l\u0026rsquo;élément n\u0026rsquo;a pas d\u0026rsquo;enfant, la fonction retourne None.\nAttention : les positions dans le tas vont de 1 à n (et non de 0 à n-1) où n est le nombre d\u0026rsquo;éléments dans le tas.\ndef plusPetitEnfant(tas,position): \u0026#34;\u0026#34;\u0026#34; plusPetitEnfant(tas: list, position: int) -\u0026gt; int ou Nonetype \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Si Tas = [3,7,8,8,7,12,9,9,8,8,8,13] et pos = 3, alors plusPetitEnfant(Tas,pos) doit retourner 7 (car à la position 3, on trouve 8 dont les deux enfants 12 et 9 sont aux positions 6 et 7).\nCorrection (cliquer pour afficher) def plusPetitEnfant(tas,position): n = len(tas) if 2*position \u003e n: return None elif 2*position == n: return 2*position else: if tas[2*position-1] \u003c= tas[2*position]: return 2*position else: return 2*position+1 Construire les fonctions insert et extractMin (pour cette dernière, pensez à utiliser plusPetitEnfant).\nOn supposera que le tas ne contient que des entiers.\ndef insert(tas,x): \u0026#34;\u0026#34;\u0026#34; insert(tas: list , x: int) -\u0026gt; Nonetype la fonction doit ajouter un élément au tas de manière à ce qu\u0026#39;il reste un arbre binaire presque complet tout en respectant l\u0026#39;invariant : les valeurs des parents doivent être inférieures à celles des enfants. la fonction ne retourne rien. \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Correction (cliquer pour afficher) def insert(tas,x): tas.append(x) n = len(tas) enfant = n parent = enfant//2 while enfant \u003e 1 and tas[enfant-1] \u003c tas[parent-1]: tas[enfant-1],tas[parent-1] = tas[parent-1],tas[enfant-1] enfant = parent parent = enfant//2 Test : Tas = [3,7,8,8,7,12,9,9,8,8,8,13] insert(Tas,1) print(Tas) [1, 7, 3, 8, 7, 8, 9, 9, 8, 8, 8, 13, 12] def extractMin(tas): \u0026#34;\u0026#34;\u0026#34; extractMin(tas: list) -\u0026gt; Min: int la fonction doit retirer la racine du tas tout en respectant l\u0026#39;invariant : les valeurs des parents doivent être inférieures à celles des enfants. \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Correction (cliquer pour afficher) def extractMin(tas): n = len(tas) # on place la racine à la fin et on l'extrait tas[n-1],tas[0] = tas[0],tas[n-1] Min = tas.pop() n -= 1 # Si le tas ne contient plus qu'1 ou 0 élément, c'est fini if n == 0 or n == 1: return Min # on identifie ensuite le plus petit des deux enfants de la nouvelle racine (ou l'unique enfant s'il n'y en a qu'un...) parent = 1 enfant = plusPetitEnfant(tas,parent) # tant que le plus petit enfant est plus petit que son parent, on les permute while tas[enfant-1] \u003c tas[parent-1]: tas[enfant-1],tas[parent-1] = tas[parent-1],tas[enfant-1] # nouveaux parents et enfants parent = enfant if not plusPetitEnfant(tas,parent): break # si le nouveau parent n'a pas d'enfant else: enfant = plusPetitEnfant(tas,parent) return Min Test : Tas = [3,7,8,8,7,9,12,9,8,8,8,10] m = extractMin(Tas) print(m,Tas) 3 [7, 7, 8, 8, 8, 9, 12, 7, 8, 10, 8] Construisons maintenant un tri par tas et montrons qu\u0026rsquo;il est bien plus rapide que le tri par sélection dont il est issu.\ndef triParSelection(liste): n = len(liste) for i in range(n-1): min = i for j in range(i+1,n): if liste[j]\u0026lt;liste[min]: min = j if min != i: liste[i], liste[min] = liste[min], liste[i] return L def triParTas(liste): T = [] Ltrie = [] n = len(liste) for e in liste: insert(T,e) # on construit un tas à partir de la liste for i in range(n): Ltrie.append(extractMin(T)) # la recherche du min est remplacé par extractMin return Ltrie L = [-13,12,5,1,95,4] print(triParSelection(L)) print(triParTas(L)) [-13, 1, 4, 5, 12, 95]\n[-13, 1, 4, 5, 12, 95]\nfrom time import time from random import randint import matplotlib.pyplot as plt plt.style.use(\u0026#39;ggplot\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 5) I, T_trisel, T_tritas = [], [], [] for i in range(100,1000,1): L = [] L = [randint(0,i) for k in range(i)] start1 = time() triParSelection(L) stop1 = time() T_trisel.append(stop1-start1) start2 = time() triParTas(L) stop2 = time() T_tritas.append(stop2-start2) I.append(i) plt.plot(I,T_trisel,label=\u0026#34;tri par sélection\u0026#34;) plt.plot(I,T_tritas,label=\u0026#34;tri par tas\u0026#34;) plt.xlabel(\u0026#39;taille de la liste\u0026#39;) plt.ylabel(\u0026#34;temps d\u0026#39;exécution (s)\u0026#34;) plt.legend() Commentaire (cliquer pour afficher) Le tri par tas rejoint donc le tri fusion et le tri rapide dans la catégorie des tris comparatifs quasilinéaires (meilleur complexité possible pour un tri à base de comparaisons). Les graphes nous ont donc ici permis de mettre au point une structure de données capable d\u0026rsquo;upgrader tout algorithme nécessitant une détermination répétée d\u0026rsquo;un plus petit (ou grand) élément dans un ensemble.\nParcours d\u0026rsquo;un graphe Détecteur de cycle Les graphes orientés sont générallement utilisés pour représenter un ensemble de dépendances (l\u0026rsquo;ensemble des prérequis d\u0026rsquo;un cours, l\u0026rsquo;ensemble des installations nécessaires au fonctionnement d\u0026rsquo;un programme, etc\u0026hellip;).\nEt la présence de cycles dans de tels graphes est synonyme de bloquage (exemple : pour faire la première tâche, vous attendez la seconde, et pour faire la seconde, vous attendez la première\u0026hellip;).\nQuelle que soit l\u0026rsquo;application, détecter les cycles est donc primordial pour éviter de se retrouver dans ce type de situation.\nUne idée pour détecter un cycle est d\u0026rsquo;utiliser à nouveau le parcours en profondeur : si on tombe sur un sommet déjà exploré au cours de la progression dans une branche, alors on a affaire à un cycle.\nPoint important : on suppose ici que les graphes donnés en argument à la fonction sont non orientés.\nLe problème que pose ce type de graphe pour la recherche de cycle est la présence systématique du sommet considéré dans la liste de ses voisins (si \u0026lsquo;A\u0026rsquo; est le voisin de \u0026lsquo;B\u0026rsquo; alors \u0026lsquo;B\u0026rsquo; est le voisin de \u0026lsquo;A\u0026rsquo;) puisqu\u0026rsquo;un graphe non-orienté permet les aller-retour.\nOn oriente alors dans un premier temps le graphe non orienté donné en argument en retirant systématiquement de la liste des voisins d\u0026rsquo;un sommet les sommets dont lui-même est le voisin. On ne sera ainsi plus piégé par un aller-retour entre deux voisins. On peut s\u0026rsquo;assurer ensuite de la présence d\u0026rsquo;un cycle si le parcours en profondeur rencontre un sommet présent dans Vus.\nAjoutez donc à la fonction un bout de code qui construit un graphe Go orienté à partir de G.\nfrom collections import deque def detecteCycles(G,depart): \u0026#34;\u0026#34;\u0026#34; detecteCycles(G: dict, depart) -\u0026gt; bool depart est une des clés de G detecteCycles doit retourner True si un cycle est rencontré \u0026#34;\u0026#34;\u0026#34; pile = deque() pile.append(depart) Vus = {s : False for s in G} # on transforme G en un graphe orienté Go Go = copy.deepcopy(G) # on veut éviter de modifier G qui est mutable # VOTRE CODE while pile: sommet = pile.pop() if not Vus[sommet]: Voisins = Go[sommet].copy() pile += Voisins Vus[sommet] = True else: return True return False Correction (cliquer pour afficher) On ajoute ces 3 lignes avant le while\u0026nbsp;: for s1 in Go: for s2 in Go[s1]: Go[s2].remove(s1) # sans deepcopy, on modifierait G Testez votre fonction sur les trois graphes suivants :\nG1 = {\u0026#39;A\u0026#39; : [\u0026#39;B\u0026#39;], \u0026#39;B\u0026#39; : [\u0026#39;A\u0026#39;,\u0026#39;C\u0026#39;], \u0026#39;C\u0026#39; : [\u0026#39;B\u0026#39;,\u0026#39;D\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;D\u0026#39; : [\u0026#39;C\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;E\u0026#39; : [\u0026#39;C\u0026#39;,\u0026#39;D\u0026#39;]} G2 = {\u0026#39;A\u0026#39; : [\u0026#39;B\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;B\u0026#39; : [\u0026#39;A\u0026#39;,\u0026#39;C\u0026#39;], \u0026#39;C\u0026#39; : [\u0026#39;B\u0026#39;,\u0026#39;D\u0026#39;], \u0026#39;D\u0026#39; : [\u0026#39;C\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;E\u0026#39; : [\u0026#39;A\u0026#39;,\u0026#39;D\u0026#39;]} G3 = {\u0026#39;A\u0026#39; : [\u0026#39;B\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;B\u0026#39; : [\u0026#39;A\u0026#39;,\u0026#39;C\u0026#39;], \u0026#39;C\u0026#39; : [\u0026#39;B\u0026#39;,\u0026#39;D\u0026#39;], \u0026#39;D\u0026#39; : [\u0026#39;C\u0026#39;], \u0026#39;E\u0026#39; : [\u0026#39;A\u0026#39;]} Correction (cliquer pour afficher) print(detecteCycles(G1,'A')) detecteCycles(G2,'A') detecteCycles(G3,'A') True\nTrue\nFalse\nPlus court chemin Une autre application ultra importante des graphes : trouver le plus vite possible le plus court chemin entre deux points.\nOn peut presque toujours modéliser un déplacement comme un chemin sur un graphe (ou plutôt une chaîne dans le cas présent car nos graphes ne seront pas orientés).\nReprésentons par exemple la carte d\u0026rsquo;un petit jeu vidéo sous forme de graphe.\nPour cela, on transforme chaque lieu possible en un sommet et chaque transition possible d\u0026rsquo;un point à un autre comme une arête.\nCréons une petite carte de 20 cases sur 20 avec des déplacements possibles horizontaux, verticaux mais aussi diagonaux d\u0026rsquo;une case à une case voisine.\nTous les arcs reçoivent d\u0026rsquo;abord le même poids de 1.\ncarte = {} imax = 20 jmax = 20 for i in range(imax): for j in range(jmax): poids_voisins = {} if i \u0026gt; 0: poids_voisins[(i-1,j)] = 1 if j \u0026gt; 0: poids_voisins[(i,j-1)] = 1 if i \u0026gt; 0 and j \u0026gt; 0: poids_voisins[(i-1,j-1)] = 1 if i \u0026gt; 0 and j \u0026lt; jmax-1: poids_voisins[(i-1,j+1)] = 1 if i \u0026lt; imax-1: poids_voisins[(i+1,j)] = 1 if j \u0026lt; jmax-1: poids_voisins[(i,j+1)] = 1 if i \u0026lt; imax-1 and j \u0026gt; 0: poids_voisins[(i+1,j-1)] = 1 if i \u0026lt; imax-1 and j \u0026lt; jmax-1: poids_voisins[(i+1,j+1)] = 1 carte[(i,j)] = poids_voisins Compliquons notre carte en y rajoutant différents environnements : des marécages où il est difficile de se mouvoir et des murs infranchissables.\nPour modéliser les marécages on va modifier les pondérations : on augmente le poids des arêtes amenant à des sommets s\u0026rsquo;y trouvant. Et pour les murs, on va retirer du graphe les sommets correspondant.\ndessin = {s : 1 for s in carte.keys()} # dictionnaire aidant pour le tracé # marécages composés de deux rectangles en L limites_marecages_1 = ((5,11),(2,12)) # le 1er rectangle s\u0026#39;étend de 5 à 19 en largeur, et de 5 à 12 en hauteur for sommet in carte.keys(): for voisin in carte[sommet].keys(): i,j = voisin if limites_marecages_1[0][0]\u0026lt;=i\u0026lt;=limites_marecages_1[0][1] and limites_marecages_1[1][0]\u0026lt;=j\u0026lt;=limites_marecages_1[1][1]: carte[sommet][voisin] = 5 limites_marecages_2 = ((12,20),(2,6)) # 2eme rectangle for sommet in carte.keys(): for voisin in carte[sommet].keys(): i,j = voisin if limites_marecages_2[0][0]\u0026lt;=i\u0026lt;=limites_marecages_2[0][1] and limites_marecages_2[1][0]\u0026lt;=j\u0026lt;=limites_marecages_2[1][1]: carte[sommet][voisin] = 5 # pour reconnaître les sommets dans le marécage lors du dessin for i in range(limites_marecages_1[0][0],limites_marecages_1[0][1]+1): for j in range(limites_marecages_1[1][0],limites_marecages_1[1][1]+1): dessin[(i,j)] = 5 for i in range(limites_marecages_2[0][0],limites_marecages_2[0][1]+1): for j in range(limites_marecages_2[1][0],limites_marecages_2[1][1]+1): dessin[(i,j)] = 5 # murs (on retire les sommets concernés (y compris des voisins)) limites_murs = ((11,16),(17,11),(16,11),(15,11),(17,12),(16,12),(15,12),(15,13),(15,14),(15,15),(15,16),(15,17),(15,18),(14,18),(13,18),(12,18),(11,18),(11,17),(15,10),(16,10),(17,10),(15,9),(16,9),(17,9)) # chaque couple (a,b) correspond aux coordonnées d\u0026#39;une case de mur for sommet in carte.copy().keys(): for voisin in carte[sommet].copy().keys(): i,j = voisin if (i,j) in limites_murs: del carte[sommet][voisin] for sommet in carte.copy().keys(): i,j = sommet if (i,j) in limites_murs: del carte[sommet] Définissons les sommets de départ et d\u0026rsquo;arrivée.\ndepart = (2,2) arrivee = (17,15) Et construsions enfin une fonction permettant de tracer la carte en faisant apparaître les marécages, les murs et les points de départ et d\u0026rsquo;arrivée.\nimport matplotlib.pyplot as plt from matplotlib.patches import Rectangle plt.style.use(\u0026#39;seaborn\u0026#39;) fig, ax = plt.subplots(figsize=(15,15)) def trace_terrain(dim,dep,arr): coul_bords = (0/255,110/255,118/255) coul_marec = (155/255,207/255,255/255) coul_prairie = (214/255,232/255,147/255) coul_murs = (0.3,0.3,0.3) coul_depart = (39/255,187/255,40/255) coul_arrivee = (255/255,25/255,0/255) for i in range(dim[0]): for j in range(dim[1]): if (i,j) not in carte: ax.add_patch(Rectangle((i,j), 1, 1, edgecolor = coul_bords, facecolor = coul_murs, fill=True, lw=2)) elif dessin[(i,j)] == 1: ax.add_patch(Rectangle((i, j), 1, 1, edgecolor = coul_bords, facecolor = coul_prairie, fill=True, lw=2)) else: ax.add_patch(Rectangle((i, j), 1, 1, edgecolor = coul_bords, facecolor = coul_marec, fill=True, lw=2)) ax.add_patch(Rectangle(dep, 1, 1, edgecolor = coul_bords, facecolor = coul_depart, fill=True, lw=2)) ax.add_patch(Rectangle(arr, 1, 1, edgecolor = coul_bords, facecolor = coul_arrivee, fill=True, lw=2)) ax.autoscale_view() trace_terrain((20,20),depart,arrivee) Recherche en largeur Utilisons l\u0026rsquo;algorithme de recherche en largeur (Breadth-First Search ou BFS) vu en cours pour tenter de trouver la plus petite chaîne de sommets reliant le départ à l\u0026rsquo;arrivée.\ndef recherche_largeur(G,depart,arrivee): file = [(depart,[depart])] Vus = {} while file: sommet,chemin = file.pop(0) if sommet == arrivee: return chemin,Vus if not sommet in Vus: for s in G[sommet]: nv_chemin = chemin+[s] file.append((s,nv_chemin)) Vus[sommet] = True return False Chaîne obtenue :\nrecherche_largeur(carte,depart,arrivee)[0] [(2, 2), (3, 2), (4, 2), (5, 2), (6, 2), (7, 2), (8, 2), (9, 2), (10, 2), (11, 2), (12, 3), (13, 4), (14, 5), (15, 6), (16, 7), (17, 8), (18, 9), (18, 10), (18, 11), (18, 12), (17, 13), (16, 14), (17, 15)]\nTraçons la chaîne en rose sur la carte :\ntrace_terrain((20,20),depart,arrivee) for sommet in recherche_largeur(carte,depart,arrivee)[0][1:-1]: ax.add_patch(Rectangle(sommet,1, 1,edgecolor=(0/255,110/255,118/255),facecolor=(255/255,209/255,247/255),fill=True,lw=2)) fig On constate donc que la recherche en largeur trouve un chemin très court qui évite bien le mur.\nVisualisons aussi (en les blanchissant) l\u0026rsquo;ensemble des sommets inspectés par l\u0026rsquo;algorithme pour trouver son chemin.\ntrace_terrain((20,20),depart,arrivee) for sommet in recherche_largeur(carte,depart,arrivee)[1]: ax.add_patch(Rectangle(sommet,1,1,edgecolor=(0/255,110/255,118/255),facecolor=(1,1,1,0.8),fill=True,lw=2)) fig Quasiment toute la carte a été inspectée\u0026hellip;\nRépondez aux trois questions suivantes :\nle chemin trouvé est-il le plus court possible indépendemment des pondérations ? le chemin trouvé est-il le plus court possible si on prend en compte les pondérations ? l\u0026rsquo;algorithme est-il efficace en terme de nombre de sommets inspectés ? Correction (cliquer pour afficher) oui non non Dijkstra Passons de la recherche en largeur à l\u0026rsquo;algorithme de Dijkstra. On utilise l\u0026rsquo;implémentation du cours avec des tas (file de priorité) fournis par le module heapq.\nimport heapq def Dijkstra(G, depart, arrivee): Scores = {sommet : float(\u0026#39;inf\u0026#39;) for sommet in G} Preds = {sommet : None for sommet in G} Scores[depart] = 0 Vus = {} tas = [(0, depart)] while tas: score_actuel, sommet_actuel = heapq.heappop(tas) if sommet_actuel == arrivee: return Preds,Scores,Vus if score_actuel == Scores[sommet_actuel]: score_voisin = G[sommet_actuel] for voisin in score_voisin.keys(): if voisin not in Vus: Vus[voisin] = True score = score_actuel + score_voisin[voisin] if score \u0026lt; Scores[voisin]: Scores[voisin] = score Preds[voisin] = sommet_actuel heapq.heappush(tas, (score, voisin)) Preds = Dijkstra(carte,depart,arrivee)[0] Définissez une fonction qui reconstitue la plus petite chaîne à partir de la liste des prédécesseurs fournie par Dijkstra.\ndef reconstruction_chaine(predecesseurs,depart,arrivee): \u0026#34;\u0026#34;\u0026#34; reconstruction_chemin(predecesseur: dict , depart: tuple , arrivee: tuple) -\u0026gt; chemin: liste de tuples predecesseur est un dictionnaire qui pour chaque clé sous forme de tuple (x,y) (un des sommets) donne son prédécesseur là aussi sous forme de tuple (x\u0026#39;,y\u0026#39;). la liste retournée, chaine, doit contenir la liste des sommets (chaque sommet est un tuple (x,y)) allant du depart à l\u0026#39;arrivee. \u0026#34;\u0026#34;\u0026#34; s = arrivee chaine = [s] # VOTRE CODE return chaine Correction (cliquer pour afficher) def reconstruction_chaine(predecesseurs,depart,arrivee): s = arrivee chaine = [arrivee] while s != depart : s = predecesseurs[s] chaine = [s] + chaine return chaine chaine_Dijk = reconstruction_chaine(Preds,depart,arrivee) Vérifiez que votre chaîne est bien la même que celle ci-dessous :\nchaine_Dijk = [(2, 2), (1, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (1, 9), (2, 10), (3, 11), (4, 12), (5, 13), (6, 14), (7, 15), (8, 16), (9, 17), (10, 18), (11, 19), (12, 19), (13, 19), (14, 19), (15, 19), (16, 18), (16, 17), (16, 16), (17, 15)] Traçons la chaîne obtenue.\ntrace_terrain((20,20),depart,arrivee) for sommet in chaine_Dijk[1:-1]: ax.add_patch(Rectangle(sommet,1,1,edgecolor=(0/255,110/255,118/255),facecolor=(255/255,209/255,247/255),fill=True,lw=2)) fig On constate que le chemin trouvé par Dijkstra prend maintenant soin de contourner le marécage.\ntrace_terrain((20,20),depart,arrivee) for sommet in Dijkstra(carte,depart,arrivee)[2]: ax.add_patch(Rectangle(sommet,1,1,edgecolor=(0/255,110/255,118/255),facecolor=(1,1,1,0.8),fill=True,lw=2)) fig À nouveau, une grande partie de la carte est inspectée.\nRépondez aux trois questions suivantes :\nle chemin trouvé est-il le plus court possible indépendemment des pondérations ? le chemin trouvé est-il le plus court possible si on prend en compte les pondérations ? l\u0026rsquo;algorithme est-il efficace en terme de nombre de sommets inspectés ? Correction (cliquer pour afficher) non oui non Ajout d\u0026rsquo;une heuristique Pour améliorer la vitesse des algorithmes précédents, on va leur ajouter une heuristique. Une heuristique est une petite recette, une règle simple, que l\u0026rsquo;algorithme va suivre pour s\u0026rsquo;économiser des étapes.\nLe point noir des algorithmes précédents est qu\u0026rsquo;ils semblent contraints de parcourir quasiment toute la carte avant d\u0026rsquo;être sûr d\u0026rsquo;avoir trouvé le bon chemin.\nOn va les aider en les guidant vers l\u0026rsquo;arrivée.\nL\u0026rsquo;heuristique va donc consister à guider le choix du prochain sommet de manière à ce qu\u0026rsquo;il diminue la distance jusqu\u0026rsquo;à l\u0026rsquo;arrivée. On le dirrige en quelque sorte vers sa destination\u0026hellip;\nImplémentons donc une fonction distance qui donne la distance entre deux sommets A et B.\nMais quelle distance ? Plusieurs définition non équivalentes sont possibles : distance euclidienne, distance de Manhattan\u0026hellip;\nIci, on va utiliser la distance de Tchebychev qui correspond à la distance sur un échiquier où les mouvements en diagonale coûte 1.\ndef distance(A,B): x_A,y_A = A x_B,y_B = B X = abs(x_B-x_A) Y = abs(y_B-y_A) return max(X,Y) Implémentons maintenant une variante de la recherche en largeur qui intègre l\u0026rsquo;heuristique grâce à un tas : pour chaque nouveau voisin inspecté, on calcule sa distance à l\u0026rsquo;arrivée puis on l\u0026rsquo;ajoute à un tas avec cette distance comme clé de classement.\nOn s\u0026rsquo;assure ainsi à chaque itération de retirer du tas le sommet rapprochant le plus de la destination finale.\nIl s\u0026rsquo;agit à nouveau d\u0026rsquo;un algorithme glouton.\nimport heapq def bfs_glouton(G,depart,arrivee): tas = [(0, depart)] Vus = {} Preds = dict() Preds[depart] = None while tas: dist_actuelle, sommet_actuel = heapq.heappop(tas) # on retire le sommet le plus proche de l\u0026#39;arrivée if sommet_actuel == arrivee: return Preds,Vus for voisin in G[sommet_actuel]: if voisin not in Vus: Vus[voisin] = True if voisin not in Preds: dist = distance(arrivee, voisin) heapq.heappush(tas, (dist, voisin)) # on place dans le tas le voisin affublé de sa distance Preds[voisin] = sommet_actuel chaine_glouton = reconstruction_chaine(bfs_glouton(carte,depart,arrivee)[0],depart,arrivee) trace_terrain((20,20),depart,arrivee) for sommet in chaine_glouton[1:-1]: ax.add_patch(Rectangle(sommet,1,1,edgecolor=(0/255,110/255,118/255),facecolor=(255/255,209/255,247/255),fill=True,lw=2)) fig On voit que le chemin se dirige tout de suite vers l\u0026rsquo;arrivée, jusqu\u0026rsquo;à rencontrer un mur\u0026hellip;\ntrace_terrain((20,20),depart,arrivee) for sommet in bfs_glouton(carte,depart,arrivee)[1]: ax.add_patch(Rectangle(sommet,1,1,edgecolor=(0/255,110/255,118/255),facecolor=(1,1,1,0.8),fill=True,lw=2)) fig Le nombre de sommets inspectés a spectaculairement diminué !\nRépondez aux trois questions suivantes :\nle chemin trouvé est-il le plus court possible indépendemment des pondérations ? le chemin trouvé est-il le plus court possible si on prend en compte les pondérations ? l\u0026rsquo;algorithme est-il efficace en terme de nombre de sommets inspectés ? Correction (cliquer pour afficher) non non oui A* Appliquons maintenant l\u0026rsquo;heuristique à l\u0026rsquo;algorithme de Dijkstra. On obtient l\u0026rsquo;algorithme A* (A étoile ou A star).\ndef Astar(G, depart, arrivee): Scores = {sommet : float(\u0026#39;inf\u0026#39;) for sommet in G} Preds = {sommet : None for sommet in G} Scores[depart] = 0 Vus = {} tas = [(0, 0, depart)] while tas: _, score_actuel, sommet_actuel = heapq.heappop(tas) # on utilise par convention \u0026#39;_\u0026#39; pour déballer un élément d\u0026#39;un tuple dont on ne fera pas usage. if sommet_actuel == arrivee: return Preds,Scores,Vus if score_actuel == Scores[sommet_actuel]: score_voisin = G[sommet_actuel] for voisin in score_voisin.keys(): if voisin not in Vus: Vus[voisin] = True score = score_actuel + score_voisin[voisin] if score \u0026lt; Scores[voisin]: Scores[voisin] = score Preds[voisin] = sommet_actuel heuristique = score + distance(voisin,arrivee) heapq.heappush(tas, (heuristique, score, voisin)) chaine_Astar = reconstruction_chaine(Astar(carte,depart,arrivee)[0],depart,arrivee) trace_terrain((20,20),depart,arrivee) for sommet in chaine_Astar[1:-1]: ax.add_patch(Rectangle(sommet,1,1,edgecolor=(0/255,110/255,118/255),facecolor=(255/255,209/255,247/255),fill=True,lw=2)) fig trace_terrain((20,20),depart,arrivee) for sommet in Astar(carte,depart,arrivee)[2]: ax.add_patch(Rectangle(sommet,1,1,edgecolor=(0/255,110/255,118/255),facecolor=(1,1,1,0.8),fill=True,lw=2)) fig Répondez aux trois questions suivantes :\nle chemin trouvé est-il le plus court possible indépendemment des pondérations ? le chemin trouvé est-il le plus court possible si on prend en compte les pondérations ? l\u0026rsquo;algorithme est-il efficace en terme de nombre de sommets inspectés ? Correction (cliquer pour afficher) non oui oui Évolutions comparées de recherche_largeur et de Dijkstra :\nThere should have been a video here but your browser does not seem to support it. Évolutions comparées de bfs_glouton et de Astar (vidéo ralentie 2$\\times$ par rapport à la précédente) :\nThere should have been a video here but your browser does not seem to support it. "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp7image/",
	"title": "TP 7 : matrices de pixels et image",
	"tags": [],
	"description": "",
	"content": " Tableau de pixels et images Cliquez sur cette invitation pour récupérer le repository du TP. Importer une image PIL (python imaging library) est l\u0026rsquo;une des librairies Python permettant de manipuler des fichiers image. On va l\u0026rsquo;utiliser en association avec numpy qui est le module de choix pour jouer avec des tableaux numériques.\nListes et tableaux (array en anglais) :\nLes deux structures permettent l\u0026rsquo;indexation, le découpage et l\u0026rsquo;itération sur les éléments.\nLes tableaux n\u0026rsquo;existent pas nativement en python, on les utilise en important le package NumPy.\nLes tableaux sont moins souples que les listes. Il faut par exemple les déclarer en amont.\nL\u0026rsquo;avantage des tableaux est qu\u0026rsquo;ils sont plus optimisés pour traiter des quantités de données importantes et pour réaliser des opérations mathématiques lorsque ces données sont numériques (multiplication d\u0026rsquo;un tableau de nombre par un scalaire, produit matriciel entre deux tableaux, etc.).\nExemple : tableau = np.array([3, 6, 9, 12]\ndivision = tableau/3\nprint(division)\nprint(type(division))\n$\\rightarrow$ [1. 2. 3. 4.]\n$\\rightarrow$ \u0026lt;class 'numpy.ndarray'\u0026gt;\nfrom PIL import Image import urllib.request # pour récupérer une image sur le web from IPython.display import display # pour afficher dans le notebook import matplotlib.pyplot as plt import numpy as np plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = (15,10) urllib.request.urlretrieve(\u0026#39;https://i.redd.it/quqjmqmi44q51.jpg\u0026#39;, \u0026#39;girafe\u0026#39;) # récupération du fichier image image_girafe = np.array(Image.open(\u0026#39;girafe\u0026#39;)) # le fichier est convertie en un tableau numpy girafe = Image.fromarray(image_girafe) # le tableau est converti en un objet image display(girafe) # affichage On a récupéré les données de l\u0026rsquo;image dans un tableau à trois dimensions numpy.\nOn a récupéré les données de l\u0026rsquo;image dans un tableau à trois dimensions numpy.\nLes deux premières dimensions correspondent aux coordonnées spatiales du pixel.\nL\u0026rsquo;indexation d\u0026rsquo;un tableau numpy autorise l\u0026rsquo;utilisation de virgules pour imiter les coordonnées mathématiques (mais les x et les y sont inversés car il s\u0026rsquo;agit de matrice et on commence toujours par indexer les lignes avant les colonnes). Le pixel ayant la coordonnée cartésienne $(x,y)$ avec une origine $(0,0)$ en haut à gauche va donc correspondre à l\u0026rsquo;élément image[y,x] (on peut aussi, comme avec les listes python, obtenir l\u0026rsquo;élément via image[y][x]).\nEt à chacun de ses pixels correspond un tableau de 3 entiers compris entre 0 et 255 codant la couleur du pixel (codage rgb, un nombre pour l\u0026rsquo;intensité du rouge, un pour l\u0026rsquo;intensité du vert et le dernier pour le bleu). C\u0026rsquo;est la 3e dimension du tableau.\nEt à chacun de ses pixels correspond un tableau de 3 entiers compris entre 0 et 255 codant la couleur du pixel (codage rgb, un nombre pour l\u0026rsquo;intensité du rouge, un pour l\u0026rsquo;intensité du vert et le dernier pour le bleu). C\u0026rsquo;est la 3e dimension du tableau.\nprint(image_girafe.shape) (1263, 843, 3)\nhauteur, largeur, _ = image_girafe.shape print(f\u0026#39;largeur : {largeur} pixels, hauteur : {hauteur} pixels\u0026#39;) largeur : 843 pixels, hauteur : 1263 pixel\nprint(image_girafe[20,700]) print(image_girafe[20][700]) [96 96 60]\n[96 96 60]\nCodage RGB RGB pour Red Green Blue (RVB en français) est un système de codage informatique des couleurs. Il repose sur la synthèse additive et suit donc le même principe que le codage des couleurs dans notre cerveau à partir des signaux envoyés par trois cellules spécialisées tapissant nos rétines, les cones, chacune ayant un spectre d\u0026rsquo;absorption centré sur les longueurs d\u0026rsquo;onde correspondantes à l\u0026rsquo;une des trois couleurs, rouge, vert ou bleu.\nlongueur = 400 synthese = np.zeros([longueur, longueur, 3], dtype=np.uint8) # création d\u0026#39;un tableau de dimension 3 (2 dimensions spatiales + la couleur) dont les entrées sont des entiers non signés codés sur 8 bits taille = longueur//2 x1,y1 = longueur//8,5*longueur//16 x2,y2 = longueur//4,longueur//8 x3,y3 = 3*longueur//8,3*longueur//8 synthese[y1:y1+taille,x1:x1+taille] = [255, 0, 0] synthese[y2:y2+taille,x2:x2+taille] = [0, 255, 0] synthese[y3:y3+taille,x3:x3+taille] = [0, 0, 255] affichage = Image.fromarray(synthese) display(affichage) On voit qu\u0026rsquo;il manque à l\u0026rsquo;image les zones de superposition.\nModifier le tableau synthese pour reproduire la figure suivante.\nCorrection (cliquer pour afficher) synthese[y3:y2+taille,x1+taille:x2+taille] = [0, 255, 255] synthese[y1:y2+taille,x2:x3] = [255, 255, 0] synthese[y1:y3,x3:x1+taille] = [255, 255, 0] synthese[y2+taille:y1+taille,x3:x1+taille] = [255, 0, 255] synthese[y3:y2+taille,x3:x1+taille] = [255, 255, 255] affichage = Image.fromarray(synthese) display(affichage) Faisons notre propre expérience physique de synthèse additive en codant des zones où les pixels alternent 2 couleurs primaires :\nlargeur = 900 hauteur = 300 synth_phy = np.zeros([hauteur, largeur, 3], dtype=np.uint8) # On alterne les pixels rouges et verts dans cette partie du tableau for i in range(hauteur): for j in range(largeur//3): if (i+j)%2: synth_phy[i,j] = [255,0,0] else: synth_phy[i,j] = [0,255,0] # On alterne les pixels verts et bleus dans cette partie du tableau for i in range(hauteur): for j in range(largeur//3,2*largeur//3): if (i+j)%2: synth_phy[i,j] = [0,0,255] else: synth_phy[i,j] = [0,255,0] # On alterne les pixels rouges et bleus dans cette partie du tableau for i in range(hauteur): for j in range(2*largeur//3,largeur): if (i+j)%2: synth_phy[i,j] = [0,0,255] else: synth_phy[i,j] = [255,0,0] synth_phy = Image.fromarray(synth_phy) display(synth_phy) Récupérons les composantes bleues, vertes et rouges de la photo de girafe :\nimage_R = image_girafe.copy() image_R[:,:,(1,2)] = 0 # équivalent à : # for i in range(hauteur) : # for j in range(largeur) : # image_R[i][j][1] = 0 # image_R[i][j][2] = 0 image_G = image_girafe.copy() image_G[:,:,(0,2)] = 0 image_B = image_girafe.copy() image_B[:,:,(0,1)] = 0 rvb = np.concatenate((image_R, image_G, image_B), axis=1) rvb = Image.fromarray(rvb) display(rvb) La superposition des trois filtres reproduit les couleurs d\u0026rsquo;origine.\nimage_rec = image_B.copy() image_rec[:,60:500] += image_G[:,60:500] image_rec[75:650,:] += image_R[75:650,:] image_rec = Image.fromarray(image_rec) display Dans le codage RGB utilisé aujourd\u0026rsquo;hui, l\u0026rsquo;intensité de chacune des 3 couleurs primaires est codée sur un octet (8 bits), ce qui permet une profondeur de 24 bits pour différentier les couleurs.\nCombien de couleurs sont alors représentables par ce système ?\nCorrection (cliquer pour afficher) $2^{24} = \\left(2^8\\right)^3 = 16\\,777\\,216$ Fabriquons une image contenant toutes ces couleurs !\nL\u0026rsquo;idée est de fabriquer d\u0026rsquo;abord une image $256\\times 256$ contenant toutes les nuances possibles de vert et rouge, de l\u0026rsquo;agrandir d\u0026rsquo;un facteur 16 de manière à qu\u0026rsquo;une combinaison rouge/vert unique corresponde à un gros pixel de $16\\times16$. Et on additionne à chacun de ces gros pixels une image $16\\times16$ bleu contenant les 256 teintes de bleu disposées en spirale.\nL\u0026rsquo;image rouge/verte est assez simple à coder (l\u0026rsquo;exécution met un peu de temps) :\nL1 = 4096 rougevert = np.zeros([L1, L1, 3], dtype=np.uint8) for r in range(256*16): for g in range(256*16): rougevert[r,g]=[r//16,g//16,0] plt.imshow(rougevert) Fabriquer la spirale bleue est plus dur\u0026hellip;\nL\u0026rsquo;image doit faire $16\\times16$ et contenir toutes les nuances de bleu. On commence en haut à gauche (x=0 et y=0) par du noir (0,0,0), et on progresse dans le sens des aiguilles d\u0026rsquo;une montre en ajoutant 1 à l\u0026rsquo;intensité du bleu à chaque pixel successif de la spirale pour finir au centre (en position x=7, y=8 pour être précis) par un pixel 100% bleu (0,0,255).\nIl reste une ligne à compléter dans le code suivant construisant le tableau permettant de représenter la spirale bleue. À vous de jouer\u0026hellip;\nL2 = 16 bleu = np.zeros([L2, L2, 3], dtype=np.uint8) liste1 = [L2] for i in range(1,L2): liste1 += [L2-i]*2 # liste1 = [16, 15, 15, 14, 14, 13, 13, 12, 12, 11, 11, 10, 10, 9, 9, 8, 8, 7, 7, 6, 6, 5, 5, 4, 4, 3, 3, 2, 2, 1, 1] liste2 = [0] s = 0 for e in liste1: s += e liste2 += [s] # liste2 = [0, 16, 31, 46, 60, 74, 87, 100, ..., 252, 254, 255, 256] k = 0 for i in range(0,len(liste2),4): bleu[k,k:L2-k,2] = np.arange(liste2[i],liste2[i+1]) # bleu[i,j,2] indexe la couleur bleue # np.arange(a,b) fournit un tableau des entiers consécutifs de a (inclus) à b (exclu) bleu[...,...,2] = np.arange(...,...) bleu[L2-1-k,k:L2-1-k,2] = np.arange(liste2[i+2],liste2[i+3])[::-1] if i != 28: bleu[k+1:L2-1-k,k,2] = np.arange(liste2[i+3],liste2[i+4])[::-1] k += 1 plt.imshow(bleu) Correction (cliquer pour afficher) On complète bleu[...,...,2] = np.arange(...,...)\u0026nbsp;:\nbleu[k+1:L2-k,L2-1-k,2] = np.arange(liste2[i+1],liste2[i+2]) longueur = 4096 rougevertbleu = np.zeros([longueur, longueur, 3], dtype=np.uint8) for i in range(0,4096,16): # on avance d\u0026#39;un gros pixel à l\u0026#39;autre avec le pas de 16 for j in range(0,4096,16): # les pixels du gros \u0026#34;pixel\u0026#34; 16*16 ont la même teinte rouge-vert rougevertbleu[i:i+16,j:j+16] = rougevert[i:i+16,j:j+16]+bleu # on ajoute la spirale bleue au gros pixel rougevertbleu = Image.fromarray(rougevertbleu) display(rougevertbleu) Les premières consoles de jeu avaient des graphismes de 6 bits (de profondeur). Plutôt que 256 possibilités pour chaque sous-pixel, on en était réduit à seulement 4 choix (2 bits).\nDéfinissez une fonction permettant de convertir l\u0026rsquo;image de la girafe en 6 bits.\ndef sixbit(image): \u0026#34;\u0026#34;\u0026#34; prend en argument un tableau numpy à 3 dimensions permettant de représenter une image couleur 24 bits et renvoie un nouveau tableau de mêmes dimensions correspondant à une conversion en 6 bits de l\u0026#39;image (chacune des 3 couleurs doit maintenant n\u0026#39;avoir que 4 valeurs d\u0026#39;intensité possibles uniformément réparties). \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE girafe = Image.fromarray(sixbit(image_girafe)) display(girafe) Correction (cliquer pour afficher) Solution la plus simple : def sixbit(image): image = (image+85//2)//85*85 #(arrondi inférieur) return image Commentaire (cliquer pour afficher) Cependant, l'étape de calcul (image+85//2) peut provoquer un dépassement de capacité si la valeur réelle dépasse 255.\nPour éviter cela, on peut convertir momentanément image en un tableau d'entiers 16 bits puis repasser en 8 bits une fois le calcul terminé\u0026nbsp;:\ndef sixbit(image): image = (image.astype(np.uint16)+85//2)//85*85 # pour éviter les dépassements return image.astype(np.uint8) On peut très facilement inverser les couleurs de l\u0026rsquo;image. Une ligne suffit :\nimage_inv = 255-image_girafe image_inv = Image.fromarray(image_inv) display(image_inv) Complétez la fonction NB qui retourne une version \u0026ldquo;niveau de gris\u0026rdquo; de l\u0026rsquo;image donnée en argument.\nPrincipe de la manœuvre : $(r,g,b)\\rightarrow (\\frac{r+g+b}{3},\\frac{r+g+b}{3},\\frac{r+g+b}{3})$\ndef NB(image): \u0026#34;\u0026#34;\u0026#34; prend en argument un tableau numpy à 3 dimensions (hauteur,largeur,3) représentant une image et renvoie un nouveau tableau correspondant à une conversion en niveau de gris de l\u0026#39;image. \u0026#34;\u0026#34;\u0026#34; hauteur, largeur, _ = image.shape image_NB = np.zeros([hauteur, largeur, 3], dtype=np.uint8) ### VOTRE CODE return image_NB Correction (cliquer pour afficher) def NB(image): hauteur, largeur, _ = image.shape image_NB = np.zeros([hauteur, largeur, 3], dtype=np.uint8) for k in range(3): image_NB[:,:,k] = (image[:,:,0]//3+image[:,:,1]//3+image[:,:,2]//3) return image_NB Transformation d\u0026rsquo;une image Construisez une fonction recadrage qui prend en argument l\u0026rsquo;image à recadrer, les coordonnées du coin supérieur gauche du nouveau cadre (sous la forme d\u0026rsquo;un tuple (x,y)), la largeur et la hauteur du nouveau cadre.\nFaites en sorte que recadrage(image_girafe,(30,50),500,600) recadre la tête de la girafe comme ci-dessous.\ndef recadrage(image,xy_coin,l_cadre,h_cadre): \u0026#34;\u0026#34;\u0026#34; prend en argument un tableau numpy à 3 dimensions (hauteur,largeur,3) représentant une image et renvoie un nouveau tableau à 3 dimensions (h_cadre,l_cadre,3). xy_coin est un tuple (x,y) où x et y sont des entiers correspondants aux coordonnées du coin supérieur gauche du nouveau cadre. l_cadre et h_cadre étant des nombres de pixels, ils doivent être entiers. \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE affichage = Image.fromarray(recadrage(image_girafe,(30,50),500,600)) display(affichage) Correction (cliquer pour afficher) def recadrage(image,xy_coin,l_cadre,h_cadre): i,j = xy_coin image_recadre = image[j:j+h_cadre,i:i+l_cadre] return image_recadre Complétez ensuite une fonction rotation qui tourne l\u0026rsquo;image de 90° vers la gauche en modifiant la disposition des pixels.\ndef rotation(image): \u0026#34;\u0026#34;\u0026#34; prend en argument un tableau numpy à 3 dimensions (hauteur,largeur,3) représentant une image et renvoie un nouveau tableau correspondant à l\u0026#39;image tournée de 90° vers la gauche. \u0026#34;\u0026#34;\u0026#34; hauteur, largeur, _ = image.shape image_tourne = np.zeros([largeur, hauteur, 3], dtype=np.uint8) ### VOTRE CODE return image_tourne affichage = Image.fromarray(rotation(image_girafe)) display(affichage) Correction (cliquer pour afficher) def rotation(image): hauteur, largeur, _ = image.shape image_tourne = np.zeros([largeur, hauteur, 3], dtype=np.uint8) for i in range(hauteur): for j in range(largeur): image_tourne[j][i] = image[i][j] return image_tourne On peut aussi s\u0026rsquo;amuser avec les symétries :\nhauteur, largeur, _ = image_girafe.shape image_sym = np.copy(image_girafe) for i in range(min(hauteur,largeur)): for j in range(min(hauteur,largeur)): image_sym[i][j]=image_sym[j][i] affichage = Image.fromarray(image_sym) display(affichage) Traitement d\u0026rsquo;image (filtrage) On va maintenant passer à des traitements plus évoluées :\nflou amélioration de la netteté détection des contours Elles reposent sur des convolutions dont la recette est la suivante :\nune petite matrice, la matrice de convolution, appelée noyau, est choisie, on balaye l\u0026rsquo;image à traiter avec un cadre ayant la taille de la matrice, à l\u0026rsquo;intérieur du cadre, on multiplie chacune des valeurs d\u0026rsquo;intensité des pixels par le coefficient correspondant de la matrice, on somme tous ces produits et on attribue la valeur au pixel au centre du cadre, on obtient ainsi une nouvelle matrice image correspondant à la convolution de l\u0026rsquo;image par le noyau. Suivant le noyau utilisé, on va modifier l\u0026rsquo;image de différentes façons.\nLa fonction suivante permet de calculer rapidement le produit de convolution lorsque le noyau est une matrice $3\\times 3$.\ndef conv(M,N): \u0026#34;\u0026#34;\u0026#34; M est la grande matrice (l\u0026#39;image) N est la petite matrice (le noyau) \u0026#34;\u0026#34;\u0026#34; h = len(M) l = len(M[0]) taille = len(N) marge = (taille-1) C = np.zeros((h-marge, l-marge)) for i in range(taille): for j in range(taille): C += N[i,j]*M[i:h-marge+i,j:l-marge+j] return C M = np.array([[2,2,2,2,2,2], [2,1,1,1,2,2], [2,1,3,4,2,2], [2,1,2,1,2,2], [2,2,3,2,2,2]]) N = np.array([[1,0,1], [0,2,0], [1,0,1]]) # Rq : on peut très bien écrire ces matrices en une ligne, on ne va ici à la ligne que pour améliorer la clarté. # N = np.array([[1,0,1],[0,2,0],[1,0,1]]) C = conv(M,N) print(C) # affiche # [[11. 11. 11. 14.] # [ 9. 10. 15. 10.] # [12. 13. 12. 14.]] Que valent les éléments $c_{kl}$ de la matrice $C$ donnée par conv(M,N) lorsque N est une matrice $3 \\times 3$ ?\na : $\\sum_{i=1}^{3}m_{ki}n_{il}$ b : $\\sum_{i=1}^{3}\\sum_{j=1}^{3}m_{(k-1+i)(l-1+j)}n_{ij}$ c : $\\sum_{i=1}^{3}\\sum_{j=1}^{3}m_{(k-i+1)(l-j+1)}n_{kl}$ Correction (cliquer pour afficher) La traduction mathématique de l'opération dans la double boucle est\u0026nbsp;:\n$$c_{kl}=\\sum_{i=1}^{3}\\sum_{j=1}^{3}m_{(k-1+i)(l-1+j)}n_{ij}$$ Floutage Pour flouter, l\u0026rsquo;idée va être de moyenner la valeur des pixels à l\u0026rsquo;intérieur du bloc grâce à un noyau $F$ du type : $$F=\\frac{1}{9}\\begin{pmatrix}1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\\end{pmatrix}$$ Cela revient à passer l\u0026rsquo;image dans un filtre passe-bas (= un moyenneur). En effet, la valeur de l\u0026rsquo;intensité d\u0026rsquo;un pixel sera maintenant une moyenne entre tous ses voisins.\nPlus la matrice $F$ sera grande et plus la fenêtre de moyennage sera grande et donc plus l\u0026rsquo;effet de flou sera intense.\nOn va ainsi pouvoir contrôler l\u0026rsquo;intensité du floutage en liant la taille de la matrice $F$ au paramètre force.\ndef flou(image,force): \u0026#34;\u0026#34;\u0026#34; flou(image,intensite_flou)-\u0026gt;image_floue image doit être un tableau dimension d\u0026#39;entier non signés codés sur 8 bits intensité_flou est un entier \u0026gt;= 1 image_floue est du même type qu\u0026#39;image \u0026#34;\u0026#34;\u0026#34; taille = 2*force+1 # taille de la matrice F F = np.ones((taille,taille))*1/taille**2 # matrice pour la convolution image_floue = image.copy() hauteur,largeur = image_floue.shape marge = (taille-1)//2 image_floue[marge:-marge,marge:-marge] = conv(image,F) image_floue = image_floue.astype(np.uint8) return image_floue urllib.request.urlretrieve(\u0026#39;https://fichier0.cirkwi.com/image/photo/poi/800x500/545297/fr/0.jpg\u0026#39;, \u0026#39;LaR\u0026#39;) image = np.array(Image.open(\u0026#39;LaR\u0026#39;)) hauteur,largeur,_ = image.shape LaR = np.zeros([hauteur, largeur]) # on associe maintenant à chaque pixel un seul chiffre : l\u0026#39;intensité de gris (entre 0 et 255) LaR = NB(image)[:,:,0] # il suffit de récupérer une des 3 couleurs de la conversion en niveau de gris de l\u0026#39;image affichage = Image.fromarray(LaR) display(affichage) LaR_floues = (LaR,) # un singulet nécessite cette petite virgule pour être reconnu for i in range(1,5): LaR_floues += (flou(LaR,i),) comparaison = np.concatenate(LaR_floues, axis=1) affichage = Image.fromarray(comparaison) display(affichage) Les matrices F utilisées dans les 4 images floutées :\n$\\frac{1}{9}\\begin{pmatrix}1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\\end{pmatrix}$,$\\frac{1}{25}\\begin{pmatrix}1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\end{pmatrix}$,$\\frac{1}{49}\\begin{pmatrix}1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\end{pmatrix}$ et $\\frac{1}{81}\\begin{pmatrix}1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\end{pmatrix}$\nAmélioration de la netteté On ne veut maintenant plus moyenner, mais au contraire accentuer les différences.\nPour cela, on choisit un noyau $N$ qui récompense les variations entre pixels voisins et est sans effet dans les zones de mêmes teintes : $$N=\\begin{pmatrix}0\u0026amp;-1\u0026amp;0\\\\-1\u0026amp;5\u0026amp;-1\\\\0\u0026amp;-1\u0026amp;0\\end{pmatrix}$$\nComplétez l\u0026rsquo;instruction manquante dans la définition de la fonction net qui renvoie le résultat d\u0026rsquo;une image convoluée par $N$.\ndef net(image): \u0026#34;\u0026#34;\u0026#34; net(image)-\u0026gt;image_nette \u0026#34;\u0026#34;\u0026#34; image = image.astype(np.int32) ### VOTRE CODE # on fixe les valeurs qui ont dépassé 255 à 255 et celles sous 0 à 0. image_nette[image_nette\u0026lt;0] = 0 image_nette[image_nette\u0026gt;255] = 255 image_nette = image_nette.astype(np.uint8) return image_nette Correction (cliquer pour afficher) L'instruction manquante est la construction du noyau\u0026nbsp;:\nN = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]) LaR_nette = net(LaR_floues[1]) comparaison = np.concatenate((LaR_floues[1][1:-1,1:-1],LaR_nette), axis=1) affichage = Image.fromarray(comparaison) display(affichage) Détection de contour (filtre de Sobel) On va agir en deux temps, grâce à deux noyaux.\nLe premier, $S_x$, va donner des valeurs d\u0026rsquo;autant plus loin de $0$ qu\u0026rsquo;il y a un fort gradient horizontal dans le bloc $3\\times3$ de l\u0026rsquo;image inspectée.\nEt l\u0026rsquo;autre, $S_y$, va mettre en valeur les gradients verticaux.\n$S_x = \\begin{pmatrix}-1\u0026amp;0\u0026amp;1\\\\-2\u0026amp;0\u0026amp;2\\\\-1\u0026amp;0\u0026amp;1\\end{pmatrix}$ et $S_y = \\begin{pmatrix}1\u0026amp;2\u0026amp;1\\\\0\u0026amp;0\u0026amp;0\\\\-1\u0026amp;-2\u0026amp;-1\\end{pmatrix}$\n$S_x$ fait la différence entre les voisins de droite et ceux de gauche quand $S_y$ fait la différence entre les voisins du dessus et ceux de dessous.\ndef grad_x(image): image = image.astype(np.int32) Sx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]) image_gradx = conv(image,Sx) # les gradients peuvent très bien être négatifs. On translate alors toutes les valeurs pour que la plus basse soit zéro. image_gradx = image_gradx - np.min(image_gradx) # on normalise ensuite en faisant en sorte que la plus haute valeur vaille 255 image_gradx = image_gradx/np.max(image_gradx)*255 image_gradx = image_gradx.astype(np.uint8) return image_gradx Écrivez la fonction grad_y sur le même modèle :\ndef grad_y(image): ### VOTRE CODE Correction (cliquer pour afficher) def grad_y(image): image = image.astype(np.int32) Sy = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]) image_grady = conv(image,Sy) image_grady = image_grady - np.min(image_grady) image_grady = image_grady/np.max(image_grady)*255 image_grady = image_grady.astype(np.uint8) return image_grady Gx = grad_x(LaR) Gy = grad_y(LaR) comparaison = np.concatenate((Gx,Gy), axis=0) affichage = Image.fromarray(comparaison) display(affichage) Le gradient global $G$ s\u0026rsquo;obtient en \u0026ldquo;pythagorisant\u0026rdquo; Gx et Gy : $G=\\sqrt{G_x^2+G_y^2}$.\nRemarque : cela revient finalement à appliquer un filtre passe-haut à l\u0026rsquo;image.\ndef grad(image): Gx = grad_x(image).astype(np.int32) Gy = grad_y(image).astype(np.int32) image_grad = np.sqrt(Gx**2+Gy**2) image_grad = image_grad/np.max(image_grad)*255 image_grad = image_grad.astype(np.uint8) return image_grad affichage = Image.fromarray(grad(LaR)) display(affichage) L\u0026rsquo;effet de relief est rendu par l\u0026rsquo;information sur la direction du gradient, information inutile si le contour est tout ce qui nous intéresse (que l\u0026rsquo;on passe d\u0026rsquo;une forte intensité à une faible ou l\u0026rsquo;inverse détecte un contour dans les deux cas).\nOn va donc reprendre les définitions en utilisant cette fois les valeurs absolues des gradients.\ndef grad_abs_x(image): image = image.astype(np.int32) Sx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]) image_gradx = np.abs(conv(image,Sx)) image_gradx = image_gradx/np.max(image_gradx)*255 image_gradx = image_gradx.astype(np.uint8) return image_gradx def grad_abs_y(image): image = image.astype(np.int32) Sy = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]) image_grady = np.abs(conv(image,Sy)) image_grady = image_grady/np.max(image_grady)*255 image_grady = image_grady.astype(np.uint8) return image_grady def contour(image): Gx = gradabs_x(image).astype(np.int32) Gy = gradabs_y(image).astype(np.int32) image_cont = np.sqrt(Gx**2+Gy**2) image_cont = image_cont/np.max(image_cont)*255 image_cont = image_cont.astype(np.uint8) return image_cont affichage = Image.fromarray(contour(LaR)) display(affichage) Nous partons maintenant de l\u0026rsquo;image d\u0026rsquo;un échiquier :\nParmi les images suivantes numérotées de 1 à 4, laquelle est produite par :\nA : grad_x(echiquier) B : grad_abs_y(echiquier) C : contour(echiquier) D : grad(echiquier) Correction (cliquer pour afficher) A $\\leftrightarrow$ 4 B $\\leftrightarrow$ 2 C $\\leftrightarrow$ 3 D $\\leftrightarrow$ 1 Quand on joue avec des images, les erreurs de code donnent parfois des résultats étonnants. N\u0026rsquo;hésitez pas à enregistrer/copier vos bizarreries, s\u0026rsquo;il y en a. Je récompenserai la plus belle/tordue.\nCi-dessous, un échec faisant tomber la pluie sur La Rochelle\u0026hellip; "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_3/numerique/",
	"title": "Algorithmique numérique",
	"tags": [],
	"description": "",
	"content": "Algorithmique numérique L\u0026rsquo;informatique n\u0026rsquo;aime pas les flottants mais les physiciens et les mathématiciens désireux de simulations ou de résolution d\u0026rsquo;équations font difficilement sans\u0026hellip; Il faut alors optimiser les algorithmes pour qu\u0026rsquo;ils évitent le mieux possible les pièges tendus par le codage fatalement imparfait des nombres réels en machine (pensez à revoir le chapitre en question pour vous rafraîchir la mémoire).\nPivot de Gauss Deux problèmes liés aux flottants :\nla vérification de la non nullité du pivot le choix du pivot Comment vérifier qu\u0026rsquo;un pivot potentiel est nul ? Tester une inégalité entre deux flottants est toujours une mauvaise idée (voirs cours sur la représentation des nombres en machine)\nPar exemple, 0.1**2==0.01 renvoie False\u0026hellip;\nDans le cas du pivot de Gauss, le plus judicieux est de se donner une tolérance faible adaptée au problème (il faut qu\u0026rsquo;elle soit suffisamment petite par rapport aux autres valeurs obtenues), et de tester que la valeur absolue du pivot candidat est indérieur à cette valeur.\nPar exemple :\ntol = 1E-6 if abs(pivot) \u0026lt; tol : # inspecter le pivot suivant Comment choisir le plus efficacement le pivot ? Imaginons que l\u0026rsquo;on veuille résoudre le système suivant :\n$$ \\begin{cases} 10^{-4}x \u0026amp;+ \u0026amp;y\u0026amp;=1 \\\\ \\hphantom{10^{-4}}x \u0026amp;+ \u0026amp;y \u0026amp;=2 \\\\ \\end{cases} $$\nEt supposons que les calculs se fassent à 3 chiffres significatifs.\nEn choisissant $\\color{red}a_{11}=10^{-4}$ comme pivot, on obtient : $$ L_2 : L_2 - L_1\\times\\frac{1}{\\color{red}10^{-4}} \\longrightarrow 0\\times x + (1 - 10^4)y = 2 - 1\\times10^4 $$ En ne gardant que 3 chiffres significatifs, on se retrouve donc avec le système suivant :\n$$ \\begin{cases} 10^{-4} \u0026amp;x \u0026amp;+\u0026amp;1 \u0026amp;y \u0026amp;=\u0026amp;1 \\\\ 0 \u0026amp;x \u0026amp;-\u0026amp; 10^4 \u0026amp;y \u0026amp;=\u0026amp;-1\\cdot10^4 \\\\ \\end{cases} $$\nCe qui donne une solution dans les choux :\n$$ \\begin{cases} x \u0026amp;= \u0026amp;0 \\\\ y \u0026amp;= \u0026amp;1 \\\\ \\end{cases} $$\nMais si plutôt que choisir le premier élément comme pivot, nous avions sélectionné le plus grand (en valeur absolu), ce qui correspond ici au choix de $\\color{blue}a_{21}=1$ plutôt que $a_{11}=10^{-4}$, nous aurions alors obtenu : $$ L_1 : L_1 - L_2\\times\\frac{10^{-4}}{\\color{blue}1} \\longrightarrow 0\\times x + (1 - 10^{-4})y = 1 - 2\\times10^{-4} $$\nOn obtient ainsi :\n$$ \\begin{cases} 0 \u0026amp;x \u0026amp;+\u0026amp;1 \u0026amp;y \u0026amp;=\u0026amp;1 \\\\ 1 \u0026amp;x \u0026amp;+\u0026amp; 1 \u0026amp;y \u0026amp;=\u0026amp;2 \\\\ \\end{cases} $$\nCe qui donne une nouvelle solution, elle aussi incorrecte, mais quand même beaucoup plus présentable :\n$$ \\begin{cases} x \u0026amp;= \u0026amp;1 \\\\ y \u0026amp;= \u0026amp;1 \\\\ \\end{cases} $$\nSi le codage des flottants permet plus de 3 chiffres significatifs, il sont malgré tout limités (16 chiffres tout au plus) et cela amène à préférer une stratégie comme la deuxième qui assure un moindre impact des troncatures dues à cette limite.\nLa méthode du pivot partiel consiste à choisir systématiquement comme pivot le terme de plus grande valeur absolue dans chaque colonne.\nElle permet d\u0026rsquo;amoindrir les erreurs d\u0026rsquo;arrondis.\nLa méthode du pivot total consiste, elle, à chosir comme $i^\\text{e}$ pivot le coefficient de valeur absolue maximale dans la matrice $\\left(a_{kl}\\right)_{k≥i,l≥i}$.\nMais on utilise en pratique très peu cette méthode, car elle nécessite de réordonner les colonnes en plus des lignes (ce qui est lourd).\nInterpolation polynomiale de Lagrange Interpolation : technique consistant à approximer une fonction $f$ à partir seulement d\u0026rsquo;un ensemble de points ${(x_i,f(x_i))}$.\nInterpolation polynomiale de Lagrange : on approxime la fonction par un polynôme devant passer par tous les points.\nLe polynôme interpolant $n$ points, s’écrit directement dans la base de Lagrange sous la forme : $$ P(x) = \\sum_{j=1}^n y_j\\left(\\color{purple}\\prod_{i=1,i≠j}^n \\frac{x-x_i}{x_j-x_i}\\color{black}\\right) $$ Par exemple, pour 3 points ${(x_1,y_1),(x_2,y_2),(x_3,y_3)}$, on obtient : $$ P(x) = y_1\\color{purple}\\frac{(x-x_2)(x-x_3)}{(x_1-x_2)(x_1-x_3)}\\color{black}+y_2\\color{purple}\\frac{(x-x_1)(x-x_3)}{(x_2-x_1)(x_2-x_3)}\\color{black}+y_3\\color{purple}\\frac{(x-x_1)(x-x_2)}{(x_3-x_1)(x_3-x_2)} $$\nL\u0026rsquo;interpolation polynomiale peut devenir instable dès que le nombre de points augmente, c\u0026rsquo;est le phénomène de Runge (voir TP).\nNumériquement, on préfère alors interpoler par morceaux, ce qui permet de se contenter de polynômes de degrés faibles (évitant ainsi les phénomènes d\u0026rsquo;oscillations).\nInterpolation par morceaux On découpe l\u0026rsquo;intervalle en morceaux sur lesquels on interpole sur un petit nombre de points.\n1 point : polynôme de degré 0 Le cas le plus simple correspond à une interpolation de chaque morceau par une constante. 2 points : polynôme de degré 1 Si on garde deux points par morceau, on obtient une interpolation linéaire et l\u0026rsquo;interpolation globale est une fonction affine par morceau. 3 points : polynôme de degré 2 Et avec 3 points par morceau, on peut modéliser chaque tronçon par une loi parabolique passant par ces 3 points. Sur l\u0026rsquo;exemple de la fonction sinus, l\u0026rsquo;interpolation par morceau avec des polynômes de degrés 2 donne un très bon résultat. Mais à nouveau, le choix du degré ne doit pas se faire aveuglément comme le montre l\u0026rsquo;exemple ci-dessous où la fonction discontinue est mal approchée par une interpolation par morceaux de degré 2. Intégration numérique L’intégration numérique (ou quadrature) consiste à intégrer (de façon approchée) une fonction sur un intervalle borné $[a, b]$, c’est-à dire calculer l’aire sous la courbe représentant la fonction, à partir d’un calcul ou d’une mesure en un nombre fini $n$ de points.\nL’intégration des polynômes étant très simple, l’opération consiste généralement à construire une interpolation polynomiale (de degré plus ou moins élevé) par morceaux (intégration composée) puis d’intégrer le polynôme sur chaque morceau.\nOn obtient la méthodes des rectangles (à gauche, à droite ou milieu) avec des polynôme de degré 0, la méthode des trapèzes avec des polynômes de degré 1 et la méthode de Simpson avec des polynômes de degré 2 (on va rarement plus loin).\nVous retrouverez un exemple d\u0026rsquo;implémentation python d\u0026rsquo;intégration numérique à la fin du TP 2.\nMéthode d\u0026rsquo;Euler La méthode d\u0026rsquo;Euler est la technique la plus simple pour déterminer numériquement la solution d\u0026rsquo;une équation différentielle.\nPlus précisément, on cherche la solution au problème de Cauchy suivant :\n$$ \\begin{cases} y\u0026rsquo;(t) = f(t,y(t)) \\\\ y(t_0) = y_0 \\\\ \\end{cases} $$\nL\u0026rsquo;idée maîtresse de la méthode est qu\u0026rsquo;une fonction suffisamment régulière se confond localement avec sa tangente. On va alors découper le temps $t$ et approximer sur chacun des pas la fonction $y(t)$ par sa tangente.\nC\u0026rsquo;est sur la détermination de la pente de la tangente à partir de $f$ que les méthodes de résolution diffèrent.\nMéthode d\u0026rsquo;Euler explicite on choisit un pas temporel constant $h$ petit et on pose $t_n=t_0+nh$. pour chaque intervalle de temps, entre $t_i$ et $t_{i+1}=t_i+h$, on calcule : $y_{i+1}=y_i + hf(t_i,y_i)$ Illustration avec le mouvement vertical d\u0026rsquo;un ballon ($h=dt$ et $f(t,y(t))=v_y(t)$) : Cette méthode ainsi décrite est dite explicite car chaque $y_{i+1}$ est une fonction explicite des $y_j$ pour $j≤i$.\nLa méthode d\u0026rsquo;Euler permet d\u0026rsquo;intégrer des équations différentielles de tout ordre puisqu\u0026rsquo;une équation diférentielle d\u0026rsquo;un ordre supérieur à 1 peut toujours s\u0026rsquo;exprimer comme un système d\u0026rsquo;équations du premier ordre.\nEn effet, l\u0026rsquo;équation $y^{(N)}(t)=f\\left(t,y(t),y\u0026rsquo;(t),\\ldots,y^{(N-1)}(t)\\right)$ peut se réécrire en introduisant les variables intermédiaires $z_1(t)=y(t),z_2(t)=y\u0026rsquo;(t),\\ldots,z_N(t)=y^{(N-1)}(t)$ : $$ \\pmb{z(t)} = \\begin{pmatrix} z\u0026rsquo;_1(t) \\\\ \\vdots \\\\ z\u0026rsquo;_{N-1}(t) \\\\ z\u0026rsquo;_N(t) \\end{pmatrix}=\\begin{pmatrix} y\u0026rsquo;(t) \\\\ \\vdots \\\\ y^{(N-1)}(t) \\\\ y^{(N)}(t) \\end{pmatrix} = \\begin{pmatrix} z_2(t) \\\\ \\vdots \\\\ z_N(t) \\\\ f(t,z_1(t),\\ldots,z_N(t)) \\end{pmatrix} $$ Il s\u0026rsquo;agit bien alors d\u0026rsquo;un système du premier ordre en la variable $\\pmb{z(t)}$ et on peut donc utiliser la méthode d\u0026rsquo;Euler.\nPrenons l\u0026rsquo;exemple de l\u0026rsquo;équation du mouvement d\u0026rsquo;un pendule : $$\\ddot{\\theta}+\\frac{g}{L}\\sin\\theta =0$$ En introduisant $z_1(t)=\\theta(t)$ et $z_2(t)=\\dot{\\theta}(t)$, on se retrouve avec le système d\u0026rsquo;équations différentielles du premier ordre suivant : $$ \\begin{cases} \\dot{z_1}(t) = z_2(t) \\\\ \\dot{z_2}(t) = -\\frac{g}{L}\\sin{z_1(t)} \\\\ \\end{cases} $$\nLimites Erreur de troncature locale L\u0026rsquo;erreur de troncature locale de la méthode d\u0026rsquo;Euler est la petite erreur faite à chaque étape. C\u0026rsquo;est la différence entre la solution numérique après une étape, $y_1$, et la solution exacte à l\u0026rsquo;instant $t_1=t_0+h$.\nLa solution numérique est donnée par : $$y_1 = y_0+hf(t,y_0)$$ Et la solution exacte, donnée par un développement de Taylor autour de $t_0$, s\u0026rsquo;écrit : $$y(t_1)=y(t_0+h)=y(t_0)+hy\u0026rsquo;(t_0)+\\frac{1}{2}h^2y\u0026rsquo;\u0026rsquo;(t_0)+O(h^3)$$ L\u0026rsquo;erreur vaut la différence : $$y(t_1)-y_1=\\frac{1}{2}h^2y\u0026rsquo;\u0026rsquo;(t)+O(h^3)$$ Cela montre que pour un petit $h$, l\u0026rsquo;erreur de troncature locale est approximativement proportionnelle à $h^2$.\nErreur de troncature globale L\u0026rsquo;erreur de troncature globale est l\u0026rsquo;erreur faite à un instant fixe $t$, après tous les pas qu\u0026rsquo;il a fallu pour arriver à $t$ à partir de $t_0$.\nL\u0026rsquo;erreur de troncature globale correspond ainsi à l\u0026rsquo;accumulation des erreurs de troncature locale.\nÉtant donné que le nombre d\u0026rsquo;étapes est donné par $\\frac{t-t_0}{h}$ ce qui le rend proportionnel à $1/h$ et que l\u0026rsquo;erreur locale est approximativement proportionnelle à $h^2$, on se retrouve avec une erreur globale proportionnelle à $h$.\nQue l\u0026rsquo;erreur globale soit approximativement linéaire en $h$ est la raison pour laquelle la méthode d\u0026rsquo;Euler est dite d\u0026rsquo;ordre 1.\nErreur d\u0026rsquo;arrondi On pourrait se dire \u0026ldquo;qu\u0026rsquo;à cela ne tienne ! Suffit de prendre un pas rikiki\u0026hellip;\u0026rdquo; Mais un nouveau problème se pose allors : les erreurs d\u0026rsquo;arrondis.\nDu fait des limites du codage des nombres réels en machine, chaque calcul à partir d\u0026rsquo;un flottant est entâché d\u0026rsquo;une erreur due à l\u0026rsquo;arrondi. On exprime généralement cette erreur en fonction de l\u0026rsquo;epsilon machine $\\varepsilon$.\nl\u0026rsquo;epsilon machine ou précision machine est la limite supérieure de l\u0026rsquo;erreur relative d\u0026rsquo;approximation causée par l\u0026rsquo;arrondi.\nEn python, comme la mantisse d\u0026rsquo;un flottant correspond à 53 bits, l\u0026rsquo;errreur relative se fait sur le dernier bit et vaut donc $2^{-53}$ ($\\varepsilon=2^{-52}$ au pire entre deux arrondis consécutifs).\nLe code ci-dessous trouve la première puissance de 2, $x$, pour laquelle $x+1$ est arrondie à $x$ (absorption), provoquant une erreur relative (la plus grande possible) de $1/x$. Par conséquent, l\u0026rsquo;erreur d\u0026rsquo;arrondi sur chaque valeur $y_n$ obtenue par la méthode d\u0026rsquo;Euler est de l\u0026rsquo;ordre de $\\varepsilon y_n$. Et en considérant ces erreurs d\u0026rsquo;arrondi comme des variables aléatoires indépendantes, l\u0026rsquo;erreur d\u0026rsquo;arrondi totale va être de l\u0026rsquo;ordre de $\\varepsilon\\sqrt{n}$ où $n$, le nombre de valeurs calculées, est inversement proportionnel au pas.\nFinalement, l\u0026rsquo;erreur d\u0026rsquo;arrondi globale est proportionnelle à $\\frac{\\varepsilon}{\\sqrt{h}}$ et donc diverge lorsque $h$ tend vers 0 !\nRéduire l\u0026rsquo;erreur de troncature se fait donc au détriment de l\u0026rsquo;erreur d\u0026rsquo;arrondi. Néanmoins, on peut se prémunir en bonne part des erreurs d\u0026rsquo;arrondi grâce à une sommation compensée (algorithme de Kahan).\nStabilité numérique Comme le montre l\u0026rsquo;exemple précédent d\u0026rsquo;un oscillateur harmonique amorti, la méthode d\u0026rsquo;Euler explicite peut être numériquement instable, la solution numérique s\u0026rsquo;écartant de plus en plus de la solution exacte.\nSi la méthode d\u0026rsquo;Euler est utilisée sur l\u0026rsquo;équation linéaire $y\u0026rsquo;=ky$, alors la solution numérique ne sera stable que si le produit $hk$ est dans la région $\\left\\{z \\in\\mathbb{C} ,|1+z| ≤ 1\\right\\}$.\nOn obtient en effet : $y_{n+1}=(1+hk)y_n$\nEt donc : $y_n = y_0(1+hk)^n$\nLe domaine de stabilité correspond à la partie du plan complexe où cette suite géométrique est bornée. Il s\u0026rsquo;agit bien du disque de centre $z=-1$ et de rayon 1 (en posant $z=hk$).\nEn généralisant à un système différentiel linéaire de la forme : $y\u0026rsquo;(t)=My(t)$ (où $M$ est une matrice carrée), il faudra, pour obtenir une solution stable, que chaque valeur propre de $M$ soit dans le disque précédent.\nPour notre exemple, on a : $$\\begin{pmatrix}\\dot{z}_1\\\\ \\dot{z}_2\\end{pmatrix}=\\begin{pmatrix}0\u0026amp;1\\\\ -{\\omega_0}^2 \u0026amp; -\\frac{\\omega_0}{Q}\\end{pmatrix}\\begin{pmatrix}z_1\\\\ z_2\\end{pmatrix}$$\nOn obtient deux valeurs propres imaginaires pures si $Q\u0026gt;1/2$ : $$\\lambda_{\\genfrac{}{}{0pt}{}{1}{2}} = \\omega_0\\left(\\frac{1}{2Q} \\pm i\\sqrt{\\left(1-\\frac{1}{2Q}\\right)^2}\\right)$$ et donc pour que $hk=h\\lambda_{\\genfrac{}{}{0pt}{}{1}{2}}$ soit à l\u0026rsquo;intérieur du domaîne de stabilité, il faut que $\\left(-\\frac{h\\omega_0}{2Q}+1\\right)^2 + \\left(\\frac{h\\omega_0}{2Q}\\right)^2(4Q^2-1) ≤ 1$. En passant la valeur de $h$ à 0.002 dans le programme de l\u0026rsquo;oscillateur harmonique amorti, on constate effectivement que l\u0026rsquo;amplitude de l\u0026rsquo;oscillation daigne bien maintenant diminuer\u0026hellip;\nPour résumer, la méthode d\u0026rsquo;Euler explicite a pour qualité d\u0026rsquo;être très simple à coder, mais elle cumule de nombreux défauts\u0026hellip;\nMéthode d\u0026rsquo;Euler implicite Si plutôt qu\u0026rsquo;évaluer $f$ au point de départ ($t_n$,$y_n$), on l\u0026rsquo;évalue au point d\u0026rsquo;arrivée ($t_{n+1}$,$y_{n+1}$), on obtient la méthode d\u0026rsquo;Euler implicite : $$y_{n+1}=y_n+hf(t_{n+1},y_{n+1})$$ La méthode est dite implicite car $y_{n+1}$ est présent dans les deux membres. Par conséquent, on doit à chaque étape résoudre une équation pour déterminer le nouveau point, ce qui rend l\u0026rsquo;implémentation plus coûteuse.\nCette méthode est aussi d\u0026rsquo;ordre 1, mais son domaîne de stabilité est beaucoup plus grand que celui de la méthode explicite puisqu\u0026rsquo;il s\u0026rsquo;agit de l\u0026rsquo;extérieur du disque de rayon 1 centré sur (1;0). Cela permet de l\u0026rsquo;utiliser sur les équations différentielles raides.\nLes méthodes explicites et implicites présentent toutes deux un gros défaut pour qui s\u0026rsquo;attelle à la résolution de problèmes de mécanique : elles ne conservent pas l\u0026rsquo;énergie !\nLa méthode explicite va avoir tendance à ajouter de l\u0026rsquo;énergie dans le système alors que la métode implicite va avoir tendance à en enlever (ce qu\u0026rsquo;on peut mettre en lien avec sa plus grande stabilité).\nL\u0026rsquo;idée pour conserver l\u0026rsquo;énergie est alors d\u0026rsquo;utiliser une combinaison des deux méthodes.\nMéthode d\u0026rsquo;Euler semi-implicite C\u0026rsquo;est la méthode la plus pratique pour résoudre des problèmes de mécanique. Elle allie la simplicité de la méthode explicite (elle est même plus simple à implémenter !) et le stabilité de la méthode implicite. Et surtout, elle conserve l\u0026rsquo;énergie.\nPour un système du deuxième ordre, on va écrire : $$\\begin{cases}z_2(t_{n+1}) = z_2(t_n) + h f(t_n,z_1(t_n),z_2(t_n)) \\\\z_1(t_{n+1}) = z_1(t_n) + h z_2(t_{n+1}) \\end{cases}$$ On utilise donc la valeur de $z_2(t_{n+1})$ qui vient d\u0026rsquo;être mise à jour dans le calcul de $z_1(t_{n+1})$.\nDans le cas de la détermination de la position d\u0026rsquo;un mobile à partir d\u0026rsquo;une équation différentielle du 2e ordre, on détermine donc d\u0026rsquo;abord la nouvelle vitesse, puis la position à partir de cette nouvelle vitesse.\nLa méthode est là encore d\u0026rsquo;ordre 1. On constate que si l\u0026rsquo;amplitude est maintenant proprement modélisée, c\u0026rsquo;est au détriment d\u0026rsquo;un déphasage entre la solution numérique et la solution exacte d\u0026rsquo;autant plus important que la pas est grand.\nMéthodes d\u0026rsquo;ordre supérieur La méthode Runge Kutta d\u0026rsquo;ordre 2 (ou méthode de Heun, ou méthode d\u0026rsquo;Euler améliorée) consiste à moyenner la valeur de la pente de la tangente au point $(t_i,y_i)$ et au point $(t_{i+1},y_{i+1})$, mais comme on ne connaît pas encore $y_{i+1}$, on utilise comme approximation la valeur donnée par la méthode d\u0026rsquo;Euler explicite : $$\\begin{cases} k_1 = f(t_i,y_i)\\\\ k_2 = f(t_{i+1},y_i+hk_1) \\\\ y_{k+1} = y_k + h\\frac{k_1+k_2}{2}\\end{cases}$$ On obtient ainsi une méthode d\u0026rsquo;ordre 2 (l\u0026rsquo;erreur de troncature globale est proportionnelle à $h^2$).\nOn peut aller encore plus loin en introduisant un point au milieu de l\u0026rsquo;intervalle et en moyennant 4 pentes de tangente différentes :\nla pente $k_1$ au début de l\u0026rsquo;intervalle, déjà connue, la pente $k_2$ au milieu de l\u0026rsquo;intervalle que l\u0026rsquo;on approxime en utilisant une première estimation de $y_{i+1/2}$ grâce à $k_1$, la pente $k_3$ au milieu de l\u0026rsquo;intervalle que l\u0026rsquo;on approxime en utilisant une seconde estimation de $y_{i+1/2}$ grâce à $k_2$, la pente $k_4$ à la fin de l\u0026rsquo;intervalle que l\u0026rsquo;on approxime en utilisant une estimation de $y_{i+1}$ grâce à $k_3$. $$\\begin{cases} k_1 = f(t_i,y_i)\\\\ k_2 = f(t_{i+1/2},y_i+h\\frac{k_1}{2}) \\\\ k_3 = f(t_{i+1/2},y_i+h\\frac{k_2}{2}) \\\\ k_4 = f(t_{i+1},y_i+hk_3) \\\\ y_{k+1} = y_k + h\\frac{k_1+2k_2+2k_3+k_4}{6}\\end{cases}$$\nOn obtient alors la méthode Runge Kutta d\u0026rsquo;ordre 4 (RK4) qui, comme son nom l\u0026rsquo;indique, est d\u0026rsquo;ordre 4. C\u0026rsquo;est sans doute la méthode la plus utilisée car elle donne des résultats précis et fidèles pour des pas n\u0026rsquo;ayant pas besoin d\u0026rsquo;être trop petits.\nOn peut écrire que :\n$y(t_{n+1}) = y(t_n)+\\int_{t_n}^{t_{n+1}}f(t,y(t))dt$\nRésoudre numériquement l\u0026rsquo;équation différentielle revient donc à intégrer la fonction $f$ sur chaque pas. Et si pour cela on applique les méthodes de quadratures évoquées plus haut (et au TP2) on retrouve que :\n● la méthode des rectangles à gauche correspond à la méthode d\u0026rsquo;Euler explicite ;\n● la méthode des rectangles à droite correspond à la méthode d\u0026rsquo;Euler implicite ;\n● la méthode des trapèzes correspond à la méthode Runge Kutta d\u0026rsquo;ordre 2 ;\n● la méthode de Simpson correspond à la méthode Runge Kutta d\u0026rsquo;ordre 4.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/projets/axelrod/",
	"title": "Tournoi d&#39;Axelrod",
	"tags": [],
	"description": "",
	"content": "Le tournoi d\u0026rsquo;Axelrod La mission est d\u0026rsquo;implémenter le tournoi d\u0026rsquo;Axelrod première version présenté dans la vidéo ci-dessous.\nVous ferez concourir les stratégies suivantes en écrivant une fonction par stratégie :\nAllC : coopère toujours. AllD : trahit toujours. Rando : joue au hasard. Alt : alterne un coup sur deux. TitforTat : coopère au premier coup puis joue le coup précédent de l\u0026rsquo;adversaire. Grudger : commence par coopérer mais dès que l\u0026rsquo;autre trahit, trahit toujours. Joss : commence par coopérer puis joue le coup précédent de l\u0026rsquo;adversaire sauf 10% du temps où il trahit. TitforTwoTats : trahit si l\u0026rsquo;autre trahit deux fois de suite, coopère sinon. TwoTitsforTat : coopère tant que l\u0026rsquo;autre coopère, mais à chaque trahison de l\u0026rsquo;adversaire, trahit deux fois consécutives. Tester : commence par trahir. Si l\u0026rsquo;autre a coopéré au premier coup, Tester se repent et joue TitforTat pour la suite, sinon il joue Alt. Eatherly : commence par trahir puis trahit en proportion du taux de trahison de l\u0026rsquo;autre jusqu\u0026rsquo;à ce coup. Gofman : commence par coopérer. Si les deux joueurs ont joué différemment au coup précédent, trahit avec une probabilité de 5/7, et coopère s\u0026rsquo;ils ont joué la même chose. Tullock : coopère les 10 premiers coups puis coopère à chaque coup 10% de moins que l\u0026rsquo;autre a coopéré sur les 10 coups qui précèdent. Pavlov : commence par coopérer. Si l\u0026rsquo;autre a coopéré au dernier tour, on garde le même coup, sinon on change. Donnez le palmarès du tournoi après 200 parties.\nUne solution : from random import random import seaborn as sns import matplotlib.pyplot as plt Les différentes stratégies :\ndef TitforTat(liste_coups_joueur,liste_coups_adverses): if len(liste_coups_adverses) == 0: return 1 elif liste_coups_adverses[-1]: return 1 else: return 0 def Grudger(liste_coups_joueur,liste_coups_adverses): if len(liste_coups_adverses) == 0: return 1 else: if liste_coups_joueur[-1] == 0: return 0 elif liste_coups_adverses[-1] == 0: return 0 else: return 1 def Joss(liste_coups_joueur,liste_coups_adverses): if len(liste_coups_adverses) == 0: return 1 else: if random()\u0026lt;0.1: return 0 else: return liste_coups_adverses[-1] def Rando(liste_coups_joueur,liste_coups_adverses): return int(random()*2) def AllD(liste_coups_joueur,liste_coups_adverses): return 0 def AllC(liste_coups_joueur,liste_coups_adverses): return 1 def TitforTwoTats(liste_coups_joueur,liste_coups_adverses): # tit for 2 tats if len(liste_coups_adverses) \u0026lt; 2: return 1 elif liste_coups_adverses[-1]+liste_coups_adverses[-2] == 0: return 0 else: return 1 def TwoTitsforTat(liste_coups_joueur,liste_coups_adverses): if len(liste_coups_adverses) \u0026lt; 1: return 1 elif liste_coups_adverses[-1] == 0 or (len(liste_coups_adverses) \u0026gt; 1 and liste_coups_adverses[-2] == 0): return 0 else: return 1 def Tester(liste_coups_joueur,liste_coups_adverses): if len(liste_coups_adverses) == 0: return 0 elif len(liste_coups_adverses) == 1: return liste_coups_adverses[-1] else: if liste_coups_adverses[1]: # tit for tat return liste_coups_adverses[-1] else: # alternance return (len(liste_coups_adverses)+1)%2 def Eatherly(liste_coups_joueur,liste_coups_adverses): if len(liste_coups_adverses) == 0: return 0 else: if random() \u0026lt; (len(liste_coups_adverses)-sum(liste_coups_adverses))/len(liste_coups_adverses): return 0 else: return 1 def Alt(liste_coups_joueur,liste_coups_adverses): return (len(liste_coups_adverses)+1)%2 def Gofman(liste_coups_joueur,liste_coups_adverses): if len(liste_coups_adverses) == 0: return 1 else: if liste_coups_adverses[-1] != liste_coups_joueur[-1]: if random() \u0026lt; 2/7: return 1 else: return 0 else: return 1 def Tullock(liste_coups_joueur,liste_coups_adverses): if len(liste_coups_adverses) \u0026lt; 11: return 1 else: if random() \u0026lt; sum(liste_coups_adverses)/len(liste_coups_adverses)-0.1: return 1 else: return 0 def Pavlov(liste_coups_joueur,liste_coups_adverses): if len(liste_coups_adverses) == 0: return 1 else: if not liste_coups_adverses[-1]: return 1-liste_coups_joueur[-1] else: return liste_coups_joueur[-1] Match entre deux joueurs :\ndef partie(joueurA,joueurB): nbre_parties = 200 score_joueurA = 0 score_joueurB = 0 liste_coups_joueurA = [] liste_coups_joueurB = [] for i in range(nbre_parties): JA = dico_strategies[joueurA](liste_coups_joueurA,liste_coups_joueurB) JB = dico_strategies[joueurB](liste_coups_joueurB,liste_coups_joueurA) liste_coups_joueurA.append(JA) liste_coups_joueurB.append(JB) if JA: if JB: score_joueurA += 3 score_joueurB += 3 else: score_joueurA += 0 score_joueurB += 5 else: if JB: score_joueurA += 5 score_joueurB += 0 else: score_joueurA += 1 score_joueurB += 1 if joueurA == joueurB: dico_scores[joueurA] += score_joueurA matrice_tournoi[liste_joueurs.index(joueurA)][liste_joueurs.index(joueurA)] += score_joueurA else: dico_scores[joueurA] += score_joueurA dico_scores[joueurB] += score_joueurB matrice_tournoi[liste_joueurs.index(joueurB)][liste_joueurs.index(joueurA)] += score_joueurB matrice_tournoi[liste_joueurs.index(joueurA)][liste_joueurs.index(joueurB)] += score_joueurA Le tournoi (on fait s\u0026rsquo;affronter tous les joueurs y compris eux-mêmes et on recommence 50 fois) :\ndef tournoi(): global partie nb_tournois = 100 for i in range(nb_tournois): for j,JA in enumerate(liste_joueurs): for JB in liste_joueurs[j:]: partie(JA,JB) for i in range(len(matrice_tournoi)): for j in range(len(matrice_tournoi[0])): matrice_tournoi[i][j] = int(matrice_tournoi[i][j]/nb_tournois) for key in dico_scores: dico_scores[key] = int(dico_scores[key]/nb_tournois) Pour réinitialiser les scores entre deux tournois :\ndef raz(): global liste_joueurs,liste_strategies,dico_strategies,dico_scores,matrice_tournoi liste_joueurs = [\u0026#34;TitforTat\u0026#34;,\u0026#34;Grudger\u0026#34;,\u0026#34;Joss\u0026#34;,\u0026#34;AllD\u0026#34;,\u0026#34;AllC\u0026#34;,\u0026#34;TitforTwoTats\u0026#34;,\u0026#34;Tester\u0026#34;,\u0026#34;Eatherly\u0026#34;,\u0026#34;Alt\u0026#34;,\u0026#34;Gofman\u0026#34;,\u0026#34;Tullock\u0026#34;,\u0026#34;Rando\u0026#34;,\u0026#34;TwoTitsforTat\u0026#34;] liste_strategies = [TitforTat,Grudger,Joss,AllD,AllC,TitforTwoTats,Tester,Eatherly,Alt,Gofman,Tullock,Rando,TwoTitsforTat] dico_strategies = {J:S for (J,S) in zip(liste_joueurs,liste_strategies)} dico_scores = {J:0 for J in liste_joueurs} matrice_tournoi = [[0 for _ in range(len(liste_joueurs))] for _ in range(len(liste_joueurs))] raz() tournoi() liste_scores = [dico_scores[k] for k in dico_scores] combo = list(zip(liste_scores,liste_joueurs)) combo.sort(reverse=True) for s,j in combo: print(f\u0026#34;{j:17} : {s}\u0026#34;) TitforTwoTats\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 7333\nGofman\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 7132\nTitforTat\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 7113\nAllC\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 7076\nTwoTitsforTat\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 7048\nGrudger\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 6990\nPavlov\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 6957\nTullock\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 6467\nRando \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 5991\nAlt\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 5962\nEatherly\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 5792\nJoss\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 5775\nAllD\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 5732\nTester\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;: 5664\nplt.figure(figsize=(15,15),dpi=150) s = sns.heatmap(matrice_tournoi, annot=True, fmt=\u0026#34;d\u0026#34;, cmap=\u0026#39;YlGnBu\u0026#39;, xticklabels=liste_joueurs, yticklabels=liste_joueurs) plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;both\u0026#39;, length=5) s.xaxis.tick_top() s.xaxis.set_label_position(\u0026#39;top\u0026#39;) plt.xticks(rotation=90) Tit for Tat Grudger Joss Rando AllD AllC Tit for Two Tats Two Tits for Tat Tester Eatherly Alt Gofman Tullock Pavlov \u0026#9889;\nTit for Tat Grudger Joss Rando AllD AllC Tit for Two Tats Two Tits for Tat Tester Eatherly Alt Gofman Tullock Pavlov Lancer le match\nScores: Player A : 0\nPlayer B : 0\nMission bonus : Imaginer une nouvelle stratégie qui se hisse sur le podium du tournoi contre les autres stratégies déjà implémentées.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_3/tp11/",
	"title": "TP 11 : algorithmique numérique",
	"tags": [],
	"description": "",
	"content": " TP 11 : algorithmique numérique Cliquez sur cette invitation pour récupérer le repository du TP. Pivot de Gauss Présentation\nOn cherche résoudre un système d\u0026rsquo;équations grâce à la méthode du pivot de Gauss (on ne considèrera que des systèmes de n équations avec un nombre d\u0026rsquo;inconnues inférieur ou égal à n).\nPour cela, on crée une fonction qui transforme la matrice augmentée obtenue à partir du sytème en une matrice échelonnée.\ndef Gauss(M,recherchePivot): \u0026#34;\u0026#34;\u0026#34; préconditions: M une liste de listes (matrice) contenant des nombres. recherchePivot est une fonction ayant pour paramètres la matrice et deux indices et renvoyant l\u0026#39;indice du prochain pivot. postcondition: M est mutée sous la forme d\u0026#39;une matrice échelonnée. La fonction ne retourne rien (elle a juste un effet de bord). \u0026#34;\u0026#34;\u0026#34; m = len(M) # nombre de lignes de la matrice M n = len(M[0]) # nombre de colonnes h = k = 0 tol = 1e-9 while h \u0026lt; m and k \u0026lt; n: # h sera l\u0026#39;indice des lignes et k celui des colonnes ipivot = recherchePivot(M,h,k) # à déterminer par la suite pivot = M[ipivot][k] if abs(pivot) \u0026lt; tol: # pour tester la nullité d\u0026#39;un candidat pivot k += 1 else: if h != ipivot: M[h],M[ipivot] = M[ipivot],M[h] # on permute la ligne du pivot et celle correspondant à h for j in range(k,n): M[h][j] /= pivot # on normalise la ligne du pivot pour avoir 1 dans la diagonale for i in range(h+1,m): f = M[i][k] for j in range(k,n): M[i][j] -= M[h][j] * f # Li \u0026lt;- Li - Lh h +=1 k += 1 Il ne reste plus qu\u0026rsquo;à définir la fonction recherchePivot\u0026hellip;\nDans sa version naïve, il s\u0026rsquo;agit simplement du prochain élément dans la diagonale.\nÉcrire la fonction recherchePivotNaive correspondante en essayant de vous y retrouver avec les indices. La fonction doit retourner l\u0026rsquo;indice du pivot.\ndef recherchePivotNaive(M: list,h: int,k: int) -\u0026gt; int: # VOTRE CODE Correction (cliquer pour afficher) def recherchePivotNaive(M,h,k): return h Tout simplement... On va utiliser un module permettant d\u0026rsquo;avoir la main sur le codage machine des flottants : decimal.\nLes valeurs de la matrice que l\u0026rsquo;on va construire ci-dessous seront limitées à 4 chiffres significatifs et l\u0026rsquo;arrondi se fera à la valeur inférieure (pour reproduire la troncature imposée par le codage des nombres).\nimport decimal from decimal import Decimal decimal.getcontext().prec= 4 decimal.getcontext().rounding = decimal.ROUND_DOWN A = [[Decimal(20),Decimal(15),Decimal(10),Decimal(45)], [Decimal(-3),Decimal(-2.249),Decimal(7),Decimal(1.751)], [Decimal(5),Decimal(1),Decimal(3),Decimal(9)]] for ligne in A: print(ligne) [Decimal(\u0026#39;20\u0026#39;), Decimal(\u0026#39;15\u0026#39;), Decimal(\u0026#39;10\u0026#39;), Decimal(\u0026#39;45\u0026#39;)] [Decimal(\u0026#39;-3\u0026#39;), Decimal(\u0026#39;-2.249000000000000110134124042815528810024261474609375\u0026#39;), Decimal(\u0026#39;7\u0026#39;), Decimal(\u0026#39;1.750999999999999889865875957184471189975738525390625\u0026#39;)] [Decimal(\u0026#39;5\u0026#39;), Decimal(\u0026#39;1\u0026#39;), Decimal(\u0026#39;3\u0026#39;), Decimal(\u0026#39;9\u0026#39;)] Pour que l\u0026rsquo;affichage soit plus propre, on reconvertit les flottants \u0026ldquo;Decimal\u0026rdquo; en flottants python habituels.\ndef affiche(M): for l in M: for e in l: print(f\u0026#34;{float(e):^10}\u0026#34;,end=\u0026#34;\u0026#34;) print() affiche(A) 20.0 15.0 10.0 45.0 -3.0 -2.249 7.0 1.751 5.0 1.0 3.0 9.0 Appliquons la méthode du pivot de Gauss avec recherche naïve du pivot sur la matrice A :\nGauss(A,recherchePivotNaive) affiche(A) 1.0 0.75 0.5 2.25 0.0 1.0 8500.0 8500.0 0.0 0.0 1.0 0.9995 Construisons maintenant une fonction substitution qui part d\u0026rsquo;une matrice échelonnée $M_{n,n+1}$ et qui en déduit le vecteur solution $V$ du système d\u0026rsquo;équations représenté par la matrice.\n$\\color{green}V \\color{black} = (\\color{green}v_1\\color{black},\\color{green}v_2\\color{black},\\color{green}\\ldots\\color{black},\\color{green}v_n\\color{black})^t$ est tel que :\n$$ \\begin{cases} m_{11}\\,\\color{green}v_1\\color{black} +m_{12}\\,\\color{green}v_2\\color{black} + \\ldots + m_{1n}\\,\\color{green}v_n\\color{black} = m_{1\\,n+1} \\\\m_{21}\\,\\color{green}v_1\\color{black}+m_{22}\\,\\color{green}v_2\\color{black} + \\ldots + m_{2n}\\,\\color{green}v_n\\color{black} = m_{2\\,n+1} \\\\ \\quad\\vdots \\qquad\\qquad\\vdots\\;\\;\\;\\;\\;\\;\\;\\;\\ddots\\qquad \\vdots \\qquad\\qquad\\vdots\\\\m_{n1}\\,\\color{green}v_1\\color{black} +m_{n2}\\,\\color{green}v_2\\color{black} + \\ldots + m_{nn}\\,\\color{green}v_n\\color{black} = m_{n\\,n+1} \\end{cases} $$\noù $m_{ii} = 1$ pour $i$ allant de $1$ à $n$, et où $m_{i,j}=0$ pour $i\u0026gt;j$.\ndef substitution(M): \u0026#34;\u0026#34;\u0026#34; précondition: M est une matrice (liste de listes) échelonnée de dimension n*(n+1) postcondition: la fonction retourne le vecteur solution V \u0026#34;\u0026#34;\u0026#34; n = len(M) V = [0]*n # VOTRE CODE return V Correction (cliquer pour afficher) def substitution(M): n = len(M) V = [0]*n for i in range(n-1,-1,-1): V[i] = M[i][n] for j in range(i+1,n): V[i] -= M[i][j]*V[j] V[i] /= M[i][i] return V def afficheSolution(M): \u0026#34;\u0026#34;\u0026#34; v est le vecteur solution \u0026#34;\u0026#34;\u0026#34; sol = [\u0026#39;x\u0026#39;,\u0026#39;y\u0026#39;,\u0026#39;z\u0026#39;] v = substitution(M) for xi,vi in zip(sol,v): print(xi,\u0026#34;=\u0026#34;,vi) afficheSolution(A) x = -1.999 y = 5 z = 0.9995 Reprenons la fonction recherchePivot afin d\u0026rsquo;implémenter la méthode du pivot partiel.\nPour cela, recherchePivotPartiel devra fournir l\u0026rsquo;indice de la ligne où se trouve l\u0026rsquo;élément de plus grande valeur absolue parmi les éléments sur la diagonale et en dessous (≥h) dans la colonne considérée (k).\ndef recherchePivotPartiel(M: list,h: int,k: int) -\u0026gt; int: # VOTRE CODE Correction (cliquer pour afficher) def recherchePivotPartiel(M,h,k): ipivot, pivot = h, abs(M[h][k]) for i in range(h+1,len(M)): if abs(M[i][k]) \u003e pivot: pivot = abs(M[i][k]) ipivot = i return ipivot A = [[Decimal(20),Decimal(15),Decimal(10),Decimal(45)], [Decimal(-3),Decimal(-2.249),Decimal(7),Decimal(1.751)], [Decimal(5),Decimal(1),Decimal(3),Decimal(9)]] print(\u0026#34;Matrice de départ :\u0026#34;) affiche(A) print(\u0026#34;\\nForme échelonnée avec méthode du pivot partiel :\u0026#34;) Gauss(A,recherchePivotPartiel) affiche(A) print(\u0026#34;\\nSolution :\u0026#34;) afficheSolution(A) Matrice de départ : 20.0 15.0 10.0 45.0 -3.0 -2.249 7.0 1.751 5.0 1.0 3.0 9.0 Forme échelonnée avec méthode du pivot partiel : 1.0 0.75 0.5 2.25 0.0 1.0 -0.1818 0.8181 0.0 0.0 1.0 0.9998 Solution : x = 1.000 y = 0.9998 z = 0.9998 On constate que la méthode avec pivot partiel est beaucoup moins aux fraises que la méthode naïve\u0026hellip;\nQuelle est la complexité de la méthode du pivot de Gauss ainsi construite ?\na : linéaire\nb : quadratique\nc : cubique\nd : polynomiale de degré \u0026gt; 3\nCorrection (cliquer pour afficher) Cubique.\nLe nombre de calculs à chaque itération correspond au nombre de cases bleues dans l'image ci-dessous. Il s'agit en effet à chaque fois de créer une nouvelle colonne de zéro sous le pivot par combinaisons linéaires avec la ligne du pivot.\nOn se retrouve finalement avec une somme de carrés consécutifs en terme de nombre d'opérations, ce qui donne un polynôme de degré 3 en la taille de la matrice. Interpolation polynomiale de Lagrange Présentation\nPhénomène de Runge L\u0026rsquo;augmentation du nombre $n$ de points d\u0026rsquo;interpolation ne constitue pas nécessairement une bonne stratégie d\u0026rsquo;approximation comme on va le voir dans l\u0026rsquo;exemple suivant.\nDéfinir en Python dans la cellule ci-dessous la fonction $f:x\\mapsto\\frac{1}{1+x^2}$.\nLa fonction devra s\u0026rsquo;appeler f.\nCorrection (cliquer pour afficher) def f(x): return 1/(1+x**2) Construisez maintenant le polynôme d\u0026rsquo;interpolation de Lagrange en suivant la formule du cours.\nAttention : le nombre de points $n$ est un paramètre de la fonction construite.\ndef interp(f, n: int, interv: tuple, x: float) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34; postcondition: la fonction retourne P(x) où P est le polynôme d\u0026#39;interpolation de Lagrange de f passant par les n points. \u0026#34;\u0026#34;\u0026#34; debut,fin = interv[0],interv[1] X = [debut + i*(fin-debut)/(n-1) for i in range(n)] Y = [f(x) for x in X] # VOTRE CODE return s Correction (cliquer pour afficher) def interp(f,n,interv,x): debut,fin = interv[0],interv[1] X = [debut + i*(fin-debut)/(n-1) for i in range(n)] Y = [f(x) for x in X] s = 0 for i in range(n): p = 1 for j in range(n): if j != i: p *= (x-X[j])/(X[i]-X[j]) s += Y[i]*p return s C'est la traduction Python de la formule mathématique)\n$\\displaystyle P(x) = \\sum_{j=1}^n y_j\\left(\\color{purple}\\prod_{i=1,i≠j}^n \\frac{x-x_i}{x_j-x_i}\\color{black}\\right)$\nLa somme est dans la boucle extérieure et le produit dans la boucle intérieure. Quelle est la complexité de la fonction interp en fonction du nombre de nœuds $n$ ?\na : linéaire b : quadratique c : cubique Correction (cliquer pour afficher) Quadratique On est paré pour illustrer le phénomène de Runge :\nimport matplotlib.pyplot as plt plt.style.use(\u0026#39;seaborn\u0026#39;) params = {\u0026#39;figure.figsize\u0026#39;: (15, 10), \u0026#39;axes.titlesize\u0026#39;: \u0026#39;xx-large\u0026#39;, \u0026#39;text.usetex\u0026#39;:True, \u0026#39;figure.dpi\u0026#39;: 150} plt.rcParams.update(params) fig, axs = plt.subplots(2, 2) I = 250 intervalle = (-5,5) X = [intervalle[0] + (intervalle[1]-intervalle[0])*i/I for i in range(I+1)] Y = [f(x) for x in X] k = 0 for n in [3,5,10,20]: axs[k//2,k%2].set_xlim([-5.5,5.5]) axs[k//2,k%2].set_ylim([-0.8,1.5]) # plot de f(x) axs[k//2,k%2].plot(X,Y,label=r\u0026#34;$\\frac{1}{1+x^2}$\u0026#34;) # plot de P_n(x) Xn,Yn = [],[] for x in X: Xn.append(x) Yn.append(interp(f,n,intervalle,x)) axs[k//2,k%2].plot(Xn,Yn,label=r\u0026#34;$P_{{{}}}(x)$\u0026#34;.format(n)) axs[k//2,k%2].set_title(f\u0026#34;n = {n}\u0026#34;) # Plot des noeuds Noeuds = [intervalle[0] + (intervalle[1]-intervalle[0])*i/(n-1) for i in range(n)] P_noeuds = [interp(f,n,intervalle,noeud) for noeud in Noeuds] axs[k//2,k%2].scatter(Noeuds,P_noeuds,c=\u0026#34;r\u0026#34;,zorder=10,label=\u0026#34;nœuds\u0026#34;) axs[k//2,k%2].legend(fontsize = 15) k += 1 plt.tight_layout() Interpolation par morceaux On découpe maintenant l\u0026rsquo;intervalle d\u0026rsquo;étude en $N-1$ sous-intervalles (découpés par $N$ nœuds) et on interpole la fonction sur un petit nombre de points sur chacun de ces intervalles.\nDegré 0 La fonction suivante produit une interpolation par morceaux de degré 0 de la fonction f.\nN est le nombre de nœuds.\ndef interp_rect(f,interv,N,x): debut,fin = interv[0],interv[1] X = [debut + i*(fin-debut)/(N-1) for i in range(N)] for i in range(N-1): if X[i] \u0026lt;= x \u0026lt; X[i+1]: return f(X[i]) nb = 2000 # nb de points pour le tracé N = 15 intervalle = (-5,5) X = [intervalle[0] + (intervalle[1]-intervalle[0])*i/nb for i in range(nb)] Y1 = [f(x) for x in X] Y2 = [interp_rect(f,intervalle,N,x) for x in X] plt.plot(X,Y1,label = \u0026#34;f(x)\u0026#34;) plt.plot(X,Y2,label = \u0026#34;interpolation de degré 0\u0026#34;) Noeuds = [intervalle[0] + (intervalle[1]-intervalle[0])*i/(N-1) for i in range(N-1)] f_noeuds = [f(n) for n in Noeuds] plt.scatter(Noeuds,f_noeuds,c=\u0026#39;r\u0026#39;,zorder=3) plt.legend() Degré 1 On considère maintenant les deux extrémités de chaque intervalle et on interpole par une loi affine :\ndef interp_lin(f,interv,N,x): debut,fin = interv[0],interv[1] X = [debut + i*(fin-debut)/(N-1) for i in range(N)] for i in range(N-1): if X[i] \u0026lt;= x \u0026lt; X[i+1]: return f(X[i])+(x-X[i])*(f(X[i+1])-f(X[i]))/(X[i+1]-X[i]) nb = 2000 N = 15 intervalle = (-5,5) X = [intervalle[0] + (intervalle[1]-intervalle[0])*i/nb for i in range(nb)] Y1 = [f(x) for x in X] Y2 = [interp_lin(f,intervalle,N,x) for x in X] plt.plot(X,Y1,label = \u0026#34;f(x)\u0026#34;) plt.plot(X,Y2,label = \u0026#34;interpolation de degré 1\u0026#34;) Noeuds = [intervalle[0] + (intervalle[1]-intervalle[0])*i/(N-1) for i in range(N)] f_noeuds = [f(n) for n in Noeuds] plt.scatter(Noeuds,f_noeuds,c=\u0026#39;r\u0026#39;,zorder=3) plt.legend() Degré 2 À vous de jouer pour construire la fonction d\u0026rsquo;interpolation par morceaux de degré 2.\nOn prendra systématiqement 2 intervalles successifs pour obtenir les 3 points à interpoler. Attention à ce que les morceaux successifs ne se superposent pas (au morceau constitué des 3 nœuds situés aux abscisses $\\left(x_0 + i\\times\\frac{I}{N},x_0 + (i+1)\\times\\frac{I}{N},x_0 + (i+2)\\times\\frac{I}{N}\\right)$ devra succéder un morceau constitué des 3 nœuds $\\left(x_0 + (i+2)\\times\\frac{I}{N},x_0 + (i+3)\\times\\frac{I}{N},x_0 + (i+4)\\times\\frac{I}{N}\\right)$ (en appelant $I$ l\u0026rsquo;intervalle).\nOn utilisera dans le code la fonction interp (définie plus haut) sur les 3 points du morceau.\ndef interp_quad(f,interv,N,x): debut,fin = interv[0],interv[1] X = [debut + i*(fin-debut)/(N-1) for i in range(N)] # VOTRE CODE Correction (cliquer pour afficher) def interp_quad(f,interv,N,x): debut,fin = interv[0],interv[1] X = [debut + i*(fin-debut)/(N-1) for i in range(N)] for i in range(0,N-2,2): if X[i] \u003c= x \u003c X[i+2]: return interp(f,3,(X[i],X[i+2]),x) nb = 2000 N = 15 intervalle = (-5,5) X = [intervalle[0] + (intervalle[1]-intervalle[0])*i/nb for i in range(nb)] Y1 = [f(x) for x in X] Y2 = [interp_quad(f,intervalle,N,x) for x in X] plt.plot(X,Y1,label = \u0026#34;f(x)\u0026#34;) plt.plot(X,Y2,label = \u0026#34;interpolation de degré 2\u0026#34;) Noeuds = [intervalle[0] + (intervalle[1]-intervalle[0])*i/(N-1) for i in range(N)] f_noeuds = [f(n) for n in Noeuds] plt.scatter(Noeuds,f_noeuds,c=\u0026#39;r\u0026#39;,zorder=3) plt.legend() Regardons enfin comment ces trois interpolations s\u0026rsquo;en sortent pour reproduire d\u0026rsquo;abord la fonction sinus, puis la fonction de Heaviside.\nplt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 5) from math import sin def h(x): return sin(x) nb = 2000 N = 15 intervalle = (-5,5) X = [intervalle[0] + (intervalle[1]-intervalle[0])*i/nb for i in range(nb)] Y1 = [h(x) for x in X] Y2 = [interp_rect(h,intervalle,N,x) for x in X] Y3 = [interp_lin(h,intervalle,N,x) for x in X] Y4 = [interp_quad(h,intervalle,N,x) for x in X] plt.plot(X,Y1,label = \u0026#34;sin(x)\u0026#34;) plt.plot(X,Y2,label = \u0026#34;interpolation de degré 0\u0026#34;) plt.plot(X,Y3,label = \u0026#34;interpolation de degré 1\u0026#34;) plt.plot(X,Y4,label = \u0026#34;interpolation de degré 2\u0026#34;, ls=\u0026#34;--\u0026#34;) Noeuds = [intervalle[0] + (intervalle[1]-intervalle[0])*i/(N-1) for i in range(N)] f_noeuds = [h(n) for n in Noeuds] plt.scatter(Noeuds,f_noeuds,c=\u0026#39;r\u0026#39;,zorder=3) plt.legend() def h(x): if x \u0026gt;= 0: return 1 else: return 0 nb = 2000 N = 15 intervalle = (-5,5) X = [intervalle[0] + (intervalle[1]-intervalle[0])*i/nb for i in range(nb)] Y1 = [h(x) for x in X] Y2 = [interp_rect(h,intervalle,N,x) for x in X] Y3 = [interp_lin(h,intervalle,N,x) for x in X] Y4 = [interp_quad(h,intervalle,N,x) for x in X] plt.plot(X,Y1,label = \u0026#34;fonction de Heaviside H(x)\u0026#34;) plt.plot(X,Y2,label = \u0026#34;interpolation de degré 0\u0026#34;, ls = \u0026#34;--\u0026#34;) plt.plot(X,Y3,label = \u0026#34;interpolation de degré 1\u0026#34;) plt.plot(X,Y4,label = \u0026#34;interpolation de degré 2\u0026#34;) Noeuds = [intervalle[0] + (intervalle[1]-intervalle[0])*i/(N-1) for i in range(N)] f_noeuds = [h(n) for n in Noeuds] plt.scatter(Noeuds,f_noeuds,c=\u0026#39;r\u0026#39;,zorder=3) plt.legend() Méthode d\u0026rsquo;Euler Présentation\nComplétez la fonction Euler ci-dessous qui implémente la méthode d\u0026rsquo;Euler explicite permettant de résoudre les équations différentielles du premier ordre : $$\\begin{cases}y\u0026rsquo;(t)=f(t,y(t))\\\\y(t_0)=y_0\\end{cases}$$\ndef Euler(f,t0,tf,y0,h): \u0026#34;\u0026#34;\u0026#34; postconditions: T est la liste des ti et Y est la liste des valeurs yi=y(ti) \u0026#34;\u0026#34;\u0026#34; n = int((tf-t0)/h) T = [t0+i*h for i in range(n)] # VOTRE CODE return T,Y Correction (cliquer pour afficher) def Euler(f,t0,tf,y0,h): n = int((tf-t0)/h) T = [t0+i*h for i in range(n)] Y = [y0] for i in range(1,n): Y.append(Y[i-1]+h*f(T[i-1],Y[i-1])) return T,Y Testons notre fonction.\nLa cellule ci-dessous définit la dérivée de $f(t)$ et les deux cellules qui suivent permettent de tracer le résultat.\nLibre à vous de modifier f et les autres paramètres (le pas en particulier) pour expérimenter.\ndef f(t,y): return 5-y/2 import matplotlib.pyplot as plt import numpy as np plt.style.use(\u0026#39;seaborn\u0026#39;) params = {\u0026#39;axes.titlesize\u0026#39;: \u0026#39;xx-large\u0026#39;, \u0026#39;legend.fontsize\u0026#39;: 15, \u0026#39;text.usetex\u0026#39;: True, \u0026#39;figure.dpi\u0026#39;: 150, \u0026#39;figure.figsize\u0026#39;: (20,10)} plt.rcParams.update(params) tmin, tmax = 0, 15 ymin, ymax = 0, 12 nbfl = 2 fig, ax = plt.subplots() ax.set_aspect(\u0026#39;equal\u0026#39;) T,Y = np.meshgrid(np.linspace(tmin,tmax,nbfl*(tmax-tmin)+1),np.linspace(ymin,ymax,nbfl*(ymax-ymin)+1)) U = 1 V = f(T,Y) N = np.sqrt(U**2+V**2) U2, V2 = U/N, V/N ax.quiver(T,Y,U2,V2,pivot=\u0026#39;mid\u0026#39;,width=0.002,scale_units=\u0026#39;xy\u0026#39;,scale=2,alpha=0.8,color=\u0026#34;white\u0026#34;,units=\u0026#39;width\u0026#39;) pas = 0.5 # pas y0 = 0 T,Y = Euler(f,tmin,tmax,y0,pas) ax.plot(T,Y,lw=1) ax.scatter(T,Y,s=8,label=r\u0026#34;$y_i$ pour $h=$\u0026#34;+f\u0026#34; {pas}\u0026#34;) Tsol = np.linspace(0,15,100) Ysol = 10*(1-np.exp(-Tsol/2)) ax.plot(Tsol,Ysol,ls=\u0026#34;-\u0026#34;,lw=2,zorder=1,label=r\u0026#34;$y(t)$ solution exacte\u0026#34;) plt.legend() def acc(t): if 2 \u0026lt;= t \u0026lt;= 4: return 4 elif 4 \u0026lt; t \u0026lt;= 8: return -2 elif 10 \u0026lt; t \u0026lt;= 11: return -4 elif 11 \u0026lt; t \u0026lt;= 13: return 2 else: return 0 Imaginons que la fonction acc ci-dessus corresponde à la commande de l\u0026rsquo;accélération d\u0026rsquo;un ascenceur.\nDéterminons la position de l\u0026rsquo;ascenceur au cours du temps.\nt0, tmax = 0, 14 v0 = 0 y0 = 2 t, v, y = t0, v0, x0 T, V, Y = [t0],[v0],[y0] dt = 1e-3 while t \u0026lt; tmax: v += acc(t)*dt y += v*dt t += dt T.append(t) V.append(v) Y.append(y) Quelle méthode d\u0026rsquo;intégration a-t-elle été mise en œuvre dans le code ci-dessus ?\na : méthode d\u0026rsquo;Euler explicite b: méthode d\u0026rsquo;Euler implicite c : méthode d\u0026rsquo;Euler semi-implicite d : méthode d\u0026rsquo;Euler améliorée Correction (cliquer pour afficher) On a un mixe dans les mises à jours de $v$ et de $y$ entre l'utilisation de valeurs aux instants $t$ ou $t+dt$\u0026nbsp;:\n$v(t+dt) = v(t)+a(\\color{orange}t\\color{#006C65})\\times dt$\n$y(t+dt) = y(t) + v(\\color{red}t+dt\\color{#006C65})\\times dt$.\nIl s'agit donc de la méthode semi-explicite. Imaginons qu\u0026rsquo;un pallier fasse 6 m et que le point de départ de l\u0026rsquo;ascenceur corresponde au RDC (étage 0), quels sont les 2 autres étages visités par l\u0026rsquo;ascenceur ?\nCorrection (cliquer pour afficher) On peut tracer l'évolution de $y(t)$ pour nous aider grâce à cette ligne\u0026nbsp;:\nplt.plot(T,Y)\nOn obtient\u0026nbsp;: L'ascenceur s'est donc arrêté aux étages 4 et 3. La dernière mission est d\u0026rsquo;intégrer le système d\u0026rsquo;équations différentielles du premier ordre suivant pour $t$ allant de 0 à 100 : $$\\begin{cases}x\u0026rsquo;=\\sigma(y-x)\\\\y\u0026rsquo;=\\rho x-y-xz\\\\z\u0026rsquo;=xy-\\beta \\end{cases}$$ on prendra : $$\\begin{cases}\\sigma = 3\\\\\\rho = 26.5\\\\\\beta = 1\\end{cases}$$ et $(x_0;y_0;z_0)=(0;1;1,05)$.\nVous utiliserez la méthode d\u0026rsquo;Euler explicite et prendrez un pas de $0,01$.\nVotre code devra produire les 3 listes de 10001 éléments contenant les valeurs $x(t_i),y(t_i),z(t_i)$ pour chaque $t_i \\in [0,100]$ et elles devront être nommées (pour faire original) X, Y et Z.\nCorrection (cliquer pour afficher) s,r,b = 3,26.5,1 x0,y0,z0 = 0,1,1.05 t = 0 h = 1e-2 x,y,z = x0,y0,z0 X,Y,Z = [x0],[y0],[z0] while t \u003c= 100: x_old, y_old, z_old = x,y,z x += (s*(y_old-x_old))*h y += (r*x_old - y_old - x_old*z_old)*h z += (x_old*y_old - b*z_old)*h X.append(x) Y.append(y) Z.append(z) t += h import plotly.graph_objects as go fig = go.Figure(data=go.Scatter3d(x=X,y=Y,z=Z,mode=\u0026#34;lines\u0026#34;,line=dict(color=\u0026#39;darkblue\u0026#39;,width=2))) fig.update_layout(scene = dict(xaxis = dict(showbackground=False,showticklabels=False,title=\u0026#39;\u0026#39;),yaxis = dict(showbackground=False,showticklabels=False,title=\u0026#39;\u0026#39;),zaxis = dict(showbackground=False,showticklabels=False,title=\u0026#39;\u0026#39;))) fig.show() "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_3/basededonnes/",
	"title": "Bases de données",
	"tags": [],
	"description": "",
	"content": "Bases de données Les bases de données (database en anglais) sont une forme d\u0026rsquo;organisation des données. Elles permettent de centraliser différentes données en évitant les duplications inutiles et en garantissant un accès contrôlé évitant les corruptions. Une base de données peut gérer des données organisées suivant différents modèles : navigationnel, hierarchique, relationnel, post-relationnel\u0026hellip; C\u0026rsquo;est le modèle relationnel, le plus utilisé, qui va nous intéresser ici.\nDans un modèle relationnel, les données sont organisées dans des tables (des tableaux à deux dimensions) ayant des relations entre elles via des clés étrangères.\nUne base de données contient généralement plusieurs tables (comme un classeur contenant plusieurs feuilles).\nUn serveur héberge généralement plusieurs bases (comme une armoire contenant plusieurs classeurs).\nUn logiciel permettant d\u0026rsquo;interagir avec les bases et les tables est un système de gestion de bases de données (SGBD et DBMS en anglais). MySQL et SQLite sont des exemples de SGBD gratuits.\nOn interagit avec un SGBD par l\u0026rsquo;intermédiaire de lignes de commandes. On peut aussi utiliser une surcouche graphique (SQLiteStudio par exemple).\nTables Les tables (ou relations) sont des tableaux à deux dimensions.\nLes colonnes sont appelées attributs. Elles sont caractérisées par un nom et un domaine dans lequel elle prend ses valeurs. Les lignes sont appelées enregistrements. Un enregistrement prend une valeur pour chaque attribut de la table. Synonymes : tuple ou n-uplet. Et chaque case est un champ. L\u0026rsquo;ensemble des valeurs permises pour les champs d\u0026rsquo;un attribut s\u0026rsquo;appelle un domaine.\nExemples de domaines : Entiers (INTEGER ou INT), chaînes de caractères de taille fixe (CHAR(X)), chaîne de caractères de taille maximale fixée (VARCHAR(X)), chaîne de caractères de taille libre (TEXT).\nClés Une clé est un groupe d\u0026rsquo;attributs (colonnes) minimum qui permet d\u0026rsquo;identifier de façon univoque un enregistrement (un tuple) dans la table.\nToute table doit comporter au moins une clé, ce qui implique qu\u0026rsquo;elle ne peut pas contenir deux enregistrements identiques.\nSi plusieurs clés existent dans une relation, on en choisit une parmi celles-ci. Cette clé est appelée clé primaire.\nLa clé primaire est généralement choisie de façon à ce qu\u0026rsquo;elle soit la plus simple, c\u0026rsquo;est à dire portant sur le moins d\u0026rsquo;attributs possibles et sur les attributs ayant des domaines le plus basique possible (entiers ou chaînes courtes typiquement).\nOn appelle clés candidates l\u0026rsquo;ensemble des clés d\u0026rsquo;une relation qui n\u0026rsquo;ont pas été choisies comme clé primaire (elles étaient candidates à cette fonction).\nRq : il y a plusieurs autres clés candidates : les différentes combinaisons des attributs aboutissant à une concaténation unique.\nS\u0026rsquo;il est impossible de trouver une clé primaire, ou que les clés candidates sont trop complexes, on peut faire appel à une clé artificielle (qui s\u0026rsquo;oppose à clé naturelle). Une clé artificielle est un attribut supplémentaire ajouté à la table, qui n\u0026rsquo;est lié à aucune signification, et qui sert uniquement à identifier de façon unique les enregistrements et/ou à simplifier les références de clés étrangères.\nC\u0026rsquo;est généralement ce qui a été fait lorsque les valeurs d\u0026rsquo;un attribut correspondent au numéro de la ligne (index).\nUne clé étrangère est un attribut ou un groupe d\u0026rsquo;attributs d\u0026rsquo;une table A apparaissant comme clé primaire dans une table B. Elle matérialise une référence entre les enregistrements de A et de B.\nUne clé étrangère d\u0026rsquo;un enregistrement référence une clé primaire d\u0026rsquo;un autre enregistrement.\nSeule une clé primaire peut être référencée par une clé étrangère, c\u0026rsquo;est même le seule fonction de la clé primaire : être la clé qui peut être référencée par les clés étrangères.\nReprésentation graphique On peut représenter les relations entre tables grâce à des diagrammes sagitaux comme dans l\u0026rsquo;exemple ci-dessous.\nLes clés primaires sont représentées en rouge et les clés étrangères en vert. Dans cet exemple, l\u0026rsquo;attribut CODCOM est insuffisant pour servir de clé primaire à la table Communes (car il y a des valeurs redondantes), mais la combinaison des attributs CODCOM et CODDEP donne bien un code unique et donc convient. Opérations sur les données Dans une base de données relationnelle, on extrait et on traite les données en utilisant un jeu d\u0026rsquo;opérations mathématiques. Il y a huit opérations principales, que l\u0026rsquo;on peut répartir en opérations ensemblistes et opérations relationnelles.\nOpérations ensemblistes Union : Intersection : Différence : Produit cartésien : Le nombre de lignes de la table résultat vaut le produit des nombres de lignes de chacune des tables.\nDivision : C\u0026rsquo;est l\u0026rsquo;opération inverse du produit cartésien. Pour trouver le quotient de la division de la table 1 par la table 2, on cherche avec quoi il faudrait faire le produit de la table 2 pour obtenir les lignes de la table 1 contenant les champs de la table 2. Opérations relationnelles Projection : La projection extrait une ou plusieurs colonnes (attributs) d\u0026rsquo;une table. Restriction : La restriction (aussi appelée sélection) extrait une ou plusieurs lignes (enregistrements) d\u0026rsquo;une table. Jointure interne : Une jointure interne permet de combiner deux tables en se servant d\u0026rsquo;une colonne dans chaque table ayant des valeurs en commun. On suture alors sur ces valeurs communes et on laisse tomber les lignes n\u0026rsquo;ayant pas de correspondance d\u0026rsquo;une table à l\u0026rsquo;autre.\nSi on joint sur la clé étrangère d\u0026rsquo;une table correspondant à la clé primaire de l\u0026rsquo;autre table, toutes les lignes seront présentes dans le résultat !\nSQL Pour dialoguer avec une base de données relationnelle, on utilise le langage SQL (Structured Query Language).\nOn entre des requêtes (ou instructions, query en anglais), qui ressemble à des phrases (terminées par des points-virgules). Chaque requête est constituée de clauses faites de commandes (ou mots clefs) suivies d\u0026rsquo;arguments dont certains peuvent être remplacés par des jokers.\nLes commandes sont des mots anglais, ce qui donne à SQL l\u0026rsquo;apparence d\u0026rsquo;une langue naturelle.\nPour illustrer les différentes requêtes, on va utiliser la base de données dont le modèle a été aperçu plus haut :\nEt voici un extrait des trois tables :\nRq : NBCOM désigne le nombre de communes (dans un département ou dans une région) et POP la population (dans une commune, un département, ou une région).\nCette base est issue des données \u0026ldquo;Populations légales 2019\u0026rdquo; de l\u0026rsquo;INSEE publiées le 12/01/2022. Elle a été construite via SQLite et elle est intégrée au repo du TP si vous voulez interagir avec et reproduire les exemples.\nSELECT C\u0026rsquo;est la commande la plus importante ! Elle permet de rechercher des données dans une table (ou plusieurs) en précisant des conditions.\nSELECT opère un mélange entre une projection et une restriction.\nLa syntaxe de base est :\nSELECT liste d\u0026rsquo;attributs projeté\nFROM liste de tables\nWHERE condition de la restriction\nLa partie SELECT indique le sous-ensemble des attributs qui doivent apparaître dans la réponse. La partie FROM décrit les tables (relations) qui sont utilisables dans la requête (c\u0026rsquo;est à dire l\u0026rsquo;ensemble des attributs que l\u0026rsquo;on peut utiliser). La partie WHERE exprime les conditions que doivent respecter les attributs d\u0026rsquo;une ligne (d\u0026rsquo;un tupe) pour pouvoir être dans la réponse. Une condition est un prédicat et par conséquent renvoie un booléen. Cette partie est optionnelle. Pour récupérer toutes les colonnes de la table commune :\nSELECT * FROM Communes; le symbole * sert de joker.\nPour récupérer seulement les colonnes CODCOM et POP de la table commune (on opère ainsi une projection) :\nSELECT CODCOM, POP FROM Communes; On peut aussi très simplement opérer le produit cartésien de deux tables en sélectionnant des attributs de chacune des tables :\nSELECT Regions.REG, Departements.CODDEP FROM Regions, Departements; Pour récupérer la colonne COM triée suivant la colonne POP en ordre ascendant (par défaut), on utilise la clause ORDER BY :\nSELECT COM FROM Communes ORDER BY POP; Aucun habitant à Cumières-le-Mort-Homme\u0026hellip; le nom semble approprié 😨\nEt pout un tri en ordre descendant, on ajoute le mot clef DESC :\nSELECT COM FROM Communes ORDER BY POP DESC; Où sont passées Lyon, Paris, Marseille ?\nPour récupérer seulement un nombre limité d\u0026rsquo;enregistrements (de lignes), on utilise le mot clef LIMIT :\nSELECT CODDEP, POP FROM Departements LIMIT 5; Et on peut aussi décaler l\u0026rsquo;ensemble des résultats d\u0026rsquo;un certain nombre de lignes grâce au mot clef OFFSET.\nSELECT CODDEP, POP FROM Departements LIMIT 5 OFFSET 3; Utilions maintenant WHERE pour filtrer les résultats (on opère alors une restriction/sélection).\nSélectionnons les codes départements des communes de plus de $50\\,000$ habitants :\nSELECT CODDEP FROM Communes WHERE POP \u0026gt; 50000; On remarque sur le résultat précédent qu\u0026rsquo;il y a des résultats redondants\u0026hellip; Pour éliminer les doublons, on peut utiliser SELECT DISTINCT.\nSELECT DISTINCT CODDEP FROM Communes WHERE POP \u0026gt; 50000; La clause WHERE d\u0026rsquo;une instruction de sélection est définie par une condition. Une telle condition s\u0026rsquo;exprime à l\u0026rsquo;aide d\u0026rsquo;opérateurs de comparaison et d\u0026rsquo;opérateurs logiques. Le résultat d\u0026rsquo;une expression de condition est toujours un booléen.\nLes opérateurs au programme :\nOpérateur Signification = égal à \u0026lt;\u0026gt; différent de \u0026lt; inférieur à \u0026lt;= inférieur ou égal à \u0026gt; supérieur à \u0026gt;= supérieur ou égal à AND et OR ou (inclusif) NOT non IN appartient à Lorsque la condition porte sur une chaîne de caractères, deux jokers sont utilisable : % pour désigner une chaîne quelconque de taille non fixée et _ pour désigner un unique caractère quelconque. Mais il faut alors utiliser l\u0026rsquo;opérateur de comparaison LIKE plutôt que =. C\u0026rsquo;est a priori hors programme.\nSELECT COM FROM Communes WHERE COM LIKE \u0026#39;Paris%\u0026#39;; SELECT COM FROM Communes WHERE COM LIKE \u0026#39;%Arrondissement\u0026#39;; SELECT COM FROM Communes WHERE COM LIKE \u0026#39;_ours\u0026#39;; Afin de décrire un attribut d\u0026rsquo;une table en particulier (dans le cas d\u0026rsquo;une requête portant sur plusieurs tables notamment), on utilise la notation table.attribut.\nSELECT Communes.COM, Departements.DEP, Regions.REG FROM Communes, Departements, Regions WHERE Communes.CODDEP = Departements.CODDEP AND Communes.CODREG = Departements.CODREG; On peut aussi renommer les tables et les attributs par des alias grâce au mot clef AS afin d\u0026rsquo;en simplifier la syntaxe.\nRéécrivons par exemple la requête précédente. Les alias servent à la fois à simplifier le nom des tables (raccourcis définis dans le FROM, mais qu\u0026rsquo;on peut déjà utiliser dans le SELECT) ou rendre le nom des attributs plus parlants (dans le SELECT).\nSELECT Co.COM AS ville, De.DEP AS departement, Re.REG AS region FROM Communes AS Co, Departements AS De, Regions AS Re WHERE Co.CODDEP = De.CODDEP AND Co.CODREG = Re.CODREG; Agrégation Fonctions d\u0026rsquo;agrégation Les fonctions d\u0026rsquo;agrégation sont des fonctions de type statistique qui prennent en argument un ou plusieurs attributs et qui s\u0026rsquo;appliquent à l\u0026rsquo;ensemble des champs ainsi sélectionnés.\nLes fonctions d\u0026rsquo;agrégation ont pour résultat une valeur atomique (pas un groupe) comme un nombre ou une chaîne.\nLes fonctions au programme sont :\nFonction renvoie MIN la valeur minimale MAX la valeur maximale SUM la somme AVG la moyenne COUNT le nombre d\u0026rsquo;enregistrements SELECT COUNT(*) AS nb_communes FROM Communes; SELECT MIN(POP), MAX(POP) FROM Regions; GROUP BY Grâce à la clause GROUP BY, on peut grouper ensemble (partitionner) des lignes qui ont les mêmes valeurs dans une ou plusieurs colonne.\nMais c\u0026rsquo;est l\u0026rsquo;application d\u0026rsquo;une fonction sur chaque agregat obtenu qui en fait tout son intérêt.\nSyntaxe générale d\u0026rsquo;une agrégation :\nSELECT liste ordonnée d\u0026rsquo;attributs de partionnement, liste d\u0026rsquo;application de fonctions sur d\u0026rsquo;autres attributs\nFROM liste de tables\nWHERE condition qui filtre les tables\nGROUP BY liste ordonnée d\u0026rsquo;attributs de partitionnement\nHAVING condition qui filtre les agrégats\nMontrons comment on peut retrouver les attributs NBCOM et POP de la table Departements directement à partir de la table Communes :\nSELECT CODDEP, COUNT(*) AS NBCOM_DEP, SUM(POP) AS POP_DEP FROM Communes GROUP BY CODDEP; On retrouve bien les mêmes valeurs que dans la table Departements.\nSupposons maintenant que l\u0026rsquo;on veuille connaître la population moyenne par commune dans chacune des régions :\nSELECT CODREG, AVG(POP) AS POP_MOY_REG FROM Communes GROUP BY CODREG; La clause HAVING permet d\u0026rsquo;effectuer une restriction sur les résultats de l\u0026rsquo;agrégation grâce à une condition.\nReprenons l\u0026rsquo;exemple des populations par département, mais n\u0026rsquo;affichons plus que les départements ayant une population supérieure à deux million d\u0026rsquo;habitant.\nSELECT CODDEP, COUNT(*) AS NBCOM_DEP, SUM(POP) AS POP_DEP FROM Communes GROUP BY CODDEP HAVING SUM(POP) \u0026gt; 2000000; On a vu lors des exemples de tri que Paris, Marseille et Lyon n\u0026rsquo;apparaissent pas parmi les communes les plus peuplées, ce qui s\u0026rsquo;explique par le fait que chacune de ces villes sont découpées administrativement en arrondissements.\nEssayons maintenant de regrouper ces arrondissements :\nSELECT COM, SUM(POP) AS POP_TOT FROM Communes WHERE COM like \u0026#39;%Arrondissement\u0026#39; GROUP BY CODDEP; Et si on voulait opérer une sélection supplémentaire sur cet aggrégat de 3 villes, c\u0026rsquo;est un HAVING que l\u0026rsquo;on utiliserait. Par exemple :\nSELECT COM, SUM(POP) AS POP_TOT FROM Communes WHERE COM like \u0026#39;%Arrondissement\u0026#39; GROUP BY CODDEP HAVING COM like \u0026#39;Lyon%\u0026#39; WHERE est un filtre sur les données ⇒ il s\u0026rsquo;applique avant l\u0026rsquo;agrégation par GROUP BY.\nHAVING est un filtre sur les résultats d\u0026rsquo;un regroupement ⇒ il s\u0026rsquo;applique après l\u0026rsquo;agrégation par GROUP BY.\nOpérateurs ensemblistes On peut utiliser les opérations ensemblistes vues plus haut grâce aux opérateurs SQL suivants :\nOpérateur SQL Opération UNION union INTERSECT intersection EXCEPT/MINUS différence La requête suivante donne les noms de communes qui sont aussi des noms de départements :\nSELECT COM FROM Communes INTERSECT SELECT DEP FROM Departements; Requêtes imbriquées On peut enchasser des requêtes les unes dans les autres en utilisant des parenthèses.\nCette requête affiche le département ayant les communes les plus faiblement peuplées en moyenne.\nSELECT DEP FROM Departements WHERE CODDEP = (SELECT CODDEP FROM (SELECT *,AVG(POP) AS Moy FROM Communes GROUP BY CODDEP) WHERE Moy = (SELECT Min(Moy) FROM (SELECT *,AVG(POP) AS Moy FROM Communes GROUP BY CODDEP))) Pour traduire de telles requêtes enchassées les unes dans les autres, le plus simple est de partir de la dernière et remonter.\nEssayons maintenant d\u0026rsquo;intégrer nos villes à arrondissements dans le classement général des 10 communes les plus peuplées :\nSELECT COM,POP FROM (SELECT * FROM Communes WHERE COM NOT like \u0026#39;%Arrondissement\u0026#39; UNION SELECT CODREG,CODDEP,CODCOM,COM,SUM(POP) FROM Communes WHERE COM like \u0026#39;%Arrondissement\u0026#39; GROUP BY CODDEP) ORDER BY POP DESC LIMIT 10; Pour que les 3 premiers résultats aient des noms corrects, on peut utiliser une commande CASE comme ci-dessous. Ce n\u0026rsquo;est pas au programme.\nSELECT (CASE WHEN COM LIKE \u0026#39;Paris%\u0026#39; THEN \u0026#39;Paris\u0026#39; WHEN COM LIKE \u0026#39;Marseille%\u0026#39; THEN \u0026#39;Marseille\u0026#39; WHEN COM LIKE \u0026#39;Lyon%\u0026#39; THEN \u0026#39;Lyon\u0026#39; ELSE COM END) AS COM, POP FROM (SELECT COM,POP FROM (SELECT * FROM Communes WHERE COM NOT like \u0026#39;%Arrondissement\u0026#39; UNION SELECT CODREG,CODDEP,CODCOM,COM,SUM(POP) FROM Communes WHERE COM like \u0026#39;%Arrondissement\u0026#39; GROUP BY CODDEP) ORDER BY POP DESC LIMIT 10); Jointures Joindre deux tables peut s\u0026rsquo;avérer très utile et s\u0026rsquo;opère grâce à la commande table1 JOIN table2 ON condition.\nAprès le mot clef ON, on précise le critère de jointure. S\u0026rsquo;il s\u0026rsquo;agit d\u0026rsquo;un critère d\u0026rsquo;égalité (du type colonneX.table1 = colonneY.table2, alors on parle d\u0026rsquo;équi-jointure.\nLes jointures évoquées ici sont des jointures internes. Ce sont de loin les plus utilisées et le programme de CPGE se limite à elles. De même le programme n\u0026rsquo;évoque que les équi-jointures.\nOn a obtenu plus haut un ensemble de communes dont le nom est aussi un nom de département. Associons-leur le nom du département où elles se trouvent grâce à une jointure :\nSELECT DEP, Communes.COM FROM Communes JOIN (SELECT COM FROM Communes INTERSECT SELECT DEP FROM Departements) AS Inter ON Inter.COM = Communes.COM JOIN Departements ON Communes.CODDEP = Departements.CODDEP; La première jointure sert à simplifier la table Communes de manière à ce qu\u0026rsquo;elle ne contienne plus que les communes ayant des noms de départements.\nEt la deuxième jointure sert à associer le nom du département où elle se trouve à chacune de ces communes.\nOn constate ainsi que le Doubs, la Corrèze et la Mayenne ont une structure récursive\u0026hellip;\nOn aurait pu obtenir le même résultat en joignant d\u0026rsquo;abord les tables Communeset Departements, puis en réalisant une auto-jointure sur le résultat de cette première jointure.\nUne auto-jointure consiste à associer ensemble deux colonnes de la même table. Cela nécessite d\u0026rsquo;utiliser deux alias différents pour désigner la table, sinon le moteur SQL est tout perdu (erreur ambiguous columnn name)\u0026hellip;\nSELECT DISTINCT DEP, COM FROM (SELECT * FROM Communes JOIN Departements ON Communes.CODDEP = Departements.CODDEP) AS ComDep1 JOIN (SELECT * FROM Communes JOIN Departements ON Communes.CODDEP = Departements.CODDEP) AS ComDep2 ON ComDep1.COM = ComDep2.DEP; "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_3/tp12/",
	"title": "TP 12 : bases de données",
	"tags": [],
	"description": "",
	"content": " TP 12 : bases de données Cliquez sur cette invitation pour récupérer le repository du TP. Présentation\nOn va utiliser python dans ce tp pout accéder aux bases de données, mais de manière la plus transparente possible.\nUn problème de mis-à-jour récent impose d\u0026rsquo;obliger Colab à passer à la dernière version du module permettant d\u0026rsquo;utiliser les commandes sql magiques.\nLa première commande exécutée de votre notebook devra donc être (ajoutez la commande dans une nouvelle cellule au début du notebook) :\n%%capture !pip install ipython-sql==0.5.0 Commençons par cloner le repository Github source dans l\u0026rsquo;instance Colab.\n!git clone https://github.com/Info-TSI-Vieljeux/s3-tp12 Puis, chargeons une extension ipython permettant de se connecter à une base de données et d\u0026rsquo;interagir avec en SQL.\n%load_ext sql Connectons-nous à la base Population.db issue de données de l\u0026rsquo;INSEE pour pouvoir tester les exemples du cours et pour quelques questions.\n%sql sqlite:///s3-tp12/Population.db Dorénavent, il suffit de débuter chaque cellule par la commande magique %%sql et d\u0026rsquo;écrire en dessous vos requêtes SQL. En ajoutant resultats \u0026lt;\u0026lt; à la ligne introductive, on stocke le résultat de la requête dans la variable resultats.\n%%sql resultats \u0026lt;\u0026lt; SELECT * FROM Communes LIMIT 10; sqlite:///s3-tp12/F1.db\n* sqlite:///s3-tp12/Population.db\nDone.\nReturning data to local variable resultats\nPour afficher les résultats, il suffit d\u0026rsquo;exécuter resultats :\nresultats CODREG CODDEP CODCOM COM POP 84 01 1 L\u0026#x27;Abergement-Clémenciat 798 84 01 2 L\u0026#x27;Abergement-de-Varey 257 84 01 4 Ambérieu-en-Bugey 14514 84 01 5 Ambérieux-en-Dombes 1776 84 01 6 Ambléon 118 84 01 7 Ambronay 2915 84 01 8 Ambutrix 777 84 01 9 Andert-et-Condon 335 84 01 10 Anglefort 1122 84 01 11 Apremont 379 Écrivez une requête affichant le numéro des départements contenant au moins une commune de plus de $100\\,000$ habitants ainsi que le nom de ces communes.\nCorrection (cliquer pour afficher) SELECT CODDEP, COM FROM Communes WHERE POP \u003e 100000; CODDEP COM 06 Nice 13 Aix-en-Provence 14 Caen 21 Dijon 25 Besançon 29 Brest 30 Nîmes 31 Toulouse 33 Bordeaux 34 Montpellier 35 Rennes 37 Tours 38 Grenoble 42 Saint-Étienne 44 Nantes 45 Orléans 49 Angers 51 Reims 54 Nancy 57 Metz 59 Lille 63 Clermont-Ferrand 66 Perpignan 67 Strasbourg 68 Mulhouse 69 Villeurbanne 69 Lyon 3e Arrondissement 72 Le Mans 74 Annecy 75 Paris 11e Arrondissement 75 Paris 12e Arrondissement 75 Paris 13e Arrondissement 75 Paris 14e Arrondissement 75 Paris 15e Arrondissement 75 Paris 16e Arrondissement 75 Paris 17e Arrondissement 75 Paris 18e Arrondissement 75 Paris 19e Arrondissement 75 Paris 20e Arrondissement 76 Le Havre 76 Rouen 80 Amiens 83 Toulon 87 Limoges 92 Boulogne-Billancourt 93 Montreuil 93 Saint-Denis 95 Argenteuil 974 Saint-Denis 974 Saint-Paul Écrivez maintenant une requête permettant d\u0026rsquo;obtenir la liste des noms de chaque département associés au nombre de communes qu\u0026rsquo;ils contiennent, en triant de manière décroissante selon le nombre de communes par département.\nCorrection (cliquer pour afficher) SELECT NBCOM,DEP FROM Departements ORDER BY NBCOM DESC; NBCOM DEP 890 Pas-de-Calais 800 Aisne 772 Somme 725 Moselle 708 Seine-Maritime 698 Côte-d\u0026#x27;Or 679 Oise 648 Nord 613 Marne 591 Meurthe-et-Moselle 586 Haute-Garonne 585 Eure 573 Doubs 565 Saône-et-Loire 546 Pyrénées-Atlantiques 539 Haute-Saône 535 Gironde 528 Calvados 514 Bas-Rhin 512 Isère 507 Seine-et-Marne 507 Vosges 505 Dordogne 499 Meuse 494 Jura 469 Hautes-Pyrénées 464 Puy-de-Dôme 463 Charente-Maritime 461 Gers 449 Ardennes 446 Manche 433 Aude 431 Aube 426 Haute-Marne 423 Yonne 393 Ain 385 Orne 366 Haut-Rhin 365 Charente 365 Eure-et-Loir 364 Drôme 354 Sarthe 351 Gard 348 Côtes-d\u0026#x27;Armor 342 Hérault 335 Ardèche 333 Ille-et-Vilaine 327 Ariège 327 Landes 325 Loiret 323 Loire 319 Lot-et-Garonne 317 Allier 314 Tarn 313 Lot 309 Nièvre 287 Cher 285 Aveyron 280 Corrèze 279 Haute-Savoie 277 Finistère 273 Savoie 272 Indre-et-Loire 267 Loir-et-Cher 267 Rhône 266 Vienne 259 Yvelines 258 Vendée 257 Haute-Loire 256 Creuse 256 Deux-Sèvres 250 Morbihan 246 Cantal 241 Indre 240 Mayenne 236 Haute-Corse 226 Pyrénées-Orientales 207 Loire-Atlantique 198 Alpes-de-Haute-Provence 195 Tarn-et-Garonne 195 Haute-Vienne 194 Essonne 184 Val-d\u0026#x27;Oise 177 Maine-et-Loire 163 Alpes-Maritimes 162 Hautes-Alpes 153 Var 152 Lozère 151 Vaucluse 124 Corse-du-Sud 119 Bouches-du-Rhône 101 Territoire de Belfort 47 Val-de-Marne 40 Seine-Saint-Denis 36 Hauts-de-Seine 34 Martinique 32 Guadeloupe 24 La Réunion 22 Guyane 1 Paris Écrivez ensuite une requête permettant d\u0026rsquo;obtenir la liste des noms de communes donnés plusieurs fois associés au nombre de fois où ils sont répétés, nombre que l\u0026rsquo;on rebaptisera NB_REDOND. La liste ne devra contenir que les noms donnés au moins 10 fois.\nCorrection (cliquer pour afficher) SELECT COM,COUNT(*) AS NB_REDOND FROM Communes GROUP BY COM HAVING NB_REDOND \u003e= 10; COM NB_REDOND Beaulieu 10 Saint-Aubin 10 Saint-Sauveur 11 Sainte-Colombe 12 Écrivez une requête donnant le nom d\u0026rsquo;une ville, ici \u0026lsquo;La Rochelle\u0026rsquo;, le nom du département auquel elle appartient, et le nom de la région auquelle elle appartient.\nCorrection (cliquer pour afficher) SELECT COM, DEP, REG FROM Communes JOIN Regions ON Communes.CODREG = Regions.CODREG JOIN Departements ON Communes.CODDEP = Departements.CODDEP WHERE COM = \"La Rochelle\"; COM DEP REG La Rochelle Charente-Maritime Nouvelle-Aquitaine La Rochelle Haute-Saône Bourgogne-Franche-Comté Écrivez enfin une requête donnant le nom du département Charente-Maritime, sa population, le nombre de communes qu\u0026rsquo;il contient, le nom de la commune la plus peuplée et sa population ainsi que le nom de la commune la moins peuplée et sa population.\nCorrection (cliquer pour afficher) SELECT DEP, Departements.POP, Departements.NBCOM, MAXCOM, MAXPOP, MINCOM, MINPOP FROM ((SELECT CODDEP, COM AS MAXCOM, MAX(POP) AS MAXPOP FROM Communes GROUP BY CODDEP) AS MAXOU JOIN (SELECT CODDEP, COM AS MINCOM, MIN(POP) AS MINPOP FROM Communes GROUP BY CODDEP) AS MINOU ON MINOU.CODDEP = MAXOU.CODDEP) AS Autojointure JOIN Departements ON Autojointure.CODDEP = Departements.CODDEP WHERE DEP = \"Charente-Maritime\"; DEP POP NBCOM MAXCOM MAXPOP MINCOM MINPOP Charente-Maritime 667287 463 La Rochelle 79333 Lussac 47 On construit généralement des grosses requêtes comme celle-ci bloc par bloc qu'on joint ensuite ensemble.\nRegardons par exemple à quoi ressemble la table intermédiaire Autojointure (qui a été construite, comme son nom l'indique, par autojointure). SELECT Autojointure.CODDEP, MAXCOM, MAXPOP, MINCOM, MINPOP FROM ((SELECT CODDEP, COM AS MAXCOM, MAX(POP) AS MAXPOP FROM Communes GROUP BY CODDEP) AS MAXOU JOIN (SELECT CODDEP, COM AS MINCOM, MIN(POP) AS MINPOP FROM Communes GROUP BY CODDEP) AS MINOU ON MINOU.CODDEP = MAXOU.CODDEP) AS Autojointure CODDEP MAXCOM MAXPOP MINCOM MINPOP 01 Bourg-en-Bresse 42853 Armix 31 02 Saint-Quentin 54851 Tannières 17 03 Montluçon 35431 Saint-Éloy-d\u0026#x27;Allier 38 04 Manosque 23197 Majastres 4 05 Gap 42176 La Haute-Beaume 8 06 Nice 345528 Auvare 33 07 Annonay 16920 Lafarre 39 08 Charleville-Mézières 47526 Le Mont-Dieu 15 09 Pamiers 16137 Senconac 13 10 Troyes 63087 Ortillon 24 11 Narbonne 56700 Fontanès-de-Sault 5 12 Rodez 26410 Arnac-sur-Dourdou 37 13 Aix-en-Provence 148336 Saint-Antonin-sur-Bayon 127 14 Caen 108404 Rapilly 48 15 Aurillac 26876 Valjouze 23 16 Angoulême 43290 Saint-Sulpice-de-Ruffec 31 17 La Rochelle 79333 Lussac 47 18 Bourges 66606 Saint-Céols 13 19 Brive-la-Gaillarde 47615 Toy-Viam 38 21 Dijon 161380 Les Goulles 9 22 Saint-Brieuc 45099 Loc-Envel 70 23 Guéret 13371 Beissat 25 24 Périgueux 31476 Faurilles 36 25 Besançon 121144 Châtillon-sur-Lison 8 26 Valence 66149 Rochefourchat 1 27 Évreux 47574 Vieux-Port 48 28 Chartres 39698 Morainville 19 29 Brest 142555 Trégarvan 120 2A Ajaccio 72228 Mela 30 2B Bastia 49198 Érone 12 30 Nîmes 150786 Revens 20 31 Toulouse 498596 Bourg-d\u0026#x27;Oueil 5 32 Auch 23276 Roquepine 35 33 Bordeaux 264257 Bossugan 38 34 Montpellier 298933 Romiguières 23 35 Rennes 224655 Bléruais 108 36 Châteauroux 44662 Saint-Médard 52 37 Tours 139843 Couziers 111 38 Grenoble 160441 Oulles 6 39 Dole 24604 Mérona 7 40 Mont-de-Marsan 31220 Arx 49 41 Blois 47418 La Madeleine-Villefrouin 31 42 Saint-Étienne 175792 La Chambonie 40 43 Le Puy-en-Velay 20096 Arlet 23 44 Nantes 323975 Juigné-des-Moutiers 335 45 Orléans 118632 Feins-en-Gâtinais 34 46 Cahors 20877 Labastide-du-Haut-Mont 51 47 Agen 33464 Boussès 36 48 Mende 13147 Sainte-Eulalie 38 49 Angers 158930 La Lande-Chasles 123 50 Cherbourg-en-Cotentin 80912 Taillepied 18 51 Reims 184114 Rouvroy-Ripont 4 52 Saint-Dizier 23427 Charmes-en-l\u0026#x27;Angle 7 53 Laval 52370 Rennes-en-Grenouilles 105 54 Nancy 106504 Leménil-Mitry 3 55 Verdun 17906 Beaumont-en-Verdunois 0 56 Lorient 58732 Hœdic 100 57 Metz 120335 Molring 5 58 Nevers 34069 Moissy-Moulinot 18 59 Lille 236400 Dehéries 39 60 Beauvais 58520 Gouy-les-Groseillers 25 61 Alençon 26622 Le Ménil-Vicomte 23 62 Calais 73134 Guinecourt 16 63 Clermont-Ferrand 150596 La Godivelle 16 64 Pau 77070 Aubous 45 65 Tarbes 43821 Ourdon 11 66 Perpignan 120771 Sansa 19 67 Strasbourg 290106 Blancherupt 34 68 Mulhouse 109531 Lucelle 33 69 Villeurbanne 153294 Vernay 105 70 Vesoul 15663 Ranzevelle 16 71 Chalon-sur-Saône 46577 Chérizet 20 72 Le Mans 146703 Nauvay 12 73 Chambéry 60478 Champ-Laurent 34 74 Annecy 134101 Novel 51 75 Paris 15e Arrondissement 232668 Paris 1er Arrondissement 16055 76 Le Havre 170120 Le Mesnil-Durdent 20 77 Meaux 56229 Montenils 25 78 Versailles 86846 Le Tartre-Gaudran 37 79 Niort 61027 Les Groseillers 57 80 Amiens 137380 Épécamps 5 81 Albi 50625 Senaux 34 82 Montauban 62832 Goas 39 83 Toulon 180641 Vérignon 9 84 Avignon 92821 Lagarde-d\u0026#x27;Apt 33 85 La Roche-sur-Yon 58103 Marillet 124 86 Poitiers 91487 Lauthiers 70 87 Limoges 133136 Surdoux 47 88 Épinal 33706 Maroncourt 7 89 Auxerre 35554 Bois-d\u0026#x27;Arcy 24 90 Belfort 47242 Lamadeleine-Val-des-Anges 45 91 Évry-Courcouronnes 67317 Chatignonville 69 92 Boulogne-Billancourt 122825 Marnes-la-Coquette 1835 93 Saint-Denis 113766 Coubron 4963 94 Vitry-sur-Seine 95969 Périgny 2712 95 Argenteuil 111595 Charmont 36 971 Les Abymes 54027 Terre-de-Bas 999 972 Fort-de-France 77410 Grand\u0026#x27;Rivière 621 973 Cayenne 65878 Saül 159 974 Saint-Denis 155302 Saint-Philippe 5264 Changeons maintenant de base de données pour celle qui a eu les honneurs de l\u0026rsquo;épreuve Centrale 2022.\nVous trouverez ci-dessous deux extraits du sujet : d\u0026rsquo;abord l\u0026rsquo;introduction générale de l\u0026rsquo;épreuve puis la présentation de la base.\nPetite modification sur la base :\nto_temps est en ms dans la base qu\u0026rsquo;on va utiliser. gp_date est de type TEXT (chaîne de caractères). Ex : 2009-03-29. Les questions qui suivent sont adaptées du sujet 2022.\nPourquoi avoir utilisé la colonne pi_id comme clef primaire de la table pilote et pas la colonne pi_nom ?\na : il peut y avoir des noms identiques. b : une clé primaire est forcément constitué d\u0026rsquo;entiers. c : pi_nom est une clé étrangère renvoyant à la table circuit. Correction (cliquer pour afficher) En cas d'homonymes (réponse a). Une clé primaire doit être unique. Estimez le nombre de lignes de la table Tour d\u0026rsquo;après les informations données dans l\u0026rsquo;énoncé du concours :\nCorrection (cliquer pour afficher) La table Tour contient un enregistrement par tour d'un participant.\nIl y en a donc environ autant que de (nombre de championnats) $\\times$ (nombre moyen de grands prix par championnat) $\\times$ (nombre moyen de pilotes par grand prix) $\\times$ (nombre moyen de tours par grand prix).\nCela donne environ $(2022-1950)\\times 20 \\times 20 \\times 60\\approx 1,7.10^6$ soit un peu moins de 2 millions de lignes.\nVérifions grâce à la requête suivante\u0026nbsp;: SELECT COUNT(*) FROM Tour; COUNT(*) 517573 On peut supposer que notre surestimation vient des nombreux abandons ayant empêché les pilotes de boucler tous les tours d'un circuit.\nEssayons de vérifier cette hypothèse\u0026nbsp;:\nVérifions d'abord que la base de données va bien jusqu'à 2022\u0026nbsp;: SELECT gp_date FROM GrandPrix ORDER BY gp_date DESC LIMIT 3; gp_date 2022-11-20 2022-11-13 2022-10-30 Vérifions ensuite le nombre moyen de tours par participation\u0026nbsp;: SELECT AVG(nb_tours) FROM (SELECT MAX(to_num) AS nb_tours FROM Tour GROUP BY Pa_id); AVG(nb_tours) 52.94864450127877 L'écart n'est pas assez grand pour expliquer la valeur obtenue...\nVérifions enfin le nombre moyen de course par année\u0026nbsp;: SELECT COUNT(*) FROM GrandPrix; COUNT(*) 1079 Étant donné que $1079/72\\approx15$, l'énoncé nous a fait surestimer cette valeur.\nVérifions enfin le nombre moyen de pilotes par grand prix\u0026nbsp;:\nSELECT AVG(nb_pilotes) FROM (SELECT COUNT(pi_id) AS nb_pilotes FROM Participation GROUP BY gp_id) AVG(nb_pilotes) 24.0188679245283 Zut, là ça va dans le mauvais sens (on avait prix 20 pilotes par course)...\nReprenons le calcul : $72\\times 15 \\times 24 \\times 53\\approx 1,4.10^6$\nOn reste encore plus de deux fois trop grand...\nL'autre hypothèse est que la base de données n'est pas complète. SELECT COUNT(*) FROM (SELECT * FROM Tour GROUP BY pa_id); COUNT(*) 9775 SELECT COUNT(*) FROM Participation; COUNT(*) 25460 Bingo ! Beaucoup de participations (62%) ne semblent pas avoir de données dans la table Tour. Connectons-nous à la base :\n%load_ext sql %sql sqlite:///s3-tp12/F1.db Connected: @s3-tp12/F1.db\nÉcrire une requête SQL qui liste, par ordre chronologique, la date et le nom du circuit de toutes les courses qui se sont déroulées en France (ci_pays = 'France').\nCorrection (cliquer pour afficher) SELECT gp_date,ci_nom FROM (SELECT ci_nom, ci_pays, gp_date FROM GrandPrix JOIN Circuit ON GrandPrix.ci_id = Circuit.ci_id) WHERE ci_pays = 'France' ORDER BY gp_date; gp_date ci_nom 1950-07-02 Reims-Gueux 1951-07-01 Reims-Gueux 1952-07-06 Rouen-Les-Essarts 1953-07-05 Reims-Gueux 1954-07-04 Reims-Gueux 1956-07-01 Reims-Gueux 1957-07-07 Rouen-Les-Essarts 1958-07-06 Reims-Gueux 1959-07-05 Reims-Gueux 1960-07-03 Reims-Gueux 1961-07-02 Reims-Gueux 1962-07-08 Rouen-Les-Essarts 1963-06-30 Reims-Gueux 1964-06-28 Rouen-Les-Essarts 1965-06-27 Charade Circuit 1966-07-03 Reims-Gueux 1967-07-02 Le Mans 1968-07-07 Rouen-Les-Essarts 1969-07-06 Charade Circuit 1970-07-05 Charade Circuit 1971-07-04 Circuit Paul Ricard 1972-07-02 Charade Circuit 1973-07-01 Circuit Paul Ricard 1974-07-07 Dijon-Prenois 1975-07-06 Circuit Paul Ricard 1976-07-04 Circuit Paul Ricard 1977-07-03 Dijon-Prenois 1978-07-02 Circuit Paul Ricard 1979-07-01 Dijon-Prenois 1980-06-29 Circuit Paul Ricard 1981-07-05 Dijon-Prenois 1982-07-25 Circuit Paul Ricard 1982-08-29 Dijon-Prenois 1983-04-17 Circuit Paul Ricard 1984-05-20 Dijon-Prenois 1985-07-07 Circuit Paul Ricard 1986-07-06 Circuit Paul Ricard 1987-07-05 Circuit Paul Ricard 1988-07-03 Circuit Paul Ricard 1989-07-09 Circuit Paul Ricard 1990-07-08 Circuit Paul Ricard 1991-07-07 Circuit de Nevers Magny-Cours 1992-07-05 Circuit de Nevers Magny-Cours 1993-07-04 Circuit de Nevers Magny-Cours 1994-07-03 Circuit de Nevers Magny-Cours 1995-07-02 Circuit de Nevers Magny-Cours 1996-06-30 Circuit de Nevers Magny-Cours 1997-06-29 Circuit de Nevers Magny-Cours 1998-06-28 Circuit de Nevers Magny-Cours 1999-06-27 Circuit de Nevers Magny-Cours 2000-07-02 Circuit de Nevers Magny-Cours 2001-07-01 Circuit de Nevers Magny-Cours 2002-07-21 Circuit de Nevers Magny-Cours 2003-07-06 Circuit de Nevers Magny-Cours 2004-07-04 Circuit de Nevers Magny-Cours 2005-07-03 Circuit de Nevers Magny-Cours 2006-07-16 Circuit de Nevers Magny-Cours 2007-07-01 Circuit de Nevers Magny-Cours 2008-06-22 Circuit de Nevers Magny-Cours 2018-06-24 Circuit Paul Ricard 2019-06-23 Circuit Paul Ricard 2021-06-20 Circuit Paul Ricard 2022-07-24 Circuit Paul Ricard Écrire une requête SQL qui liste, pour chaque course de l’année 2021, le nom du circuit, le nom du pilote gagnant et son temps de course (dans cet ordre).\nCorrection (cliquer pour afficher) SELECT ci_nom AS \"Grand Prix\", pi_nom AS Vainqueur,temps FROM Participation JOIN GrandPrix ON GrandPrix.gp_id = Participation.gp_id JOIN Circuit ON GrandPrix.ci_id = Circuit.ci_id JOIN Pilote ON Participation.pi_id = Pilote.pi_id JOIN (SELECT pa_id,SUM(to_temps) as temps FROM Tour GROUP BY pa_id) AS tpstot ON Participation.pa_id = tpstot.pa_id WHERE gp_date \u003e= 2021 AND gp_date \u003c 2022 AND pa_cla = 1; Grand Prix Vainqueur temps Bahrain International Circuit Hamilton 5523897 Autodromo Enzo e Dino Ferrari Verstappen 7354598 Autódromo Internacional do Algarve Hamilton 5671421 Circuit de Barcelona-Catalunya Hamilton 5587680 Circuit de Monaco Verstappen 5936820 Baku City Circuit Pérez 8016410 Circuit Paul Ricard Verstappen 5245770 Red Bull Ring Verstappen 4938925 Red Bull Ring Verstappen 5034543 Silverstone Circuit Hamilton 7103284 Hungaroring Ocon 7483199 Circuit de Spa-Francorchamps Verstappen 207071 Circuit Park Zandvoort Verstappen 5405395 Autodromo Nazionale di Monza Ricciardo 4914365 Sochi Autodrom Hamilton 5441001 Istanbul Park Bottas 5464103 Circuit of the Americas Verstappen 5676552 Autódromo Hermanos Rodríguez Verstappen 5919086 Autódromo José Carlos Pace Hamilton 5542851 Losail International Circuit Hamilton 5068471 Jeddah Corniche Circuit Hamilton 7575118 Yas Marina Circuit Verstappen 5417345 Que récupère la requête suivante ?\nLa requête contient deux petites erreurs et une petite bizarrerie. Les identifier et proposer des corrections.\nCorrection (cliquer pour afficher) Pour chaque circuit, on récupère son nom, le nom du pilote qui a fait le meilleur tour, la date à laquelle ce tour a eu lieu et le temps du tour.\nErreurs : faute de frappe to_tmps à la fin bugue car nécessite de préciser dans quelle table prendre les ci_id (même si ce sont les mêmes) bizarre de grouper par ci_id, ci_nom... Un seul des deux suffit ! Requête corrigée : SELECT ci_nom, pi_nom, gp_date, to_temps FROM (SELECT Circuit.ci_id, ci_nom, MIN(to_temps) AS mtt FROM Circuit JOIN GrandPrix ON GrandPrix.ci_id = Circuit.ci_id JOIN Participation ON Participation.gp_id = GrandPrix.gp_id JOIN Tour ON Tour.pa_id = Participation.pa_id GROUP BY ci_nom ) AS rdc JOIN GrandPrix ON GrandPrix.ci_id = rdc.ci_id JOIN Participation ON Participation.gp_id = GrandPrix.gp_id JOIN Pilote ON Pilote.pi_id = Participation.pi_id JOIN Tour ON Tour.pa_id = Participation.pa_id AND to_temps = mtt ORDER BY ci_nom; ci_nom pi_nom gp_date to_temps A1-Ring Schumacher 2003-05-18 68337 Albert Park Grand Prix Circuit Leclerc 2022-04-10 80260 Autodromo Enzo e Dino Ferrari Hamilton 2020-11-01 75484 Autodromo Internazionale del Mugello Hamilton 2020-09-13 78833 Autodromo Nazionale di Monza Barrichello 2004-09-12 81046 Autódromo Hermanos Rodríguez Bottas 2021-11-07 77774 Autódromo Internacional do Algarve Hamilton 2020-10-25 78750 Autódromo José Carlos Pace Bottas 2018-11-11 70540 Autódromo Juan y Oscar Gálvez Berger 1997-04-13 87981 Autódromo do Estoril Villeneuve 1996-09-22 82873 Bahrain International Circuit Russell 2020-12-06 55404 Baku City Circuit Leclerc 2019-04-28 103009 Buddh International Circuit Vettel 2011-10-30 87249 Circuit Gilles Villeneuve Bottas 2019-06-09 73078 Circuit Park Zandvoort Hamilton 2021-09-05 71097 Circuit Paul Ricard Vettel 2019-06-23 92740 Circuit de Barcelona-Catalunya Fisichella 2005-05-08 75641 Circuit de Monaco Hamilton 2021-05-23 72909 Circuit de Nevers Magny-Cours Coulthard 2002-07-21 75045 Circuit de Spa-Francorchamps Räikkönen 2004-08-29 105108 Circuit of the Americas Leclerc 2019-11-03 96169 Circuito de Jerez Frentzen 1997-10-26 83135 Fuji Speedway Massa 2008-10-12 78426 Hockenheimring Räikkönen 2004-07-25 73780 Hungaroring Schumacher 2002-08-18 76207 Indianapolis Motor Speedway Barrichello 2004-06-20 70399 Istanbul Park Pablo Montoya 2005-08-21 84770 Jeddah Corniche Circuit Hamilton 2021-12-05 90734 Korean International Circuit Vettel 2011-10-16 99605 Losail International Circuit Verstappen 2021-11-21 83196 Marina Bay Street Circuit Magnussen 2018-09-16 101905 Nürburgring Pablo Montoya 2001-06-24 78354 Red Bull Ring Sainz 2020-07-12 65619 Sepang International Circuit Vettel 2017-10-01 94080 Shanghai International Circuit Schumacher 2004-09-26 92238 Silverstone Circuit Schumacher 2004-07-11 78739 Sochi Autodrom Hamilton 2019-09-29 95761 Suzuka Circuit Hamilton 2019-10-13 90983 Valencia Street Circuit Glock 2009-08-23 98683 Yas Marina Circuit Verstappen 2021-12-12 86103 "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_3/ia/",
	"title": "Intelligence Artificielle",
	"tags": [],
	"description": "",
	"content": "Algorithmes pour l\u0026rsquo;Intelligence Artificielle L\u0026rsquo;intelligence arificielle (IA) est une discipline scientifique qui a vu officiellement le jour en 1956. Elle repose sur la conjecture selon laquelle toutes les fonctions cognitives, en particulier l\u0026rsquo;apprentissage, le raisonnement, le calcul, la perception, la mémorisation, voire la découverte scientifique ou la créativité artistique, peuvent être décrites avec une précision telle qu\u0026rsquo;il serait possible de les reproduire sur des ordinateurs.\nL\u0026rsquo;apprentissage automatique (Machine Learning) est à l\u0026rsquo;intersection de l\u0026rsquo;IA et d\u0026rsquo;un autre champ scientifique : la science des données (data science).\nArthur Samuel définit l\u0026rsquo;apprentissage automatique ainsi en 1959 :\nLa capacité à apprendre sans avoir été spécifiquement programmé pour.\nEn pratique, il s\u0026rsquo;agit de produire des réponses adaptées aux données fournies en entrée (identifier des motifs, des tendances, construire des modèles, faire des prédictions). L\u0026rsquo;apprentissage automatique n\u0026rsquo;est donc ni plus ni moins que du traitement de données visant à prédire des résultats en fonction des données entrantes.\nLe diagramme suivant1 survole le domaine.\nOn va s\u0026rsquo;intéresser dans ce cours à l\u0026rsquo;apprentissage automatique dit \u0026ldquo;classique\u0026rdquo;2 qui regroupe des algorithmes très simples nés dans les années 50 et toujours utilisés aujourd\u0026rsquo;hui à peu près partout. Cette branche classique de l\u0026rsquo;apprentissage automatique se décompose prinicipalement en deux familles d\u0026rsquo;algorithmes : l\u0026rsquo;apprentissage supervisé et son pendant, l\u0026rsquo;apprentissage non supervisé. Nous allons étudier un algorithme star de chacune de ces familles. Algorithme des k plus proches voisins \u0026ndash; Exemple d\u0026rsquo;apprentissage supervisé L\u0026rsquo;algorithme des k plus proches voisin (k-nearest neighbors ou KNN) est une des techniques les plus simples en apprentissage automatique. Sa facilité d\u0026rsquo;utilisation et sa rapidité en font un outil de choix dans l\u0026rsquo;industrie.\nKNN est un algorithme d\u0026rsquo;apprentissage supervisé ; cela signifie que l\u0026rsquo;algorithme nécessite des données classifiées en amont qui vont lui servir à trouver la bonne étiquette pour d\u0026rsquo;autres données non encore classifiées.\nSuivant la nature de l\u0026rsquo;étiquette, KNN peut servir à :\nune classification des nouvelles données si les étiquettes sont des catagories ; une régression si les étiquettes sont des nombres. Principe KNN enregistre, dans un premier temps, tous les points de données étiquetées qui vont lui servir à l\u0026rsquo;apprentissage (c\u0026rsquo;est le training set). Puis, quand arrive un point de donnée non étiqueté, l\u0026rsquo;algorithme calcule sa distance aux autres points et sélectionne les k plus proches. On a alors deux cas possibles :\nsi les étiquettes sont des catégories, l\u0026rsquo;algorithme calcule le mode des catégories des voisins sélectionnés (catégorie la plus représentée). si les étiquettes sont des nombres, l\u0026rsquo;algorithme calcule la moyenne des étiquettes des voisins sélectionnés. L\u0026rsquo;algorithme des k plus proches voisins est non paramétrique dans le sens où aucun modèle mathématique de classification ou régression n\u0026rsquo;est construit à partir des données (pas de paramètre à ajuster) puisque toutes les données d\u0026rsquo;apprentissage sont enregistrées telles quelles.\nCela signifie qu\u0026rsquo;on ne présuppose rien de particulier sur les données (à part que des points proches appartiennent à la même catégorie). L\u0026rsquo;algorithme est donc particulièrement robuste (les données parlent d\u0026rsquo;elles-même) et simple à mettre à jour (suffit d\u0026rsquo;ajouter les nouvelles données d\u0026rsquo;apprentissage).\nChoix de k Comme le montre la petite animation ci-dessus, le choix de k modifie le résultat obtenu.\nSi k est trop petit, le moyennage est faible et donc la variabilité va être très grande. On parle alors de surapprentissage (overfitting). En augmentant k, les résultats obtenus se stabilisent (vote de la majorité) et les erreurs diminuent, jusqu\u0026rsquo;au moment où la boule à l\u0026rsquo;intérieur de laquelle se fait le moyennage devient trop grosse, amenant in fine l\u0026rsquo;algorithme a choisir systématiquement la catégorie majoritaire, quel que soit le point\u0026hellip; On augmente alors le biais (ici, le biais est le préjudice en faveur du plus grand nombre). L\u0026rsquo;ajustement ne suit plus les variations, on parle de sous-apprentissage (underfitting). Pour résumer :\nvariance biais Cas d\u0026rsquo;une régression Cas d\u0026rsquo;une classification k trop petit $\\rightarrow$ overfitting forte faible k trop grand $\\rightarrow$ underfitting faible fort Lorsqu\u0026rsquo;on ne connaît rien sur les données, on peut toujours commencer par prendre la racine carrée du nombre de points dans l\u0026rsquo;ensemble d\u0026rsquo;entraînement comme k de départ.\nLe choix de k est donc affaire de compromis. Pour le rendre plus scientifique, on peut chercher à mesurer la performance de l\u0026rsquo;algorithme pour différentes valeurs de k.\nMais comment mesure-t-on la performance d\u0026rsquo;un algorithme d\u0026rsquo;apprentissage automatique ?\nValidation \u0026ndash; Matrice de confusion La matrice de confusion permet d\u0026rsquo;évaluer la qualité des prédictions d\u0026rsquo;un algorithme.\nPrenons l\u0026rsquo;exemple de l\u0026rsquo;utilisation de KNN sur une banque d\u0026rsquo;images de chiffres écrits à la main et plus spécifiquement concentrons-nous sur sa capacité à reconnaître des \u0026ldquo;3\u0026rdquo;.\nOn découpe l\u0026rsquo;espace en 4 cadrans. Sur une dimension, on regroupe d\u0026rsquo;un côté les données pertinentes (les 3) et de l\u0026rsquo;autre le reste des données (les non 3), et on décompose l\u0026rsquo;autre dimension en prédictions positives (les 3 prédits) et négatives (les non 3 prédits).\nPuis on compte dans chaque cadran le nombre de données correspondant au recouvrement des prédictions et de la réalité. Un nom issu du vocabulaire des diagnostics médicaux est attribué à chacun de ces cadrans :\nles vrais positifs VP (les 3 identifiés comme des 3), les vrais négatifs VN (les non 3 identifiés comme des non 3), les faux positifs FP (les non 3 identifiés comme des 3), les faux négatifs FN (les 3 identifiés comme des non 3). À partir de ces effectifs, on peut calculer 3 grandeurs permettant d\u0026rsquo;évaluer la qualité de la prédiction :\nNombre de données bien prédites parmi les prédictions positives : $$\\frac{VP}{VP+FP}$$\nNombre de données bien prédites parmi les données positives : $$\\frac{VP}{VP+FN}$$\n$$\\frac{VP+VN}{VP+VN+FP+FN}$$\nUn algorithme peut très bien être très précis (les prédictions positives sont bien des 3), mais peu sensible, avec un faible taux de rappel (parmi tous les 3, peu ont été identifiés).\nÀ l\u0026rsquo;inverse, on peut avoir une bonne sensibilité (la plupart des vrais 3 ont été identifiés comme tel), mais peu précis (beaucoup de chiffres identifiés comme des 3 sont en fait d\u0026rsquo;autres chiffres).\nOn peut tout aussi bien définir la matrice de confusion avec les prédictions sur les lignes et la réalité sur les colonnes.\nMaintenant qu\u0026rsquo;on sait évaluer l\u0026rsquo;algorithme, cherchons la valeur de k qui maximise l\u0026rsquo;exactitude.\nDans le graphe ci-dessous, on a tracé l\u0026rsquo;exactitude de l\u0026rsquo;algorithme pour la reconnaissance des \u0026ldquo;9\u0026rdquo; en fonction de la valeur de k (ce sont les mêmes jeux de données test et d\u0026rsquo;apprentissage que dans le TP). Si notre but est de reconnaître le mieux possible les 9 manuscrits, il semblerait que la valeur de k optimale soit 18.\nAlgorithme des k-moyennes \u0026ndash; Exemple d\u0026rsquo;apprentissage non supervisé Le boulot de l\u0026rsquo;algorithme des k-moyennes (k-means) n\u0026rsquo;est pas d\u0026rsquo;étiqueter les données, mais de les regrouper par famille. C\u0026rsquo;est donc un algorithme de partitionnement des données (clustering).\nContrairement à KNN, l\u0026rsquo;algorithme des k-moyennes ne nécessite pas de données préétiquetées. Il fait ainsi parti des algorithmes d\u0026rsquo;apprentissage automatique non-supervisé (il se débrouille tout seul avec les données mystères).\nPar contre, l\u0026rsquo;algorithme partage avec KNN sa grande simplicité d\u0026rsquo;emploi et son efficacité qui le rendent lui aussi très populaire dans l\u0026rsquo;industrie.\nPrincipe L\u0026rsquo;algorithme dépend d\u0026rsquo;un seul paramètre en plus des données : le nombre de partitions (clusters) k.\nOn commence par choisir k points au hasard dans l\u0026rsquo;espace des données (il peut s\u0026rsquo;agir de k points de données ou de k autres points). Ce sont les k centres (ou centroïdes).\nPlus les points choisis au départ sont éloignés les uns des autres, mieux c\u0026rsquo;est. Une amélioration de l\u0026rsquo;algorithme de base proposée en 2007, k-means++, s\u0026rsquo;en assure.\nOn attribue ensuite à chaque centre tous les points de données qui lui sont le plus proches, formant ainsi k groupes.\nEnfin, on déplace chaque centre au barycentre de son groupe.\nOn répète les deux dernières opérations (attribution des points les plus près et déplacement des centres) tant que les centres bougent d\u0026rsquo;une itération à l\u0026rsquo;autre.\nL\u0026rsquo;algorithme vise à résoudre au final un problème d\u0026rsquo;optimisation ; son but est en effet de trouver le minimum de la distance entre les points à l\u0026rsquo;intérieur de chaque partition.\nMathématiquement, étant donné un ensemble de points $(x_1,x_2,\\ldots,x_n)$, on cherche à partitionner les $n$ points en $k$ ensembles $S=\\{S_1,S_2,\\ldots,S_k\\}$ en minimisant la grandeur : $$I = \\sum_{i=1}^{k}\\sum_{x_j \\in S_i}||x_i-\\mu_i||^2$$ où $\\mu_i$ est le barycentre des points dans $S_i$.\n$I$ est la variance intra-classe ou inertie intra-classe (terme surtout utilisé en anglais).\nChoix de k Choisir le bon nombre de clusters est crucial pour l\u0026rsquo;algorithme des k-moyennes, comme l\u0026rsquo;illustre l\u0026rsquo;exemple suivant :\nMais ce n\u0026rsquo;est pas toujours simple (contrairement à l\u0026rsquo;exemple) de deviner le bon nombre de clusters juste en inspectant les données. Alors comment faire ?\nOn pourrait se dire qu\u0026rsquo;il suffit de prendre le modèle avec la plus faible inertie. Mais malheureusement, l\u0026rsquo;inertie n\u0026rsquo;est pas une métrique adaptée au choix de k puisqu\u0026rsquo;elle ne fait que descendre quand k augmente\u0026hellip; Logique : plus il y a de clusters, plus la distance intra-cluster diminue\u0026amp;nbsp!\nTraçons l\u0026rsquo;inertie en fonction de k pour y voir plus clair : On remarque qu\u0026rsquo;ici, le nombre de clusters idéal correspond au point d\u0026rsquo;inflexion de la courbe (ou, si on imagine un bras, au coude).\nConfirmons en simulant des données séparées en 5 tas et en retraçant la courbe. Là encore, le coude indique le nombre k idéal.\nOn semble donc avoir trouver une tactique utilisable lorsqu\u0026rsquo;on n\u0026rsquo;a pas d\u0026rsquo;autres indices.\nIl existe des méthodes plus précises pour déterminer k, mais elles sont aussi plus gourmandes en calcul. La plus répandue utilise les coefficients de silhouette de chaque point (différence entre la distance moyenne avec les points du même groupe (cohésion) et la distance moyenne avec les points des autres groupes voisins (séparation)).\nLimites L\u0026rsquo;algorithme des $k$-moyennes se confronte à une difficulté classique en apprentissage automatique, et plus généralement pour tout problème d\u0026rsquo;optimisation : obtenir un minimum global plutôt qu\u0026rsquo;un minimum local.\nLa convergence vers un des minima locaux dépend crucialement de la position initiale des centres.\nDans l\u0026rsquo;exemple suivant, on obtient 3 partitionnements différents pour 3 initialisations différentes des centres.\nOn vérifie que les centres sont bien bloqués sur leur position dans les deux premiers cas puisqu\u0026rsquo;aucun changement d\u0026rsquo;attribution n\u0026rsquo;est possible.\nDans l\u0026rsquo;algo classique, pour pallier au mieux ce problème, on initialise les centres aléatoirement et on relance l\u0026rsquo;algorithme un certain nombre de fois pour ne garder au final que la solution qui minimise l\u0026rsquo;inertie intra-classe.\nAutre souci des k-moyennes : des difficultés pour partitionner des clusters de différentes tailles, différentes densités ou des formes non sphériques.\nApplications L\u0026rsquo;algorithme des k-moyennes ne présuppose rien sur les données et peut s\u0026rsquo;avérer, par le fait, très utile en première approche.\nC\u0026rsquo;est bien ce rôle de défricheur qu\u0026rsquo;on a donné à l\u0026rsquo;algorithme dans le TP3 lors de l\u0026rsquo;analyse de l\u0026rsquo;enquête mondiale sur le bonheur pour créer des groupes de pays similaires et tenter de comprendre ce qui les rassemble.\nL\u0026rsquo;algorithme permet aussi de trancher des débats de la plus haute importance sur les couleurs comme \u0026ldquo;est-ce plus vert que bleu ?\u0026rdquo; en organisant un combat entre les centroïdes de chaque couleur.\nDans la même veine, on peut utiliser k-moyennes pour segmenter une image par couleur (voir TP13), ce qui peut s\u0026rsquo;avérer intéressant pour des données satellite par exemple. Le choix de k correspond alors au nombre de couleurs qu\u0026rsquo;on veut garder.\nL\u0026rsquo;exemple ci-dessous est issu du TP : La simplicité de k-moyennes en fait un bon outil de dégrossissage des données, y compris sur des données déjà étiquetées. Cela permet de réduire leur dimensionnalité, avant d\u0026rsquo;utiliser des algorithmes plus complexes d\u0026rsquo;apprentissage supervisé.\nJeux d\u0026rsquo;accessibilité sur un graphe Cette partie du cours a moins à voir avec les jeux vidéo qu\u0026rsquo;avec la modélisation de systèmes réactifs (automate bancaire, système-environnement), les problèmes de contrôle, la théorie de la décision, les problèmes de routage sur Internet, l\u0026rsquo;économie\u0026hellip; Autant de domaînes admettant une description en terme d\u0026rsquo;opposition entre adversaires sur une arêne (un des adversaires pouvant modéliser l\u0026rsquo;environnement). La détermination d\u0026rsquo;une stratégie gagnante résout alors le problème posé en assurant sa correction.\nL\u0026rsquo;arène On entendra ici par jeu :\ndes jeux à deux joueurs ($J_1$ et $J_2$ ou Eve et Adam) à information complète : les deux joueurs savent tout (pas comme aux cartes) alternés (pas comme à chifoumi) non randomisés (pas de hasard) L\u0026rsquo;arène dans laquelle le jeu prend place est un graphe orienté biparti.\nUn graphe biparti (ou bipartite) $G$ est un graphe dont l\u0026rsquo;ensemble des sommets peut être divisé en deux sous-ensembles de sommets disjoints $S_1$ et $S_2$ ($S_1$ et $S_2$ sont une partition de $S$ : $S_1\\cup S_2=S$, $S_1\\cap S_2=\\varnothing$) tels que chaque arête de $G$ a une extrémité dans $S_1$ et l\u0026rsquo;autre dans $S_2$.\nUn graphe est biparti si on peut colorier tous les sommets du graphe avec seulement deux couleurs de manière à ce que deux sommets voisins n\u0026rsquo;aient jamais la même couleur (on parle alors de 2-coloriage).\nOn peut montrer qu\u0026rsquo;un graphe est biparti si et seulement si il ne possède pas de cycle de longueur impaire.\nDémonstration de \u0026ldquo;graphe biparti $\\Leftrightarrow$ pas de cycle impair\u0026rdquo; :\nOn montre $\\Rightarrow$ en constatant l\u0026rsquo;impossibilité d\u0026rsquo;un 2-coloriage sur un cycle impair. Donc tout graphe contenant un cycle impair ne peut pas être biparti.\nEt on montre $\\Leftarrow$ en essayant de créer un 2-coloriage depuis un sommet ; tant qu\u0026rsquo;on ne rencontre pas de cycle, pas de problème.\nTous les sommets à une distance impaire du sommet de départ sont coloriés d\u0026rsquo;une couleur et tous ceux à une distance paire sont coloriés de l\u0026rsquo;autre couleur.\nDonc un graphe sans cycle est toujours biparti.\nPlace aux cycles maintenant. Supposons que deux des chemins partant d\u0026rsquo;un sommet se rejoignent, alors on a deux possibilités :\nla jonction se fait entre deux sommets de couleurs différentes et le 2-coloriage reste possible.\nDans ce cas, on joint un chemin de longueur pair et un chemin de longueur impair, ce qui donne un cycle de longueur pair (avec le +1 de l\u0026rsquo;arête de la jonction). la jonction se fait entre sommets de la même couleur rendant impossible le 2-coloriage.\nDans ce deuxième cas, on obtient nécessairement un cycle de longueur impaire puisqu\u0026rsquo;on joint deux chemins de la même parité (+ 1 de l\u0026rsquo;arête de jonction).\nSeuls les cycles impairs font donc échouer le 2-coloriage. Tout graphe non biparti contient au moins un cycle impair.\nRetournons aux jeux\u0026hellip;\nDeux joueurs, $J_1$ et $J_2$, s\u0026rsquo;affrontent sur un graphe orienté biparti $G=(S,A)$ où $S$ est constitué des sommets contrôlés par le joueur 1, $S_1$, et de ceux contrôlés par le joueur 2, $S_2$. Chaque sommet est une position valide du jeu et chaque arête est un mouvement autorisé entre ces positions.\nIl manque encore une condition de gain pour rendre le jeu intéressant ; dans le cas d\u0026rsquo;un jeu d\u0026rsquo;accessibilité, on attribue à chaque joueur un sous-ensemble de sommets correspondant à des états gagnants qu\u0026rsquo;il convient d\u0026rsquo;atteindre pour\u0026hellip; gagner. Il peut aussi exister un sous-ensemble de sommets correspondant à des états de partie nulle.\nUn jeu d\u0026rsquo;accessibilité est alors défini par un quadruplet $(G,S_1,S_2,F)$ où $(G,S_1,S_2)$ est une arène et $F$ est l\u0026rsquo;ensemble des sommets gagnants pour $J_1$.\nExemples Chomp Chomp est un jeu où les deux adversaires mangent à tour de rôle des carrés de chocolat d\u0026rsquo;une tablette avec la \u0026ldquo;contrainte\u0026rdquo; de manger tous les carrés à droite et au-dessus du carré choisi. Le perdant doit manger le brocoli qui reste à la fin.\nEve commence le jeu avec la tablette ci-dessous composé de 5 carrés. Il existe alors 9 configurations possibles, pas toutes atteignables par les deux joueurs.\nTraçons l\u0026rsquo;arène (les ronds bleus sont les positions contrôlées par Eve et les carrés roses par Adam).\n$F$ (sommet gagnant pour Eve) est le carré rose avec un brocoli puisque l\u0026rsquo;atteindre signifie qu\u0026rsquo;Adam se retrouve avec le légume à manger.\nUne des nombreuses variantes du jeu de Nim Un tas d\u0026rsquo;allumettes est disposé devant Eve et Adam. Eve joue en premier et peut retirer autant d\u0026rsquo;allumettes qu\u0026rsquo;elle le souhaite du moment qu\u0026rsquo;elle en prend au moins une et qu\u0026rsquo;elle en laisse au moins une. C\u0026rsquo;est ensuite au tour d\u0026rsquo;Adam de retirer des allumettes avec pour tous les tours qui suivent une contrainte supplémentaire : on ne peut pas retirer plus de deux fois le nombre d\u0026rsquo;allumettes prises par son adversaire au tour précédent. Le joueur qui retire la dernière allumette gagne. Il n\u0026rsquo;y a pas de match nul.\nTraçons le graphe du jeu en supposant que l\u0026rsquo;on commence avec 5 allumettes et étiquetons les sommets avec le couple (nombre d\u0026rsquo;allumettes présentes, nombres d\u0026rsquo;allumettes prenables). L\u0026rsquo;étiquette du nœud de départ est donc (5,4).\nOn a indiqué en jaune le sommet à atteindre pour Eve (sommet de $F$).\nLe graphe est ici plutôt simple, mais on verra dans le TP que pour des nombres d\u0026rsquo;allumettes plus grand, on sera content de pouvoir confier la tâche de sa construction à python.\nCe jeu est une variante du jeu de Nim (voir TP) comme en fait tout jeu impartial à deux joueurs (théorème de Sprague-Grundy). Un jeu impartial est un jeu tour par tour dans lequel les coups autorisés, ainsi que les gains obtenus, dépendent uniquement de la position, et pas du joueur dont c\u0026rsquo;est le tour. C\u0026rsquo;est le cas de Chomp qui est donc, lui aussi, un jeu de Nim déguisé\u0026hellip; Un jeu qui n\u0026rsquo;est pas impartial est appelé jeu partisan (le morpion ou les échecs par exemple).\nMorpion (tic-tac-toe) Pas besoin de rappeler les règles du morpion (oxo en belgique).\nDans cet exemple, Eve démarre sur un jeu déjà avancé, elle a les ronds.\nCette fois-ci, $F$ contient plusieurs sommets (toujours indiqués en jaune).\nStratégie Gagner la partie, c\u0026rsquo;est arriver sur un sommet de $F$. Comment savoir si Eve peut ou non gagner selon sa position de départ ? Et si elle le peut, comment mettre au point pour elle une stratégie gagnante ?\nPositions gagnantes et attracteurs Pour déterminer l\u0026rsquo;ensemble des positions gagnantes pour Eve sur l\u0026rsquo;arène, on travaille récursivement depuis les sommets de $F$ en suivant les deux préceptes suivants :\nun sommet d\u0026rsquo;Eve est gagnant si un de ses arcs sortants le lie à un sommet gagnant.\nEve n\u0026rsquo;a alors plus qu\u0026rsquo;à emprunter ce chemin.\nun sommet d\u0026rsquo;Adam est gagnant (pour Eve) si tous ses arcs sortants le lie à un sommet gagnant.\nEn effet, Adam ne peut alors pas éviter de mettre Eve dans une position gagnante. Formalisons un peu tout ça en définissant la suite $Attr_i(F)$ qui contient l\u0026rsquo;ensemble des sommets gagnants après $i$ étapes : $$ \\begin{array}{lll} Attr_0(F) \u0026amp;= \u0026amp;F \\\\ Attr_{i+1}(F) \u0026amp;= \u0026amp;Attr_{i}(F) \\\\ \u0026amp;\u0026amp;\\cup \\{s \\in S_1|Succ(s)\\cap Attr_i(F) ≠ \\varnothing \\} \\\\ \u0026amp;\u0026amp;\\cup \\{s\\in S_2| Succ(s)\\subseteq Attr_i(F)\\} \\end{array} $$ Étant donné que $Attr_i(F) \\subseteq Attr_{i+1}(F) \\subseteq S$, pour tout $i≥0$, si on suppose le graphe fini, la suite est croissante et bornée et donc stationnaire (à partir d\u0026rsquo;un certain $i=i_0$, $Attr_i(F)$ est constante, et si $|G|=n$, $i_0$ vaut au plus $n-1$).\nOn appelle attracteur de $F$ pour le joueur $J_1$ la limite de $Attr_i(F)$. On le note $Attr(F)$.\nTout sommet dans l\u0026rsquo;attracteur est une position gagnante pour $J_1$.\nLe complémentaire d\u0026rsquo;un attracteur est appelé piège. Si le joueur 1 est sur une position n\u0026rsquo;appartenant pas à son attracteur (et donc à son piège), cela signifie que :\nsi c\u0026rsquo;est son tour, tous les mouvements possibles restent dans le piège, si c\u0026rsquo;est le tour de l\u0026rsquo;adversaire, celui-ci a toujours au moins une possibilité de laisser le joueur 1 dans le piège. Cette position est donc perdante\u0026hellip;\nDétermination \u0026ldquo;à la main\u0026rdquo; de l\u0026rsquo;attracteur dans les exemples précédents L\u0026rsquo;attracteur dans l\u0026rsquo;exemple du jeu Chomp contient 9 sommets, dont le somme de départ.\nDans le cas de la variante de Nim, l\u0026rsquo;attracteur se réduit à $Attr(G) = \\{(0,0,1) , (1,1,0) , (2,2,0) \\}$ où la troisième valeur des triplets correspond au joueur qui contôle le sommet (0 pour Eve et 1 pour Adam). Le sommet de départ $(5,4,0)$ n\u0026rsquo;est pas dedans $\\Rightarrow$ c\u0026rsquo;est perdu pour Eve 😭..\nEnfin, sur l\u0026rsquo;exemple du morpion, l\u0026rsquo;attracteur contient 13 sommets dont celui de départ.\nProgramme permettant de calculer l\u0026rsquo;attracteur On peut écrire un programme récursif calculant l\u0026rsquo;attracteur en temps linéaire en $|S | + |A|$ (rappelons-nous que le parcours complet d\u0026rsquo;un graphe est au mieux en $O(|S | + |A|)$ car cela correspond à parcourir les $|S|$ sommets et les $|A|$ arêtes). Pour éviter de calculer plusieurs fois le même élément, l\u0026rsquo;algorithme tient à jour, pour chaque sommet $s$, un compteur n des successeurs non encore inspectés (sous la forme d\u0026rsquo;un dictionnaire) .\ndef attracteur(G: dict, F: list) -\u0026gt; list: \u0026#34;\u0026#34;\u0026#34; préconditions: G est est un graphe sous forme de liste d\u0026#39;adjacence implémentée par un dictionnaire F est la liste des sommets gagnants pour le joueur 1 postcondition: la fonction retourne l\u0026#39;attracteur de F pour le joueur 1 sous forme d\u0026#39;un dictionnaire dont les clés sont les sommets de G et les valeurs True ou False suivant que le sommet appartienne ou non à l\u0026#39;attracteur \u0026#34;\u0026#34;\u0026#34; Pred = inverseGraphe(G) n = {s:len(G[s]) for s in G} Attr = {s:False for s in G} for sommet in F: Joueur1 = True propage(sommet,Joueur1,Attr,Pred,n) return Attr def propage(sommet,Joueur1,Attr,Pred,n): if Attr[sommet]: return Attr[sommet] = True for s in Pred[sommet]: n[s] -= 1 # un successeur de s en moins if Joueur1 or (n[s] == 0) : propage(s,not Joueur1,Attr,Pred,n) Stratégie gagnante Une stratégie sans mémoire est une fonction $\\sigma$ qui assigne un mouvement autorisé à un joueur pour chaque position non terminale : $\\forall s\\in S, (s,\\sigma(s))\\in A.$\nUn joueur sur une position $s$ suit une stratégie s\u0026rsquo;il emprunte le chemin $\u0026lt;s,\\sigma(s),\\sigma^2(s),\\ldots\u0026gt;$. Elle est dite sans mémoire car pour une position donnée, la stratégie est indépendante du chemin qui y a mené ($\\sigma$ ne dépend que du sommet).\nUne stratégie sans mémoire gagnante depuis une position donnée garantit la victoire au joueur en un nombre de coups limité. Pour le joueur 1, une stratégie gagnante garantit d\u0026rsquo;arriver sur un sommet de $F$. Mais suivant la position de départ, une telle stratégie n\u0026rsquo;existe pas forcément\u0026hellip;\nEn construisant l\u0026rsquo;attracteur, on répond à notre première question : la position d\u0026rsquo;Eve est-elle gagnante ? Il suffit de vérifier qu\u0026rsquo;elle appartient à l\u0026rsquo;attracteur.\nSi c\u0026rsquo;est le cas, une stratégie gagnante est facile à mettre en place ; il faut faire en sorte que chaque déplacement sur le graphe (chaque coup joué) se fasse vers un sommet de l\u0026rsquo;attracteur. Chaque coup d\u0026rsquo;Eve vers un sommet de l\u0026rsquo;attracteur piège aussi le coup suivant d\u0026rsquo;Adam dans l\u0026rsquo;attracteur.\nComme son nom l\u0026rsquo;indique, l\u0026rsquo;attracteur attire irrémédiablement vers $F$, assurant la victoire au joueur 1.\nLe joueur 2 aussi, bien sûr, a son attracteur, et il appartient au complémentaire de l\u0026rsquo;attracteur du joueur 1, piège du joueur 1. Donc un seul écart du joueur 1 en dehors de son attracteur, et s\u0026rsquo;en est fini pour lui, le joueur 2 peut le condanner à rester dans le piège. Revenons à nos exemples :\nPour Chomp, le joueur 1 appartient à l\u0026rsquo;attracteur, ce qui signifie que sa position de départ est gagnante. Par conséquent, il a une stratégie gagnante. Mais attention à ne pas se tromper au début ! Sur 5 mouvements possibles, le seul assurant la victoire est de manger le carré en haut à droite. Pour la variante de Nim, c\u0026rsquo;est foutu\u0026hellip; Quelle que soit notre stratégie, elle sera perdante. Enfin, pour Tic-tac-toe, la victoire tend les bras au joueur 1. Et, sans surprise, son premier mouvement doit être de prendre le milieu. Arbre et minimax Pour des jeux comme les échecs, le graphe est bien trop gros pour pouvoir appliquer nos méthodes précédentes. Alors comment s\u0026rsquo;en sortir ?\nL\u0026rsquo;idée est de se contenter d\u0026rsquo;une recherche partielle autour de la position actuelle donnant à l\u0026rsquo;algorithme seulement quelques coups d\u0026rsquo;avance. Il évalue alors les différentes positions futures possibles en leur attribuant un score issu d\u0026rsquo;une heuristique.\nUne heuristique est une méthode de calcul qui fournit rapidement une solution réalisable, pas nécessairement optimale ou exacte, pour un problème d\u0026rsquo;optimisation difficile. Elle s\u0026rsquo;impose quand les algorithmes de résolution exacte sont impraticables, à savoir de complexité polynomiale de haut degré, exponentielle ou plus.\nUne heuristique est donc un compromis entre d\u0026rsquo;un côté l\u0026rsquo;optimalité (trouver la meilleure solution) et/ou la complétude (trouver toutes les solutions) de l\u0026rsquo;algorithme et de l\u0026rsquo;autre côté sa vitesse.\nPour implémenter efficacement cette recherche partielle, l\u0026rsquo;idée est d\u0026rsquo;utiliser un arbre plutôt que l\u0026rsquo;arêne précédente. Quelle différence ? L\u0026rsquo;absence de cycle qui va permettre d\u0026rsquo;élaguer ! On le paye au prix de la redondance des sommets (le même sommet peut apparaître plusieurs fois dans l\u0026rsquo;arbre). Pour chaque position, les différents coups possibles correspondent aux différentes branches et on avance ainsi niveau par niveau jusqu\u0026rsquo;aux feuilles représentant les positions terminales.\nLe gros avantage d\u0026rsquo;un arbre est qu\u0026rsquo;il permet facilement de ne garder que quelques niveaux (on raccourci alors toutes les branches jusqu\u0026rsquo;à la profondeur considérée).\nMuni de cet arbre, l\u0026rsquo;algorithme se lance dans un parcours en profondeur jusqu\u0026rsquo;à la profondeur maximale stipulée. Lorsque ce niveau est atteint (2, par exemple, si on veut que l\u0026rsquo;IA ait deux coups d\u0026rsquo;avance), l\u0026rsquo;algorithme évalue les feuilles grâce à son heuristique, puis il propage ce score vers les niveaux supérieurs en suivant le principe du minimax :\nsur un niveau correspondant au joueur 1, on sélectionne la valeur maximale parmi les branches, et sur un niveau correspondant à l\u0026rsquo;adversaire, on sélectionne la valeur minimale. Le pricipe est de maximiser les gains du joueur 1 tout en minimisant ceux du joueur 2. La valeur est au final transmise à la racine (la position depuis laquelle on a lancé la recherche) et la meilleure branche est sélectionnée.\nPrenons l\u0026rsquo;exemple du jeu de Morpion. Une heuristique possible pour évaluer un plateau pourrait consister à compter $+1$ pour chaque alignement encore possible pour le joueur et $-1$ pour ceux encore possibles pour son adversaire.\nL\u0026rsquo;arbre total du morpion n\u0026rsquo;est pas si gros ; le facteur de ramification $b$ est de 5 en moyenne et il y a au plus 9 niveaux (9 coups), ce qui donne $\\approx 5^9 = 1\\,953\\,125$ (à titre de comparaison, aux échecs, $b\\approx35$ et un partie dure en moyenne 100 coups, ce qui donne $b^m\\approx10^{54}$ sommets à inspecter\u0026hellip;).\nL\u0026rsquo;algorithme minimax appliqué au morpion inspecte en réalité environ 4 fois moins de sommets que les deux millions prédits, car ce chiffre ne tient pas compte des nombreuses parties potentielles se terminant avant le neuvième coup. Il en inspecte néanmoins beaucoup plus qu\u0026rsquo;il ne faudrait (il n\u0026rsquo;y a que $9!=362\\,880$ coups possibles si l\u0026rsquo;ordi commence et seulement $8!=40\\,320$ si l\u0026rsquo;humain a l\u0026rsquo;honneur), ce qui illustre le fait qu\u0026rsquo;un arbre contient beaucoup de sommets redondants par rapport au graphe du jeu dont il est tiré (c\u0026rsquo;est le prix à payer pour casser les cycles).\nLa taille modéré de l\u0026rsquo;arbre permet de l\u0026rsquo;explorer jusqu\u0026rsquo;aux parties finales, mais on peut constater en jouant avec le petit programme ci-dessous que la réduction à une profondeur d\u0026rsquo;un seul niveau grâce à l\u0026rsquo;heuristique3 est tout autant redoutable en inspectant presque 4000 fois moins de sommets !\nCela prouve qu\u0026rsquo;au morpion, 1 coup d\u0026rsquo;avance, c\u0026rsquo;est bien suffisant\u0026hellip; Mais ce n\u0026rsquo;est pas vraiment le cas aux échecs, où les plus grands joueurs (comme Kasparov) prévoient jusqu\u0026rsquo;à 12 coups à l\u0026rsquo;avance ! Deep Blue, qui a battu Kasparov en 1997, cherchait jusqu\u0026rsquo;à une profondeur typiquement comprise entre 6 et 16, mais pouvait aller jusqu\u0026rsquo;à 40 dans certaines situations.\nDans le cas des échecs, l\u0026rsquo;heuristique permettant d\u0026rsquo;évaluer un état de l\u0026rsquo;échiquier est bien plus complexe qu\u0026rsquo;au morpion. Elle doit prendre en compte la quantité de pièces et pions restants, la qualité des pièces et les positions de tout ce beau monde (domination du centre, structure compacte, etc.).\nLa taille du jeu de Go rend vaine toute tentative de type minimax. C\u0026rsquo;est au point que les grands joueurs de Go ont longtemps refusé de jouer contre des ordinateurs, non par peur de perdre, mais parcequ\u0026rsquo;ils les trouvaient trop mauvais. C\u0026rsquo;est l\u0026rsquo;essor du deep learning, et donc une philosophie basée sur l\u0026rsquo;apprentissage plus que sur la stratégie, qui a permis à la machine de devenir un adversaire coriace à ce jeu-là aussi.\nSac à dos et heuristique Voyons enfin une autre utilisation d\u0026rsquo;heuristique avec le problème du sac à dos, ici dans sa version \u0026ldquo;0/1\u0026rdquo; (knapsack 0/1 en anglais).\nLe problème du sac à dos est un problème classique d\u0026rsquo;optimisation avec d\u0026rsquo;importantes applications théoriques et industrielles.\nSoit $x\\in\\mathbb{N}^{*}$, soit $v$ une séquence de $n$ éléments appartenant à $\\mathbb{N}^{*}$, et soit $p$ une séquence de $n$ éléments appartenant à $\\{1,2,\u0026hellip;,c\\}$.\nNous appelons $c$ la capacité, $v$ la séquence de valeurs et $p$ la séquence de poids.\nLe problème du sac à dos consiste à mettre des objets de poids $p$, dans un sac à dos qui peut contenir un poids maximal $c$, de telle sorte que la valeur des objets choisis est maximisée.\nPlus formellement, cela revient à maximiser $$\\text{val}(x)=\\sum_{i=1}^n x[i]\\cdot v[i]$$ sous la contrainte $c≥\\sum_{i=1}^n x[i]\\cdot p[i]$, où $x\\in\\{0,1\\}^n$ indique les objets choisis.\nExemple : supposons que le sac ait une capacité de 900 et que l\u0026rsquo;on cherche à y placer les objets suivants\nobjets 🥏 🎺 🥊 🧸 🪠 ⏰ valeurs $v$ 5 50 65 20 10 12 poids $p$ 320 700 845 180 70 420 Le plus simple pour arriver à nos fins est de suivre une stratégie gloutonne (une stratégie étape par étape où un critère de classement permet de sélectionner le prochain objet à ajouter). Un critère qui semble prometteur est le ratio valeur/poids de chaque objet. L\u0026rsquo;idée est alors de placer les objets dans le sac dans l\u0026rsquo;ordre inverse de leur ratio. Cela semble une bonne stratégie puisque les objets ajoutés maximisent ainsi la valeur qu\u0026rsquo;ils apportent par rappor à la place qu\u0026rsquo;ils prennent. Mais si l\u0026rsquo;approche gloutonne a l\u0026rsquo;avantage d\u0026rsquo;être très simple, le revers de la médaille est qu\u0026rsquo;elle est à courte vue, on perd la vision d\u0026rsquo;ensemble. Et dans certaines configurations, comme c\u0026rsquo;est le cas dans notre exemple, cela s\u0026rsquo;avère contre-productif.\nobjets 🥏 🎺 🥊 🧸 🪠 ⏰ ratio $v/p$ 1/64 1/14 1/13 1/9 1/7 1/35 L\u0026rsquo;approche gloutonne nous encourage ici à placer d\u0026rsquo;abord 🪠 dans le sac, puis 🧸, et c\u0026rsquo;est tout. Plus de place pour l\u0026rsquo;objet suivant (🥊). On obtient finalement une valeur de 30 et un poids de 250.\nCet exemple nous montre que l\u0026rsquo;approche gloutonne ne garantit pas l\u0026rsquo;optimalité (loin de là même, vu la place qu\u0026rsquo;il reste dans le sac\u0026hellip;). On pourrait néanmoins facilement améliorer les choses en continuant d\u0026rsquo;essayer de placer les éléments de ratio plus grand sans s\u0026rsquo;arrêter au premier blocage. On tente 🎺, trop grosse, puis ⏰, là ça rentre, et enfin 🥏 qui ne loge pas. On obtient ainsi une valeur de 42 et un poids de 670. Mais même ainsi, on n\u0026rsquo;a pas obtenu la réponse optimale.\nPuisqu\u0026rsquo;on suppose, dans cette version \u0026ldquo;0/1\u0026rdquo; du problème qu\u0026rsquo;un objet est soit présent, soit absent (pas de fraction et pas de multiple), on peut représenter l\u0026rsquo;ensemble des possibilités par un arbre binaire.\nUne méthode sûre pour résoudre le problème consiste alors à parcourir l\u0026rsquo;arbre dans son entièreté et regarder la valeur et le poids de chaque branche complète (de la racine jusqu\u0026rsquo;à la feuille), pour choisir au final la branche la plus rémunératrice et repectant la contrainte de capacité.\nC\u0026rsquo;est la méthode par force brute.\nUn algorithme récursif possible pour faire ce travail (à chaque embranchement, on compare avec et sans l\u0026rsquo;objet) :\ndef sacadosBrute(v,p,c,i,valeur,poids): n = len(v) if i == n: if poids \u0026gt; c: return 0 else: return valeur else: valeurAvec = valeur + v[i] poidsAvec = poids + p[i] return max(sacadosBrute(v,p,c,i+1,valeur,poids),sacadosBrute(v,p,c,i+1,valeurAvec,poidsAvec)) Comme vous l\u0026rsquo;aurez deviné, la résolution du problème du sac à dos par force brute est en $O(2^n)$ où $n$ est le nombre d\u0026rsquo;objets. Donc au-delà de quelques dizaines d\u0026rsquo;objets, c\u0026rsquo;est mort\u0026hellip;\nPour améliorer les choses, on peut utiliser la méthode \u0026ldquo;séparation et évaluation\u0026rdquo; (branch and bond ou BB en anglais) qui vise à élaguer l\u0026rsquo;arbre autant que faire se peut.\nArrivé à un certain sommet de l\u0026rsquo;arbre, si l\u0026rsquo;objet se trouvant en-dessous amène à un dépassement de la capacité, cela ne sert plus à rien de continuer sa branche, alors on coupe.\nL\u0026rsquo;autre idée est d\u0026rsquo;utiliser la détermination de la valeur optimale du sac par la méthode gloutonne comme une heuristique ; si sous un sommet, la somme des valeurs des objets restant aboutit à une valeur totale inférieure à l\u0026rsquo;heuristique, on coupe.\nVoilà un code possible :\ndef sacadosBB(v,p,c,i,valeur,poids,meilleure,potentiel): nbappels += 1 n = len(v) meilleure = max(meilleure,valeur) if i == n: if poids \u0026gt; c: return 0 else: return valeur elif valeur + potentiel[i] \u0026lt; meilleure: return valeur else: valeurAvec = valeur + v[i] poidsAvec = poids + p[i] sol = sacadosBB(v,p,c,i+1,valeur,poids,meilleure,potentiel) if poidsAvec \u0026lt;= c: sol = max(sol,sacadosBB(v,p,c,i+1,valeurAvec,poidsAvec,meilleure,potentiel)) return sol Cela donne un arbre bien plus clairsemé sur notre exemple (et avec, qui plus est, une heuristique qui ne nous aide pas des masses, car très mauvaise).\nUne autre technique possible est d\u0026rsquo;utiliser la programmation dynamique qui est présentée dans la vidéo ci-dessous.\nLa programmation dynamique n\u0026rsquo;est pas au programme de TSI, mais c\u0026rsquo;est une part importante du programme des autres sections.\nUn chouïa d\u0026rsquo;apprentissage profond pour les curieux Géniale série de 4 vidéos de 3Blue1Brown sur les réseaux de neurones :\nChouette récente vidéo de ScienceEtonnante sur les IA génératives :\nadapté de cet auteur.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ngraphe issue de cette introduction assez sympa à l\u0026rsquo;apprentissage automatique.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n2-ply minimax en anglais\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_3/tp13/",
	"title": "TP 13 : intelligence artificielle",
	"tags": [],
	"description": "",
	"content": " TP 13 : Algorithmes pour l\u0026rsquo;intelligence artificielle Cliquez sur cette invitation pour récupérer le repository du TP. Présentation\nAlgorithme des k plus proches voisins Interpolation Construisons un jeu de données entâché de bruit :\nimport matplotlib.pyplot as plt plt.style.use(\u0026#39;seaborn\u0026#39;) params = {\u0026#39;figure.figsize\u0026#39;: (15, 10), \u0026#39;axes.titlesize\u0026#39;: \u0026#39;xx-large\u0026#39;, \u0026#39;figure.dpi\u0026#39; : 150} plt.rcParams.update(params) from random import random from math import pi,cos X = [] Y = [] N = 400 for i in range(N): x = pi*random()-pi/2 X.append(x) y = cos(x+0.1*(random()-0.5))+0.2*(random()-0.5) Y.append(y) Pts = list(zip(X,Y)) plt.scatter(*zip(*Pts)) # zip(*zip(L1,L2)) redonne un objet composé de L1 et L2 et * le déballe Mettez maintenant au point une fonction KNN_interp ayant pour paramètre le nombre de voisins à considérer $k$, les données d\u0026rsquo;apprentissage sous la forme d\u0026rsquo;une liste et l\u0026rsquo;abscisse de la nouvelle donnée dont on cherche l\u0026rsquo;ordonnée.\nElle retourne l\u0026rsquo;ordonnée de la nouvelle donnée en prenant la moyenne des $k$ ordonnées les plus proches. Votre fonction pourra utiliser la méthode native sort qui trie en place une liste L (la liste triée s\u0026rsquo;obtient grâce à L.sort()).\ndef KNN_interp(x: float, k: int, Pts: list) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34; préconditions: Pts est une liste de tuples contenant les coordonnées (x,y) des points d\u0026#39;entraînement postcondition: la fonction retourne la moyenne des ordonnées des k points dont l\u0026#39;abscisse est la plus proche de x \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Correction (cliquer pour afficher) def KNN_interp(x,k,Pts): Nv_Pts = [] for pt in Pts: Nv_Pts.append((abs(pt[0]-x),pt[1])) y = 0 Nv_Pts.sort() for pt in Nv_Pts[:k]: y += pt[1] y /= k return y fig, axs = plt.subplots(2, 2) K = [1,10,20,200] N = 100 X = [-pi/2+pi/N*i for i in range(N)] i = 0 for k in K: Y = [] for x in X: Y.append(KNN_interp(x,k,Pts)) axs[i//2,i%2].plot(X,Y,c=\u0026#39;r\u0026#39;,label=f\u0026#39;k = {k}\u0026#39;) axs[i//2,i%2].scatter(*zip(*Pts)) axs[i//2,i%2].legend(fontsize = 15) i += 1 plt.tight_layout() Classification La grande majorité du temps, lorsque l\u0026rsquo;on parle de la distance entre deux points, on sous-entend la distance euclidienne. Mais ce n\u0026rsquo;est pas la seule définition possible de la distance.\nDans le cas d\u0026rsquo;un monde quadrillé comme les rues des villes américaines, divisées par blocs, la distance de Manhattan est plus appropriée.\nDistance euclidienne $d_E(x,y)$ entre le points $x = (x_1,x_2,\\ldots,x_n)$ et le points $y = (y_1,y_2,\\ldots,y_n)$ : $$d_E(x,y) = \\sqrt{(y_1-x_1)^2+(y_2-x_2)^2+\\cdots+(y_n-x_n)^2}$$ Distance de Manhattan $d_M(x,y)$ entre le points $x = (x_1,x_2,\\ldots,x_n)$ et le points $y = (y_1,y_2,\\ldots,y_n)$ : $$d_M(x,y) = |y_1-x_1|+|y_2-x_2|+\\cdots+|y_n-x_n|$$ Que vaut la distance euclidienne et la distance de Manhattan entre $A$ et $B$ dans la figure ci-dessus ?\nCorrection (cliquer pour afficher) dE = 15 (hypoténuse d'un triangle reglangle de côtés 9 et 12)\ndM = 21 Existe-t-il plusieurs chemins différents ayant la même distance euclidienne ?\nCorrection (cliquer pour afficher) Plein (combien ?) Existe-t-il plusieurs chemins différents ayant la même distance de Manhattan ?\nCorrection (cliquer pour afficher) Non, un seul (le segment de droite entre A et B). On utilisera dans la suite la distance euclidienne.\nConstruisez une fonction dist prenant en paramètre les coordonnées d\u0026rsquo;un point $x$ et les coordonnées d\u0026rsquo;autres points sous la forme d\u0026rsquo;une liste et qui retourne la liste des distances entre $x$ et les $n$ autres points.\nVous assurerez par un assert que tous les points ont bien le même nombre de coordonnées.\ndef dist(x: list, Pts: list) -\u0026gt; list: \u0026#34;\u0026#34;\u0026#34; préconditions: x contient les coordonnées d\u0026#39;un point Pts est une liste de tuples ou chaque tuple contient les coordonnées d\u0026#39;un point tous les points doivent avoir le même nombre de coordonnées postcondition: la fonction doit retourner la liste des distances entre le points x et chacun des points de la liste Pts. \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Correction (cliquer pour afficher) def dist(x,Pts): n = len(x) for pt in Pts: assert n == len(pt), \"Les points n'ont pas tous le même nombre de coordonnées !\" L = [] for pt in Pts: d = 0 for i in range(n): d += (pt[i]-x[i])**2 d = d**0.5 L.append(d) return L On va se servir d\u0026rsquo;un jeu de données célèbre pour tester l\u0026rsquo;algorithme KNN : un extrait de la MNIST database contenant des images carrées (8 pixels sur 8 pixels) de chiffres écrits à la main, accompagnés de leur étiquette (le chiffre sensé être représenté sur l\u0026rsquo;image).\nfrom sklearn.datasets import load_digits digits = load_digits() n_samples = len(digits.images) data = digits.images.reshape((n_samples, -1)).astype(int) data = list(map(list,data)) labels = list(digits.target) Chacune des images a été applatie, c\u0026rsquo;est-à-dire qu\u0026rsquo;on les a réduites à une liste unidimensionnelle de 64 entiers entre 0 et 255.\ndata contient une liste de 1797 images qui sont donc chacune une liste de 64 valeurs.\nlabels contient les étiquettes correspondantes (dans le même ordre).\nConstruisez une fonction capable de transformer une liste de 64 valeurs en une matrice $8\\times 8$ :\ndef lignetomatrice(liste64: list) -\u0026gt; list: \u0026#34;\u0026#34;\u0026#34; posctconditions: la liste retournée doit être de dimensions 2 et de format 8*8 \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Correction (cliquer pour afficher) def lignetomatrice(liste64): mat = [] for j in range(64): if j%8 == 0: mat.append([]) mat[-1].append(liste64[j]) return mat Visualisons quelques unes des images grâce aux lignes suivantes et ajoutons le label comme titre à l\u0026rsquo;image :\nfig, axs = plt.subplots(2, 5) i = 0 for ax in axs.flat: image64 = data[i] image88 = lignetomatrice(image64) ax.imshow(image88, interpolation=\u0026#39;nearest\u0026#39;, cmap=\u0026#39;Greys\u0026#39;) ax.set_title(f\u0026#39;{labels[i]}\u0026#39;) ax.axis(\u0026#39;off\u0026#39;) i += 1 plt.tight_layout() On va séparé le jeu de données en deux, une moitié pour nous servir pour l\u0026rsquo;apprentissage et l\u0026rsquo;autre pour tester.\nn = len(data) data_appr = data[:n//2] labels_appr = labels[:n//2] data_test = data[n//2:] labels_test = labels[n//2:] C\u0026rsquo;est le moment de construire une fonction KNN_clas prenant en paramètre une image (liste de 64 flottants), l\u0026rsquo;entier $k$ du nombre de voisins à considérer, la liste des données servant à l\u0026rsquo;apprentissage et la liste des étiquettes (dans le même ordre) et qui retourne un entier entre 0 et 9 correspondant au mode (étiquette la plus représentée) des k plus proches voisins.\nVotre fonction devra utiliser la fonction dist.\nPour calculer le mode d\u0026rsquo;une liste L, vous utiliserez mode du module statistics.\nAide : une liste de listes ou de tuples est triée en fonction du premier élément de la sous-liste ou du tuple.\nfrom scipy import stats def KNN_class(X: list, k: int, Appr: list, Etiq: list) -\u0026gt; list: \u0026#34;\u0026#34;\u0026#34; préconditions: X est l\u0026#39;image dont on veut déterminer l\u0026#39;étiquette Appr est l\u0026#39;ensemble des données d\u0026#39;apprentissage, c\u0026#39;est une liste de listes, chacune de ces liste correspond à une image Etiq est une liste d\u0026#39;entiers correspondant aux étiquettes de chaque image. postconditions: la fonction doit retourner l\u0026#39;étiquette la plus fréquente (mode) parmi les k images les plus proches \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Correction (cliquer pour afficher) import statistics as stat def KNN_class(X,k,Appr,Etiq): L = dist(X,Appr) LplusEtiq = [] for i in range(len(L)): LplusEtiq.append((L[i],Etiq[i])) LplusEtiq.sort() EtiqFin = [] for e in LplusEtiq[:k]: EtiqFin.append(e[1]) return stat.mode(EtiqFin) Validation La matrice de confusion va nous aider à évaluer notre algorithme de classification.\nCommençons par construire une matrice carrée $10\\times 10$ dont les lignes correspondent aux étiquettes réelles et les colonnes aux étiquettes prédites.\nOn va prendre k = 8 (comme ça, au hasard\u0026hellip;).\nRq : la cellule met environ 25 s à s\u0026rsquo;exécuter.\nM = [[0 for j in range(10)] for i in range(10)] k = 8 for m in range(len(data_test)) : i = labels_test[m] j = KNN_class(data_test[m],k,data_appr,labels_appr) M[i][j] += 1 import seaborn as sns s = sns.heatmap(M,annot=True) s.set(xlabel=\u0026#39;Chiffres prédits\u0026#39;, ylabel=\u0026#39;Chiffres réels\u0026#39;) s.xaxis.tick_top() s.xaxis.set_label_position(\u0026#39;top\u0026#39;) À partir de cette matrice générale, construisez la matrice de confusion pour le chiffre 3. La matrice comprend les valeurs suivantes :\nvrais positifs VP vrais négatifs VN faux positifs FP faux négatifs FN # La matrice de confusion Mc3 devra avoir la forme [[VP,FP],[FN,VN]] # Les valeurs VP,FP,FN,VN sont des entiers correspondant aux effectifs dans chaque catégorie # Attention : vos calculs doivent pouvoir s\u0026#39;adapter automatiquement à une autre matrice M !! ### VOTRE CODE Mc3 = [[VP,FN],[FP,VN]] Correction (cliquer pour afficher) # VP : chiffres prédits comme 3 et qui sont des 3 VP = M[3][3] # FP : chiffre qui sont prédits comme des 3 mais qui n'en sont pas FP = sum([M[i][3] for i in range(len(M)) if i != 3]) # VN : chiffres prédits comme autre chose que des 3 et qui sont bien autre chose VN = sum([sum([M[i][j] for j in range(len(M)) if j != 3]) for i in range(len(M)) if i!= 3]) # FN : chiffres qui sont prédits comme autre chose que des 3 mais qui en sont FN = sum([sum([M[i][j] for j in range(len(M)) if j != 3]) for i in range(len(M)) if i== 3]) n = len(data_test) labels = [[f\u0026#39;VP\\n{VP}\\n{VP/n:.1%}\u0026#39;,f\u0026#39;FN\\n{FN}\\n{FN/n:.1%}\u0026#39;],[f\u0026#39;FP\\n{FP}\\n{FP/n:.1%}\u0026#39;,f\u0026#39;VN\\n{VN}\\n{VN/n:.1%}\u0026#39;]] x_axis_labels = [\u0026#39;Positif\u0026#39;,\u0026#39;Négatif\u0026#39;] y_axis_labels = [\u0026#39;Positif\u0026#39;,\u0026#39;Négatif\u0026#39;] s = sns.heatmap(Mc3,annot=labels,fmt=\u0026#39;\u0026#39;,annot_kws={\u0026#34;size\u0026#34;: 18}) s.set_xticklabels(x_axis_labels, fontsize=10) s.set_yticklabels(y_axis_labels, fontsize=10) s.xaxis.tick_top() s.xaxis.set_label_position(\u0026#39;top\u0026#39;) s.set_xlabel(\u0026#39;Chiffres 3 prédits\u0026#39;, fontsize=15) s.set_ylabel(\u0026#39;Chiffres 3 réels\u0026#39;, fontsize=15) Que peut-on dire des talents de classificateur de notre algorithme pour ce qui est du chiffre 4 (attention, on ne parle plus du chiffre 3) :\na : il est plus sensible que précis (rappel \u0026gt; précision) b : il est plus précis que sensible (précision \u0026gt; rappel) Correction (cliquer pour afficher) La matrice de confusion nous montre que\u0026nbsp;: Parmi les 86 \"4\" prédits, tous sont bien des 4 $\\Rightarrow$ précision de 100% Parmi tous les vrais \"4\" (92), 8 sont prédits comme étant autre chose (à chaque fois des 9...) $\\Rightarrow$ rappel de 87,0% Donc pour le chiffre 4, l'algo est plus précis que sensible. Calculez enfin l\u0026rsquo;exactitude totale de l\u0026rsquo;algorithme sur les 899 images testées.\nCorrection (cliquer pour afficher) On obtient l'exactitude en sommant les éléments dans la diagonale\u0026nbsp;:\nval2 = sum([M[i][i] for i in range(len(M))])/len(datatest)\nOn obtient 95,4%. Des librairies dédiées contenant des algorithmes optimisés permettent de grandement accélérer les choses.\nIci, on va utiliser scikit-learn qui s\u0026rsquo;appuie grandement sur numpy, lui-même principalement écrit en C.\nfrom sklearn.neighbors import KNeighborsClassifier model = KNeighborsClassifier(n_neighbors=8) # n_neighbors correspond à la valeur k model.fit(data_appr, labels_appr) predictions = model.predict(data_test) # predictions est la liste des prédictions pour chaque image dans data_test M = [[0 for j in range(10)] for i in range(10)] for m in range(len(data_test)) : i = labels_test[m] j = predictions[m] M[i][j] += 1 sns.heatmap(M,annot=True) Commentaire (cliquer pour afficher) Les petites différences observées viennent de l'algorithme utilisé pour donner le mode statistique de la liste des chiffres prédits. Quel résultat donne-t-il quand il y a plusieurs modes possibles en concurrence (deux étiquettes majoritaires présentes autant de fois l'une que l'autre par exemple)\u0026nbsp;? Suivant son choix, les résultats diffèrent. Et visiblement le mode du module statistics ne fait pas les mêmes choix que le mode utilisé par scikit-learn. Cherchons maintenant la valeur optimale de k, celle qui optimise l\u0026rsquo;exactitude.\nPour cela, et par souci de rapidité, on va utiliser l\u0026rsquo;implémentation de la librairie scikit-learn ci-dessus.\nn = len(data_test) K = [i for i in range(1,50)] Exa = [] for k in range(1,50): model = KNeighborsClassifier(n_neighbors=k) model.fit(data_appr, labels_appr) predictions = model.predict(data_test) M = [[0 for j in range(10)] for i in range(10)] for m in range(len(data_test)): i = labels_test[m] j = predictions[m] M[i][j] += 1 Exa.append(sum([M[i][i] for i in range(10)])/n) plt.plot(K,Exa) plt.xlabel(\u0026#39;k\u0026#39;) plt.ylabel(\u0026#39;exactitude\u0026#39;) Correction (cliquer pour afficher) $k=3$ optimise l'exactitude. Algorithme des k moyennes from random import random import matplotlib.pyplot as plt plt.style.use(\u0026#39;seaborn\u0026#39;) params = {\u0026#39;figure.figsize\u0026#39;: (15, 10), \u0026#39;axes.titlesize\u0026#39;: \u0026#39;xx-large\u0026#39;, \u0026#39;figure.dpi\u0026#39; : 150} plt.rcParams.update(params) def kmoyennes(k: int, data: list) -\u0026gt; list: n = len(data) dim = len(data[0]) itermax = 100 itgenmax = 10 assert n \u0026gt; k, \u0026#34;plus de clusters que de points de données...\u0026#34; itgen = 0 distancemin = float(\u0026#39;inf\u0026#39;) sauvegarde_presente = False while itgen \u0026lt; itgenmax: test = True iteration = 1 # initialisation aléatoire des k centres Centres = initialisation(k,data,dim) # Copie des positions de ces centres pour tester plus loin s\u0026#39;ils ont bougé Centres_old = [] for e in Centres: Centres_old.append(e[:]) # on utilise le slicing pour créer un nouvel objet et pas seulement une référence ### coeur de l\u0026#39;algorithme : while test and (iteration \u0026lt; itermax): # calcul des distance entre un centre et tous les points de données, pour chaque centre Dist = [] for i in range(k): Dist.append(dist(Centres[i],data)) # attribution des données au centre le plus proche Clusters = attribution(k,data,Dist) # déplacement du centre au milieu de son cluster deplacement(k,Clusters,Centres,data) # si les clusters n\u0026#39;ont pas bougé, test reste faux et on sort du while test = False for i in range(k): if max(dist(Centres[i],[Centres_old[i]])) \u0026gt; 1e-6*max(Dist[i]): test = True for i in range(k): Centres_old[i] = Centres[i][:] iteration += 1 # on recommence plusieurs fois en calculant à chaque fois l\u0026#39;inertie # pour ne garder au final que l\u0026#39;itération avec l\u0026#39;inertie la plus petite # le but est de se prémunir d\u0026#39;un blocage sur une solution suboptimale itgen += 1 distance = evaluation(k,Clusters,Centres,data) if distance \u0026lt; distancemin: distancemin = distance Clusters_save = Clusters[:] # meilleurs Clusters jusque-là Centres_save = [] for i in range(k): Centres_save.append(Centres[i][:]) # meilleurs Centres jusque-là sauvegarde_presente = True if sauvegarde_presente: Clusters = Clusters_save Centres = Centres_save return Clusters, Centres def initialisation(k: int, data: list, dim : int) -\u0026gt; list: Centres = [] Ampl = [] for d in range(dim): MA = max([data[i][d] for i in range(len(data))]) MI = min([data[i][d] for i in range(len(data))]) Ampl.append((MI,MA)) for i in range(k): Centres.append([]) for d in range(dim): Centres[i].append(Ampl[d][0]+(Ampl[d][1]-Ampl[d][0])*random()) return Centres def evaluation(k: int, Clusters: list, Centres: list, data: list) -\u0026gt; float: n = len(data) distance = 0 for i in range(k): data_clusters = [data[j] for j in range(n) if Clusters[j] == i] distance += sum(dist(Centres[i],data_clusters)) return distance Il manque encore la définition de 2 fonctions utilisées dans kmoyennes.\nCommençons par écrire la fonction permettant d\u0026rsquo;attribuer un centre à chaque point de données.\ndef attribution(k: int, data: list, Dist: list) -\u0026gt; list: \u0026#34;\u0026#34;\u0026#34; préconditions: Dist est une liste à deux dimensions contenant k sous-listes chaque sous-liste contient les distances de chaque point de data à un des centres Une sous-liste correspond à un centre postconditions: la fonction doit retourner (sous forme de liste) le numéro de cluster (de 0 à k-1) associé à chaque point de data Si le premier point appartient au cluster 1, le deuxième au cluster 3, le troisème au cluster 0, la liste Clusters commencera ainsi [1,3,0,...] \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Correction (cliquer pour afficher) def attribution(k,data,Dist): Cluster = [] n = len(data) for m in range(n): imin = 0 mini = Dist[0][m] for i in range(1,k): if Dist[i][m] \u003c mini: mini = Dist[i][m] imin = i Cluster.append(imin) return Cluster Écrivons maintenant la fonction déplacement qui modifie en place la position des k centres.\ndef deplacement(k: int, Clusters: list, Centres: list, data: list) -\u0026gt; list: \u0026#34;\u0026#34;\u0026#34; préconditions: Clusters est une liste du numéro de cluster associé au point à la même position dans data Centres doit être mutable postconditions: en sortie, les positions des centres sont mis à jour et correspondent aux barycentres des points qui leur sont attribués \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Correction (cliquer pour afficher) def deplacement(k,Clusters,Centres,data): dim = len(data[0]) DataCluster = [] n = len(data) for i in range(k): DataCluster.append([]) for i in range(n): DataCluster[Clusters[i]].append(data[i]) for i in range(k): lcluster = len(DataCluster[i]) if lcluster != 0: for l in range(dim): moy = 0 for j in range(lcluster): moy += DataCluster[i][j][l] moy /= lcluster Centres[i][l] = moy Testons l\u0026rsquo;algorithme sur des points dispersés artificiellement en 5 groupes.\nfrom random import random n = 10 X1 = [-15+(random()-0.5)*15 for i in range(n)] Y1 = [8+(random()-0.5)*12 for i in range(n)] X2 = [0+(random()-0.5)*12 for i in range(n)] Y2 = [-7+(random()-0.5)*15 for i in range(n)] X3 = [15+(random()-0.5)*12 for i in range(n)] Y3 = [10+(random()-0.5)*18 for i in range(n)] X4 = [30+(random()-0.5)*15 for i in range(n)] Y4 = [-10+(random()-0.5)*12 for i in range(n)] X5 = [45+(random()-0.5)*13 for i in range(n)] Y5 = [8+(random()-0.5)*12 for i in range(n)] data = list(zip(X1+X2+X3+X4+X5,Y1+Y2+Y3+Y4+Y5)) fig,ax = plt.subplots() ax.axis(\u0026#39;equal\u0026#39;) ax.scatter(X1+X2+X3+X4+X5,Y1+Y2+Y3+Y4+Y5,s=100) ax.set_title(\u0026#34;Les données\u0026#34;) fig,ax = plt.subplots() ax.axis(\u0026#39;equal\u0026#39;) k = 5 clusters, centres = kmoyennes(k,data) Couleurs = [\u0026#34;#1DB100\u0026#34;,\u0026#34;#F8BA00\u0026#34;,\u0026#34;#EF5FA7\u0026#34;,\u0026#34;#00A89D\u0026#34;,\u0026#34;#FF644E\u0026#34;] for i in range(len(data)): ax.scatter(*data[i],c=Couleurs[clusters[i]],s=100) for i in range(k) : ax.scatter(*centres[i],c=Couleurs[i],s=200,marker=\u0026#39;*\u0026#39;) ax.set_title(\u0026#34;Partition en 5 clusters grâce à k-moyennes\u0026#34;) Traçons la courbe représentant la somme des distances entre un centre et les points de son cluster en fonction de k.\nK = [i for i in range(1,20)] V = [] n = len(data) for k in K: clusters, centres = kmoyennes(k,data) v = evaluation(k,clusters,centres,data) V.append(v) plt.xticks([k for k in K]) plt.plot(K,V) plt.xlabel(\u0026#39;k\u0026#39;) plt.ylabel(\u0026#39;distance\u0026#39;) Si vous passez la valeur de itgenmax à 1 dans le code de kmoyennes, on obtient une courbe bien moins monotone. Le vérifier.\nVoyez-vous pourquoi ?\nCorrection (cliquer pour afficher) itgenmax correspond au nombre de fois que l'algorithme est relancé sachant qu'au final, on ne garde que la meilleure solution (celle minimisant l'inertie).\nSans répétition, la probabilité, pour un k donné, de se retrouver bloquer sur une solution suboptimale (augmentant l'inertie) est donc bien plus grande. Familiarisons-nous maintenant justement avec l\u0026rsquo;implémentation de scikit-learn et vérifions qu\u0026rsquo;elle fait bien le même boulot (mais bien plus vite).\nfrom sklearn.cluster import KMeans fig,ax = plt.subplots() ax.axis(\u0026#39;equal\u0026#39;) k = 5 kmeans_model = KMeans(n_clusters = k) cluster_labels = kmeans_model.fit_predict(data) # donne la liste ordonnée du cluster auquel appartient chaque point de données centres = kmeans_model.cluster_centers_ Couleurs = [\u0026#34;#1DB100\u0026#34;,\u0026#34;#F8BA00\u0026#34;,\u0026#34;#EF5FA7\u0026#34;,\u0026#34;#00A89D\u0026#34;,\u0026#34;#FF644E\u0026#34;] for i in range(len(data)) : ax.scatter(*data[i],c=Couleurs[cluster_labels[i]],s=100) for i in range(k) : ax.scatter(*centres[i],c=Couleurs[i],s=200,marker=\u0026#39;*\u0026#39;) La grande popularité de Python aujourd\u0026rsquo;hui dans le monde scientifique et professionnel s\u0026rsquo;explique en grande partie par ses librairies. En peu de lignes, elles permettent d\u0026rsquo;obtenir très rapidement des résultats de bonne tenue.\nimport seaborn as sns import pandas as pd import numpy as np n = 5000 # Simulation des données x1 = np.random.normal(-4, 0.8, n) y1 = np.random.normal(-2, 1.2, n) x2 = np.random.normal(0, 0.9, n) y2 = np.random.normal(0, 0.9, n) x3 = np.random.normal(2, 1.2, n) y3 = np.random.normal(4, 0.5, n) x4 = np.random.normal(1.5, 0.3, n) y4 = np.random.normal(-6, 0.3, n) x5 = np.random.normal(3.5, 0.3, n) y5 = np.random.normal(-4, 0.4, n) data = list(zip(np.concatenate((x1,x2,x3,x4,x5)),np.concatenate((y1,y2,y3,y4,y5)))) k = 5 kmeans_model = KMeans(n_clusters = k) cluster_labels = kmeans_model.fit_predict(data) centres = kmeans_model.cluster_centers_ df = pd.DataFrame(data,columns=[\u0026#39;x\u0026#39;,\u0026#39;y\u0026#39;]) df[\u0026#39;cluster\u0026#39;] = cluster_labels sns.scatterplot(x=\u0026#39;x\u0026#39;,y=\u0026#39;y\u0026#39;,hue=\u0026#39;cluster\u0026#39;,data=df) K = [i for i in range(1,20)] V = [] n = len(data) for k in K : kmeans_model = KMeans(n_clusters = k) kmeans_model.fit_predict(data) V.append(kmeans_model.inertia_) plt.xticks([k for k in K]) plt.plot(K,V) plt.xlabel(\u0026#39;k\u0026#39;,fontsize=15) plt.ylabel(\u0026#39;inertie\u0026#39;,fontsize=15) Dans un TP du premier semestre, on s\u0026rsquo;était amusé à downgrader le nombre de couleurs d\u0026rsquo;une image en passant d\u0026rsquo;un codage de 24 bits à 6 bits pour la profondeur des couleurs.\nOn va essayer d\u0026rsquo;utiliser k-moyennes pour faire un travail ressemblant, mais plus fin : on va chosir un nombre de couleurs et laisser k-moyennes trouver lui-même les couleurs les plus adaptées et créer le partitionnement.\nLes couleurs vont être données par les coordonnées des k centres !\nCette opération s\u0026rsquo;appelle segmentation d\u0026rsquo;image et il s\u0026rsquo;agit là plus précisément d\u0026rsquo;une segmentation par la couleur. C\u0026rsquo;est une technique utilisée en diagnostique médical ou pour l\u0026rsquo;analyse d\u0026rsquo;images satellites (pour déterminer, par exemple, la proportion de forêt dans une région).\nfrom PIL import Image import urllib.request from IPython.display import display import matplotlib.pyplot as plt import numpy as np urllib.request.urlretrieve(\u0026#39;https://webb.nasa.gov/content/webbLaunch/assets/images/firstImages/image5-StarForming/STSCI-J-p22031a-1100px.jpg\u0026#39;, \u0026#39;webb\u0026#39;) image_webb = np.array(Image.open(\u0026#39;webb\u0026#39;)) webb = Image.fromarray(image_webb) display(webb) h,l,c = image_webb.shape print(f\u0026#39;hauteur : {h} px ; largeur : {l} px\u0026#39;) hauteur : 1200 px ; largeur : 1200 px\nOn transforme d\u0026rsquo;abord l\u0026rsquo;image bidimensionnelle en un tableau à une dimension contenant hauteur$\\times$largeur triplets. On a ainsi un long vecteur de points tridimensionnels.\nEnsuite, on applique l\u0026rsquo;algorithme (celui de scikit-learn vu le nombre de points) et on récupère les centres.\nRq : mon vieil ordinateur met environ une heure avec l\u0026rsquo;algo maison\u0026hellip;\nimage_1D = image_webb.reshape(h*l,c) k = 10 kmeans_model = KMeans(n_clusters = k) cluster_labels = kmeans_model.fit_predict(image_1D) centres = kmeans_model.cluster_centers_ print(centres) [[ 43.72023216 76.8437927 139.7439622 ]\n\u0026nbsp;[ 65.2464465 40.79341585 42.47060682]\n\u0026nbsp;[132.70876194 76.59044699 62.2814825 ]\n\u0026nbsp;[186.45279371 137.82358444 113.88598154]\n\u0026nbsp;[ 35.02064311 48.64635552 93.31092396]\n\u0026nbsp;[ 99.94155291 58.02521904 52.17321541]\n\u0026nbsp;[ 89.34394389 119.63315649 172.00437611]\n\u0026nbsp;[ 27.29924084 25.17800936 34.18811588]\n\u0026nbsp;[209.40854976 195.09625895 200.31127399]\n\u0026nbsp;[155.8400736 105.64875463 88.45913989]]\nPour faire passer les coordonnées de ces centres pour des couleurs, on convertit les flottants en entier :\ncouleurs = kmeans_model.cluster_centers_.round(0).astype(np.uint8) print(couleurs) [[ 44 77 140]\n\u0026nbsp;[ 65 41 42]\n\u0026nbsp;[133 77 62]\n\u0026nbsp;[186 138 114]\n\u0026nbsp;[ 35 49 93]\n\u0026nbsp;[100 58 52]\n\u0026nbsp;[ 89 120 172]\n\u0026nbsp;[ 27 25 34]\n\u0026nbsp;[209 195 200]\n\u0026nbsp;[156 106 88]]\nPlus qu\u0026rsquo;à former l\u0026rsquo;image finale. numpy permet de faire ça en une ligne\u0026hellip;\nimage_webb_clust = np.reshape(couleurs[cluster_labels],(h,l,c)) webbClus = Image.fromarray(image_webb_clust) display(webbClus) Vous allez faire le même travail sur la petite image suivante, mais sans utiliser scikit-learn (on reste avec notre lent kmoyennes) ni numpy (seulement des braves listes python).\nimage_2D = [] for i in range(64): image_2D.append([]) for j in range(64): image_2D[i].append((min(255,64+(i+j)*2),255-i*3,255-j*3)) plt.figure(figsize=(3,3)) plt.imshow(image_2D) plt.axis(\u0026#39;off\u0026#39;) image_1D = [] for i in range(64): for j in range(64): image_1D.append(image_2D[i][j]) Vous devez obtenir une liste bidimensionnelle contenant les valeurs des pixels de l\u0026rsquo;image segmentée en 8.\nVous appelerez cette liste image_2D_seg4.\nÀ la suite de votre cellule réponse, vous pourrez tester votre liste en affichant l\u0026rsquo;image qu\u0026rsquo;elle contient. Si vous obtenez 8 partitions, c\u0026rsquo;est gagner (n\u0026rsquo;hésitez pas à relancer l\u0026rsquo;algo car il peut se bloquer sur un découpage suboptimal contenant moins de parties).\nCorrection (cliquer pour afficher) k = 8 clusters,centres = kmoyennes(k,image_1D) for i in range(k): for j in range(3): centres[i][j] = int(centres[i][j]) for i in range(len(image_1D)): image_1D[i] = centres[clusters[i]] image_2D_seg4 = [] i1D = 0 for i in range(64): image_2D_seg4.append([]) for j in range(64): image_2D_seg4[i].append(image_1D[i1D]) i1D += 1 Jeux d\u0026rsquo;accessibilité à deux joueurs La démonstration du cours sur les graphes bipartis donne une idée d\u0026rsquo;algorithme pour les détecter si le graphe est non orienté :\non explore un graphe en partant d\u0026rsquo;un sommet grâce au parcours en largeur qui progrese couche par couche, on dresse un inventaire des distances entre le sommet de départ et les sommets explorés grâce à un dictionnaire, à chaque ajout d\u0026rsquo;un sommet à la file, on enregistre sa distance dans le dictionnaire en ajoutant 1 à la distance de son prédécesseur.\nPour prouver qu\u0026rsquo;un graphe n\u0026rsquo;est pas biparti, il suffit de trouver au moins un cycle de longueur impair. Or la présence d\u0026rsquo;un tel cycle impose de tomber sur un sommet déjà exploré avec la même distance au sommet de départ que son prédécesseur (s\u0026rsquo;il n\u0026rsquo;y a pas de cycle impair, cela n\u0026rsquo;arrive jamais).\nCompléter la fonction suivante pour qu\u0026rsquo;elle retourne vrai si le graphe est biparti et faux sinon.\nfrom collections import deque def testBipartite(G,depart): \u0026#34;\u0026#34;\u0026#34; precondition: le graphe G doit être non orienté postconditions: le dictionnaire Vus dit si un sommet a été exploré ou non le dictionnaire Distance donne la distance de chaque sommet ajouté par rapport au sommet de départ la fonction retourne Vrai si on tombe sur un sommet déjà exploré dont la distance au sommet de départ est la même que celle de son prédécesseur et Faux si aucun tel cas n\u0026#39;est rencontré. \u0026#34;\u0026#34;\u0026#34; Vus = {s : False for s in G} Distance = {s : 0 for s in G} file = deque() file.append(depart) # VOTRE CODE Correction (cliquer pour afficher) def testBipartite(G,depart): Vus = {s : False for s in G} Distance = {s : 0 for s in G} file = deque() file.append(depart) while file: sommet = file.popleft() if not Vus[sommet]: Vus[sommet] = True for s in G[sommet]: if Vus[s]: if Distance[s] == Distance[sommet]: return False Distance[s] = Distance[sommet] + 1 file.append(s) return True # Deux graphes pour tester votre algorithme Ga = {\u0026#39;A\u0026#39;: [\u0026#39;B\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;B\u0026#39;: [\u0026#39;A\u0026#39;,\u0026#39;C\u0026#39;,\u0026#39;D\u0026#39;,\u0026#39;F\u0026#39;], \u0026#39;C\u0026#39;: [\u0026#39;B\u0026#39;], \u0026#39;D\u0026#39;: [\u0026#39;B\u0026#39;], \u0026#39;E\u0026#39;: [\u0026#39;A\u0026#39;,\u0026#39;F\u0026#39;], \u0026#39;F\u0026#39;: [\u0026#39;B\u0026#39;,\u0026#39;E\u0026#39;] } Gb = {\u0026#39;A\u0026#39;: [\u0026#39;B\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;B\u0026#39;: [\u0026#39;A\u0026#39;,\u0026#39;C\u0026#39;,\u0026#39;D\u0026#39;,\u0026#39;E\u0026#39;,\u0026#39;F\u0026#39;], \u0026#39;C\u0026#39;: [\u0026#39;B\u0026#39;], \u0026#39;D\u0026#39;: [\u0026#39;B\u0026#39;], \u0026#39;E\u0026#39;: [\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;,\u0026#39;F\u0026#39;], \u0026#39;F\u0026#39;: [\u0026#39;B\u0026#39;,\u0026#39;E\u0026#39;] } Le graphe suivant est-il bipati ?\nCorrection (cliquer pour afficher) Appelons Gc le graphe dessiné. Gc = {0:[1,6,8,9], 1:[0,3,4,5], 2:[3,5,7], 3:[1,2,9], 4:[1,8,9], 5:[1,2,9], 6:[0,7], 7:[2,6,8,9], 8:[0,4,7], 9:[0,3,4,5,7], } print(testBipartite(Ga,'A')) print(testBipartite(Gb,'A')) print(testBipartite(Gc,1)) True\nFalse\nTrue\nOn peut prouver que Ga et Gc sont bipartis en les 2-coloriant (il ne faut pas que 2 sommets adjacents aient la même couleur) alors que c'est impossible pour Gb\u0026nbsp;: Revenons maintenant sur la variante du jeu de Nim présenté dans le cours.\nCommentaire (cliquer pour afficher) Ce notebook Colab reprend et détaille la partie qui suit du TP. Construire le graphe correspondant à un paquet de 10 allumettes au départ.\nVous appelerez ce graphe G1.\nCorrection (cliquer pour afficher) La construction suivante est récursive\u0026nbsp;: pour chaque sommet, on construit la liste de ses successeurs puis on appelle la fonction sur chacun d'eux. Le cas de base correspond à l'absence de successeur possible. Depart = (10,9,0) # 0 pour Eve def constrG(S,G): G[S] = [] if S[0] == 0: return i = 1 while i \u003c= S[1] and S[0]-i \u003e= 0: if 2*i \u003c S[0]-i: nvSommet = (S[0]-i,2*i,(1+S[2])%2) else: nvSommet = (S[0]-i,S[0]-i,(1+S[2])%2) G[S].append(nvSommet) i += 1 for s in G[S]: constrG(s,G) G1 = {} constrG(Depart,G1) Eve est représentée par les ronds bleus dans la représentation suivante.\nimport networkx as nx import matplotlib.pyplot as plt g = nx.DiGraph(G1) edge_colors = [\u0026#39;#0076BA\u0026#39; if e[0][2]==0 else \u0026#39;#CB297B\u0026#39; for e in g.edges] Eve_nodes = [s for s in g.nodes if s[2]==0] Adam_nodes = list(set(g.nodes) - set(Eve_nodes)) Eve_edges = [e for e in g.edges if e[0][2]==0] Adam_edges = list(set(g.edges) - set(Eve_edges)) pos = nx.spring_layout(g,k=1,iterations=5) shift = 0.06 pos_higher = {k:(v[0],v[1]+shift) if v[1]\u0026gt;0 else (v[0],v[1]-shift*1.1) for k,v in pos.items()} fig, ax = plt.subplots(figsize=(15,10)) nx.draw_networkx_nodes(g, pos, nodelist=Eve_nodes, node_color=\u0026#39;#0076BA\u0026#39;, node_shape=\u0026#39;o\u0026#39;, linewidths=0) nx.draw_networkx_nodes(g, pos, nodelist=Adam_nodes, node_color=\u0026#39;#CB297B\u0026#39;, node_shape=\u0026#39;s\u0026#39;, linewidths=0) nx.draw_networkx_edges(g, pos, edgelist=Eve_edges, edge_color=\u0026#39;#0076BA\u0026#39;, arrows=True, arrowsize=20, connectionstyle=\u0026#39;arc3,rad=0.2\u0026#39;) nx.draw_networkx_edges(g, pos, edgelist=Adam_edges, edge_color=\u0026#39;#CB297B\u0026#39;, arrows=True, arrowsize=20, connectionstyle=\u0026#39;arc3,rad=0.2\u0026#39;) nx.draw_networkx_labels(g, pos = pos_higher, font_color=\u0026#39;#000000\u0026#39;, font_size=10, font_weight=\u0026#39;bold\u0026#39;) ax.set_facecolor(\u0026#39;w\u0026#39;) ax.axis(\u0026#39;off\u0026#39;) plt.show() Reprenons le code du cours visant à assembler l\u0026rsquo;attracteur du jeu pour Eve.\ndef attracteur(G: dict, F: list) -\u0026gt; list: \u0026#34;\u0026#34;\u0026#34; préconditions: G est est un graphe sous forme de liste d\u0026#39;adjacence implémentée par un dictionnaire F est la liste des sommets gagnants pour le joueur 1 postcondition: la fonction retourne l\u0026#39;attracteur de F pour le joueur 1 sous forme d\u0026#39;un dictionnaire dont les clés sont les sommets de G et les valeurs True ou False suivant que le sommet appartienne ou non à l\u0026#39;attracteur \u0026#34;\u0026#34;\u0026#34; Pred = inverseGraphe(G) n = {s:len(G[s]) for s in G} Attr = {s:False for s in G} for sommet in F: Joueur1 = True propage(sommet,Joueur1,Attr,Pred,n) return Attr def propage(sommet,Joueur1,Attr,Pred,n): if Attr[sommet]: return Attr[sommet] = True for s in Pred[sommet]: n[s] -= 1 if Joueur1 or (n[s] == 0): propage(s,not Joueur1,Attr,Pred,n) Il manque la définition de la fonction inverseGraphe qui retourne la liste d\u0026rsquo;adjacence du graphe G dont on aurait inversé chacun des arcs.\nÀ vous de jouer\u0026hellip;\ndef inverseGraphe(G: dict) -\u0026gt; dict: \u0026#34;\u0026#34;\u0026#34; précondition: G est la liste d\u0026#39;adjacence (sous forme de dictionnaire) d\u0026#39;un graphe orienté \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Correction (cliquer pour afficher) def inverseGraphe(G): inv = {s:[] for s in G} for pred in G: for succ in G[pred]: inv[succ].append(pred) return inv Fabriquons l\u0026rsquo;attracteur de G1.\nAttr = attracteur(G1,[(0,0,1)]) Dans la représentation ci-dessous, l\u0026rsquo;attracteur est en orange.\ng = nx.DiGraph(G1) Eve_nodes = [s for s in g.nodes if s[2]==0] Eve_Attr_nodes = [s for s in Eve_nodes if Attr[s]==True] Eve_piege_nodes = list(set(Eve_nodes) - set(Eve_Attr_nodes)) Adam_nodes = list(set(g.nodes) - set(Eve_nodes)) Adam_attr_nodes = [s for s in Adam_nodes if Attr[s]==True] Adam_piege_nodes = list(set(Adam_nodes) - set(Adam_attr_nodes)) Attr_edges = [e for e in g.edges if Attr[e[0]]==True and Attr[e[1]]==True] Piege_edges = list(set(g.edges) - set(Attr_edges)) fig, ax = plt.subplots(figsize=(15,10)) nx.draw_networkx_nodes(g, pos, nodelist=Eve_piege_nodes, node_color=\u0026#39;#56C1FF\u0026#39;, node_shape=\u0026#39;o\u0026#39;, linewidths=0) nx.draw_networkx_nodes(g, pos, nodelist=Eve_Attr_nodes, node_color=\u0026#39;#FF9300\u0026#39;, node_shape=\u0026#39;o\u0026#39;, linewidths=0) nx.draw_networkx_nodes(g, pos, nodelist=Adam_piege_nodes, node_color=\u0026#39;#56C1FF\u0026#39;, node_shape=\u0026#39;s\u0026#39;, linewidths=0) nx.draw_networkx_nodes(g, pos, nodelist=Adam_attr_nodes, node_color=\u0026#39;#FF9300\u0026#39;, node_shape=\u0026#39;s\u0026#39;, linewidths=0) nx.draw_networkx_edges(g, pos, edgelist=Attr_edges, edge_color=\u0026#39;#FF9300\u0026#39;, arrows=True, arrowsize=20, connectionstyle=\u0026#39;arc3,rad=0.2\u0026#39;) nx.draw_networkx_edges(g, pos, edgelist=Piege_edges, edge_color=\u0026#39;#56C1FF\u0026#39;, arrows=True, arrowsize=20, connectionstyle=\u0026#39;arc3,rad=0.2\u0026#39;) nx.draw_networkx_labels(g, pos = pos_higher, font_color=\u0026#39;#000000\u0026#39;, font_size=10, font_weight=\u0026#39;bold\u0026#39;) ax.set_facecolor(\u0026#39;w\u0026#39;) ax.axis(\u0026#39;off\u0026#39;) plt.show() def strategie(G,depart,F,attracteur): Joueur1 = True if not attracteur[depart]: print(\u0026#34;Pas de stratégie gagnante possible pour le joueur1 depuis cet endroit :(\u0026#34;) return False S = depart while S not in F: if Joueur1: for s in G[S]: if attracteur[s]: print(f\u0026#34;Coup gagnant : {s}.\u0026#34;) S = s break else: print(\u0026#34;Qu\u0026#39;a joué l\u0026#39;adversaire ?\u0026#34;) for i,s in enumerate(G[S],1): print(f\u0026#34;{i} : {s}\u0026#34;) S = G[S][int(input(\u0026#34;Choisir : \u0026#34;))-1] Joueur1 = not Joueur1 print(\u0026#34;C\u0026#39;est gagné !\u0026#34;) En utilisant le programme ci-dessus, répondre à la question suivante :\nsi Adam joue (6,4,0) à son premier coup, sur quel sommet doit se déplacer Eve pour continuer à avoir l\u0026rsquo;avantage ?\nCorrection (cliquer pour afficher) (5,2,1) Créez un graphe G2 pour répondre à cette question :\nLa position de départ $(21,5,0)$ est-elle gagnante ?\nCorrection (cliquer pour afficher) G2 = {} constrG((21,5,0),G2) strategie(G2,(21,5,0),[(0,0,1)],attracteur(G2,[(0,0,1)])) S'affiche alors\u0026nbsp;:\nPas de stratégie gagnante possible pour le joueur1 depuis cet endroit :( Rq : on peut montrer que le joueur 1 aura toujours une stratégie gagnante si la position de départ (le nombre initial d\u0026rsquo;allumettes) ne se trouve pas dans la suite de Fibonacci.\nPassons maintenant au vrai jeu de Nim, dans sa variante misère, popularisé dans le film d\u0026rsquo;Alain Resnais \u0026ldquo;L\u0026rsquo;Année dernière à Marienbad\u0026rdquo;.\nOn a 4 tas composés au départ de 1, 3, 5 et 7 allumettes. Chaque joueur peut, l\u0026rsquo;un après l\u0026rsquo;autre, prendre autant d\u0026rsquo;allumettes qu\u0026rsquo;il le veut, mais dans un tas seulement.\nLa variante misère impose que celui qui prend la dernière allumette ait perdu !\nComposez le graphe du jeu que vous appelerez G3. Chaque sommet prendra la forme d\u0026rsquo;un tuple de 5 entiers (les 4 premiers correspondent aux nombres d\u0026rsquo;allumettes dans les 4 tas et le 5e est le numéro du joueur (0 pour Eve et 1 pour Adam).\nLa position de départ est alors (1,3,5,7,0).\nLa position de départ est-elle gagnante pour le joueur 1 (Eve) ?\nCorrection (cliquer pour afficher) def suivantsPossibles(sommet): t1,t2,t3,t4,joueur = sommet Suivants = [] for i in range(t1): Suivants.append((i,t2,t3,t4,(1+joueur)%2)) for i in range(t2): Suivants.append((t1,i,t3,t4,(1+joueur)%2)) for i in range(t3): Suivants.append((t1,t2,i,t4,(1+joueur)%2)) for i in range(t4): Suivants.append((t1,t2,t3,i,(1+joueur)%2)) return Suivants G3 = {} def constG(depart,G): S = depart Suivants = suivantsPossibles(S) G[S] = Suivants if len(Suivants) == 0: return else: for s in Suivants: if s not in G: constG(s,G) constG((1,3,5,7,0),G3) Dans la variante misère, les positions gagnantes pour Eve correspondent à une allumette restante sur une des rangées lorsque c'est au tour d'Adam\u0026nbsp:\nF = [(1,0,0,0,1),(0,1,0,0,1),(0,0,1,0,1),(0,0,0,1,1)]\nstrategie(G3, (1,3,5,7,0), F, attracteur(G3,F)) nous apprend alors que c'est peine perdue de vouloir commencer. Même chose pour la variante classique (où le gagnant est celui qui prend les derniers jetons) comme nous montre cette implémentation javascript, si vous commencez, vous allez perdre. La vidéo ci-dessous présente plus généralements les jeux de Nim. Ils ont la particularité d\u0026rsquo;avoir une stratégie (due à M. Bouton) ne nécessitant pas le parcours du graphe théoriquement généralisable à tout jeu impartial.\nOccupons-nous enfin du problème du sac-à-dos.\nCommentaire (cliquer pour afficher) À nouveau, un notebook Colab explore cette dernière partie. Dans le code du cours, il manque à nouveau la définition d\u0026rsquo;une fonction : sacadosGlouton.\nÀ vous de construire cette fonction qui donne la valeur du sac en suivant la logique gloutonne (et on s\u0026rsquo;arrêtera au premier objet qui fait dépasser la capacité du sac).\ndef sacadosGlouton(v: list,p: list,c: int) -\u0026gt; int: ### VOTRE CODE Correction (cliquer pour afficher) def sacadosGlouton(v,p,c): n = len(v) ratio = [] valeur, poids = 0, 0 for i in range(n): ratio.append((v[i]/p[i],v[i],p[i])) ratio.sort(reverse=True) for r,val,poi in ratio: if poids + poi \u003e= c: return valeur valeur += val poids += poi Utiliser ensuite votre fonction et le code du cours pour déterminer la valeur du sac si $v=[1,2,\\ldots,200]$, $p=[400,298,296,\\ldots,2]$ et $c=156$ (ce nombre d\u0026rsquo;objets rend la méthode par force brute totalement inutile).\nCorrection (cliquer pour afficher) def sacadosBB(v,p,c,i,valeur,poids,meilleure,potentiel): global nbappels nbappels += 1 n = len(v) meilleure = max(meilleure,valeur) if i == n: if poids \u003e c: return 0 else: return valeur elif valeur + potentiel[i] \u003c meilleure: return valeur else: valeurAvec = valeur + v[i] poidsAvec = poids + p[i] sol = sacadosBB_sol(v,p,c,i+1,valeur,poids,meilleure,potentiel) if poidsAvec \u003c= c: sol = max(sol,sacadosBB_sol(v,p,c,i+1,valeurAvec,poidsAvec,meilleure,potentiel)) return sol v = [i for i in range(1,201)] p = [2*i for i in range(200,0,-1)] c = 156 nbappels = 0 print(sacadosBB(v,p,c,0,0,0,meilleure,potentiel)) On obtient ainsi $2334$ (l'algorithme glouton avait, lui, trouvé $2145$, ce qui n'est pas loin du tout et permet donc d'élaguer une grosse partie de l'arbre\u0026nbsp;!). Déterminez aussi (grâce à une variable globale) le nombre d\u0026rsquo;appels récursifs passés.\nCorrection (cliquer pour afficher) print(nbappels) nous donne 64317, ce qui n'est vraiment pas énorme comparé au nombre d'appels qu'il faudrait à l'algo sans élagage. "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/divers/",
	"title": "Divers",
	"tags": [],
	"description": "",
	"content": "Divers Commentaires Tous les langages de programmations permettent d\u0026rsquo;introduire des commentaires dans le code qui servent d\u0026rsquo;aides et de repères à celui qui lit le code, mais qui sont ignorés lors de l\u0026rsquo;exécution.\nEn Python, les commentaires sont introduits par le symbole dièse (hashtag) #.\nUtilisation de print print est la première fonction native que l\u0026rsquo;on rencontre. C\u0026rsquo;est une fonction à effet de bord : elle ne retourne rien (elle est de type None), mais elle permet d\u0026rsquo;afficher une chaîne de caractères, ou le contenu d\u0026rsquo;une variable, quel que soit son type.\nnom = \u0026#39;Joe\u0026#39; age = 212 print(nom,\u0026#39;a\u0026#39;,age,\u0026#39;ans.\u0026#39;) Joe a 212 ans.\nDe plus, print affiche par défaut un retour à la ligne.\nLes caractères d\u0026rsquo;échapement font partie de la chaîne de caractères, mais sont interprétés par print comme des commandes. Le plus utilisé est le retour à la ligne \\n.\nprint(\u0026#34;a\\nb\\nc\u0026#34;) a\nb\nc\nBien que non exigible, l\u0026rsquo;utilisation des f-strings, introduites depuis Python 3.6, peut s\u0026rsquo;avérer très pratique. Les f-strings permettent d\u0026rsquo;inserrer des variables dans des chaînes de caractères et de les mettre en forme avec une syntaxe minimale.\nPour les utiliser, il suffit de mettre un f devant la chaîne de caractères et de placer chaque variable entre accolade.\nprint(f\u0026#39;{nom} a {age} ans.\u0026#39;) print(f\u0026#39;{nom = }, {age = }) # très pratique pour les jeux de tests Joe a 212 ans.\nnom = 'Joe', age = 212\nImportation de modules import module Pour importer le module machin, il suffit d\u0026rsquo;écrire import machin. Chaque fonction contenue dans le module devra alors être applée en utilisant la notation point : machin.fonction (le point désigne ici une relation d\u0026rsquo;appartenance caractéristique de la programmation orientée objet).\nimport math print(f\u0026#39;{math.sqrt(2) = }\u0026#39;) math.sqrt(2) = 1.4142135623730951\nimport module as X Lorsqu\u0026rsquo;on utilise fréquemment un module, il est pratique d\u0026rsquo;abréger son nom. Pour cela, on ajoute le raccourci souhaité après un as lors de l\u0026rsquo;import : import machin as mch.\nimport numpy as np import matplotlib.pyplot as plt X = np.linspace(-np.pi,np.pi,100) Y = np.sin(X) plt.plot(X,Y) from module import x,y On peut aussi récupérer uniquement certaines fonctions ou variables d\u0026rsquo;un module afin d\u0026rsquo;y avoir accès directement (sans utiliser machin.).\nfrom math import pi,cos print(f\u0026#39;{cos(pi) = }\u0026#39;) cos(pi) = -1.0\nfrom module import * Lorsqu\u0026rsquo;on est sûr que cela ne va pas poser problème, on peut importer tout le contenu du module de la même manière. On utilise alors l\u0026rsquo;étoile * qui signifie \u0026ldquo;tout\u0026rdquo;.\nCe type d\u0026rsquo;import est néanmoins déconseillé à moins de très bien connaître le contenu du module. Le danger est que dans l\u0026rsquo;ensemble de ce qui est importé, il peut se trouver des variables ou des fonctions ayant un nom déjà attribué. L\u0026rsquo;import réaffectera alors ces variables contre notre gré et sans nous le dire.\nd = 8 e = 2 from math import * print(sqrt(d ** e)) 16.88210319127114\nManipulation de fichier texte Ouvrir et fermer un fichier Un objet file est créé par l\u0026rsquo;utilisation de la fonction open(nom du fichier,mode) qui prend deux arguments.\nf = open(\u0026#39;monfichier.txt\u0026#39;,\u0026#39;w\u0026#39;) Le premier argument, nom du fichier, est une chaîne contenant le nom du fichier. Ce nom peut être donné avec le chemin d\u0026rsquo;accès absolu ou seulement l\u0026rsquo;arborescence relative au dossier dans lequel le programme est exécuté. En écrivant un nom sans chemin, le fichier se trouve dans le répertoire courant.\nLe deuxième argument, mode, est une chaîne d\u0026rsquo;un ou deux caractères décrivant la façon dont le fichier est utilisé.\nmode peut être r quand le fichier n\u0026rsquo;est accédé qu\u0026rsquo;en lecture, w en écriture seulement (un fichier existant portant le même nom sera alors écrasé) et a ouvre le fichier en mode ajout (toute donnée écrite dans le fichier est automatiquement ajoutée à la fin). r+ ouvre le fichier en mode lecture/écriture. L\u0026rsquo;argument mode est optionnel, sa valeur par défaut est r.\nb collé à la fin du mode indique que le fichier doit être ouvert en mode binaire c\u0026rsquo;est-à-dire que les données sont lues et écrites sous forme d\u0026rsquo;octets (type bytes). Ce mode est à utiliser pour les fichiers contenant autre chose que du texte.\nLes objets file sont fermés grâce à la méthode close() : f.close() par exemple. Python ferme les fichiers automatiquement lorsque le programme se termine.\nÉcrire dans un fichier La méthode write() d\u0026rsquo;un objet file écrit une chaîne de caractères dans le fichier et renvoie le nombre de caractères inscrits.\nf.write(\u0026#39;Coucou monde !\u0026#39;) 14\nPlus pratique, la fonction native print() peut accepter en argument un objet file. Plutôt que d\u0026rsquo;être affichée sur le shell, la sortie de print() est alors redirigée vers ce fichier.\nprint(\u0026#39;\\nKill all humans\u0026#39;, file=f) f.close() Exemple : le programme suivant écrit les quatre premières puissances de tous les entiers entre 1 et 1000, chaque champ étant séparé par une virgule, dans le fichier puissances.txt.\nfi = open(\u0026#39;puissances.txt\u0026#39;,\u0026#39;w\u0026#39;) for i in range(1,1001): print(i, i**2, i**3, i**4, sep=\u0026#39;, \u0026#39;, file=fi) fi.close() Lire un fichier Pour lire n bytes d\u0026rsquo;un fichier, on utilise f.read(n). En omettant n, tout le fichier est lu. readline() lit une seule ligne d\u0026rsquo;un fichier jusqu\u0026rsquo;au, en l\u0026rsquo;incluant, caractère \\n de nouvelle ligne. Un nouvel appel de readline() lit la ligne suivante et ainsi de suite.\nread() et readline() renvoie toutes les deux une chaîne vide lorsque la fin du fichier est atteinte.\nPour lire en une fois toutes les lignes dans une liste de chaînes, on utilise f.readlines().\nLes objet file sont itérables. On peut ainsi retourner chaque ligne d\u0026rsquo;un fichier une à une en utilisant une boucle :\nf = open(\u0026#39;monfichier.txt\u0026#39;) for ligne in f: print(ligne, end=\u0026#39;\u0026#39;) f.close() Coucou monde !\n.\n.\n.\nKill all humans\nComme ligne contient déjà le caractère de nouvelle ligne lorsqu\u0026rsquo;elle est lue, on utilise end = '' pour empêcher print d\u0026rsquo;en ajouter un autre.\nCette méthode de lecture ligne à ligne est à privilégier pour les gros fichiers à moins de vraiment vouloir contenir en mémoire l\u0026rsquo;ensemble du fichier.\nGrâce à la méthode split, on peut transformer un texte en une liste de ces éléments. L’argument de split correspond aux caractères utilisés comme séparateur. Par défaut il s’agit du caractère d’espacement ' ' (si on veut découper un texte en paragraphe, on utilisera le caractère d’échappement de retour à la ligne \\n).\nfo = open(\u0026#39;monfichier.txt\u0026#39;) texte = fo.read() liste1 = texte.split(\u0026#39;\\n\u0026#39;) liste2 = texte.split() print(liste1) print(liste2) fo.close() ['Coucou monde !', '.', '.', '.', 'Kill all humans']\n['Coucou', 'monde', '!', '.', '.', '.', 'Kill', 'all', 'humans']\nPour lire les nombres du fichier 'puissance.txt' écrit précédemment, les colonnes doivent être converties en une liste d\u0026rsquo;entiers.\nPour cela, chaque ligne doit être décomposée en ses différents champs et chaque champ explicitement converti en entier grâce à int() :\nfo = open(\u0026#39;puissances.txt\u0026#39;) carrés, cubes, puiss4 = [],[],[] lignes = fo.readlines() fo.close() for ligne in lignes: champs = ligne.split(\u0026#39;,\u0026#39;) carrés.append(int(champs[1])) cubes.append(int(champs[2])) puiss4.append(int(champs[3])) n = 500 print(n, \u0026#39;au cube vaut\u0026#39;, cubes[n-1]) 500 au cube vaut 125000000\nMais en pratique, il vaut mieux utiliser les bibliothèques NumPy ou Pandas pour des fichiers de données comme celui-ci.\nVous apprendrez aussi au 3e trimestre à utiliser les méthodes des bases de données.\nLes assertions Les assertions sont un moyen simple de s’assurer, avant de continuer, qu’une condition est respectée.\nOn utilise la syntaxe : assert test. Si le test renvoie True, l’exécution se poursuit normalement. Sinon, une exception AssertionError est levée.\nOn peut utiliser les assertions pour s’assurer que les arguments d’une fonction vont permettre son exécution.\nOn peut par exemple sécuriser la définition d\u0026rsquo;une fonction racines donnant les racines d\u0026rsquo;un trinôme du second degré. On va s’assurer que les arguments passés sont bien des nombres (et renvoyer un message explicatif si ce n’est pas le cas) :\nimport math def racines(a,b,c): \u0026#34;\u0026#34;\u0026#34;Retourne les racines de ax^2 + bx + c\u0026#34;\u0026#34;\u0026#34; type_nombre = (float,int) assert (type(a) in type_nombre) and (type(b) in type_nombre) and (type(c) in type_nombre),\u0026#34;les arguments doivent être des nombres !\u0026#34; d = b**2 - 4*a*c r1 = (-b - math.sqrt(d))/2/a r2 = (-b + math.sqrt(d))/2/a return r1, r2 racines(1,6,5) retourne (-5.0, -1.0), mais racines(1,6,'5') lève l\u0026rsquo;erreur suivante :\nAssertionError: les arguments de la fonction racines doivent être des nombres !\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "But Compétences visées (d\u0026rsquo;après le BO) : analyser et modéliser un problème ou une situation, notammant en utilisant les objets conceptuels de l\u0026rsquo;informatique pertinents (table relationnelle, graphe, dictionnaire, etc.) ; imaginer et concevoir une solution, décomposer en blocs, se ramener à des sous-problèmes simples et indépendants, adopter une stratégie appropriée, décrire une démarche, un algorithme ou une structure de données permettant de résoudre le problème ; décrire et spécifier les caractéristiques d’un processus, les données d’un problème, ou celles manipulées par un algorithme ou une fonction ; mettre en œuvre une solution, par la traduction d’un algorithme ou d’une structure de données dans un langage de programmation ou un langage de requête ; justifier et critiquer une solution, que ce soit en démontrant un algorithme par une preuve mathématique ou en développant des processus d’évaluation, de contrôle, de validation d’un code que l’on a produit ; communiquer à l’écrit ou à l’oral, présenter des travaux informatiques, une problématique et sa solution ; défendre ses choix ; documenter sa production et son implémentation. Aide La partie Feedback du repository du TP, caché dans l'onglet Pull requests, permet de me demander de l'aide en dehors des TP. Ou vous pouvez m'envoyer un mail à l'adresse suivante : "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://info-tsi-vieljeux.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]