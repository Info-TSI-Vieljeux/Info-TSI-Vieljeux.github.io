[
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/bonnes_pratiques/",
	"title": "Les bonnes pratiques",
	"tags": [],
	"description": "",
	"content": "Les bonnes pratiques Beaucoup de personnes amenées à coder plus ou moins régulièrement se sont un jour retrouvées à maudire leur moi du passé en reprenant un programme qu\u0026rsquo;ils avaient écrit seulement quelques semaines/mois auparavant mais qui leur est subitement devenu complètement cryptique.\nLe temps perdu est alors énorme et vécu d\u0026rsquo;autant plus douloureusement qu\u0026rsquo;il était facilement évitable\u0026hellip;\n Commenter son code Commenter son code via l\u0026rsquo;utilisation de # est la principale protection contre de telles autotortures.\n Il ne s\u0026rsquo;agit pas de commenter chaque ligne comme on voit parfois\u0026hellip;\na,b = 2,3\t# j\u0026#39;affecte la valeur 2 à la variable a et la valeur 3 à b c = a+b # j\u0026#39;affecte à c le résultat de l\u0026#39;addition entre a et b print(c) # j\u0026#39;affiche le résultat Il faut au contraire se concenter sur les points délicats susceptibles d\u0026rsquo;échapper à son moi du futur (qui n\u0026rsquo;a jamais autant de mémoire qu\u0026rsquo;on le pense).\nC\u0026rsquo;est souvent intéressant d\u0026rsquo;y justifier ses choix de programmation comme celui d\u0026rsquo;utiliser une structure de données plutôt qu\u0026rsquo;une autre (un dictionnaire plutôt qu\u0026rsquo;une liste par exemple). Ces différents choix sont en effet sensés ne rien devoir au hasard, donc autant noter clairement ce qui vous a fait préférer telle option plutôt qu\u0026rsquo;une autre, histoire que votre lecteur puisse comprendre votre démarche (et pour aider votre moi du futur à s\u0026rsquo;y retrouver).\nDe manière plus systématique, une structure minimale de commentaires permet de cadrer rapidement les points clé d\u0026rsquo;un bloc d\u0026rsquo;instruction (qu\u0026rsquo;il s\u0026rsquo;agisse d\u0026rsquo;une boucle ou d\u0026rsquo;une fonction).\nUn bloc de code utilise généralement un ou plusieurs paramètres appelés paramètres d\u0026rsquo;entrées et construit à partir d\u0026rsquo;eux un ou plusieurs paramètres de sortie.\nDans l\u0026rsquo;idéal, on commente alors chaque bloc de code en précisant dans la mesure du possibles les 3 éléments suivants :\n préconditions postconditions invariant   préconditions : ce sont les conditions que doivent vérifier impérativement les paramètres d\u0026rsquo;entrée pour que le code fasse ce qui est attendu.\n postconditions : ce sont les conditions que doivent vérifier impérativement les paramètres de sortie (après le bloc).\n Par exemple, si le bloc de code est sensé calculer une moyenne sur 20, la postcondition sera que la variable de sortie soit bien un flottant compris entre 0 et 20 valant la moyenne des valeurs en entrée. invariant : propriété qui devra être vérifiée à chaque itération de manière à ce que la précondition aboutisse bien au final à la poscondition.\n Exemples :\n si l\u0026rsquo;algorithme correspond à \u0026ldquo;manger une pizza\u0026rdquo;, une précondition est la présence de la pizza et une postcondition est l\u0026rsquo;absence de ladite pizza. pour calculer une racine carrée, une précondition est que le nombre en entrée ne soit pas négatif et une postcondition est que le carré de la sortie valle le nombre en entrée. pour utiliser une recherche dichotomique, la précondition principale est que la liste soit triée. lors d\u0026rsquo;un tri par sélection l'invariant est : \u0026ldquo;la partie de la liste déjà inspectée est triée\u0026rdquo;.  Exemple complet avec la division euclidienne :\n# ce code permet de calculer le quotient et le reste de la division euclidienne de a par b # préconditions : a et b entiers, a ≥ 0 et b \u0026gt; 0 a, b = 28, 5 r = a q = 0 while r \u0026gt;= b : # invariant : a = b*q + r r = r-b q = q+1 print(q,r) # postconditions : a = b*q + r, 0 ≤ r \u0026lt; b, a et b inchangés  Choisir des noms explicites Bien nommer ses variables améliore fortement la lisibilité du code.\nChoisir des noms explicites qui se rapportent au rôle et/ou aux types des variables utilisées est en effet un bien meilleur guide pour le lecteur du code que des noms génériques tel a, b, c\u0026hellip;\ny_0, v_0 = 0.3, 7.2 g = -9.8 t = 0 dt = 1e-3 y, v = y_0, v_0 while y \u0026gt; 0 : v += g*dt y += v*dt t += dt print(t) Un physicien comprend rapidement le but de ce code, mais d\u0026rsquo;autres choix de noms l\u0026rsquo;auraient rendu bien plus obscur.\n Utiliser des fonctions Autre pratique améliorant son code : l\u0026rsquo;utilisation de fonctions.\nBut :\n éviter de réécrire du code : on appelle la fonction contenant le code à la place (toute répétition de code est globalement à éviter, comme dans un texte littéraire) ; simplifier la lecture du code (et plus les noms des fonctions seront clairs, plus la compréhension du code sera simplifiée) ; rendre son code modulaire : les fonctions construites sont autant d\u0026rsquo;outils ayant une mission clairement définie. Et on peut très bien utiliser des fonctions au sein d\u0026rsquo;autres fonctions pour améliorer encore la lisibilité.   Documenter ses fonctions Les fonctions ont pour vocation d\u0026rsquo;être réutilisées (par vous ou par d\u0026rsquo;autres) et demande donc une attention particulière à leur description. Les fonctions ont ainsi droit à une forme de commentaire spéciale, le docstring, qui peut être interrogée directement par l\u0026rsquo;utilisateur (voir note ci-dessous).\nOn indique les types attendus des entrées (les paramètres) et des sorties (les retours) en inscrivant la signature de la fonction dans son docstring et on y ajoute les préconditions et les postconditions ainsi qu\u0026rsquo;une brêve descritpion.\nexemple :\ndef moyenne(notes) : \u0026#34;\u0026#34;\u0026#34; calcule une moyenne sur 20 à partir de différentes notes sur 20 moyenne(notes:list) -\u0026gt; moy:float précondition : la liste notes contient des nombres entre 0 et 20 postcondition : moy est la moyenne des éléments de notes \u0026#34;\u0026#34;\u0026#34; moy = 0 for n in notes : moy += n moy /= len(notes) return moy  On peut afficher le docstring d\u0026rsquo;une fonction via la méthode .__doc__.\n print(moyenne.__doc__) calcule une moyenne sur 20 à partir de différentes notes sur 20\nmoyenne(notes:list) -\u0026gt; moy:float\nprécondition : la liste notes contient des nombres entre 0 et 20\npostcondition : moy est la moyenne des éléments de notes\n Contraindre les spécifications avec des assertions En sus de noter les préconditions dans les commentaires, on peut aussi tenter de s\u0026rsquo;assurer qu\u0026rsquo;elles sont bien vérifiées. Qui vous assure en effet que votre fonction, par ailleurs parfaitement sage lorsque les entrées respectent les préconditions ne devienne pas folle dans certains cas loufoques ? C\u0026rsquo;est bien vous qui serez blamé lorsque l\u0026rsquo;entrée farfelue causera une catastrophe\u0026hellip;\nL\u0026rsquo;explosion du vol 501 d\u0026rsquo;Ariane est à cet égard un exemple édifiant. Un même programme ayant parfaitement accompli son œuvre de nombreuses années pour Ariane 4 a été réutilisé en toute sérénité dans le nouveau modèle. Mais voilà\u0026hellip; Le plan de vol différent d\u0026rsquo;Ariane 5 provoquait des accélérations très supérieures à celles enregistrées sur Ariane 4 jusqu\u0026rsquo;à déborder la capacité alors allouée au codage de ces mesures dans la station inertielle. La valeur élevée non prévue a planté le programme car elle a d\u0026rsquo;abord été répercutée sans lever d\u0026rsquo;erreur et du coup mal interprétée par les dispositifs de correction de trajectoire. Une petite assertion bien placée aurait peut-être pu économiser 1 milliard d\u0026rsquo;euros\u0026hellip;\nExemple (aux répercutions moins coûteuses) : pour s\u0026rsquo;assurer que le notes passées en argument sont bien des nombres entre 0 et 20, on peut écrire dans le corps de la fonction :\nfor n in notes : assert type(n) in (int,float) and 0\u0026lt;=n\u0026lt;=20  Tester Quand un code ne donne pas le résultat attendu, il faut partir à la recherche de l\u0026rsquo;erreur. Pour cela, le plus simple est d\u0026rsquo;utiliser un jeu de test.\nIl s\u0026rsquo;agit tout simplement de disposer des print tout le long de son code pour afficher conjointement les valeurs à cette endroit du code des différentes variables et les valeurs qu\u0026rsquo;on aimerait qu\u0026rsquo;elles aient.\nLe plus efficace est d\u0026rsquo;adopter une démarche dichotomique pour placer ces tests : début-milieu-fin dans un premier temps, puis on découpe en deux début-milieu et milieu-fin, etc.\n Prenons un exemple. Le programme suivant est sensé décider si la suite de caractères qu\u0026rsquo;on a entré au clavier est un palindrome ou non :\ndef bug() : res = [] fini = False print(\u0026#39;Ajoutez des caractères un par un en validant avec entrée, puis appuyez sur entrée pour terminer\u0026#39;) while not fini : elem = input(\u0026#39;\u0026#39;) if elem == \u0026#39;\u0026#39; : fini = True else : res.append(elem) tmp = res tmp.reverse() Pal = (res == tmp) if Pal : print(\u0026#39;palindrome\u0026#39;) else : print(\u0026#39;pas palindrome\u0026#39;) Lançons bug et entrons les caractères 'a','2','a'.\nLa fonction affiche alors : palindrome\nJusque-là tout va bien.\nEntrons maintenant 'a','2','b'.\nLa fonction affiche maintenant\u0026hellip; palindrome\nDonc ça bugue. Mettons en place note démarche systématique en inserrant un premier print à peu près au milieu, juste après le while. À ce niveau, on a construit la liste res, affichons-la au côté de ce qu\u0026rsquo;on attend qu\u0026rsquo;elle soit.\ndef bug() : res = [] fini = False print(\u0026#39;Ajoutez des caractères un par un en validant avec entrée, puis appuyez sur entrée pour terminer\u0026#39;) while not fini : elem = input(\u0026#39;\u0026#39;) if elem == \u0026#39;\u0026#39; : fini = True else : res.append(elem) print(\u0026#34;res devrait être [\u0026#39;a\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;b\u0026#39;] et est\u0026#34;,res) tmp = res tmp.reverse() Pal = (res == tmp) if Pal : print(\u0026#39;palindrome\u0026#39;) else : print(\u0026#39;pas palindrome\u0026#39;) Après avoir relancé bug() et retapé 'a','2' et 'b', on voit s\u0026rsquo;afficher : res devrait être ['a','2','b'] et est ['a', '2', 'b']\nOn sait maintenant que la première partie du code fait son boulot !\nConcentrons-nous sur la deuxième partie en plaçant un print avant le if. On a ici une nouvelle variable, tmp, en plus de res. Testons les deux :\ndef bug() : res = [] fini = False print(\u0026#39;Ajoutez des caractères un par un en validant avec entrée, puis appuyez sur entrée pour terminer\u0026#39;) while not fini : elem = input(\u0026#39;\u0026#39;) if elem == \u0026#39;\u0026#39; : fini = True else : res.append(elem) #print(\u0026#34;res devrait être [\u0026#39;a\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;b\u0026#39;] et est\u0026#34;,res) tmp = res tmp.reverse() Pal = (res == tmp) print(f\u0026#39;{tmp = } {res = }\u0026#39;) if Pal : print(\u0026#39;palindrome\u0026#39;) else : print(\u0026#39;pas palindrome\u0026#39;) S\u0026rsquo;affiche alors : tmp = ['b', '2', 'a'] res = ['b', '2', 'a']\nAha ! tmp a la bonne tête, maisres aussi a été modifié, et ça, ce n\u0026rsquo;était pas prévu\u0026hellip; Le problème est donc dans les 3 lignes qui précèdent le print. On pourrait placer un nouveau test entre ces lignes, mais vous aurez sans doute déjà trouvé le piège dans lequel le codeur est tombé.\nOn aurait pu être tenté de ne pas retester res à cette étape puisqu\u0026rsquo;on venait de le faire au test précédent, mais cela aurait été du coup très mal joué (un bug dans la chasse au bug) !\n L\u0026rsquo;expérience la plus vexante et retorse, elle aussi vécue par beaucoup, voit le codeur présenter fièrement un programme qui répond parfaitement à ses attentes, mais qui crashe piteusement à la première utilisation d\u0026rsquo;une autre personne\u0026hellip;\nUne des raisons possibles est qu\u0026rsquo;il n\u0026rsquo;ait pas testé son programme pour des entrées suffisamment différentes. Et si le testeur n\u0026rsquo;a pas reçu le mémo l\u0026rsquo;obligeant à ne tenter que les quelques entrées que le codeur a validées, il se retrouve en terrain miné !\nMorale : il faut tester le plus largement possible les entrées d\u0026rsquo;un programme.\n Pour ne pas non plus se perdre dans une revue systématique, vous gagnerez à partitionner le domaîne des entrées en grandes classes.\nUne classe est telle qu\u0026rsquo;à l\u0026rsquo;intérieur, le programme réagisse de la même façon avec toutes les entrées. Il suffit alors de ne tester qu\u0026rsquo;une seule valeur par classe.\n Exemple : si on fabrique une fonction valeur absolue, plutôt que de tester des milliers de nombres, on peut se contenter de tester une valeur dans chacune des trois classes suivantes correspondantes aux différents comportements de la fonction (et donc aux différents branchements de son code) : entrées $\u0026lt; 0$, entrées $\u0026gt; 0$ et la frontière entrées $=0$.\nEn conclusion, mieux vous aurez défini l\u0026rsquo;ensemble des entrées acceptables et bien inspecté leurs frontières, plus facilement vous pourrez guider le lecteur de votre code à l\u0026rsquo;intérieur de ces frontières de bon fonctionnement via les préconditions. Car s\u0026rsquo;il est évident pour votre moi du présent que votre code demande nécessairement un type de données précis et qu\u0026rsquo;il ne viendrait à l\u0026rsquo;idée de personne d\u0026rsquo;utiliser autre chose, attendez seulement quelques temps que le doute vous assaille en le relisant\u0026hellip; Et s\u0026rsquo;il vous arrive d\u0026rsquo;hésiter un tant soit peu, imaginez quelqu\u0026rsquo;un d\u0026rsquo;autre !\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp0/",
	"title": "TP 0 : Démarrage",
	"tags": [],
	"description": "",
	"content": "TP 0 : Démarrage Cliquez sur cette invitation pour récupérer le repository du TP. Exo 1 Combien de fois une feuille de papier d’épaisseur $e=0,1$ mm doit-elle être pliée pour atteindre la Lune ?\n Écrivez dans la cellule suivante un code permettant d\u0026rsquo;obtenir la réponse. Le plus simple est d\u0026rsquo;utiliser une boucle while.\n Wolfram alpha vous donne avec précision la distance Terre-Lune.\n### VOTRE CODE  Dans la cellule suivante, affectez à la variable nb_plis la valeur entière trouvée.\n nb_plis = 0  Exo 2  Complétez le code de la fonction palindrome pour qu\u0026rsquo;il retourne un booléen valant True si la chaîne de caractères passée en argument est bien un palindrome et False sinon.\n def palindrome(chaine) : \u0026#34;\u0026#34;\u0026#34; palindrome(chaine : string) -\u0026gt; test : bool précondition : chaine est une chaine de caractères postcondition : si chaine est un palindrome, test vaut True, et False sinon. \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE return test  Exo 3 Une liste peut être utilisée comme une représentation simple d’un polynôme, $P(x)$, où les éléments sont les coefficients des puissances de $x$ successives et les indices sont les puissances elles-mêmes. Ainsi le polynôme $P(x)=3+6x+2x^3$ sera représenté par la liste [3,6,0,2].\nL\u0026rsquo;exécution du code de la cellule suivante ne donne pas le résultat attendu. Il est sensé donné la liste représentant le polynôme dérivé $P'(x)$.\n Corrigez-le afin de rendre le retour affiché correct.\n P = [3, 6, 0, 2] dPdx = [] i = 0 for c in P : i += 1 dPdx.append(i*c) dPdx [3, 12, 0, 8]\n Exo 4 L’algorithme de Luhn est une formule de somme de contrôle permettant de valider un numéro de carte bancaire. On considère le numéro de carte comme une suite de nombres à 1 chiffre.\n Renverser la liste. Prendre tous les chiffres en position paire dans la liste renversée (2e chiffre, 4e chiffre, etc.) et doubler leur valeur, si le résultat dépasse 10, on ajoute les deux chiffres du résultat (par exemple 6→12→3). Sommer tous les nombres de la nouvelle liste (les modifiés et les non-modifiés) Si cette somme vaut 0 modulo 10. Le numéro de carte est valide.   Compléter la fonction suivante permettant de vérifier un numéro de carte.\n def verifcarte(numero) : \u0026#34;\u0026#34;\u0026#34; verifcarte(numero : string) -\u0026gt; bool précondition : numéro est une chaîne de caractères (par exemple \u0026#39;1205 1205 1205 1205\u0026#39;) postcondition : la fonction retourne vrai si le numéro est valide et faux sinon \u0026#34;\u0026#34;\u0026#34; num = \u0026#39;\u0026#39; for c in numero : if c in \u0026#39;0123456789\u0026#39; : num += c assert len(num)==16, \u0026#39;Le numéro ne contient pas 16 chiffres\u0026#39; ### VOTRE CODE # Pour tester votre fonction num = \u0026#39;0000 0000 0000 9258\u0026#39; verifcarte(num)  Exo 5 La suite de Syracuse est une suite d’entiers naturels définie de la manière suivante :\non part d’un nombre entier plus grand que zéro ;\n s’il est pair, on le divise par 2 ; s’il est impair, on le multiplie par 3 et on ajoute 1.  En répétant l’opération, on obtient une suite d’entiers positifs dont chacun ne dépend que de son prédécesseur.\nLorsque 1 est atteint, un cycle de longueur 3 se répète sans fin : 1, 4, 2, 1, 4, 2, 1,…\nOn ajoute donc une nouvelle règle :\n si 1 est atteint, la suite s’arrête.  Appelons temps de vol le nombre de termes de la suite.\n Construisez une fonction qui renvoie le temps de vol correspondant à une entrée donnée.\n def tpsdevol(nombre) : \u0026#34;\u0026#34;\u0026#34; tpsdevol(nombre : int) -\u0026gt; T : int précondition : nombre est un entier positif \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE return T La conjecture de Syracuse (ou Collatz) dit que toutes les suites de Syracuse ont une fin.\nConfirmons la conjecture pour tous les entiers inférieurs à 100 grâce à votre fonction.\nimport matplotlib.pyplot as plt plt.style.use(\u0026#39;seaborn\u0026#39;) plt.figure(figsize=(15,8),dpi=150) X = [i for i in range(1,100)] T = [] for x in X : T.append(tpsdevol(x)) plt.plot(X,T) plt.xlabel(\u0026#39;nombre de départ\u0026#39;) plt.ylabel(\u0026#39;temps de vol\u0026#39;) "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp1recherche/",
	"title": "TP 1 : recherche simple",
	"tags": [],
	"description": "",
	"content": "TP 1 : Recherche séquentielle dans un tableau unidimensionnel. Dictionnaires. Cliquez sur cette invitation pour récupérer le repository du TP. Recherche d\u0026rsquo;un élément dans une liste  Écrire une fonction recherche qui prend pour argument un élément et une liste et qui retourne True si l\u0026rsquo;élément est présent et False sinon.\nLe corps de la fonction devra comprendre une boucle.\n Rq : le but de recherche est de reproduire le fonctionnement du mot clé in.\ndef recherche(x,L) : \u0026#39;\u0026#39;\u0026#39; recherche(x : tout type, L : list) -\u0026gt; bool \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE  Dans le pire des cas (élément ne se trouvant pas dans la liste), combien de comparaisons doit-on opérer pour savoir si un élément est présent dans une liste de taille 400 ?\n  Construisez une fonction dico qui prend en argument une liste L de $n$ entiers inférieurs à $n$ et qui retourne un dictionnaire de longueur $n$ dont les clés sont les $n$ premiers entiers (de 0 à $n$-1) et les valeurs comptent le nombre de fois que la clé est présente dans la liste.\nExemple : s\u0026rsquo;il y a 2 fois l\u0026rsquo;élément 18 dans la liste L, alors dico(L)[18]==2, et si l\u0026rsquo;élément 97 n\u0026rsquo;est pas présent dans la liste, alors dico(L)[97]==0.\n from random import randint def dico(L) : \u0026#39;\u0026#39;\u0026#39; dico(L : list) -\u0026gt; dict précondition : si la longueur de L vaut n, alors L ne contient que des entiers \u0026lt; n \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE Définissons une fonction recherche_dico qui vérifie si un entier est bien présent :\ndef recherche_dico(e,dic) : \u0026#39;\u0026#39;\u0026#39; recherche_dico(e : int, dic : dict) -\u0026gt; bool \u0026#39;\u0026#39;\u0026#39; if dic[e] \u0026gt;= 1 : return True else : return False # Exemple d\u0026#39;utilisation : L = [5,2,3,1,2,0,2] dic = dico(L) (recherche_dico(3,dic),recherche_dico(4,dic)) (True, False)\nL\u0026rsquo;intérêt de recherche-dico est d\u0026rsquo;aller beaucoup plus vite que recherche comme le montre le graphe suivant (l\u0026rsquo;execution du code peut prendre quelques secondes) :\nfrom time import time from random import randint import matplotlib.pyplot as plt plt.style.use(\u0026#39;ggplot\u0026#39;) I, T_ch, T_dico = [], [], [] for i in range(1000,200000,1000) : L = [] L = [randint(0,i-1) for k in range(i)] # randint(i,j) retourne un entier dans {i;...;j} # la liste L contient i éléments tirés au hasard entre 0 et i-1 dic = dico(L) # on crée un dictionnaire à partir de L grâce à la fonction \u0026#39;dico\u0026#39; element = randint(0,i-1) # \u0026#39;element\u0026#39; est un entier tiré au hasard entre 0 et i-1 start = time() # on note l\u0026#39;heure exacte recherche(element,L) stop1 = time() recherche_dico(element,dic) stop2 = time() T_ch.append(stop1-start) T_dico.append(stop2-stop1) I.append(i) plt.figure(figsize = (15,5)) plt.plot(I,T_dico,label=\u0026#34;recherche_dico\u0026#34;) plt.plot(I,T_ch,label=\u0026#34;votre fonction \u0026#39;recherche\u0026#39;\u0026#34;) plt.xlabel(\u0026#39;taille de la liste\u0026#39;) plt.ylabel(\u0026#34;temps d\u0026#39;exécution (s)\u0026#34;) plt.legend() Recherche d\u0026rsquo;un maximum  Écrire une fonction maximum qui prend pour argument une liste et qui retourne le plus grand élément de la liste.\n(Interdiciton d\u0026rsquo;utiliser la fonction native max évidemment)\n def maximum(L) : \u0026#39;\u0026#39;\u0026#39; maximum(L : list) -\u0026gt; float ou int \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE Que se passera-t-il si on passe la liste suivante [1,3,'a',-2] en argument à maximum ?\nmaximum([1,3,\u0026#39;a\u0026#39;,-2])  Pour éviter cela, vous devrez vous assurez en amont que la liste donnée en argument contient bien que des nombres.\nRappel : type(3) renvoie int et type(2.8) renvoie float.\nVous placerez un assert en début de fonction prévenant l\u0026rsquo;utilisateur que la liste contient des types farfelus.\n def maximum_secure(L) : \u0026#39;\u0026#39;\u0026#39; maximum(L : list) -\u0026gt; float ou int la fonction lève une \u0026#39;AsserionError\u0026#39; si la liste ne contient pas que des nombres \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE  Construisez maintenant une fonction max_2 qui retourne le deuxième maximum défini comme le plus grand élément strictement inférieur au maximum (s\u0026rsquo;il y a plusieurs éléments ayant la valeur maximale, il ne faut pas retourner un de ceux-là).\nVotre fonction max_2 devra utiliser votre ancienne fonction maximum, mais vous ferez attention à ne pas placer maximum à l\u0026rsquo;intérieur d\u0026rsquo;une boucle.\n def max_2(L) : \u0026#39;\u0026#39;\u0026#39; max_2(L : list) -\u0026gt; float ou int précondition : L est une liste de nombres postcondition : la fonction retourne le plus grand élément strictement plus petit que le max de la liste. \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE Ci-dessous est représentée l\u0026rsquo;évolution du temps d\u0026rsquo;exécution de la fonction native max ainsi que de la fonction maximum (si vous avez réussi à l\u0026rsquo;implémenter) en fonction de la taille de la liste en argument.\nOn remarque que cette évolution est linéaire : l\u0026rsquo;augmentation du temps d\u0026rsquo;exécution semble proportionnelle à l\u0026rsquo;augmentation de la taille de la liste.\nI, T_max, T_maximum = [], [], [] for i in range(50000,1000000,50000) : L = [] for k in range(i) : L += [randint(0,k)] # randint(i,j) retourne un entier dans {i;...;j} start1 = time() max(L) stop1 = time() T_max.append(stop1-start1) start2 = time() maximum(L) stop2 = time() T_maximum.append(stop2-start2) I.append(i) plt.figure(figsize = (15,5)) plt.plot(I,T_max,label=\u0026#34;la fonction Python \u0026#39;max\u0026#39;\u0026#34;) plt.plot(I,T_maximum,label=\u0026#34;votre fonction \u0026#39;maximum\u0026#39;\u0026#34;) plt.xlabel(\u0026#39;taille de la liste\u0026#39;) plt.ylabel(\u0026#34;temps d\u0026#39;exécution (s)\u0026#34;) plt.legend()  Ajoutez la fonction max_2 à ce graphe et répondre dans la cellule suivante si oui ou non, le temps d\u0026rsquo;exécution de max_2 semble dépendre linéairement de la taille de la liste.\n "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/traitsgaux/",
	"title": "Traits généraux",
	"tags": [],
	"description": "",
	"content": "Traits généraux Introduction Shell et IDE Python est un langage de programmation interprété développé par Guido van Rossum en 1989. Langage impératif de haut-niveau doté d\u0026rsquo;une syntaxe simple, Python s\u0026rsquo;adapte à de nombreux contextes grâce à sa modularité ; une importante librairie de modules et packages permet en effet d\u0026rsquo;étendre ses capacités.\nPython possède son propre shell (interface en ligne de commande) : l\u0026rsquo;utilisateur entre une commande Python qui est interprétée immédiatement lorsque Entrée est tapée.\nAu lancement, le shell Python, poli, se présente :\nLes 3 chevrons sont l\u0026rsquo;invite (ou prompt) où les commandes seront écrites.\nIPython, un shell plus évolué, utilise [1] comme invite (où le chiffre dans les crochets s\u0026rsquo;incrémente à chaque commande).\nPour sortir du shell classique, il faut taper exit(), et exit ou quit pour sortie du shell IPython.\nOn peut tout à fait exécuter des commandes Python une à une dans le shell.\nUne commande qui renvoie un résultat est appelée expression, alors qu\u0026rsquo;une commande qui ne renvoie rien est une instruction.\nToute fonction est une expression, mais certaines ont en plus un effet sur l\u0026rsquo;environnement comme print() qui permet d\u0026rsquo;afficher une chaîne de caractères dans le shell ou dans un fichier (elle retourne aussi la valeur None qui est omise dans ce cas par le shell). Par une mauvaise traduction de l\u0026rsquo;anglais side effect, les fonctions qui modifient un état en dehors de leur environnement local comme une modification de la mémoire (écriture d\u0026rsquo;un fichier) ou une modification d\u0026rsquo;un périphérique (affichage sur l\u0026rsquo;écran par exemple) sont dites à effet de bord.\n Pour les projets plus complexes nécessitant d\u0026rsquo;enchaîner les instructions, on écrit l\u0026rsquo;ensemble de ces commandes (le programme) dans un éditeur de texte et on enregistre le fichier avec une extension .py.\nOn demande alors à l\u0026rsquo;interprète Python d\u0026rsquo;exécuter l\u0026rsquo;ensemble du script en utilisant la commande python nom_du_fichier.py dans le shell de l\u0026rsquo;OS. Les différents retours dans le shell ne sont alors plus affichés, seuls les effets ont un\u0026hellip; effet.\nLe plus simple pour coder est d\u0026rsquo;utiliser un environnement de travail (IDE pour \u0026ldquo;integrated development environment\u0026rdquo;) qui combine un éditeur de code et un shell Python permettant d\u0026rsquo;exécuter le script entier ou une partie directement via l\u0026rsquo;interface.\nInstallation L\u0026rsquo;installation d'Anaconda rend disponible les principales bibliothèques scientifiques Python ainsi que le preformant IDE Spyder ou encore Jupyterlab (très intéressant pour les présentations de projets car associant dans une même interface texte et code pour former un notebook).\n  Passons maintenant en revue quelques caractéristiques du langage Python.\nTypage dynamique Contrairement à des langages à typage statique comme le C, le type de la variable n\u0026rsquo;a pas besoin d\u0026rsquo;être déclarée en Python. On parle alors de typage dynamique.\nL\u0026rsquo;interprète Python détermine par lui-même le type en fonction de l\u0026rsquo;objet affecté à la variable.\n Principe d\u0026rsquo;indentation Beaucoup de langage de programmation (C++, Java par exemple) utilisent des accolades {} pour définir un bloc de code (boucles,fonctions, instructions conditionnelles). Python utilise l'indentation (décalage d\u0026rsquo;un nombre constant d\u0026rsquo;espaces blancs, généralement 4, ou une tabulation).\nfor i in range(3) : mot = \u0026#39;\u0026#39; for lettre in (\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;) : mot += lettre*i print(mot)  Qu\u0026rsquo;est-ce qui s\u0026rsquo;affiche ?\n  Portée lexicale Les variables définies à l\u0026rsquo;intérieur d\u0026rsquo;une fonction ont une portée locale. Elles ne sont pas reconnues dans le code principal (en dehors du bloc de la fonction).\nÀ l\u0026rsquo;inverse, les variables affectées dans le programme principal peuvent être utilisées partout (y compris dans la fonction) et sont dites globales.\nExemple :\ndef foo() : a = \u0026#39;locale\u0026#39; print(a) print(b) b = \u0026#39;globale\u0026#39; foo() locale\nglobale\nComme b n\u0026rsquo;est pas définie dans la bloc de la fonction, Python va la chercher dans le champ global. Mais il faut que b soit affectée avant l\u0026rsquo;appel de la fonction.\nQue se passe-t-il si une fonction définit une variable locale avec le même nom qu\u0026rsquo;une variable globale ?\nLe champ local est scruté en premier.\nExemple :\ndef foo() : a = \u0026#39;locale\u0026#39; print(a) a = \u0026#39;globale\u0026#39; foo() print(a) locale\nglobale\nNotons bien que la variable locale a n\u0026rsquo;existe que dans le bloc de définition, qu\u0026rsquo;elle ait ou non le même nom qu\u0026rsquo;une variable globale ne change rien. Elle disparait quand l\u0026rsquo;interprète sort de la fonction et n\u0026rsquo;écrase donc pas la variable globale a.\nDans l\u0026rsquo;ordre, Python regarde d\u0026rsquo;abord le champ local, puis non local (le champ englobant la fonction intérieure dans le cas de fonctions imbriquées), puis global, puis built-in (les fonctions natives qu\u0026rsquo;il convient donc de ne pas redéfinir).\n Une fonction ne peut pas modifier une variable globale sans préciser qu\u0026rsquo;elle le souhaite.\nExemple :\nx = 2 def fct1() : print(x) def fct2() : x += 1 print(x)  Que se passe-t-il lorsqu\u0026rsquo;on appelle fct1() ? Et fct2() ?\n Pour régler le problème, il faut utiliser le mot clé global qui permet de réaffecter la variable globale à l\u0026rsquo;intérieur de la fonction.\ndef fct2() : global x x += 1 print(x) L\u0026rsquo;appel de fct2() se fait maintenant sans heurt et 3 s\u0026rsquo;affiche.\nCe type de réaffectation est néanmoins à éviter, car il amène pas mal de confusion. C\u0026rsquo;est souvent plus logique de passer x en argument de la fonction.\n  Appel de fonction par valeur Lors de l\u0026rsquo;appel d\u0026rsquo;une fonction, les arguments sont copiés et la fonction travaille alors uniquement sur cette copie.\nLa copie disparaît lors du retour au programme principal.\nSi la fonction modifie la valeur d\u0026rsquo;un de ses arguments, seule la copie sera modifiée, pas la variable du programme principal.\nOn dit que les arguments d\u0026rsquo;une fonction sont transmis par valeurs (par contraste avec la transmission par référence ou adresse comme dans le langage Java où une modification de l\u0026rsquo;argument dans la fonction se répercute dans le programme principal).\nExemple :\ndef foo(a) : print(\u0026#34;valeur de \u0026#39;a\u0026#39; au début de la fonction :\u0026#34;,a) a = a*2 print(\u0026#34;valeur de \u0026#39;a\u0026#39; à la fin de la fonction :\u0026#34;,a) a = 2 print(\u0026#34;valeur de \u0026#39;a\u0026#39; dans le programme principal avant l\u0026#39;appel de la fonction :\u0026#34;,a) foo(a) print(\u0026#34;valeur de \u0026#39;a\u0026#39; dans le programme principal après l\u0026#39;appel de la fonction :\u0026#34;,a) valeur de 'a' dans le programme principal avant l'appel de la fonction : ...\nvaleur de 'a' au début de la fonction : ...\nvaleur de 'a' à la fin de la fonction : ...\nvaleur de 'a' dans le programme principal après l'appel de la fonction : ...\nNotons toutefois que si l\u0026rsquo;argument est une liste, c\u0026rsquo;est sa référence qui est cette fois transmise\u0026hellip; Toute modification de la liste dans la fonction se répercute à l\u0026rsquo;extérieur. La fonction a alors un effet de bord. C\u0026rsquo;est dû au statut mutable des listes dans Python. Et cela sera donc la même chose avec les dictionnaires, autre objet mutable.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/",
	"title": "Python",
	"tags": [],
	"description": "",
	"content": "Python Éléments du langage Python dont la connaissance est exigibles aux concours.\nAucun concept sous-jacent n\u0026rsquo;est exigible ainsi qu\u0026rsquo;aucune connaissance sur un module particulier.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/correctionterminaison/",
	"title": "Correction / Terminaison",
	"tags": [],
	"description": "",
	"content": "Prouver un algorithme Le mot algorithme vient de la latinisation du nom du savant arabe al-Khuwārizmī (780-850) qui a entre autres permis l\u0026rsquo;introduction de l\u0026rsquo;algèbre en Europe (et il est aussi à l\u0026rsquo;origine de ce mot).\nUn algorithme est une méthode qui sert à résoudre un problème en un nombre fini d’étapes : chercher un mot dans le dictionnaire, classer des mots par ordre alphabétique, classer des nombres par ordre de grandeur, chercher le meilleur parcours possible sur une carte, trouver une racine carrée, construire des listes de nombres premiers, etc.\nOn peut décrire un algorithme comme étant une suite d\u0026rsquo;actions à accomplir séquentiellement, dans un ordre fixé.\nPour Gérard Berry, ex titulaire de la chaire Informatique et sciences numériques au Collège de France, l\u0026rsquo;algorithmique est l\u0026rsquo;art d\u0026rsquo;organiser un calcul complexe en partant d\u0026rsquo;opérations simples (un ordinateur étant un objet extraordinairement stupide mais très obéissant).\nLes algorithmes manipulent trois types de choses :\n des objets : bits, entiers, flottants, mots, images, etc. des structures de données (comment on organise les objets) : piles, listes, chaînes, arbres, etc. des structures de contrôle (comment on organise les opérations) : séquence, condition, boucle, etc.  Face à un algorithme, on peut se poser plusieurs questions :\n Est-ce qu\u0026rsquo;il donne un résultat ou bien est-ce qu’il ne s’arrête jamais ? C\u0026rsquo;est le problème de la terminaison d\u0026rsquo;un algorithme. Est-ce qu\u0026rsquo;il donne le résultat attendu ou bien est-ce qu’il calcule n’importe quoi ? C\u0026rsquo;est le problème de la correction de l\u0026rsquo;algorithme. Est-ce qu’il donne le résultat en un temps raisonnable ou bien est-ce qu’il faut attendre plusieurs siècles ? C\u0026rsquo;est le problème de la complexité de l\u0026rsquo;algorithme.   Terminaison d\u0026rsquo;un algorithme Un algorithme doit se terminer en un temps fini !\nOn est sûr qu\u0026rsquo;un algorithme termine si le nombre d\u0026rsquo;étapes est fixé.\nLes deux énemis de la terminaison sont :\n les boucles while la récursivité   Algorithmes itératifs : Pour les algorithmes itératifs, les boucles while (tant que) sont la partie pouvant poser problème, car le nombre d\u0026rsquo;étapes n\u0026rsquo;est pas fixé à l\u0026rsquo;avance.\nPour prouver leur terminaison, on exhibe un variant de boucle.\nUn variant de boucle est un entier strictement positif avant l\u0026rsquo;entrée dans la boucle qui décroît strictement à chaque passage dans la boucle.\n Trouver un variant de boucle prouve que la boucle termine, car sinon il existerait une suite décroissante d\u0026rsquo;entiers naturels, ce qui est impossible.\nExemple : preuve de la terminaison de l'algorithme d\u0026rsquo;exponentiation rapide\ndef puissance(a,n) : p = 1 while n \u0026gt; 0 : if n%2 == 0 : a *= a n //= 2 else : p *= a n -= 1 return p Si on spécifie que n doit être un entier positif, alors n est un variant de boucle. En effet :\n $n$ est bien un entier strictement positif avant chaque passage dans la boucle : $n$ est initialement un entier positif (par hypothèse) et $n$ reste entier après k passages dans la boucle (par récurrence simple). De plus, la boucle s\u0026rsquo;arrête si $n≤0$. $n$ est bien strictement décroissant : en notant $n'$ la valeur de $n$ après un passage dans la boucle, si $n$ est pair avant un passage dans la boucle, on a $\\displaystyle n'=\\frac{n}{2}$ et comme $n≥2$, $n'\u0026lt;n$. Et si $n$ est impair, alors on a $n'=n-1$ et donc à nouveau $n'\u0026lt;n$.   Algorithmes récursifs : On prouve la terminaison d\u0026rsquo;un algorithme récursif par récurrence (par construction, tout ce qui est lié aux algorithme récursifs se prouve par récurrence).\nExemple : l\u0026rsquo;algorithme récursif suivant calcul la somme des n premiers entiers.\ndef sommerec(n) : \u0026#34;\u0026#34;\u0026#34; sommerec(n : int) -\u0026gt; int préconditions : n est un entier positif postcondition : retourne la somme des entiers positifs ≤ n \u0026#34;\u0026#34;\u0026#34; if n == 0 : return 0 else : return n + sommerec(n-1) Prouvons par récurrence sur n que l\u0026rsquo;algorithme termine :\n pour n = 0, c\u0026rsquo;est bon (cas de base). supposons que l\u0026rsquo;algorithme termine pour l\u0026rsquo;entrée n-1 (ie sommerec(n-1) termine).\nPour l\u0026rsquo;entrée n, l\u0026rsquo;algorithme retourne n + sommerec(n-1), donc sommerec(n) termine. conclusion : sommerec termine pour tout n.    On ne peut pas prouver automatiquement l\u0026rsquo;arrêt d\u0026rsquo;un programme.\nC\u0026rsquo;est ce qu\u0026rsquo;affirme le théorème de l\u0026rsquo;arrêt : il n\u0026rsquo;existe pas de programme prenant en entrée le code d\u0026rsquo;un programme et ses arguments et qui renvoie oui si le programme se termine pour une certaine entrée, non sinon.\nLa conjecture de syracuse (tp0) est un exemple de programme dont on ne sait pas s\u0026rsquo;il se termine pour une entrée quelconque.\n Preuve de correction d’un algorithme Ariane 501 a explosé à cause d\u0026rsquo;un bug tout petit dans un programme qui ne servait à rien.\nProuver la correction d\u0026rsquo;un algorithme permet d\u0026rsquo;éviter une telle mésaventure, mais c\u0026rsquo;est difficile. Il faut pouvoir prouver qu’un programme s’exécute correctement dans toutes les situations. Mais correct selon quels critères ? Quelles situations sont à considérer ?\nSpécifier les données acceptables (les préconditions), les résultats attendus (les postconditions) et exprimer logiquement la propriété devant lier les données aux résultats (les entrées aux sorties) sont des éléments fondamentaux. Plus précisément, on prouve qu\u0026rsquo;un algorithme fait ce qu\u0026rsquo;il est sensé faire si pour toute entrée vérifiant les préconditions, il donne une sortie vérifiant les postconditions.\n Si on prouve que pour toute donnée d\u0026rsquo;entrée qui vérifie les préconditions, l\u0026rsquo;algorithme renvoie des données de sortie vérifiant les postconditions,\non dit qu\u0026rsquo;on a prouvé la correction partielle de l\u0026rsquo;algorithme.\n Si on prouve en plus que l\u0026rsquo;algorithme termine,\non dit qu\u0026rsquo;on a prouvé la correction totale de l\u0026rsquo;algorithme.\n  Algorithmes itératifs : Les difficultés se concentrent encore au niveau des boucles. Pour prouver qu\u0026rsquo;une boucle fait bien son boulot, on utilise cette fois-ci un invariant de boucle.\nUn invariant de boucle est une propriété vraie avant le premier tour de boucle et qui se conservera pendant toute l’exécution de la boucle (donc qui restera vraie d’un tour à l’autre de la boucle), et sera toujours vraie une fois que la boucle aura fini de s’exécuter.\n Une démonstration par invariant de boucle se déroule en 3 étapes analogues à une preuve par récurrence (seule la terminaison diffère) :\n  Entrée de boucle = initialisation ($\\rightarrow$ initialisation) :\non démontre que juste avant de rentrer dans le premier tour de boucle l’invariant est vrai.\n  Passage dans la boucle = conservation ($\\rightarrow$ hérédité) :\non suppose que l’invariant est vrai au début d’un passage quelconque dans la boucle et on démontre que l’invariant reste vrai en fin de boucle.\n  Sortie de boucle = terminaison ($\\rightarrow$ conclusion) :\nl’invariant est toujours vrai (car il était vrai à la fin du dernier tour de boucle) mais la condition de boucle est devenue fausse.\n   Exemple : preuve de la correction de l'algorithme d\u0026rsquo;Euclide\ndef pgcd(a,b) : while b != 0 : a, b = b, a%b return a On note $a_k$ et $b_k$ les valeurs de a et b à la fin de la kème itération ($a_0$ et $b_0$ désignent les valeurs de a et b avant d’entrer dans la boucle).\nL\u0026rsquo;invariant de boucle est le $pgcd$ de a et b. En effet :\n Initialisation :\nelle est triviale puisque $a$ et $b$ n\u0026rsquo;ont pas encore été modifié ($pgcd(a_0,b_0)=pgcd(a,b)$). Conservation :\nsi $a=bq+r$, il est clair que tout diviseur commun de $a$ et $b$ est un diviseur commun de $b$ et $r$ et réciproquement. Notamment, $pgcd(a,b) = pgcd(b,r)$.\nCeci prouve que $pgcd(a_k,b_k) = pgcd(a_{k+1},b_{k+1})$. La quantité $pgcd(a_k,b_k)$ est donc bien un invariant de boucle. Terminaison :\nà la fin de la dernière itération (numérotée $f$), $b_f=0$ de sorte que $pgcd(a_0,b_0)=pgcd(a_f,b_f)=pgcd(a_f,0)=a_f.$\nEn renvoyant $a_f$, la fonction pgcd(a,b) renvoie donc bien le $pgcd$ de a et b.   Algorithmes récursifs : La correction d\u0026rsquo;un algorithme récursif est généralement beaucoup plus simple à prouver que celle d\u0026rsquo;un itératif (c\u0026rsquo;est là une des principales qualités de la récursivité).\nEn effet, la propriété transmise des préconditions au postconditions (jouant le rôle d\u0026rsquo;invariant de boucle) est généralement beaucoup plus simple à trouver et souvent même directement inscrite dans le corps de la fonction.\nReprenons l\u0026rsquo;exemple de la somme des entiers et démontrons par récurrence sa correction :\n si n = 0, la somme vaut bien 0. supposons que sommerec(n-1) donne la somme des n-1 premiers entiers. Alors la somme des n premiers entiers vaudra sommerec(n-1) + n et c\u0026rsquo;est bien ce que retourne sommerec(n). Conclusion : pour tout n, sommerec(n) retourne la somme des n premiers entiers.  On aurait pu se montrer plus technique en utilisant comme propriété héréditaire : $u_n=$sommerec(n) $=\\frac{n(n+1)}{2}$\nEn supposant la propriété vraie au rang n-1, sommerec(n) = n + sommerec(n-1) $=n+u_{n-1}$ $= n + \\frac{n(n-1)}{2} = \\frac{n(n+1)}{2}$\n Construire un algorithme pour qu\u0026rsquo;il soit correct Expliciter l\u0026rsquo;invariant comme on a vu dans les bonnes pratiques en s\u0026rsquo;en servir comme guide permet de s\u0026rsquo;assurer en amont de la correction de l\u0026rsquo;algorithme ; on sait où on va.\nPar exemple, pour le tri par sélection, faire en sorte que l\u0026rsquo;invariant \u0026ldquo;la partie de la liste déjà inspectée est triée\u0026rdquo; soit toujours vrai nous assure de la correction future de l\u0026rsquo;algorithme ; en s\u0026rsquo;assurant que la partie non triée diminue à chaque tour, on finira bien par obtenir une liste entièrement triée.\nAutre exemple, pour consruire les méthodes liées à la structure de données appelée tas que l\u0026rsquo;on retrouvera dans le chapitre sur les graphes, on est guidé par la conservation de l\u0026rsquo;invariant \u0026ldquo;les clé des enfants doivent être supérieures à celles du parent\u0026rdquo; (voir la vidéo pour les détails).\n Exercice : prouver la correction totale de l\u0026rsquo;algorithme de la division euclidienne vu dans les bonnes pratiques.\n "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp2imbrication/",
	"title": "TP 2 : boucles imbriquées",
	"tags": [],
	"description": "",
	"content": "Algorithmes opérant sur une structure séquentielle par boucles imbriquées Cliquez sur cette invitation pour récupérer le repository du TP. Chercher un mot dans un texte  Écrire une fonction cherche_mot naïve qui recherche si un mot est présent dans un texte en comparant chaque morceau du texte de la taille du mot au mot recherché.\nVous devrez vous assurez (grâce à des assertions) que le mot et le texte sont bien des chaînes de caractères et que le mot n\u0026rsquo;est pas plus long que le texte.\n def cherche_mot(mot,texte) : \u0026#39;\u0026#39;\u0026#39; cherche_mot(mot:string, texte:string)-\u0026gt;bool \u0026#39;\u0026#39;\u0026#39; ### VOTRE CODE # importation de la classique liste de mots de passe rockyou (cela prend quelques secondes) from urllib.request import urlopen url = \u0026#39;http://cordier-phychi.toile-libre.org/Info/github/rockyou.txt\u0026#39; rockyou = urlopen(url).read().decode(\u0026#39;latin-1\u0026#39;) print(f\u0026#34;Le fichier rockyou contient {len(rockyou.split())} mots de passe !\u0026#34;) Le fichier rockyou contient 14445388 mots de passe !\n# vous pouvez tester la présence de votre mot de passe dans la liste mot_de_passe = \u0026#39;...\u0026#39; cherche_mot(mot_de_passe,rockyou)  Sans ce soucier de l\u0026rsquo;implémentation, combien faudra-t-il théoriquement faire de comparaisons au minimum pour s\u0026rsquo;assurer qu\u0026rsquo;un mot de 3 caractères est absent d\u0026rsquo;une chaîne de 10 caractères ?\n Traçons l\u0026rsquo;évolution du temps d\u0026rsquo;exécution de cherche_mot en fonction de la taille du texte pour une taille du mot fixe.\nfrom time import time from random import randint import matplotlib.pyplot as plt plt.style.use(\u0026#39;ggplot\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 5) I, T_in, T_ch = [], [], [] mot = \u0026#39;\u0026amp;\u0026#39;*100 for i in range(10000,500000,10000) : texte = rockyou[:i] start = time() cherche_mot(mot,texte) stop = time() T_ch.append(stop-start) I.append(i) plt.figure(figsize = (15,5)) plt.plot(I,T_ch) plt.xlabel(\u0026#34;longeur du texte (longueur mot = moitié longueur texte)\u0026#34;) plt.ylabel(\u0026#34;temps d\u0026#39;exécution (s)\u0026#34;) plt.title(\u0026#34;Temps d\u0026#39;excution de \u0026#39;cherche_mot\u0026#39; en fonction de la taille du texte\u0026#34;) Sur le même modèle, vous allez tracer l\u0026rsquo;évolution du temps d\u0026rsquo;exécution de cherche_mot en fonction de la taille du mot pour une taille de texte fixe et pour des mots petits devant le texte.\n Pour cela vous compléterez le code ci-dessous.\n I, T_ch_mot = [], [] texte = rockyou[:200000] for i in range(1000,20000,1000) : # à compléter (i doit correspondre au nombre de caractères du mot) fig,ax = plt.subplots(figsize = (15,5)) ax.plot(I,T_ch_mot) ax.set(xlabel=\u0026#34;longueur du mot\u0026#34;, ylabel=\u0026#34;temps d\u0026#39;exécution (s)\u0026#34;) ax.set_title(\u0026#34;Temps d\u0026#39;excution de \u0026#39;cherche_mot\u0026#39; en fonction de la longueur du mot\u0026#34;) Pour des petits mots par rapport au texte et en appelant $n$ la longueur du texte et $m$ la longueur du mot, quelle fonction semble-t-elle le mieux modéliser l\u0026rsquo;évolution du temps d\u0026rsquo;exécution en fonction de $n$ et $m$ ?\n A : $a\\times m + b\\times n$ où $a$ et $b$ sont des constantes B : $a\\times m^2$ où $a$ est une constante C : $a\\times n^2$ où $a$ est une constante D : $a\\times m\\times n$ où $a$ est une constante   Chercher un doublon La fonction suivante cherche si un élément d\u0026rsquo;une liste se trouve en double et le cas échéant, le retourne.\ndef cherche_duplicata(liste) : N = len(liste) for i in range(N) : for j in range(N) : if i != j and liste[i] == liste[j] : print(\u0026#39;Un élément en double a été trouvé :\u0026#39;) return liste[i] return \u0026#39;Pas de doublons trouvés 😞\u0026#39; liste_fruits = [\u0026#34;🍓\u0026#34;, \u0026#34;🍐\u0026#34;, \u0026#34;🍊\u0026#34;, \u0026#34;🍌\u0026#34;, \u0026#34;🍍\u0026#34;, \u0026#34;🍑\u0026#34;, \u0026#34;🍎\u0026#34;, \u0026#34;🍈\u0026#34;, \u0026#34;🍊\u0026#34;, \u0026#34;🍇\u0026#34;] a = cherche_duplicata(liste_fruits) print(a) Un élément en double a été trouvé :\n🍊\n Combien de fois la comparaison liste[i] == liste[j] est-elle opérée au maximum si la liste contient 200 éléments ?\n On peut aisément améliorer la fonction en évitant de doubler les comparaisons :\ndef cherche_duplicata_bis(liste) : N = len(liste) for i in range(N-1) : for j in range(i+1,N) : if liste[i] == liste[j] : print(\u0026#39;Un élément en double a été trouvé :\u0026#39;) return liste[i] return \u0026#39;Pas de doublons trouvés 😞\u0026#39; liste_fruits = [\u0026#34;🍓\u0026#34;, \u0026#34;🍐\u0026#34;, \u0026#34;🍊\u0026#34;, \u0026#34;🍌\u0026#34;, \u0026#34;🍍\u0026#34;, \u0026#34;🍑\u0026#34;, \u0026#34;🍎\u0026#34;, \u0026#34;🍈\u0026#34;, \u0026#34;🍊\u0026#34;, \u0026#34;🍇\u0026#34;] a = cherche_duplicata(liste_fruits) print(a) Un élément en double a été trouvé :\n🍊\n Combien de comparaisons sont opérées au maximum avec cette nouvelle fonction si la liste contient 200 éléments ?\n # Pour vous aider à raisonner N = 10 for i in range(N-1) : L = [] for j in range(i+1,N) : L.append((i,j)) print(L) [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9)]\n[(1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9)]\n[(2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9)]\n[(3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9)]\n[(4, 5), (4, 6), (4, 7), (4, 8), (4, 9)]\n[(5, 6), (5, 7), (5, 8), (5, 9)]\n[(6, 7), (6, 8), (6, 9)]\n[(7, 8), (7, 9)]\n[(8, 9)]\nfrom random import randint I, T_dup, T_dup_bis = [], [], [] for i in range(200,5000,200) : L = [i for i in range(i)] start = time() cherche_duplicata(L) stop1 = time() cherche_duplicata_bis(L) stop2 = time() I.append(i) T_dup.append(stop1-start) T_dup_bis.append(stop2-stop1) fig,axs = plt.subplots(3,figsize = (15,15)) axs[0].plot(I,T_dup) axs[0].set_title(\u0026#34;cherche_duplicata\u0026#34;) axs[1].plot(I,T_dup_bis,c=\u0026#39;#3388BB\u0026#39;,label=\u0026#34;cherche_duplicata_bis\u0026#34;) axs[1].set_title(\u0026#34;cherche_duplicata_bis\u0026#34;) axs[2].plot(I,T_dup,label=\u0026#34;cherche_duplicata\u0026#34;) axs[2].plot(I,T_dup_bis,c=\u0026#39;#3388BB\u0026#39;,label=\u0026#34;cherche_duplicata_bis\u0026#34;) axs[2].set_title(\u0026#34;Comparaison\u0026#34;) axs[2].legend() On constate que même si l\u0026rsquo;amélioration est visible entre les deux fonctions, le comportement général (la classe de complexité comme on le verra plus tard) est identique.\n Intégration numérique def trapeze(f, a, b): return (f(a) + f(b))/2 * (b - a) def rect_gauche(f, a, b): return f(a)*(b-a) def integrale(f, a, b, n, methode): p = (b-a)/n s = 0 for i in range(n) : s += methode(f,a+i*p,a+(i+1)*p) return s def f(x) : return np.cos(x)*x**2 + 10 import numpy as np import matplotlib.patches as patches a = -np.pi b = 3/2*np.pi x = np.linspace(a,b,2000) y = f(x) n_possibles = (6,10,20,50,200) fig,axs = plt.subplots(5,2,figsize=(20,20)) for k in range(5) : n = n_possibles[k] p = (b-a)/n I_rect = integrale(f,a,b,n,rect_gauche) I_trap = integrale(f,a,b,n,trapeze) for i in range(n) : rect = plt.Polygon(((a+i*p,0),(a+i*p,f(a+i*p)),(a+(i+1)*p,f(a+i*p)),(a+(i+1)*p,0),(a+i*p,0)),alpha=0.5,facecolor=\u0026#39;#9988DD\u0026#39;,edgecolor=\u0026#39;#9988DD\u0026#39;) trap = plt.Polygon(((a+i*p,0),(a+i*p,f(a+i*p)),(a+(i+1)*p,f(a+(i+1)*p)),(a+(i+1)*p,0),(a+i*p,0)),alpha=0.5,edgecolor=\u0026#39;#3388BB\u0026#39;) for j in range(2) : axs[k][j].plot(x,y,c=\u0026#39;#EE6666\u0026#39;) axs[k][0].add_patch(rect) axs[k][1].add_patch(trap) axs[k][0].text(0,4,s=f\u0026#39;I = {I_rect:.2f}\u0026#39;,fontsize=18,c=\u0026#39;w\u0026#39;,horizontalalignment=\u0026#39;center\u0026#39;) axs[k][1].text(0,4,s=f\u0026#39;I = {I_trap:.2f}\u0026#39;,fontsize=18,c=\u0026#39;w\u0026#39;,horizontalalignment=\u0026#39;center\u0026#39;) À comparer à : $$ \\int_{-\\pi}^{3\\pi/2}(x^2\\cos(x)+10)dx = 2+23\\pi-9\\frac{\\pi^2}{4}\\approx 52,05$$\n Pour quelle valeur de $n$, la valeur de $I$ atteint-elle 52 (à 0,5 près) avec la méthode des rectangles à gauche ?\nVous appelerez cette valeur n_cible et votre code devra l\u0026rsquo;afficher.\n "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/typesbase/",
	"title": "Types de base",
	"tags": [],
	"description": "",
	"content": "Types de base Les types de base en python (les catégories fondamentales des objets manipulés) sont :\n  Les entiers int (en anglais, entier se dit integer).\nExemples : 1, 2, 1012, -18 etc. Leur précision est infinie et leur taille est illimitée en Python.\n   Les flottants float. Ce sont des approximations de nombres réels. La méthode d\u0026rsquo;écriture en machine de ces nombres, équivalente à une écriture scientifique pour nombre binaire, explique leur nom : ce sont des nombres à virgule flottante.\nExemples : 3.58, -0.0398, 2e-7, 3e4 (les puissances de dix, notés e ou E renvoient toujours des nombres flottants). Leur précision est limitée à 53 bits, soit environ 16 chiffres significatifs en décimal.\n C\u0026rsquo;est le point . qui sert de démarcation entre la partie entière et la partie décimale et non la virgule ,.\n   Les booléens bool. Ce sont des variables à deux états, True ou False, permettant de représenter des propositions logiques vraies ou fausses.\n  On peut convertir d\u0026rsquo;un type en l\u0026rsquo;autre en utilisant les fonctions natives int(), float() et bool().\nExemple :\n\u0026gt;\u0026gt;\u0026gt; int(5.8)\n5 int() donne la partie entière d\u0026rsquo;un nombre flottant.\n \u0026gt;\u0026gt;\u0026gt; float(5)\n5.0\n\u0026gt;\u0026gt;\u0026gt; bool(0)\nFalse\n\u0026gt;\u0026gt;\u0026gt; bool(5.8)\nTrue N\u0026rsquo;importe quel nombre non nul (entier ou flottant) est considéré comme vrai.\n Opérations sur les entiers (int) Les entiers sont stables pour les opérations suivantes (le résultat est un entier).\n Addition + \u0026gt;\u0026gt;\u0026gt; 2+3\n5\n Soustraction - \u0026gt;\u0026gt;\u0026gt; 2-3\n-1\n Multiplication * \u0026gt;\u0026gt;\u0026gt; 2*3\n6\n Division entière // a//b donne le quotient de la division euclidienne de a par b.\n\u0026gt;\u0026gt;\u0026gt; 2//3\n0 Attention à ne pas confondre avec la division décimale /.\n Si on travaille avec des entiers, de précision infinie, il est contre-productif d\u0026rsquo;introduire des flottants en utilisant / plutôt que //.\n  Modulo % a%b donne le reste de la division euclidienne de a par b.\n\u0026gt;\u0026gt;\u0026gt; 2%3\n1 L\u0026rsquo;opérateur modulo sert énormément en informatique, notamment pour éviter de dépasser des valeurs (i%8 ne dépassera jamais 7, quoi que valle i).\n Les opérations suivent les règles de priorité habituelles, et on utilise les parenthèses pour les modifier :\n\u0026gt;\u0026gt;\u0026gt; 8//2*(2+2)\n16\nQue va donner 5*3%2 ? Et 5*(3%2) ?\n Puissance ** \u0026gt;\u0026gt;\u0026gt; 2**3\n8\n On parle aussi d\u0026rsquo;opérateur d\u0026rsquo;exponentiation.\n Les puissances négatives retournent des flottants.\n\u0026gt;\u0026gt;\u0026gt; 2**(-3)\n0.125\n  Opérations sur les flottants (float) Du moment qu\u0026rsquo;un des deux nombres est un flottant, les opérations +, - et * donnent des flottants.\n Exemples :\n\u0026gt;\u0026gt;\u0026gt; 3-1.0\n2.0\n\u0026gt;\u0026gt;\u0026gt; 2e-3*500\n1.0\n\u0026gt;\u0026gt;\u0026gt; 2**(5/2)\n5.656854249492381\nLa précision limitée des flottants et le fait qu\u0026rsquo;ils soient définis en binaire peut donner des résultats surprenants.\nExemple :\n\u0026gt;\u0026gt;\u0026gt; 3*0.1\n0.30000000000000004\n La division décimale / retourne un flottant même avec deux entiers, et même si le résultat est entier :\n \u0026gt;\u0026gt;\u0026gt; 10/5\n2.0\n Opérations sur les booléens (bool) Négation logique (not) Sert à nier une proposition :\n   P ¬P     F V   V F    a , b = True, False print(not a,not b) False True\nDisjonction logique (or)    P Q P ∨ Q     V V V   V F V   F V V   F F F    print(True or True,True or False,False or True, False or False) True True True False\nConjonction logique (and)    P Q P ∧ Q     V V V   V F F   F V F   F F F    print(True and True,True and False,False and True, False and False) True False False False\nnot est prioritaire devant and qui est prioritaire devant or.\nQue vaut False or not False and True ?\n  Caractère paresseux des opérateurs or et and Lorsqu\u0026rsquo;on écrit a or b, si a est vrai, alors Python ne s\u0026rsquo;embête pas à évaluer b. Le résultat est nécessairement vrai (cf. la table de vérité), et c\u0026rsquo;est donc ce qui est retourné.\nTrue or qué_pasa True\nDe même, si a est faux, alors a and b retourne False sans évaluer b.\nCe comportement peut s\u0026rsquo;avérer utile pour éviter les erreurs.\nExemple : on veut tester si la première valeur d\u0026rsquo;une liste est positive. Appelons ce test Test. Si la liste est vide, l\u0026rsquo;expression Test va provoquer une erreur.\nOn ajoute alors un deuxième test, Test_vide, qui n\u0026rsquo;est vrai que si la liste est vide. En utilisant l\u0026rsquo;expression (non Test_vide) and Test, on s\u0026rsquo;assure de ne pas lever d\u0026rsquo;erreur en cas de liste vide.\nPour en savoir plus sur l\u0026rsquo;algèbre de Boole :    Comparaisons Les différents comparateurs utilisables en Python sont :\n   comparateur signification     == égal à   != différent de   \u0026gt; supérieur à   \u0026lt; inférieur à   \u0026gt;= supérieur ou égal à   \u0026lt;= inférieur ou égal à    Le résultat d’une comparaison est un booléen.\nNe pas confondre l\u0026rsquo;opérateur d\u0026rsquo;affectation = et l\u0026rsquo;opérateur de comparaison ==.\n La précision finie des nombres flottants rend leur comparaison dangereuse :\n0.1**2 == 0.01 retourne False !\nSolution : utiliser un encadrement.\n0.1**2 \u0026gt; 0.01 - 1e-9 and 0.1**2 \u0026lt; 0.01 + 1e-9 renvoie bien True.\n Les opérateurs de comparaison sont prioritaires devant not, and et or.\nExemple : que vaut not 7.5 \u0026lt; 0.9 or 4 == 4 ?\n "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/",
	"title": "Semestre 1",
	"tags": [],
	"description": "",
	"content": "Semestre 1 Les séances de travaux pratiques du premier semestre poursuivent les objectifs suivants :\n consolider l’apprentissage de la programmation en langage Python qui a été entrepris dans les classes du lycée ; mettre en place un environnement de travail ; mettre en place une discipline de programmation : spécification précise des fonctions et programmes, annotations et commentaires, jeux de tests ; introduire les premiers éléments de complexité des algorithmes ; introduire des outils de validation : variants et invariants.  "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/complexite/",
	"title": "Complexité",
	"tags": [],
	"description": "",
	"content": "Complexité d\u0026rsquo;un algorithme Parmi les 3 questions qu\u0026rsquo;on peut se poser naturellement devant un algorithme (termine-t-il ? est-il correct ? combien de temps met-il ?), on a laissé la dernière en plan dans le chapitre précédent.\nLa question du temps mis par l\u0026rsquo;algorithme est le problème de la complexité de l\u0026rsquo;algorithme.\nL\u0026rsquo;objectif premier d\u0026rsquo;un calcul de complexité algorithmique est de pouvoir comparer l’efficacité d’algorithmes résolvant le même problème. Dans une situation donnée, cela permet donc d\u0026rsquo;établir lequel des algorithmes disponibles est le meilleur (du point de vue temps d\u0026rsquo;exécution).\n   complexité en temps Réaliser un calcul de complexité en temps revient à décompter le nombre d’opérations élémentaires (affectation, calcul arithmétique ou logique, comparaison…) effectuées par l’algorithme.\nPour rendre ce calcul réalisable, on émettra l\u0026rsquo;hypothèse que toutes les opérations élémentaires sont à égalité de coût. En pratique ce n\u0026rsquo;est pas tout à fait exact, mais cette approximation est cependant raisonnable.\nOn pourra donc estimer que le temps d\u0026rsquo;exécution de l\u0026rsquo;algorithme est proportionnel au nombre d’opérations élémentaires.\nLa complexité $T(n)$ d\u0026rsquo;un algorithme va naturellement être fonction de la taille $n$ des données passées en entrée. Cette dépendance est logique, plus ces données seront volumineuses, plus il faudra d\u0026rsquo;opérations élémentaires pour les traiter.\nSouvent la complexité dépendra aussi de la donnée en elle même et pas seulement de sa taille. En particulier la façon dont sont réparties les différentes valeurs qui la constituent.\nRappelons-nous par exemple l\u0026rsquo;algorithme de recherche séquentielle d’un élément dans une liste non triée du cours \u0026ldquo;structures de données\u0026rdquo;. Le principe de l\u0026rsquo;algorithme est simple, on parcourt un par un les éléments jusqu\u0026rsquo;à trouver, ou pas, celui recherché. Ce parcours peut s’arrêter dès le début si le premier élément est \u0026ldquo;le bon\u0026rdquo;. Mais on peut également être amené à parcourir la liste entière si l’élément cherché est en dernière position, ou même n\u0026rsquo;y figure pas. Le nombre d\u0026rsquo;opérations élémentaires effectuées dépend donc non seulement de la taille de la liste, mais également de la répartition de ses valeurs.\nCette remarque nous conduit à préciser un peu notre définition de la complexité en temps. En toute rigueur, on devra en effet distinguer trois formes de complexité en temps :\n  la complexité dans le meilleur des cas : c\u0026rsquo;est la situation la plus favorable, qui correspond par exemple à la recherche d\u0026rsquo;un élément situé à la première postion d\u0026rsquo;une liste, ou encore au tri d\u0026rsquo;une liste déjà triée. la complexité dans le pire des cas : c\u0026rsquo;est la situation la plus défavorable, qui correspond par exemple à la recherche d\u0026rsquo;un élément dans une liste alors qu\u0026rsquo;il n\u0026rsquo;y figure pas, ou encore au tri par ordre croissant d\u0026rsquo;une liste triée par ordre décroissant. la complexité en moyenne : on suppose là que les données sont réparties selon une certaine loi de probabilités.   On calcule le plus souvent la complexité dans le pire des cas, car elle apporte une garantie (pas de mauvaises surprises en tablant sur le pire).\nDernière chose importante à prendre en considération, si la donnée est un nombre entier, la façon de le représenter influera beaucoup sur l’appréciation de la complexité.\nPar exemple, si $n=2020$, on peut considérer que la taille de $n$ est :\nsoit la valeur de $n$ en elle-même, façon la plus naturelle de voir les choses, c.-à-d. $2020$,\nsoit le nombre de chiffres que comporte l\u0026rsquo;écriture en binaire de $n$, c.-à-d. 11,\nsoit le nombre de chiffres que comporte l\u0026rsquo;écriture en décimal de $n$, c.-à-d. 4.\nVu la finalité informatique de nos algorithmes, nous devrions choisir le nombre de chiffres dans l\u0026rsquo;écriture binaire de l\u0026rsquo;entier, mais par souci de simplicité, on considèrera le plus souvent la valeur de l\u0026rsquo;entier comme taille.\nNéanmoins, lors de l\u0026rsquo;étude de la complexité des algorithmes arithmétiques (test de primalité, algorithme d\u0026rsquo;Euclide, etc.), la taille de l\u0026rsquo;entier est le paramètre important et il faudra donc considérer la taille de l\u0026rsquo;entrée $n$ comme étant $\\log_2(n)$.\nExemple : la fonction somme\n1def somme(L) : 2 s = 0 3 for e in L : 4 s += e 5 return s  Le calcul somme([1,2,3]) nécessite à priori 4 opérations (1 fois la ligne 2, et 3 fois la ligne 4). Toutefois, la notion d\u0026rsquo;opération élémentaire n\u0026rsquo;est pas précisément définie : on pourrait considérer par exemple que la ligne 4 fait non pas une, mais deux opérations élémentaires (une somme puis une affectation) et alors somme([1,2,3]) nécessiterait 7 opérations.\n Cette imprécision est sans conséquence, car on estime la complexité \u0026ldquo;à la louche\u0026rdquo;. Pour définir formellement ce que signifie ce \u0026ldquo;à la louche\u0026rdquo;, nous introduisons les trois notations suivantes :\n Étant donné deux fonctions $\\mathbb{N}\\rightarrow \\mathbb{R}^*_+$ $f$ et $g$ : $f(n)$ est un grand $\\mathcal{O}$ de $g(n)$ s\u0026rsquo;il existe une constante $k_2$ telle que pour tout $n$ assez grand $f(n)≤k_2\\cdot g(n)$ ;\non note $f(n) = \\mathcal{O}(g(n))$. Et on dit que $g$ domine $f$ asymptotiquement.\n $f(n)$ est un grand $\\Omega$ de $g(n)$ s\u0026rsquo;il existe une constante $k_1\u0026gt;0$ telle que pour tout $n$ assez grand $k_1\\cdot g(n)≤f(n)$ ;\non note $f(n) = \\Omega(g(n))$.\n $f(n)$ est un grand $\\Theta$ de $g(n)$ s\u0026rsquo;il existe deux constantes $k_1\u0026gt;0$ et $k_2$ telles que pour tout $n$ assez grand $k_1\\cdot g(n)≤f(n)≤k_2\\cdot g(n)$ ;\non note $f(n) = \\Theta(g(n))$.\n$f$ et $g$ sont asymptotiquement du même ordre de grandeur.\n Comme on l\u0026rsquo;a dit, notre souhait est de connaître le nombre d\u0026rsquo;étapes que nécessitera l\u0026rsquo;algorithme dans le pire des cas, quitte à le surestimer. On veut par contre absolument éviter de le sous-estimer ; on se concentre alors sur la première notation, grand $O$ (correspondant à la majoration).\nEn effet, si on sait que $T(n)=O(g(n))$, on est alors assuré que le nombre d\u0026rsquo;étapes $T(n)$ ne sera asymptotiquement jamais plus grand que $g(n)$ (asymptotiquement signifiant en pratique \u0026ldquo;pour des $n$ suffisamment grands\u0026rdquo;).\nExemple : $T(n)=5n+3$\nDès $n\u0026gt;3$, $T(n)\u0026lt;6n$, ce qu\u0026rsquo;on réécrit $T(n)\u0026lt;6\\times g(n)$ avec $g(n)=n$, d\u0026rsquo;où' $T(n)=O(n)$.\nLes complexités algorithmiques sont exprimées comme des grands $\\mathcal{O}$ ou grands $\\mathcal{\\Theta}$ des fonctions de référence. Cela va nous permettre de les classer.\nDes algorithmes appartenant à une même classe sont alors considérés comme de complexité équivalente ; ils ont la même efficacité.\nLe tableau suivant récapitule les complexités de référence (rangées par ordre croissant) :\n   $\\mathcal{O}$ Type de complexité     $\\mathcal{O(1)}$ constant   $\\mathcal{O}(\\ln(n))$ logarithmique   $\\mathcal{O}(n)$ linéaire   $\\mathcal{O}(n\\times\\ln(n))$ quasi-linéaire   $\\mathcal{O}(n^2)$ quadratique   $\\mathcal{O}(n^3)$ cubique   $\\mathcal{O}(2^n)$ exponentiel   $\\mathcal{O}(n!)$ factoriel    Lors de la somme de deux complexités de types différents, la classe de plus grande complexité domine.\nPar exemple : $\\mathcal{O}(n)+\\mathcal{O}(n^2)=\\mathcal{O}(n^2)$.\n Si $T(n)$ est un grand $O$ d\u0026rsquo;une certaine fonction $g$, alors il sera un grand $O$ de toutes les fonctions $h$ qui dominent $g$ (toutes les fonctions appartenant à une classe de complexité supérieure). Laquelle de ces classes désigne la complexité de $T(n)$ ?\nOn choisit toujours la plus petite classe possible pour définir la classe de complexité de $T(n)$, car si on cherche bien à se prémunir contre les mauvaises surprises, cela ne sert à rien de s\u0026rsquo;assurer contre l\u0026rsquo;impossible (cela reviendrait à toujours répondre l\u0026rsquo;infini quand on nous demande une borne supérieure, c\u0026rsquo;est certes vrai mais pas très utile\u0026hellip;).\n Moralité, quand on parle de grand $O$, la plupart du temps, il s\u0026rsquo;agit en fait de grand $Θ$.\n Dans l\u0026rsquo;exemple de $5n+3$, on a $T(n) = O(n)$, et par conséquent on a aussi $T(n)=O(n^2)$, $T(n)=O(n^3)$, etc.\nMais attention, quand on nous demande la complexité asymptotique au pire de $T(n)$, la réponse attendue est bien $O(n)$ !\n Ordres de grandeurs : en supposant qu\u0026rsquo;un système donné permette un milliard d\u0026rsquo;opérations par seconde (de type constant), on obtient les valeurs de temps d\u0026rsquo;exécution suivantes en fonction du type de complexité et de la taille des données :\n   taille des données $\\ln n$ $n$ $n\\ln n$ $n^2$ $n^3$ $2^n$ $n!$     $10^2$ $5$ ns $100$ ns $500$ ns $10$ μs $1$ ms $4.10^{13}$ ans $3.10^{141}$ ans   $10^3$ $7$ ns $1$ μs $7$ μs $1$ ms $1$ s     $10^4$ $9$ ns $10$ μs $90$ μs $100$ ms $17$ min     $10^5$ $12$ ns $100$ μs $1,2$ ms $10$ s $12$ jours     $10^6$ $14$ ns $1$ ms $14$ ms $17$ min $32$ ans       Quelques relations utiles (valables pour toute constante $c$) :\n(1) $\\mathcal{O}(n+c)=\\mathcal{O}(n)$\n(2) $\\mathcal{O}(cn)=\\mathcal{O}(n)$\n(3) $\\mathcal{O}(n/c)=\\mathcal{O}(n)$\n(4) $\\mathcal{O}(c)=1$\n(5) $n\\times\\mathcal{O}(1)=\\mathcal{O}(n)$\n Exemples :\n Le calcul de la somme des $n$ premiers entiers à l’aide d’une formule explicite (n*(n+1)//2) est de complexité constante. Ce même calcul réalisé de façon itérative grâce à la fonction somme() est de complexité linéaire. En effet, la taille de l\u0026rsquo;entrée est $n=$ len(L) et la complexité est en : $$T(n)=\\underbrace{\\mathcal{O}(1)}_\\text{ligne 2}+\\underbrace{n\\times \\underbrace{\\mathcal{O}(1)}_\\text{ligne 4}}_{\\text{for}}=\\mathcal{O}(n)$$ L\u0026rsquo;algorithme de recherche par dichotomie (TP4) est de complexité logarithmique puisque l\u0026rsquo;algorithme nécessite au pire $\\log_2 n$ passages dans la boucle et chaque instruction dans la boucle (comparaison, division euclidienne, affectations) se fait en temps constant $$T(n)=\\log_2(n)\\times \\mathcal{O}(1) = \\mathcal{O}(\\ln n)$$  Plus tordu : trouvons la complexité de la fonction neufs() suivante qui calcule naïvement le plus grand nombre de 9 consécutifs dans l\u0026rsquo;écriture en base 10 de $n$.\ndef neufs(n) : L = [] while n!= 0 : L.append(n%10) n //= 10 M = 0 for k in range(len(L)) : i = k while i \u0026lt; len(L) and L[i]==9 : i += 1 M = max(M, i - k) return M  Chacune des instructions utilisées est en $\\mathcal{O}(1)$ (temps constant). On utilise bien max qui a une complexité linéaire, mais on ne l\u0026rsquo;utilise que sur 2 valeurs.\nOn passe dans le premier while une fois par chiffre de $n$ en base 10 (n//10 fait perdre un chiffre à $n$), soit environ $\\log_{10}(n)$ fois.\nLa liste L contient alors (à moins de 1 près) $\\log_{10}(n)$ valeurs. On passe dans le for $\\log_{10}(n)$ fois, et au pire le même nombre de fois dans le second while.\nLa complexité est donc $T(n)=\\underbrace{\\log_{10}(n) \\times \\mathcal{O}(1)}_{\\text{premier while}}+\\underbrace{\\log_{10}(n) \\times\\log_{10}(n) \\times\\mathcal{O}(1)}_{\\text{boucles imbriquées}}=\\mathcal{O}(\\ln ^2 n)$\n  La complexité sert essentiellement à comparer les algorithmes.\nOn peut aussi tenter de confirmer expérimentalement nos conclusions en mesurant le temps mis par la machine pour faire tourner l\u0026rsquo;algorithme. Grâce au module time, on va ainsi pouvoir vérifier empiriquement que l\u0026rsquo;algorithme de recherche par dichotomie est bien meilleur que l\u0026rsquo;algorithme de recherche naïf. On va aussi tenter d\u0026rsquo;en savoir plus sur l\u0026rsquo;opérateur natif in qui accomplit la même fonction.\nPour cela, on va mesurer le temps mis par les différentes méthodes pour chercher un nombre au hasard entre $0$ et $b$ dans une liste des $b$ premiers entiers. On moyenne ce temps en faisant $50\\,000$ essais avec des nombres à rechercher différents. Puis on multiplie $b$ par $2$ et on recommence :\nimport random import time b, m = 1, 50000 print(\u0026#39;\\n| n | tps algo naïf | tps algo dicho | tps \u0026#34;in\u0026#34; |\u0026#39;) print(\u0026#39;-\u0026#39;*54) for i in range(12) : b *= 2 T = [i for i in range(0,b)] t1 = t2 = t3 = 0 for j in range(m) : x = random.randint(0,b) d1 = time.time() #time() note la valeur de l\u0026#39;horloge (en s) recherche_naïve(x,T) f1 = time.time() d2 = time.time() recherche_dicho(x,T) f2 = time.time() d3 = time.time() x in T f3 = time.time() t1 += f1 - d1 #f1-d1 = laps de temps qu\u0026#39;a duré la recherche linéaire t2 += f2 - d2 #f2-d2 = laps de temps qu\u0026#39;a duré la recherche dicho t3 += f3 - d3 #f3-d3 = laps de temps qu\u0026#39;a duré la recherche avec \u0026#34;in\u0026#34; print(\u0026#39;| {:\u0026gt;4d} |{:^15.2E}|{:^16.2E}|{:^12.2E}|\u0026#39;.format(b,t1/m,t2/m,t3/m)) | n | tps algo naïf | tps algo dicho | tps \u0026quot;in\u0026quot; | ------------------------------------------------------ | 2 | 3.56E-07 | 6.81E-07 | 1.90E-07 | | 4 | 4.04E-07 | 7.87E-07 | 2.12E-07 | | 8 | 4.58E-07 | 8.58E-07 | 2.38E-07 | | 16 | 5.86E-07 | 9.48E-07 | 2.80E-07 | | 32 | 8.11E-07 | 1.06E-06 | 3.60E-07 | | 64 | 1.30E-06 | 1.19E-06 | 5.37E-07 | | 128 | 2.25E-06 | 1.33E-06 | 8.83E-07 | | 256 | 4.18E-06 | 1.53E-06 | 1.57E-06 | | 512 | 8.09E-06 | 1.87E-06 | 2.96E-06 | | 1024 | 1.57E-05 | 2.14E-06 | 5.70E-06 | | 2048 | 3.09E-05 | 2.38E-06 | 1.12E-05 | | 4096 | 6.13E-05 | 2.63E-06 | 2.22E-05 | in est plus rapide que l\u0026rsquo;algo de recherche naïf mais ils réagissent tous deux pareil à un changement d\u0026rsquo;échelle ; si on on multiplie n par 2, les deux algorithmes mettent 2 fois plus de temps. C\u0026rsquo;est ce qui nous montre qu\u0026rsquo;ils ont la même complexité ! Pour la recherche dichotomique en revanche, une multiplication du nombre de valeur par 2 ne se solde pas par un doublement du temps, mais par l\u0026rsquo;ajout d\u0026rsquo;un temps constant seulement. C\u0026rsquo;est typique d\u0026rsquo;une complexité logarithmique. On remarque que\nL\u0026rsquo;opérateur in semble de complexité linéaire. Derrière ces deux petits caractères se cache donc du code loin d\u0026rsquo;être de la complexité constante des opérations de base. Ce n\u0026rsquo;est pas la taille qui compte\u0026hellip;\n  Complexité en espace La complexité en espace est quant à elle la taille de la mémoire nécessaire pour stocker les différentes structures de données utilisées lors de l\u0026rsquo;exécution de l\u0026rsquo;algorithme.\nOn considère pour simplifier qu\u0026rsquo;un type de base (un entier, un flottant, un caractère,\u0026hellip;) occupe une place en mémoire constante (complexité en $\\mathcal{O}(1)$).\nExemples : Pour la fonction somme(), on constate que si la liste L contient des entiers ou des flottants, chaque variable intermédiaire (e et s) contient un type de base, donc demande une place en mémoire en $\\mathcal{O}(1)$ et donc la complexité en mémoire au pire est en $\\mathcal{O}(1)$.\nPour la fonction neufs(), la complexité en mémoire vient de la variable L (toutes les autres variables demandent $\\mathcal{O}(1)$ en mémoire). Or cette variable va contenir environ $\\log_{10}(n)$ éléments d’où une complexité en mémoire de $\\mathcal{O}(\\log_{10}(n)) = \\mathcal{O}(ln(n))$.\n  Retour sur les TP du premier semestre :\n TP 1 : quelle est la complexité des fonctions recherche, recherche_dico, max, maximum et max_2 ? TP 2 : quelle est la complexité de cherche_mot, cherche_duplicata et cherche_duplicata_bis ? TP 4 : quelle est la complexité de recherche_dicho_corr ? Et celle de racine en fonction du nombre de chiffres significatifs ? TP 6 : trier les algorithmes de tri en différentes catégories de complexité.   Dans la vidéo suivante, on compare plusieurs algorithmes dont la mission est de trouver un doublon dans une liste. Quel est le meilleur ? Étudions leurs complexités en temps et en espace.\n  "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp3data/",
	"title": "TP 3 : utilisation de modules",
	"tags": [],
	"description": "",
	"content": "L\u0026rsquo;idée de ce TP est de constater combien des modules/bibliothèques adaptés peuvent fournir des outils puissants et permettre un gain de temps gigantesque.\nOn va se placer dans un des champs les plus porteurs actuellement (et où python est très utilisé), l\u0026rsquo;analyse de données.\nCliquez sur cette invitation pour récupérer le repository du TP. Exploration d\u0026rsquo;un jeu de données Statistiques simples import pandas as pd # bibliothèques dédiée au traitement de jeux de données import matplotlib.pyplot as plt # bibliothèque graphique import seaborn as sns # bibliothèque graphique reposant sur matplotlib et dédiée plus particulièrement à la représentation de jeux de données import numpy as np # bibliothèque puissante permettant de gérer des tableaux multidimensionnels import plotly.express as px # libraire permettant des graphes interactifs import plotly.graph_objects as go # complémentaire à la première (seulement utile dans les cas complexes) Pour pouvoir être importé, un module doit avoir été préalablement installé. Les plus importants sont installés par défaut dans certaines distributions (comme Anaconda).\nLes gros modules sont généralement importés sous la forme import module as x où x est un raccourci pour le nom du module (np pour numpy ou plt pour matplotlib.pyplot). Se référer au cours Python pour les autres formes d\u0026rsquo;importation.\nPour obtenir de l\u0026rsquo;aide sur un module, on peut demander à Python (help(pd) par exemple pour avoir de l\u0026rsquo;aide sur pandas ou help(pd.read_csv) pour avoir de l\u0026rsquo;aide sur la fonction spécifique read_csv), mais il y a généralement beaucoup moins indigeste : l\u0026rsquo;aide en ligne des modules (pour Pandas par exemple).\n# paramètres par défaut pour les graphes plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 6) plt.rcParams[\u0026#39;font.family\u0026#39;] = \u0026#34;serif\u0026#34; plt.rcParams[\u0026#39;font.size\u0026#39;] = 13 sns.set_style(\u0026#34;white\u0026#34;) Le premier jeu de données qu\u0026rsquo;on va utiliser est issu du World Happiness report (une publication annuelle de l\u0026rsquo;ONU mesurant le degrés de bonheur de la population mondiale par pays à partir de sondages).\nurl = \u0026#34;https://raw.githubusercontent.com/Info-TSI-Vieljeux/s1-tp3/main/2020.csv\u0026#34; data_monde = pd.read_csv(url,sep=\u0026#34;;\u0026#34;,index_col=0) # data_monde est une dataframe Pandas # Une dataframe est une sorte de dictionnaire dont les clés sont les en-têtes des colonnes et dont les lignes sont indexées. data_monde   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Région du monde Score de bonheur Écart-type PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Score de bonheur en Distopie   Pays               Finland Western Europe 7.8087 0.031156 10.639267 0.954330 71.900825 0.949172 -0.059482 0.195445 1.972317   Denmark Western Europe 7.6456 0.033492 10.774001 0.955991 72.402504 0.951444 0.066202 0.168489 1.972317   Switzerland Western Europe 7.5599 0.035014 10.979933 0.942847 74.102448 0.921337 0.105911 0.303728 1.972317   Iceland Western Europe 7.5045 0.059616 10.772559 0.974670 73.000000 0.948892 0.246944 0.711710 1.972317   Norway Western Europe 7.4880 0.034837 11.087804 0.952487 73.200783 0.955750 0.134533 0.263218 1.972317   ... ... ... ... ... ... ... ... ... ... ...   Central African Republic Sub-Saharan Africa 3.4759 0.115183 6.625160 0.319460 45.200001 0.640881 0.082410 0.891807 1.972317   Rwanda Sub-Saharan Africa 3.3123 0.052425 7.600104 0.540835 61.098846 0.900589 0.055484 0.183541 1.972317   Zimbabwe Sub-Saharan Africa 3.2992 0.058674 7.865712 0.763093 55.617260 0.711458 -0.072064 0.810237 1.972317   South Sudan Sub-Saharan Africa 2.8166 0.107610 7.425360 0.553707 51.000000 0.451314 0.016519 0.763417 1.972317   Afghanistan South Asia 2.5669 0.031311 7.462861 0.470367 52.590000 0.396573 -0.096429 0.933687 1.972317    153 rows × 10 columns\n Précisions sur ces données :\n le score de bonheur est un score sur 10 correspondant à la moyenne des réponses des sondés (0 correspond à la pire vie possible et 10 à la meilleure) ce n\u0026rsquo;est pas le PIB par habitant mais son logarithme qui est utilisé pour ne pas avoir des valeurs sur des ordres de grandeur trop différents d\u0026rsquo;une colonne à l\u0026rsquo;autre entraide sociale : moyenne des réponses à la question binaire \u0026ldquo;en cas de difficultés, pouvez-vous compter sur de la famille ou des amis pour vous aider ?\u0026rdquo; (0 : non, 1 : oui) liberté des choix de vie : moyenne des réponses à la question binaire \u0026ldquo;êtes-vous satisfait ou non de votre liberté à choisir ce que vous voulez faire de votre vie ?\u0026rdquo; (0 : non, 1 : oui) générosité : moyenne des réponses à \u0026ldquo;Avez-vous donné à une association caritative le mois dernier ?\u0026rdquo; ajustée par rapport au PIB par habitant (valeur résiduelle) corruption perçue : moyenne des réponses à la question binaire \u0026ldquo;la corruption est-elle répandue dans le gouvernement ?\u0026rdquo; (0 : non, 1 : oui)  On simplifie un peu le jeu de données en retirant la colonne \u0026lsquo;Écart-type\u0026rsquo; et \u0026lsquo;Score de bonheur en distopie\u0026rsquo; (score minimal obtenu).\ndata_monde.drop(columns=[\u0026#39;Écart-type\u0026#39;,\u0026#39;Score de bonheur en Distopie\u0026#39;], inplace=True) data_monde.head(3)   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue   Pays             Finland Western Europe 7.8087 10.639267 0.954330 71.900825 0.949172 -0.059482 0.195445   Denmark Western Europe 7.6456 10.774001 0.955991 72.402504 0.951444 0.066202 0.168489   Switzerland Western Europe 7.5599 10.979933 0.942847 74.102448 0.921337 0.105911 0.303728     data_monde.tail(3)   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue   Pays             Zimbabwe Sub-Saharan Africa 3.2992 7.865712 0.763093 55.61726 0.711458 -0.072064 0.810237   South Sudan Sub-Saharan Africa 2.8166 7.425360 0.553707 51.00000 0.451314 0.016519 0.763417   Afghanistan South Asia 2.5669 7.462861 0.470367 52.59000 0.396573 -0.096429 0.933687     Traçons un histogramme brut du jeu de données complet pour y voir plus clair (la librairie Seaborn rend cela très simple).\nsns.histplot(data=data_monde) La méthode describe s\u0026rsquo;appliquant à des dataframe pandas retourne un résumé statistique très pratique des données de chaque colonne :\ndata_monde.describe()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue     count 153.00000 153.000000 153.000000 153.000000 153.000000 153.000000 153.000000   mean 5.47324 9.295706 0.808721 64.445529 0.783360 -0.014568 0.733120   std 1.11227 1.201588 0.121453 7.057848 0.117786 0.151809 0.175172   min 2.56690 6.492642 0.319460 45.200001 0.396573 -0.300907 0.109784   25% 4.72410 8.350645 0.737217 58.961712 0.714839 -0.127015 0.683019   50% 5.51500 9.456313 0.829204 66.305145 0.799805 -0.033665 0.783122   75% 6.22850 10.265124 0.906747 69.289192 0.877709 0.085429 0.849151   max 7.80870 11.450681 0.974670 76.804581 0.974998 0.560664 0.935585      Pour confirmer certaines des valeurs, vous allez construire différentes fonctions :\n une fonction decompte qui retourne le nombre d\u0026rsquo;éléments d\u0026rsquo;une liste, une fonction moyenne qui retourne la moyenne des éléments d\u0026rsquo;une liste, une fonction mediane qui retourne la médiane des éléments d\u0026rsquo;une liste triée en ordre croissant.  L\u0026rsquo;utilisation de fonctions statistiques déjà existantes est bien sûr prohibée.\n  Calculez, pour les 3 formes d\u0026rsquo;importation du module, l\u0026rsquo;écart-type des éléments de la liste Liste_scores en utilisant la fonction stdev du module statistics.\nIl s\u0026rsquo;agit d\u0026rsquo;évaluer directement l\u0026rsquo;expresion (le nombre doit s\u0026rsquo;afficher sous la cellule sans utiliser de print).\n Tracons maintenant un diagramme en batons des scores de bonheur des 60 premiers pays.\nfig,ax = plt.subplots(figsize=(20,4)) sns.barplot(ax = ax,x = data_monde.index[:60], y = data_monde[\u0026#39;Score de bonheur\u0026#39;].head(60)) plt.xticks(rotation=90) ax.set_xlabel(\u0026#39;\u0026#39;) On remarque que les pays sont classés par score de bonheur décroissant dans le jeu de données d\u0026rsquo;origine.\nMais on peut évidemment choisir un autre critère de classement si on le désire :\ndata_monde.sort_values(by=\u0026#34;PIB par habitant (log)\u0026#34;,ascending=True).head(10)   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue   Pays             Burundi Sub-Saharan Africa 3.7753 6.492642 0.490326 53.400002 0.626350 -0.017552 0.606935   Central African Republic Sub-Saharan Africa 3.4759 6.625160 0.319460 45.200001 0.640881 0.082410 0.891807   Congo (Kinshasa) Sub-Saharan Africa 4.3110 6.694256 0.672159 52.900002 0.700794 0.083638 0.809404   Niger Sub-Saharan Africa 4.9096 6.842167 0.617435 53.500095 0.759772 0.013861 0.722530   Liberia Sub-Saharan Africa 4.5579 7.054380 0.709281 56.096313 0.735269 0.042273 0.856376   Malawi Sub-Saharan Africa 3.5380 7.062226 0.544007 57.592888 0.803223 0.021433 0.731701   Mozambique Sub-Saharan Africa 4.6236 7.069346 0.723874 54.205822 0.864452 0.032376 0.683019   Sierra Leone Sub-Saharan Africa 3.9264 7.268803 0.636142 50.865143 0.715315 0.088661 0.861331   Madagascar Sub-Saharan Africa 4.1656 7.281686 0.668196 59.105427 0.557574 -0.011824 0.817486   Gambia Sub-Saharan Africa 4.7506 7.321815 0.693169 55.012016 0.733163 0.343199 0.690718     data_monde.sort_values(by=\u0026#34;Corruption perçue\u0026#34;,ascending=False).head()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue   Pays             Bulgaria Central and Eastern Europe 5.1015 9.869319 0.937840 66.803978 0.745178 -0.143908 0.935585   Romania Central and Eastern Europe 6.1237 10.107584 0.825162 67.207237 0.842823 -0.197815 0.934300   Bosnia and Herzegovina Central and Eastern Europe 5.6741 9.455817 0.829204 67.808136 0.651353 0.098275 0.933769   Afghanistan South Asia 2.5669 7.462861 0.470367 52.590000 0.396573 -0.096429 0.933687   Kosovo Central and Eastern Europe 6.3252 9.204430 0.820727 63.885555 0.861536 0.190934 0.922328     data_monde.sort_values(by=\u0026#34;Générosité\u0026#34;,ascending=False).iloc[[45]]   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue   Pays             Denmark Western Europe 7.6456 10.774001 0.955991 72.402504 0.951444 0.066202 0.168489     D\u0026rsquo;après la cellule précédente, le 46e (le 1er est à l\u0026rsquo;indice 0) meilleur score de générosité appartient au Danemark.\n Quel pays correspond à la 59e plus courte espérance de vie en bonne santé ?\n On peut aussi aisément filtrer le jeu de données en fonction de n\u0026rsquo;importe quel critère :\ndata_monde[(data_monde[\u0026#34;Espérance de vie en bonne santé\u0026#34;]\u0026gt;60) \u0026amp; (data_monde[\u0026#34;Espérance de vie en bonne santé\u0026#34;]\u0026lt;61)] # Rq : pandas nécessite les opérateurs logiques bit à bit \u0026#39;\u0026amp;\u0026#39; (et) et \u0026#39;|\u0026#39; (ou)  # plutôt que les opérateurs élément par élément \u0026#39;and\u0026#39; et \u0026#39;or\u0026#39; qui lèveraient une erreur.   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue   Pays             Kenya Sub-Saharan Africa 4.5830 8.029776 0.702652 60.096931 0.829748 0.294682 0.831499   India South Asia 3.5733 8.849824 0.592201 60.215187 0.881445 0.057552 0.772043      Quel pays possède un score de bonheur inférieur à 5 malgré une valeur de corruption perçue inférieure à 0.5 ?\n Pour récupérer l\u0026rsquo;ensemble des données d\u0026rsquo;un pays en particulier, on utilise :\ndata_monde.loc[\u0026#39;France\u0026#39;] Région du monde Western Europe Score de bonheur 6.6638 PIB par habitant (log) 10.584223 Entraide sociale 0.937104 Espérance de vie en bonne santé 73.801933 Liberté des choix de vie 0.825468 Générosité -0.130642 Corruption perçue 0.583521 Name: France, dtype: object Pour chaque variable mesurée (chaque colonne), on peut facilement tracer des histogrammes illustrant la répartition des valeurs.\nsns.displot(data_monde, x=\u0026#34;Score de bonheur\u0026#34;, bins=20, kde=True, height=4, aspect=3) # bins contrôle le nombre de classes On peut faciliter la lecture des graphes en les rendant interactif.\nOn utilise pour cela la bibliothèque Plotly express qui sait (comme seaborn) parler à une dataframe pandas.\nOn peut zoomer sur ces graphiques interactifs et obtenir des informations en survolant avec le curseur.\npx.histogram(data_monde,\u0026#39;Corruption perçue\u0026#39;,nbins=40,title=\u0026#34;Corruption perçue\u0026#34;) # Cette fois-ci, le nombre de classes est désigné par nbins.     Plotly.d3.json(\"/corrup.json\", function(err, fig) { Plotly.plot('\\/corrup.json', fig.data, fig.layout, {responsive: true}); }); \n Modifez le graphe précedent pour répondre à cette question : combien la classe la plus peuplée de l\u0026rsquo;histogramme de l\u0026rsquo;espérence de vie en bonne santé compte-elle de valeurs si l\u0026rsquo;histogramme comporte 30 classes ?\n  Regroupement des données On remarque que le jeu de données contient une colonne catégorielle : \u0026ldquo;Région du monde\u0026rdquo;.\nCela va nous permettre d\u0026rsquo;explorer de possibles dynamiques régionales : est-ce que les pays d\u0026rsquo;une même zone ont des indicateurs semblables ?\npd.unique(data_monde[\u0026#34;Région du monde\u0026#34;]) # permet d\u0026#39;afficher une seule fois chacune des valeurs différentes de la colonne array(['Western Europe', 'North America and ANZ','Middle East and North Africa', 'Latin America and Caribbean','Central and Eastern Europe', 'East Asia', 'Southeast Asia','Commonwealth of Independent States', 'Sub-Saharan Africa','South Asia'], dtype=object)\nTraçons des diagrammes en boîte à moustaches représentant les scores de bonheur pour chacune des régions.\nConstruction des boîtes à moustaches (ou diagrammes en boîtes de Tukey) :\nLes frontières de la boites sont formées des premier Q1 et troisième quartile Q3 et la barre dans la boite correspond à la médiane (50% des valeurs sont donc dans la boîte).\nPour les moustaches, on calcule d\u0026rsquo;abord 1,5 fois la distance interquartile entre le premier et le troisième quartile (la longueur de la boîte) : L=1,5×(Q3-Q1). Si les valeurs ne s\u0026rsquo;étendent pas au-delà de Q1-L et Q3+L, on trace les moustaches aux valeurs min et max. Sinon, on trace les moustaches au niveau des valeurs précédant immédiatement la limite. Les valeurs au-delà sont représentées par des points et sont le plus souvent considérées comme des anomalies.\n À nouveau Seaborn rend cela très simple\u0026hellip;\nsns.set_style(\u0026#34;white\u0026#34;) fig, ax = plt.subplots(figsize=(12,8)) sns.boxplot(ax = ax, x=\u0026#34;Score de bonheur\u0026#34;, y=\u0026#34;Région du monde\u0026#34;, palette=\u0026#34;husl\u0026#34;, data=data_monde) sns.despine(offset=10, trim=True) ax.set_ylabel(\u0026#39;\u0026#39;) Traçons maintenant un graphe plus général représentant toutes les relations possibles entre deux axes du jeu de données pour voir si certaines combinaisons discriminent plus nettement les différentes régions.\n# Un peu long à s\u0026#39;exécuter (environ 30 s) g = sns.pairplot(data_monde, hue=\u0026#34;Région du monde\u0026#34;, corner=True) g._legend.set_bbox_to_anchor((0.6, 0.8)) On constate que les groupes régionaux sont relativement homogènes pour la plupart des critères.\nZoomons sur un de ces graphes :\nsns.set_style(\u0026#34;whitegrid\u0026#34;) sns.jointplot(data=data_monde,x=\u0026#34;PIB par habitant (log)\u0026#34;, y=\u0026#34;Score de bonheur\u0026#34;, hue=\u0026#34;Région du monde\u0026#34;, kind=\u0026#39;scatter\u0026#39;, height=8, legend=False) Une version interactive du même graphique permet de consulter les informations pour chaque point :\npx.scatter(data_monde,x=\u0026#39;PIB par habitant (log)\u0026#39;, y=\u0026#39;Score de bonheur\u0026#39;, hover_name=data_monde.index, color=\u0026#39;Région du monde\u0026#39;)    Plotly.d3.json(\"/zoompairplot.json\", function(err, fig) { Plotly.plot('\\/zoompairplot.json', fig.data, fig.layout, {responsive: true}); });   Trouvez la région du monde représentée sur le graphe suivant (le graphe interactif permet de trouver la réponse facilement).  Allons maintenant au-delà de la proximité géographique pour regrouper les pays en 3 grands blocs socioéconomiques : \u0026ldquo;Nord\u0026rdquo;, \u0026ldquo;Sud\u0026rdquo;, \u0026ldquo;Intermédiaire\u0026rdquo;.\nconditions = [(data_monde[\u0026#39;Région du monde\u0026#39;] == \u0026#39;Western Europe\u0026#39;) | (data_monde[\u0026#39;Région du monde\u0026#39;] == \u0026#39;North America and ANZ\u0026#39;),(data_monde[\u0026#39;Région du monde\u0026#39;] == \u0026#39;South Asia\u0026#39;) | (data_monde[\u0026#39;Région du monde\u0026#39;] == \u0026#39;Sub-Saharan Africa\u0026#39;)] choix = [\u0026#39;\u0026#34;Nord\u0026#34;\u0026#39;, \u0026#39;\u0026#34;Sud\u0026#34;\u0026#39;] data_monde[\u0026#39;Groupe\u0026#39;] = np.select(conditions, choix, default=\u0026#39;Autres\u0026#39;) deux_gpes = data_monde[data_monde[\u0026#34;Groupe\u0026#34;].isin([\u0026#39;\u0026#34;Nord\u0026#34;\u0026#39;,\u0026#39;\u0026#34;Sud\u0026#34;\u0026#39;])] # Un peu long à s\u0026#39;exécuter (environ 30 s) sns.set_style(\u0026#34;white\u0026#34;) g = sns.PairGrid(data_monde, diag_sharey=False, hue=\u0026#34;Groupe\u0026#34;) g.map_upper(sns.scatterplot) g.map_lower(sns.kdeplot,common_norm=False) g.map_diag(sns.histplot,bins=20,kde=True) g.add_legend(title=\u0026#34;Grands groupes\u0026#34;,adjust_subtitles=True) L\u0026rsquo;homogénéité de ces 3 groupes saute aux yeux.\n Corrélations Les graphiques précédents mettent en évidence des corrélations assez fortes entre certaines grandeurs.\nCreusons un peu.\ng = sns.PairGrid(data_monde, y_vars=[\u0026#34;Score de bonheur\u0026#34;], x_vars=[\u0026#34;PIB par habitant (log)\u0026#34;, \u0026#34;Corruption perçue\u0026#34;], height=7, aspect=1.5) g.map(sns.regplot) On constate sur cet exemple que le score de bonheur est corrélé positivement avec le PIB par habitant et négativement avec le degré de corruption perçue.\nPour avoir un panorama complet, traçons la matrice de corrélation donnant, pour chaque couple de variable, la valeur du coefficient de corrélation $r$ (valeur entre -1 et 1 traduisant le degré de dépendance linéaire entre deux variables) :\nfig, ax = plt.subplots(figsize=(12,10)) cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True).reversed() # choix de la palette de couleurs sns.heatmap(data_monde.iloc[:,1:].corr(), cmap=cmap, center=0, annot=True, fmt=\u0026#34;.2f\u0026#34;, linewidth = 0.5, ax=ax)  Citez les deux variables les moins corrélées entre elles (donner les noms exacts tels qu\u0026rsquo;ils apparaissent dans les données, attention à la casse). L\u0026rsquo;ordre des variables n\u0026rsquo;est pas important.\n  Fin du TP3a\n Un chouïa d\u0026rsquo;apprentissage automatique (machine learning) On a vu qu\u0026rsquo;un regroupement des données en 3 grands groupes \u0026ldquo;Nord\u0026rdquo;, \u0026ldquo;Sud\u0026rdquo; et \u0026ldquo;Intermédiaire\u0026rdquo; semble plutôt cohérent.\nMais pourquoi pas laisser un algorithme décider lui-même de qui va le mieux ensemble ? Ensuite nous pourrons vérifier si cela recoupe notre découpage fait à la main.\nOn appelle cela un apprentissage non supervisé.\nNous allons utiliser l\u0026rsquo;algorithme des k-moyennes pour partitionner automatiquement nos données.\nIl consiste à placer chaque point de données dans un espace à $n$ dimensions où $n$ est le nombre de variables (les descripteurs) et chercher à les regrouper en clusters en fonction de leurs distances.\nChaque variable correspondant à un axe du repère.\nPour aider l\u0026rsquo;algorithme, on peut tenter de réduire la dimension de l\u0026rsquo;espace dans lequel chaque point de données est plongé en utilisant une analyse en composantes principales.\nL\u0026rsquo;idée est de déterminer les combinaisons des différentes variables expliquant le mieux la variance des données. Chaque nouvel axe ainsi formé (les composantes principales) explique une part décroissante mais complémentaire de la variance (sur la deuxième composante, les données sont moins étalées que sur la première, mais elles s\u0026rsquo;étalent dans une direction orthogonale, et ainsi de suite).\nProjeter les données sur les premières composantes permet de les étaler le plus possible. On peut ainsi réduire l\u0026rsquo;espace à n dimensions du départ à un espace de seulement 2 ou 3 dimensions expliquant la majorité de la variance des données.\nL\u0026rsquo;animation suivante montre comment serait sélectionné l\u0026rsquo;axe de la composante principale dans un espace à deux dimensions : il correspond à la position de la droite pour laquelle la distance cumulée de tous les points à la droite est la plus grande.\nLa bibliothèque Scikit-learn, destinée à l\u0026rsquo;apprentissage automatique, contient tout ce qu\u0026rsquo;il nous faut :\nfrom sklearn.decomposition import PCA # l\u0026#39;algorithme d\u0026#39;analyse en composantes principales (PCA en anglais) from sklearn.preprocessing import StandardScaler # pour centrer-réduire les données from sklearn.cluster import KMeans # l\u0026#39;algorithme des k-moyennes variables = data_monde.columns.values[1:-1] scaler = StandardScaler() X = scaler.fit_transform(data_monde[variables]) # chaque vecteur correspondant à chacune des variables est maintenant centré-réduit pca = PCA() components = pca.fit_transform(X) Quelle combinaison des variables de départ utilise la première composante ?\ndata = data_monde.copy() # pour pouvoir revenir sur le graphe suivant même après ajout de colonnes à data_monde n_c = 1 # numéro de la composante principale à décrire px.bar(components.T, x=data.columns.values[1:-1], y=n_c-1, labels={f\u0026#34;{n_c-1}\u0026#34;: f\u0026#34;Composante Principale (CP) {n_c}\u0026#34;})    Plotly.d3.json(\"/compppale.json\", function(err, fig) { Plotly.plot('\\/compppale.json', fig.data, fig.layout, {responsive: true}); });   Quelle est le nom de la variable participant le plus à la composante principale n°34 ?\n Représentons le pourcentage de variance expliquée par chacune des composantes :\nexp_var_cumul = np.cumsum(pca.explained_variance_ratio_) fig = px.bar(x=range(1, exp_var_cumul.shape[0] + 1),y=pca.explained_variance_ratio_,labels={\u0026#34;x\u0026#34;: \u0026#34;composante\u0026#34;, \u0026#34;y\u0026#34;: \u0026#34;% variance expliquée\u0026#34;}) fig.add_scatter(x=list(range(1, exp_var_cumul.shape[0] + 1)), y=exp_var_cumul, name=\u0026#34;\u0026#34;, showlegend=False)    Plotly.d3.json(\"/explvariance.json\", function(err, fig) { Plotly.plot('\\/explvariance.json', fig.data, fig.layout, {responsive: true}); }); \nLes trois premières composantes expliquent plus de 80% de la variance !\nPlaçons les données dans un espace réduit à ces 3 dimensions :\npx.scatter_3d(components, x=0, y=1, z=2, color=data_monde[\u0026#39;Groupe\u0026#39;], labels={\u0026#39;0\u0026#39;: \u0026#39;CP 1\u0026#39;, \u0026#39;1\u0026#39;: \u0026#39;CP 2\u0026#39;, \u0026#39;2\u0026#39;: \u0026#39;CP 3\u0026#39;}, hover_name=data_monde.index)    Plotly.d3.json(\"/scat3Dgpe.json\", function(err, fig) { Plotly.plot('\\/scat3Dgpe.json', fig.data, fig.layout, {responsive: true}); });  On constate à nouveau que nos 3 groupes discriminent plutôt très bien nos données même si quelques chevauchements existent.\nC\u0026rsquo;est le moment d\u0026rsquo;utiliser l\u0026rsquo;algorithme des k-moyennes pour essayer de former 3 groupes homogènes :\n# on ne garde que les 3 premières composantes principales pca = PCA(n_components = 3) pca.fit(X) score_pca = pca.transform(X) kmeans_pca = KMeans(n_clusters=3,init=\u0026#39;k-means++\u0026#39;,random_state=42) kmeans_pca.fit(score_pca) data_monde[\u0026#34;Cluster\u0026#34;]=kmeans_pca.labels_.astype(str) data_monde.head(3)   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Groupe Cluster   Pays               Finland Western Europe 7.8087 10.639267 0.954330 71.900825 0.949172 -0.059482 0.195445 \"Nord\" 2   Denmark Western Europe 7.6456 10.774001 0.955991 72.402504 0.951444 0.066202 0.168489 \"Nord\" 2   Switzerland Western Europe 7.5599 10.979933 0.942847 74.102448 0.921337 0.105911 0.303728 \"Nord\" 2     fig = px.scatter_3d(components, x=0, y=1, z=2, color=data_monde[\u0026#39;Cluster\u0026#39;], labels={\u0026#39;0\u0026#39;: \u0026#39;CP 1\u0026#39;, \u0026#39;1\u0026#39;: \u0026#39;CP 2\u0026#39;, \u0026#39;2\u0026#39;: \u0026#39;CP 3\u0026#39;}, color_discrete_sequence=px.colors.qualitative.Bold, hover_name=data_monde.index) fig.update_layout(legend_title = \u0026#34;Cluster\u0026#34;)    Plotly.d3.json(\"/scat3Dclust.json\", function(err, fig) { Plotly.plot('\\/scat3Dclust.json', fig.data, fig.layout, {responsive: true}); });  Les 3 clusters créés reproduisent à peu de chose près les 3 groupes \u0026ldquo;Nord\u0026rdquo;, \u0026ldquo;Sud\u0026rdquo;, \u0026ldquo;Intermédiaire\u0026rdquo; construits à la main.\n À quel cluster correspondent approximativement les pays du groupe \u0026ldquo;Sud\u0026rdquo; ?\n Mais l\u0026rsquo;accord n\u0026rsquo;est pas parfait !\n Citez un pays qui appartient au groupe \u0026ldquo;Nord\u0026rdquo; mais qui n\u0026rsquo;appartient pas au cluster lui correspondant.\n Nous allons voir dans la prochaine partie du TP comment représenter ces données sur une carte pour y voir plus clair.\n Fin du TP3b\n Un peu de géographie Le module suivant va permettre d\u0026rsquo;ajouter à nos données le code à 3 lettres (SO 3166-1 alpha-3) de chaque pays.\nMais pourquoi donc ? plotly express permet de tracer la carte d\u0026rsquo;un pays directement à partir de ce petit code de 3 lettres !\nimport country_converter as coco iso3 = coco.convert(names=data_monde.index, to=\u0026#39;ISO3\u0026#39;, not_found=None) data_monde[\u0026#34;code\u0026#34;] = iso3 data_monde.head()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Groupe Cluster code   Pays                Finland Western Europe 7.8087 10.639267 0.954330 71.900825 0.949172 -0.059482 0.195445 \"Nord\" 2 FIN   Denmark Western Europe 7.6456 10.774001 0.955991 72.402504 0.951444 0.066202 0.168489 \"Nord\" 2 DNK   Switzerland Western Europe 7.5599 10.979933 0.942847 74.102448 0.921337 0.105911 0.303728 \"Nord\" 2 CHE   Iceland Western Europe 7.5045 10.772559 0.974670 73.000000 0.948892 0.246944 0.711710 \"Nord\" 2 ISL   Norway Western Europe 7.4880 11.087804 0.952487 73.200783 0.955750 0.134533 0.263218 \"Nord\" 2 NOR     fig = px.choropleth(data_monde, locations = \u0026#34;code\u0026#34;, color = \u0026#34;Score de bonheur\u0026#34;, projection = \u0026#34;orthographic\u0026#34;, color_continuous_scale = \u0026#34;Spectral_r\u0026#34;, hover_name = data_monde.index, hover_data = {\u0026#34;code\u0026#34; : False}) fig.update_geos( showland = True, landcolor = \u0026#34;LightGrey\u0026#34;, showocean = True, oceancolor = \u0026#34;LightBlue\u0026#34;, showlakes = True, lakecolor = \u0026#34;LightBlue\u0026#34;, showframe = False) fig.update_layout(margin={\u0026#34;r\u0026#34;:0,\u0026#34;t\u0026#34;:0,\u0026#34;l\u0026#34;:0,\u0026#34;b\u0026#34;:0}) fig.show()    Plotly.d3.json(\"/cartechoro1.json\", function(err, fig) { Plotly.plot('\\/cartechoro1.json', fig.data, fig.layout, {responsive: true}); });  On est maintenant paré pour représenter les 3 clusters obtenus par l\u0026rsquo;algo des k-moyennes du tp3b.\ndata_monde[\u0026#34;Cluster\u0026#34;] = [f\u0026#39;n°{cluster}\u0026#39; for cluster in data_monde[\u0026#34;Cluster\u0026#34;].astype(\u0026#39;int64\u0026#39;) if cluster != \u0026#39;nan\u0026#39;] data_monde.head(1)   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Région du monde Score de bonheur PIB par habitant (log) Entraide sociale Espérance de vie en bonne santé Liberté des choix de vie Générosité Corruption perçue Groupe Cluster code   Pays                Finland Western Europe 7.8087 10.639267 0.95433 71.900825 0.949172 -0.059482 0.195445 \"Nord\" n°2 FIN     fig = px.choropleth(data_monde, locations = \u0026#34;code\u0026#34;, color = \u0026#34;Cluster\u0026#34;, projection = \u0026#34;natural earth\u0026#34;, color_discrete_sequence = px.colors.qualitative.Set2, hover_name = data_monde.index, hover_data = {\u0026#34;code\u0026#34; : False} ) #fig.update_geos(fitbounds=\u0026#34;locations\u0026#34;, visible=True) fig.update_layout(margin = {\u0026#34;r\u0026#34;:0,\u0026#34;t\u0026#34;:0,\u0026#34;l\u0026#34;:0,\u0026#34;b\u0026#34;:0}) fig.update_geos(showframe = False) fig.show()    Plotly.d3.json(\"/cartechoro2.json\", function(err, fig) { Plotly.plot('\\/cartechoro2.json', fig.data, fig.layout, {responsive: true}); });  Terminons en fabriquant une carte régionale.\npd.unique(data_monde[\u0026#34;Région du monde\u0026#34;]) array(['Western Europe', 'North America and ANZ','Middle East and North Africa', 'Latin America and Caribbean','Central and Eastern Europe', 'East Asia', 'Southeast Asia','Commonwealth of Independent States', 'Sub-Saharan Africa','South Asia'], dtype=object)\nregion = data_monde[data_monde[\u0026#34;Région du monde\u0026#34;] == \u0026#34;Middle East and North Africa\u0026#34;] fig = px.choropleth(region, locations = \u0026#34;code\u0026#34;, color = \u0026#34;Score de bonheur\u0026#34;, projection = \u0026#34;natural earth\u0026#34;, color_continuous_scale = \u0026#34;Temps\u0026#34;, hover_name = region.index, hover_data = {\u0026#34;code\u0026#34; : False} ) fig.update_geos(fitbounds = \u0026#34;locations\u0026#34;, visible = True) fig.update_layout(margin = {\u0026#34;r\u0026#34;:0,\u0026#34;t\u0026#34;:0,\u0026#34;l\u0026#34;:0,\u0026#34;b\u0026#34;:0}) fig.update_geos(showframe = False, resolution = 50) fig.show()    Plotly.d3.json(\"/cartechoro3.json\", function(err, fig) { Plotly.plot('\\/cartechoro3.json', fig.data, fig.layout, {responsive: true}); });   Modifiez les cellules qui précèdent pour que le graphique ci-dessus affiche la carte du score de générosité des pays d\u0026rsquo;Asie du sud-est.\n  De quelle couleur est le Vietnam sur cette carte ?\n  Fin du TP3c\n Série temporelle Utilisons un nouveau jeu de données comprenant des relevés de consommation électrique allemands entre 2006 et 2018 :\nurl = \u0026#34;http://cordier-phychi.toile-libre.org/Info/github/elec_allemagne.csv\u0026#34; serie_temp = pd.read_csv(url,sep=\u0026#34;,\u0026#34;) serie_temp.drop(columns=\u0026#34;Wind+Solar\u0026#34;,inplace=True) serie_temp   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Date Consumption Wind Solar     0 2006-01-01 1069.18400 NaN NaN   1 2006-01-02 1380.52100 NaN NaN   2 2006-01-03 1442.53300 NaN NaN   3 2006-01-04 1457.21700 NaN NaN   4 2006-01-05 1477.13100 NaN NaN   ... ... ... ... ...   4378 2017-12-27 1263.94091 394.507 16.530   4379 2017-12-28 1299.86398 506.424 14.162   4380 2017-12-29 1295.08753 584.277 29.854   4381 2017-12-30 1215.44897 721.247 7.467   4382 2017-12-31 1107.11488 721.176 19.980    4383 rows × 4 columns\n Petit toilettage des données : on transforme les valeurs de la colonne des dates en un type date reconnu par pandas et on les utilise comme index.\nserie_temp[\u0026#39;Date\u0026#39;] = pd.to_datetime(serie_temp[\u0026#39;Date\u0026#39;]) serie_temp = serie_temp.set_index(\u0026#39;Date\u0026#39;) serie_temp.head()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Consumption Wind Solar   Date        2006-01-01 1069.184 NaN NaN   2006-01-02 1380.521 NaN NaN   2006-01-03 1442.533 NaN NaN   2006-01-04 1457.217 NaN NaN   2006-01-05 1477.131 NaN NaN     On francise ensuite les noms de colonne\u0026hellip;\nserie_temp.columns = [\u0026#34;Consommation\u0026#34;,\u0026#34;Vent\u0026#34;,\u0026#34;Solaire\u0026#34;] serie_temp.head()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Consommation Vent Solaire   Date        2006-01-01 1069.184 NaN NaN   2006-01-02 1380.521 NaN NaN   2006-01-03 1442.533 NaN NaN   2006-01-04 1457.217 NaN NaN   2006-01-05 1477.131 NaN NaN     Et enfin, on ajoute des colonnes \u0026ldquo;jour\u0026rdquo;, \u0026ldquo;mois\u0026rdquo; et \u0026ldquo;année\u0026rdquo;.\nserie_temp[\u0026#39;jour\u0026#39;] = serie_temp.index.day_name() serie_temp[\u0026#39;mois\u0026#39;] = serie_temp.index.month serie_temp[\u0026#39;année\u0026#39;] = serie_temp.index.year serie_temp[\u0026#34;date\u0026#34;] = serie_temp.index serie_temp[\u0026#34;date\u0026#34;] = serie_temp[\u0026#34;date\u0026#34;].dt.date # pour aider Colab qui a des soucis avec les dates serie_temp.head()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Consommation Vent Solaire jour mois année date   Date            2006-01-01 1069.184 NaN NaN Sunday 1 2006 2006-01-01   2006-01-02 1380.521 NaN NaN Monday 1 2006 2006-01-02   2006-01-03 1442.533 NaN NaN Tuesday 1 2006 2006-01-03   2006-01-04 1457.217 NaN NaN Wednesday 1 2006 2006-01-04   2006-01-05 1477.131 NaN NaN Thursday 1 2006 2006-01-05     px.line(serie_temp[[\u0026#34;Consommation\u0026#34;,\u0026#34;Vent\u0026#34;,\u0026#34;Solaire\u0026#34;]])    Plotly.d3.json(\"/linecomplet.json\", function(err, fig) { Plotly.plot('\\/linecomplet.json', fig.data, fig.layout, {responsive: true}); });  On constate d\u0026rsquo;importantes variations saisonnières.\nzoom = serie_temp[serie_temp[\u0026#39;année\u0026#39;]==2016] fig1 = px.line(zoom,\u0026#39;date\u0026#39;,\u0026#39;Consommation\u0026#39;) fig2 = px.scatter(zoom,\u0026#39;date\u0026#39;,\u0026#39;Consommation\u0026#39;,color=\u0026#39;jour\u0026#39;) fig = go.Figure() fig.add_traces([fig1.data[0],*[fig2.data[i] for i in range(7)]])    Plotly.d3.json(\"/zoom2016.json\", function(err, fig) { Plotly.plot('\\/zoom2016.json', fig.data, fig.layout, {responsive: true}); });  Une variabilité hebdomadaire se superpose à la tendance saisonnière.\nGrâce à la méthode des dataframe pandas groupby, on peut facilement grouper les donner de manière à obtenir les statistiques qui nous intéressent.\nExemple : trouvons combien d\u0026rsquo;électricité d\u0026rsquo;origine éolienne a été produite chaque mois en 2016.\nserie_temp[serie_temp[\u0026#39;année\u0026#39;]==2016].groupby(\u0026#34;mois\u0026#34;)[\u0026#34;Vent\u0026#34;].sum() mois\n1 9264.588\n2 9814.294\n3 6030.177\n4 5910.504\n5 6089.484\n6 3369.069\n7 4651.582\n8 4742.343\n9 4222.315\n10 5585.248\n11 8076.232\n12 9252.290\nName: Vent, dtype: float64\n Sur le modèle précédent, déterminez le jour de la semaine où l\u0026rsquo;Allemagne a consommé le plus d\u0026rsquo;électricité en moyenne en 2016 (vous pourrez utilisez la méthode mean à la place de sum.\n Traçons une boîte à moustaches de la répartition des 3 variables mois par mois :\nfig, axes = plt.subplots(3, 1, figsize=(15, 10), sharex=True) for var, ax in zip([\u0026#39;Consommation\u0026#39;, \u0026#39;Solaire\u0026#39;, \u0026#39;Vent\u0026#39;], axes): sns.boxplot(data=serie_temp, x=\u0026#39;mois\u0026#39;, y=var, ax=ax) ax.set_ylabel(\u0026#39;GWh\u0026#39;) ax.set_title(var) if ax != axes[-1]: ax.set_xlabel(\u0026#39;\u0026#39;) On observe que :\n les trois graphes présentent bien une variabilité saisonnière ; la consommation électrique est plus forte en hiver ainsi que la production éolienne (même si l\u0026rsquo;écart est moins marqué) et la production solaire est beaucoup plus importante en été. beaucoup de valeurs se retrouvent à l\u0026rsquo;extérieur des moustaches supérieures pour la production éolienne, ce qui est probablement dû à des périodes de fort vent.  Regardons maintenant jour par jour :\nserie_temp[\u0026#34;date\u0026#34;]=(serie_temp.index.strftime(\u0026#39;%d%B\u0026#39;)) px.box(serie_temp,x=\u0026#39;jour\u0026#39;, y=\u0026#39;Consommation\u0026#39;,hover_data={\u0026#34;date\u0026#34;})    Plotly.d3.json(\"/jourparjour.json\", function(err, fig) { Plotly.plot('\\/jourparjour.json', fig.data, fig.layout, {responsive: true}); });   Pourquoi y a-t-il autant de points au-delà des moustaches les jours de semaine ?\n "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/typesstruct/",
	"title": "Types structurés",
	"tags": [],
	"description": "",
	"content": "Types structurés Les types structurés (chaînes, tuiles, listes, dictionnaires, ensembles) sont des objets composés ; ils contiennent eux-mêmes d\u0026rsquo;autres objets.\nCertains de ces objets composites sont en plus indicés. Comme leur nom l\u0026rsquo;indique, on peut parcourir les éléments présents d\u0026rsquo;une structure indicée à l\u0026rsquo;aide d\u0026rsquo;un indice (un nombre entier étiquetant l\u0026rsquo;indice). Les structures indicés sont donc ordonnées, ce sont des séquences. L\u0026rsquo;indice commence toujours à 0.\nEt donc si la structure contient n éléments, le dernier indice est n-1.\n  Structures indicées immuables (chaînes, tuples) Une structure est dite immuable si on ne peut pas modifier les éléments qu\u0026rsquo;elle contient une fois qu\u0026rsquo;elle est construite.\nIl y a deux structures de ce type en Python : les chaînes de caractères (type string) et les tuples (type tuple).\n Les chaînes de caractères sont des séquences de caractères (du texte) définies par des apostrophes ', des guillemets \u0026quot;, des triples apostrophes ''' ou des triples guillemets \u0026quot;\u0026quot;\u0026quot; ('abc', \u0026quot;abc\u0026quot;,'''abc''',\u0026quot;\u0026quot;\u0026quot;abc\u0026quot;\u0026quot;\u0026quot; ).\nLes chaînes de caractères peuvent être constituées de tous les caractères possibles, y compris des emojis 👍.   Les guillemets \u0026quot;\u0026quot; permettent d\u0026rsquo;utiliser des apostrophes ' dans la chaîne sans que cela ne la ferme (\u0026quot;C'est bon\u0026quot;).\nLes triples apostrophes ''' ou guillemets \u0026quot;\u0026quot;\u0026quot; permettent d\u0026rsquo;écrire des chaînes sur plusieurs lignes (on utilise de telles chaînes pour les signatures des fonctions).\n L\u0026rsquo;espace est un caractère comme un autre !\n  Les tuples sont des ensembles d\u0026rsquo;objets (pas forcément du même type) placés entre parenthèses (pas obligatoires) et séparés par des virgules comme (3.2, 'abc', True).   len La fonction native len() permet d\u0026rsquo;obtenir le nombre d\u0026rsquo;éléments présents dans la structure, c\u0026rsquo;est-à-dire sa longueur (len est l'\u0026lsquo;abréviation de length).\nlen(\u0026#39;abc\u0026#39;) 3\nlen((3.2, \u0026#39;abc\u0026#39;, True)) 3\nMême si le deuxième élément du tuple du dernier exemple est lui-même composé, len le considère comme un (et un seul) des éléments du tuple.\nDe même, si un tuple contient un autre tuple imbriqué, il ne comptera que pour un seul élément pour len :\nlen((\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,(1,2,3),18)) 4\n Accès par indice d\u0026rsquo;un élément On place l\u0026rsquo;indice de l\u0026rsquo;élément qui nous intéresse entre crochets pour le récupérer :\nS = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39; n = len(S) print(\u0026#39;de\u0026#39;,S[0],\u0026#39;à\u0026#39;,S[n-1]) de a à z\ns[n] provoque l\u0026rsquo;erreur classique IndexError: string index out of range.\nSi $n$ est le nombre d\u0026rsquo;éléments de la structure (donné par len), alors l\u0026rsquo;indice doit être un entier inférieur ou égal à $n-1$.\n Si une structure indicée se trouve enchassée au sein d\u0026rsquo;une autre structure indicée, on peut aussi accéder à ses éléments :\nT = (1,\u0026#39;abcd\u0026#39;,2) len(T[1]) 4\nT[1][3] d\nAutre source d\u0026rsquo;erreur : on ne peut pas modifier la valeur d\u0026rsquo;un élément dans une structure immuable.\n T = (1,2,3) T[2] = 4 TypeError: 'tuple' object does not support item assignment\n\u0026#39;abc\u0026#39;[1] = \u0026#39;d\u0026#39; TypeError: 'str' object does not support item assignment\n Concaténation + L\u0026rsquo;opérateur + permet de concaténer deux structures du même type.\n\u0026#39;abc\u0026#39;+\u0026#39;de\u0026#39; 'abcde'\n(1,\u0026#39;b\u0026#39;,2.2) + (True,1/5) (1, 'b', 2.2, True, 0.2)\nLa longueur de la structure résultante vaut la somme des longueurs des deux tructures concaténées.\n Répétition * L\u0026rsquo;opérateur * permet de répéter une structure.\n\u0026#39;abc\u0026#39;*2 abcabc\nOn peut combiner * et + :\n(\u0026#39;z\u0026#39;*5 + \u0026#39; \u0026#39;)*3 zzzzz zzzzz zzzzz \n Tranches On peut extraire plusieurs éléments d\u0026rsquo;une structure indicée en une seule fois grâce au découpage en tranches (slicing en anglais). On utilise les crochets comme pour l\u0026rsquo;indexation mais on utilise maintenant 2 ou 3 indices séparés par :. La tranche va du premier indice (inclu) jusqu\u0026rsquo;au deuxième indice (exclu).\n S = \u0026#39;0123456789\u0026#39; S[1:4] '123'\nCette règle d\u0026rsquo;exclusion du deuxième indice permet d\u0026rsquo;avoir une épaisseur de tranche (len(S[i:j])) valant la différence entre les deux indices (j-i).\nSi on omet le premier indice ([:j]), on part du début. Si on omet le second ([i:]), on va jusqu\u0026rsquo;au bout.\n S[:4],S[5:] ('0123', '56789')\nUn troisième indice installe un pas dans la découpe :\nS[::2],S[1::4] ('02468', '159')\nEt si le troisième indice est négatif, il permet de parcourir la séquence en sens inverse :\nS[::-1],S[8:0:-2] ('9876543210', '8642')\n Appartenance in On peut tester l\u0026rsquo;appartenance d\u0026rsquo;un élément ou d\u0026rsquo;une tranche à une structure composée grâce au mot clé in :\n\u0026#39;b\u0026#39; in (5,\u0026#39;a\u0026#39;,12.5) False\n\u0026#39;567\u0026#39; in S True\n Listes Une liste (type list) est une collection d\u0026rsquo;objets placés entre crochets et séparés par des virgules.\nExemple : L = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\nComme avec les chaînes de caractères et les tuples :\n on accède à un élément via son indice :\nL[3] renvoie 0.3. on obtient le nombre d\u0026rsquo;éléments d\u0026rsquo;une liste grâce à la fonction len :\nlen(L) retourne 9 ; on peut concaténer deux listes avec +:\n[5,6]+[7,8] donne [5,6,7,8] ; on peut extraire par tranche des éléments :\nL[1:6] donne [0.1,0.2,0.3,0.4,0.5] ; on peut tester la présence d\u0026rsquo;un élément grâce au mot clé in :\n0.1 in L renvoie True et 1 in L renvoie False.  Mais contrairement aux chaînes de caractères et aux tuples, les listes ne sont pas immuables. On peut donc réaffecter des éléments.\nEn reprenant la liste L précédente, si on écrit L[2] = 'a', L devient [0.0,0.1,'a',0.3,0.4,0.5,0.6,0.7,0.8].\n Création d\u0026rsquo;une liste  par duplication : L\u0026rsquo;opérateur * permet de créer une liste répétant un élément.\nPar exemple, pour créer une liste L de 10 zéros, il suffit d\u0026rsquo;écrire L = [0]*10.\n par append successifs : On initialise une liste vide ([]), puis on la garnit élément par élément grâce à la méthode append.\nExemple :\nL = [] for i in range(10) : L.append(i/10) L [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\n par compréhension La construction par compréhension d\u0026rsquo;une liste est une méthode concise et élégante. L\u0026rsquo;idée est d\u0026rsquo;intégrer les boucles et enventuelles conditions dans une seule expression entre crochets pour aboutir à une définition plus directe de la liste.\nExemples :\nL1 = [i/10 for i in range(9)] L2 = [k**2 if (k%2==0) else k**3 for k in range(9)] print(f\u0026#34;{L1 = }\u0026#34;) print(f\u0026#34;{L2 = }\u0026#34;) L1 = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\nL2 = [0, 1, 4, 27, 16, 125, 36, 343, 64]\n Copie d\u0026rsquo;une liste Si on copie une liste en l\u0026rsquo;affectant à un nouveau nom, alors toute modification de l\u0026rsquo;ancienne liste se répercutera sur la nouvelle (et inversement). Les deux noms pointent en réalité vers le même espace mémoire. En effet, lorsqu\u0026rsquo;on affecte une liste à un nom de variable via =, ce n\u0026rsquo;est pas la liste mais sa référence (son adresse mémoire) qui est assignée à la variable. Et donc lorsqu\u0026rsquo;on affecte la liste à une nouvelle variable, c\u0026rsquo;est une copie de la référence et non des valeurs qui est faite.\nL_originelle = [\u0026#39;🍓\u0026#39;, \u0026#39;🍇\u0026#39;, \u0026#39;🍊\u0026#39;] L_copie = L_originelle L_originelle[1] = \u0026#39;?\u0026#39; print(L_originelle,L_copie) ['🍓', '?', '🍊'] ['🍓', '?', '🍊']\nAucune différence !\nSi on veut que la liste copiée conserve ses éléments tels qu\u0026rsquo;ils étaient au moment de la copie, on peut soit utiliser une \u0026ldquo;copie par tranche\u0026rdquo;, en affectant une tranche complète (avec [:]) de la liste, soit utiliser la méthode copy(), soit utiliser la fonction list.\nL_originelle = [\u0026#39;🍓\u0026#39;, \u0026#39;🍇\u0026#39;, \u0026#39;🍊\u0026#39;] L_copie_1 = L_originelle[:] L_copie_2 = L_originelle.copy() L_copie_3 = list(L_originelle) L_originelle[1] = \u0026#39;?\u0026#39; print(L_originelle,L_copie_1,L_copie_2,L_copie_3) ['🍓', '?', '🍊'] ['🍓', '🍇', '🍊'] ['🍓', '🍇', '🍊'] ['🍓', '🍇', '🍊']\n'?' ne se retrouve pas dans les copies !\nMais ces deux copies n\u0026rsquo;en restent pas moins superficielles. En effet, si la liste originelle contient des éléments mutables (comme une autre liste), alors seule l\u0026rsquo;adresse de ceux-ci est copiée, et s\u0026rsquo;ils sont modifiés, la copie aussi le sera :\nL = [\u0026#39;🍋\u0026#39;,\u0026#39;🍑\u0026#39;,[\u0026#39;🍈\u0026#39;,\u0026#39;🍒\u0026#39;],\u0026#39;🍏\u0026#39;] L_copie = L[:] L.append(\u0026#39;🥥\u0026#39;) L[2].append(\u0026#39;🍌\u0026#39;) print(L_copie) ['🍋', '🍑', ['🍈', '🍒', '🍌'], '🍏']\n'🥥' ne se retrouve pas dans la copie, mais 🍌 y est bien\u0026hellip;\n Retirer un élément La méthode pop() permet de retirer le dernier élément d\u0026rsquo;une liste.\nL = [\u0026#39;🥥\u0026#39;, \u0026#39;🍐\u0026#39;, \u0026#39;🍋\u0026#39;, \u0026#39;🍒\u0026#39;] print(f\u0026#34;{L.pop() = }\u0026#34;) print(f\u0026#34;{L = }\u0026#34;) L.pop() = '🍒'\nL = ['🥥', '🍐', '🍋']\nComme on le voit, pop retourne l\u0026rsquo;élément retiré (c\u0026rsquo;est une expression), et une fois que pop a été utilisé, l\u0026rsquo;élément a disparu.\nSi on veut retirer un autre élément que le dernier et qu\u0026rsquo;on connaît son indice i, on peut utiliser pop(i), mais on peut aussi utiliser le slicing (L[i:i+1]=[]) ou encore le mot clé del (del L[i]).\nL1 = [\u0026#39;🥥\u0026#39;, \u0026#39;🍐\u0026#39;, \u0026#39;🍋\u0026#39;, \u0026#39;🍒\u0026#39;] L2 = [\u0026#39;🥥\u0026#39;, \u0026#39;🍐\u0026#39;, \u0026#39;🍋\u0026#39;, \u0026#39;🍒\u0026#39;] L3 = [\u0026#39;🥥\u0026#39;, \u0026#39;🍐\u0026#39;, \u0026#39;🍋\u0026#39;, \u0026#39;🍒\u0026#39;] # Si on veut retirer la poire L1.pop(1) L2[1:2]=[] del L3[1] print(L1) print(L2) print(L3) ['🥥', '🍋', '🍒']\n['🥥', '🍋', '🍒']\n['🥥', '🍋', '🍒']\nEt si plutôt que l\u0026rsquo;indice de l\u0026rsquo;élément à retirer, on veut utiliser sa valeur, on emploie la méthode remove.\nL = [\u0026#39;🥥\u0026#39;, \u0026#39;🍐\u0026#39;, \u0026#39;🍋\u0026#39;, \u0026#39;🍒\u0026#39;] # Si on veut retirer la poire L.remove(\u0026#39;🍐\u0026#39;) print(L) ['🥥', '🍋', '🍒']\n Dictionnaires Un dictionnaire (type dict) est une collection d\u0026rsquo;objets, comme une liste ou un tuple, mais au lieu d\u0026rsquo;indicer les objets s\u0026rsquo;y trouvant (appelés valeurs) par un nombre, on utilise une clé.\nLes dictionnaires sont l\u0026rsquo;implémentation en Python des tables de hachage.\n Une clé peut être n\u0026rsquo;importe quel objet immuable, mais il s\u0026rsquo;agit le plus souvent d\u0026rsquo;une chaîne de caractères.\nPour créer un dictionnaire, on utilise la syntaxe {clé1 : valeur1, clé2 : valeur2, ...}.\nExemple où les clés sont des prénoms et les valeurs, des notes :\nnote = {\u0026#39;Giselle\u0026#39; : 7.5, \u0026#39;Alphonse\u0026#39; : 12, \u0026#39;Dudule\u0026#39; : 7.5, \u0026#39;Berthe\u0026#39; : 16.5} Chaque valeur peut être récupérée grâce à la clé comme s\u0026rsquo;il s\u0026rsquo;agisait d\u0026rsquo;un indice : note['Dudule'] donne 7.5\n Ajouter une clé à un dictionnaire On peut ajouter une entrée au dictionnaire en écrivant simplement dico[nouvelleClé]=valeur.\nnote[\u0026#39;Raoul\u0026#39;] = 14 # ajoute la note de Raoul au dictionnaire note print(note) {'Giselle': 7.5, 'Alphonse': 12, 'Dudule': 7.5, 'Berthe': 16.5, 'Raoul': 14}\nOn peut partir d\u0026rsquo;un dictionnaire vide {} et le construire ainsi étape par étape :\ncoef = {} # dictionnaire vide coef[\u0026#39;maths\u0026#39;] = 9 coef[\u0026#39;physique\u0026#39;] = 10 coef[\u0026#39;philo\u0026#39;] = 9 print(coef) {'maths': 9, 'physique': 10, 'philo': 9}\nComme les listes, les dictionnaires sont des objets mutables.\nnote[\u0026#39;Berthe\u0026#39;] = 18 # modifie la note de Berthe dans le dictionnaire note print(note) {'Giselle': 7.5, 'Alphonse': 12, 'Dudule': 7.5, 'Berthe': 18, 'Raoul': 14}\nChaque clé doit être unique, mais les valeurs peuvent être identiques (comme les notes de Dudule et Giselle).\n Tenter d\u0026rsquo;accéder à une clé qui ne figure pas dans le dictionnaire se solde par une erreur.\n print(note[\u0026#39;Gourmandine\u0026#39;]) # la clé Gourmandine n\u0026#39;existe pas KeyError: 'Gourmandine'\nPour y échapper, on peut tester la présence d\u0026rsquo;une clé grâce à in.\nExemple : à partir d\u0026rsquo;une liste de 12 éléments pris au hasard parmi les entiers de 1 à 10, fabriquons un dictionnaire qui compte les occurrences de chacun des 10 entiers :\nfrom random import randint L = [] for i in range(12) : L = L+[randint(1,10)] effectifs = {} for e in L : if not e in effectifs : effectifs[e] = 1 else : effectifs[e] = effectifs[e]+1 print(effectifs) {5: 3, 10: 1, 9: 1, 4: 1, 8: 1, 6: 2, 1: 3}\nSans la condition, effectifs[e]+1 aurait levé une KeyError car le dictionnaire n\u0026rsquo;a initialement aucune entrée et donc effectifs[e] n\u0026rsquo;est pas défini.\n Retirer une clé On peut retirer une clé d\u0026rsquo;un dictionnaire grâce au mot clé del.\ndel note[\u0026#39;Alphonse\u0026#39;] print(note) {'Giselle': 7.5, 'Dudule': 7.5, 'Berthe': 18, 'Raoul': 14}\nSi on utilise del sur une clé inexistante, une erreur KeyError est là encore produite.\n  Parcourir un dictionnaire Les méthodes keys et values permettents de récupérer les clés et valeurs d\u0026rsquo;un dictionnaire sous forme d\u0026rsquo;itérables, ce qui peut s\u0026rsquo;avérer pratique pour un tracé, par exemple.\nimport matplotlib.pyplot as plt clés = effectifs.keys() valeurs = effectifs.values() plt.bar(clés, valeurs) plt.show() La méthode items regroupe clés et valeurs au sein de tuples (clé,valeur).\nfor clé, valeur in effectifs.items() : print(\u0026#39;nombre de\u0026#39;,clé,\u0026#39;:\u0026#39;,valeur) nombre de 5 : 3\nnombre de 10 : 1\nnombre de 9 : 1\nnombre de 4 : 1\nnombre de 8 : 1\nnombre de 6 : 2\nnombre de 1 : 3\nLes dictionnaires sont des ensemble de paires clé-valeur qui n\u0026rsquo;ont aucun ordre particulier. Les dictionnaires ne sont donc pas des séquences.\n Comme pour les listes, une affectation d\u0026rsquo;un dictionnaire existant à une nouvelle variable n\u0026rsquo;en copie que la référence. Toute modification de l\u0026rsquo;un se retrouve dans l\u0026rsquo;autre.\nEt si on veut conserver invariante les valeurs copiées, on peut ici aussi utiliser la méthode copy().\ninfos = {\u0026#39;prénom\u0026#39;: \u0026#39;Russell\u0026#39;, \u0026#39;nom\u0026#39;: \u0026#39;Bell\u0026#39;, \u0026#39;alias\u0026#39;: \u0026#39;Stringer\u0026#39;, \u0026#39;notes\u0026#39;: [13,18,7]} infos_copie = infos.copy() infos[\u0026#39;prénom\u0026#39;] = infos.pop(\u0026#39;alias\u0026#39;) infos[\u0026#39;notes\u0026#39;][:] = [\u0026#39;abs\u0026#39;] print(infos) print(infos_copie) {'prénom': 'Stringer', 'nom': 'Bell', 'notes': ['abs']}\n{'prénom': 'Russell', 'nom': 'Bell', 'alias': 'Stringer', 'notes': ['abs']}\nOn remarque que le remplacement du prénom par l\u0026rsquo;alias et la suppression de l\u0026rsquo;alias n\u0026rsquo;ont pas été répercutés sur la copie, par contre la modification de la liste de notes, objets mutable, oui.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/",
	"title": "Semestre 2",
	"tags": [],
	"description": "",
	"content": "Semestre 2 On consolide certains concepts rencontrés pendant les TP du semestre 1 :\n les bonnes pratiques en programmation la correction et la terminaison d\u0026rsquo;un algorithme la complexité  Puis on développe deux nouveaux points :\n la représentation des nombres les graphes  "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/structcontr/",
	"title": "Strucutres de contrôle",
	"tags": [],
	"description": "",
	"content": "Structures de contrôle Instruction d\u0026rsquo;affectation Définition Lorsqu\u0026rsquo;un objet est créé dans un programme Python, une certaine place en mémoire lui est allouée. Cette place est repérée par une adresse dont la valeur peut être obtenue grâce à la fonction id().\nid(3.7) 4387417928\nIl est beaucoup plus pratique de pouvoir récupérer une valeur en mémoire grâce à un petit nom plutôt que par son adresse. C\u0026rsquo;est à ça que servent les variables. Une variable est liée à un objet grâce à une affectation et identifie cet objet pour les calculs suivants. Une affectation est une instruction (pas de retour).\nEn Python, une affectation s\u0026rsquo;opère avec le symbole =.\nEn pseudocode, on utilise généralement := ou ← pour les affectations.\n La variable est un tiroir avec une étiquette. Et comme on l\u0026rsquo;a vu, en Python, pas besoin de choisir un tiroir correspondant au type d\u0026rsquo;objet qu\u0026rsquo;il va contenir, c\u0026rsquo;est l\u0026rsquo;interpréteur qui s\u0026rsquo;en charge pour nous (le typage est dynamique).\na = 3 b = -2 a * b -6\nSi on veut pouvoir utiliser le résultat de a * b pour des calculs ultérieurs, il faut lui aussi le stocker en mémoire.\nc = a * b c -6\nOn peut interroger le type d\u0026rsquo;une variable avec la fonction type() :\nc = 3,2 type(c) \u0026lt;class 'tuple'\u0026gt;\n Instruction plutôt qu\u0026rsquo;expression Le fait que l\u0026rsquo;affectation soir une instruction plutôt qu\u0026rsquo;une expression est un choix d\u0026rsquo;écriture du langage (en C, l\u0026rsquo;affectation est une expression).\nD\u0026rsquo;ailleurs, Python 3.8 a introduit l\u0026rsquo;opérateur := (dit le walrus opérator ou opérateur de morse du fait de sa ressemblance à un morse\u0026hellip;) permettant justement une expression d\u0026rsquo;affectation au sein d\u0026rsquo;une expression plus large. L\u0026rsquo;intérêt est de permettre de raccourcir l\u0026rsquo;écriture ou d\u0026rsquo;éviter les répétitions dans certains cas.\nL\u0026rsquo;opérateur de morse n\u0026rsquo;est pas à connaître, mais il va nous permettre, dans les deux exemples suivants, de bien faire la différence entre une instruction et une expression.\nif (n := len(a)) \u0026gt; 5: print(f\u0026#34;La liste est trop grande ({n} élements alors qu\u0026#39;on en attend 5 au plus)\u0026#34;)  Montrer que sans :=, on aurait soit une répétition, soit une ligne en plus.\n Autre exemple :\nwhile (choix := input(\u0026#39;Entrer q ou p : \u0026#39;)) != \u0026#39;q\u0026#39;: if choix == \u0026#39;p\u0026#39;: print(\u0026#34;Salut !\u0026#34;)  Comment aurait-on dû écrire ce code sans := ?\n  Réaffectation Une affectation ne retourne rien mais a un effet sur la mémoire : l\u0026rsquo;adresse de la variable est modifiée à chaque nouvelle affectation. C\u0026rsquo;est ce qui rend possible les réaffectations à partir de la variable elle-même.\nid(a) 4304751488\nid(a+1) 4304751520\na = a + 1 id(a) 4304751520\nCes types de réaffectation sont si fréquents qu\u0026rsquo;il existe une notation raccourcie : +=, -=, *=, /=, //=, %=.\nAinsi, a += 1 équivaut à a = a + 1 et b /= 5 équivaut à b = b/5.\n  Affectation parallèle Comment faire si on veut permuter les valeurs auxquelles sont liées deux variables ? Dès qu\u0026rsquo;on écrit a = b, la valeur initiale de a est perdue. Et si on commence par b = a, c\u0026rsquo;est la valeur initiale de b qui est perdue. Il faudrait donc utiliser une variable temporaire et écrire : tmp = a, a = b et b = tmp.\nMais l\u0026rsquo;affectation parallèle de Python va nous permettre d\u0026rsquo;être plus élégants. Il suffit en effet d\u0026rsquo;une petite ligne :\na = \u0026#39;haut\u0026#39; b = \u0026#39;bas\u0026#39; a , b = b , a print(a,b) bas haut\nL\u0026rsquo;affectation parallèle repose sur le dépaquetage (unpacking) de tuples.\nEn effet, des objets séparés par des virgules forment un tuple (pas besoin de parenthèses). Donc a,b,c = 1,2,3 correspond au dépaquetage du tuple (1,2,3) sur les 3 variables a, b et c.\n  Noms de variable Règles sur les noms de variables :\n ils sont sensibles à la casse (minuscule ou majuscule) ils peuvent contenir n\u0026rsquo;importe quelles lettres ou chiffres et le tiret-bas \u0026ldquo;_\u0026rdquo; mais ne doivent pas commencer par un chiffre. certains noms sont interdits (attention en particulier à lambda) :  and assert break class continue def del elif else except finally for from global if\nimport in is lambda nonlocal not or pass print raise return try while yield\nIl est important pour la lisibilité de son code de donner les noms les plus explicites possibles aux variables. Les rapports de jury le répète tous les ans\u0026hellip;\n Rapport 2019 de l\u0026rsquo;épreuve de Centrale par exemple :\n Des noms de variables explicites aident à la compréhension du code. De trop nombreux candidats utilisent des noms de variables quelconques (a, b, c\u0026hellip;) ce qui nuit à la compréhension du programme. La clarté du programme (en particulier le choix des noms de variables) ainsi que la présence de commentaires opportuns sont prises en compte dans l’évaluation.\n  Instuction conditionnelle Les instructions conditionnelles permettent de rediriger le flot d\u0026rsquo;exécution d\u0026rsquo;un programme en proposant des alternatives.\nif,elif,else La structure if ... elif ... else permet d\u0026rsquo;exécuter des instructions seulement si une condition, donnée par le résultat d\u0026rsquo;un ou plusieurs tests logiques, est vérifiée.\nif \u0026lt;expression logique 1\u0026gt; :\n\u0026lt;bloc d\u0026rsquo;instructions 1\u0026gt;\nelif \u0026lt;expression logique 2\u0026gt; :\n\u0026lt;bloc d\u0026rsquo;instructions 2\u0026gt;\n\u0026hellip;\nelse :\n\u0026lt;bloc d\u0026rsquo;instructions\u0026gt;\nSi l'\u0026lt;expression logique 1\u0026gt; est évaluée comme vraie, le \u0026lt;bloc d\u0026rsquo;instructions 1\u0026gt; est exécuté ; dans le cas contraire, si l'\u0026lt;expression logique 2\u0026gt; est évaluée comme vraie, le \u0026lt;bloc d\u0026rsquo;instructions 2\u0026gt; est exécuté, et ainsi de suite ; et si aucune des expressions logiques précédentes n\u0026rsquo;est vraie, le bloc d\u0026rsquo;instructions faisant suite au else: est exécuté.\nPar exemple :\nfor x in range(10) : if x\u0026lt;= 3 : print(x,\u0026#39;est inférieur ou égal à 3\u0026#39;) elif x \u0026gt; 5 : print(x,\u0026#39;est plus grand que 5\u0026#39;) else : print(x,\u0026#39;doit être 4 ou 5\u0026#39;) 0 est inférieur ou égal à 3 1 est inférieur ou égal à 3 2 est inférieur ou égal à 3 3 est inférieur ou égal à 3 4 doit être 4 ou 5 5 doit être 4 ou 5 6 est plus grand que 5 7 est plus grand que 5 8 est plus grand que 5 9 est plus grand que 5  Python reconnaît comme vrai n\u0026rsquo;importe quel type de donnée (même pas besoin d\u0026rsquo;expression logique) du moment qu\u0026rsquo;il ne s\u0026rsquo;agit ni de l\u0026rsquo;entier 0, du décimal 0., de la chaîne de caractères vide '', du tuple vide (), de la liste vide [], ou encore de la valeur None.\n Exemple :\nDans le calendrier grégorien, une année est bissextile si elle est divisible par 4 sauf si elle est aussi divisible par 100 à l\u0026rsquo;exception des années divisibles par 400 qui sont bien bissextiles.\nLe programme suivant détermine si une année est bissextile :\nannée = 2022 if not année % 400 : est_bissextile = True elif not année % 100 : est_bissextile = False elif not année % 4 : est_bissextile = True else : est_bissextile = False s = \u0026#39;est une\u0026#39; if est_bissextile else \u0026#34;n\u0026#39;est pas une\u0026#34; print(\u0026#34;L\u0026#39;année\u0026#34;, année , s ,\u0026#34;année bissextile.\u0026#34;) L'année 2022 n'est pas une année bissextile.\n  Boucle while Une boucle while ou \u0026ldquo;tant que\u0026rdquo; permet de répéter une suite d\u0026rsquo;instructions tant qu' une condition est respectée.\nLa suite d\u0026rsquo;instructions répétées devra être indentée et forme alors le corps de la boucle.\nLes boucles while sont dangereuses ! Rien ne dit en effet que la condition sera un jour fausse et la boucle peut donc tourner indéfiniment.\nLes boucles infinis posent le problème de la terminaison d\u0026rsquo;un programme.\n i = 0 while i \u0026lt; 10 : i += 1 print(i,end =\u0026#39;.\u0026#39;) print(\u0026#39;\\nLa boucle est finie...\u0026#39;) 1.2.3.4.5.6.7.8.9.10. La boucle est finie...  Le compteur i est initialisé à 0 et comme 0 est inférieur à 10, la boucle while démarre. À chaque itération, i est incrémenté de 1 et sa valeur affichée. Puis i atteint 10 et à l\u0026rsquo;itération suivante i \u0026lt; 10 devient faux, la boucle s\u0026rsquo;arrête et l\u0026rsquo;éxécution reprend après la boucle.\nUn exemple plus intéressant :\nimplémentons l\u0026rsquo;algorithme d\u0026rsquo;Euclide permettant de déterminer le plus grand diviseur commun de deux entiers.\na , b = 1920 , 1080 print(f\u0026#39;pgcd({a},{b}) = \u0026#39;,end = \u0026#39;\u0026#39;) while b : a , b = b, a % b print(a) pgcd(1920,1080) = 120\nLa boucle continue jusqu\u0026rsquo;à ce que b divise a. À chaque itération, b prend la valeur du reste de la division euclidienne de a par b et a prend l\u0026rsquo;ancienne valeur de b.\nwhile b est équivalent à while b != 0 puisque la valeur 0 est évaluée comme fausse.\n break L\u0026rsquo;instruction break, placée dans le bloc d\u0026rsquo;instructions d\u0026rsquo;une boucle, met immédiatement fin à cette boucle lorsqu\u0026rsquo;arrive son tour d\u0026rsquo;être exécutée.\nL\u0026rsquo;exécution reprend à l\u0026rsquo;instruction suivant la boucle.\nx = 0 while True : x += 1 if not (x % 15 or x % 25) : break print(x,\u0026#39;est divisible à la fois par 15 et 25.\u0026#39;) 75 est divisible à la fois par 15 et 25.\nLa condition du while est ici littéralement toujours vraie donc la seule sortie possible de la boucle passe par une exécution de l\u0026rsquo;instruction break, ce qui ne peut arriver que si x est à la fois divisible par 15 et 25 (c\u0026rsquo;est une pratique risquée !).\nDe la même manière, pour trouver l\u0026rsquo;indice de la première occurrence d\u0026rsquo;un nombre négatif dans une liste :\nliste = [5, 2, 99, 0, 100, -2, 37, 43, -124] for i, a in enumerate(liste) : if a \u0026lt; 0 : break print(\u0026#34;L\u0026#39;élément d\u0026#39;indice\u0026#34;,i,\u0026#34;valant\u0026#34;,a,\u0026#34;est le premier élément négatif.\u0026#34;) L'élément d'indice 5 valant -2 est le premier élément négatif.\nAprès la sortie de la boucle, les variables i et a gardent les valeurs qu\u0026rsquo;elles ont au moment de l\u0026rsquo;instruction break.\n  return L\u0026rsquo;instruction return permet elle aussi de s\u0026rsquo;échapper d\u0026rsquo;une boucle.\nEn effet, l\u0026rsquo;utilisation du return a pour effet de sortir du corps d\u0026rsquo;une fonction donc à fortiori, si une boucle est utilisée dans la définition de cette fonction, le return permet aussi d\u0026rsquo;en sortir.\ndef vol(i) : t = 0 while(1) : if not i%2 : i //= 2 elif i != 1 : i = 3*i+1 else : return t t += 1 vol(27) renvoie alors 111.\n  Boucle for Une boucle for se différencie d\u0026rsquo;une boucle while en ce que le nombre d\u0026rsquo;itérations est connu à l\u0026rsquo;avance.\nLa structure d\u0026rsquo;une telle boucle est en effet :\nfor \u0026lt;élément\u0026gt; in \u0026lt;itérable\u0026gt; :\n\u0026lt;bloc d\u0026rsquo;instructions\u0026gt;\nL\u0026rsquo;itérable est une collection d\u0026rsquo;éléments et le bloc d\u0026rsquo;instructions est alors répété autant de fois que l\u0026rsquo;itérable contient d\u0026rsquo;éléments.\nPassons en revue quelques itérables.\nrange range permet d\u0026rsquo;itérer sur une suite arithmétique d\u0026rsquo;entiers :\nfor i in range(5) : print(i,end=\u0026#34;.\u0026#34;) 0.1.2.3.4.\nL\u0026rsquo;itération sur range(n) va de $0$ à $n-1$ par pas de 1.\n On peut spécifier un point de départ et un pas différents en les passant en argument : range(depart,fin,pas).\nfor i in range(5,10) : print(i,end=\u0026#34;.\u0026#34;) 5.6.7.8.9.\nfor i in range(0,100,20) : print(i,end=\u0026#34;.\u0026#34;) 0.20.40.60.80.\n une chaîne de caractères Itérer sur une chaîne de caractères décompose la chaîne caractère par caractère :\nfor car in \u0026#39;abc😱\u0026#39; : print(car*2,end=\u0026#39; \u0026#39;) aa bb cc 😱😱 \n une liste, un tuple On peut de même parcourir une liste ou un tuple élément par élément.\nL = [(\u0026#39;🙈\u0026#39;,\u0026#39;🙊\u0026#39;,\u0026#39;🙉\u0026#39;),(\u0026#39;🌖\u0026#39;,\u0026#39;🌗\u0026#39;,\u0026#39;🌘\u0026#39;),] s = \u0026#39;\u0026#39; i = 1 for tuple in L : for element in tuple : s += element*i i += 1 print(s) 🙈🙊🙊🙉🙉🙉🌖🌖🌖🌖🌗🌗🌗🌗🌗🌘🌘🌘🌘🌘🌘\n un dictionnaire Pour pacourir uniquement les clés d\u0026rsquo;un dictionnaire, on peut utiliser la méthode keys :\nDico = {\u0026#39;pwd_1\u0026#39; : \u0026#39;123456\u0026#39;, \u0026#39;pwd_2\u0026#39; : \u0026#39;qwerty\u0026#39;, \u0026#39;pwd_3\u0026#39; : \u0026#39;password\u0026#39;} for cle in Dico.keys() : print(cle,\u0026#39;-\u0026gt;\u0026#39;,Dico[cle]) pwd_1 -\u0026gt; 123456\npwd_2 -\u0026gt; qwerty\npwd_3 -\u0026gt; password\nEt grâce à la méthode items, on peut déballer clés et valeurs associées dans un tuple :\nfor cle,valeur in Dico.items() : print(cle,\u0026#39;-\u0026gt;\u0026#39;,valeur) pwd_1 -\u0026gt; 123456\npwd_2 -\u0026gt; qwerty\npwd_3 -\u0026gt; password\nConstruisons par exemple un nouveau dictionnaire inversant clés et valeurs :\nDico = {\u0026#39;$\u0026#39; : \u0026#39;dollar\u0026#39;, \u0026#39;€\u0026#39; : \u0026#39;euro\u0026#39;, \u0026#39;¥\u0026#39; : \u0026#39;yen\u0026#39;, \u0026#39;£\u0026#39; : \u0026#39;livre\u0026#39;} Dico_inv = {} for cle,valeur in Dico.items() : Dico_inv[valeur] = cle print(Dico_inv) {'dollar': '$', 'euro': '€', 'yen': '¥', 'livre': '£'}\nDernier exemple, modifions une à une chaque valeur d\u0026rsquo;un dictionnaire :\ndico_notes = {\u0026#39;Kurt\u0026#39; : 19, \u0026#39;Kris\u0026#39; : 11, \u0026#39;Dave\u0026#39; : 13, \u0026#39;Pat\u0026#39; : 10, \u0026#39;Courtney\u0026#39; : 15} for eleve,note in dico_notes.items() : dico_notes[eleve] = note+1 print(dico_notes) {'Kurt': 20, 'Kris': 12, 'Dave': 14, 'Pat': 11, 'Courtney': 16}  Définition d\u0026rsquo;une fonction Une fonction est un ensemble d\u0026rsquo;instructions auxquelles on accède par un raccourci : le nom de la fonction. Elles se comportent comme des sous-programmes à l\u0026rsquo;intérieur du programme principal. Et comme tout programme, elles peuvent agir sur des données, les entrées, et fournir de nouvelles données, les sorties.\nLa signature d\u0026rsquo;une fonction résume ces points clés : son nom, les différents arguments et leurs types, les différentes sorties et leur type. nom(arg_1:type, arg_2:type, etc) -\u0026gt; sortie_1:type, sortie_2:type, etc\nOn définit une fonction grâce au mot clé def en suivant la structure suivante :\n def nom(arguments séparés par des virgules) :\n\u0026lt; corps de la fonction contenant les différentes instructions \u0026gt;\n La définition d\u0026rsquo;une fonction est une instruction.\ndef addition(a,b) : c = a+b print(c) On appelle une fonction en utilisant son nom et en affectant chaque argument dans les parenthèses qui suivent son nom.\nLes instructions du corps de la fonction sont alors exécutée une par une et si des variables correspondant aux nom des arguments (on parle alors d'arguments formels) sont rencontrées, ce sont les valeurs utilisées lors de l\u0026rsquo;appel (les arguments effectifs) qui les remplacent.\naddition(5,2) 7 On utilise aussi le terme \u0026ldquo;paramètre\u0026rdquo; pour désigner les arguments formels, c\u0026rsquo;est-à-dire les variables qui entrent dans la définition de la fonction. Et on réserve alors le terme argument aux valeurs données à ces variables au moment de l\u0026rsquo;appel.\nDans l\u0026rsquo;exemple, a et b sont alors les paramètres (= arguments formels) et 5 et 2 sont les arguments (= arguments effectifs).\n Malgré ce que l\u0026rsquo;affichage peut laisser croire, la fonction précédente ne retourne rien !\nLa valeur de c est prisonnière du corps de la fonction, elle n\u0026rsquo;est pas accessible dans le code principal. C\u0026rsquo;est une variable locale.\nSi on veut pouvoir accéder à c ailleurs que dans la fonction, il faut l\u0026rsquo;extirper en utilisant un return.\nIl ne faut ainsi pas confondre print et return !\nLe return transforme l\u0026rsquo;appel de la fonction en expression puisqu\u0026rsquo;une valeur est retournée.\nLe print n\u0026rsquo;a qu\u0026rsquo;un effet de bord. La valeur est affichée mais inutilisable. L\u0026rsquo;appel de la fonction n\u0026rsquo;est alors qu\u0026rsquo;une instruction et on nomme procédure une telle fonction.\n Ainsi, addition(5,2) + 7 va lever une erreur : TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'.\nEn effet, comme addition ne retourne rien, Python la considère de type NoneType et ne comprend pas pourquoi on cherche à additionner quelque chose à rien.\nArrangeons cela grâce à un return :\ndef addition(a,b) : c = a+b return c Maintenant, addition(5,2) + 7 retourne gentiment 12.\nDès que l\u0026rsquo;instruction return est rencontrée lors de l\u0026rsquo;appel de la fonction le flot d\u0026rsquo;exécution du code de la fonction est interrompu et reprend à la ligne suivant l\u0026rsquo;appel.\ndef demo() : print(\u0026#34;Ligne exécutée car avant le return\u0026#34;) return print(\u0026#34;Ligne non exécutée car après le return\u0026#34;) demo() Ligne exécutée car avant le return\nL\u0026rsquo;exemple précédent nous montre aussi qu\u0026rsquo;une fonction n\u0026rsquo;a pas nécessairement d\u0026rsquo;argument et qu\u0026rsquo;un return peut ne rien retourner (il ne sert alors qu\u0026rsquo;à interrompre l\u0026rsquo;exécution).\nComme on l\u0026rsquo;a vu précédemment, un return, à l\u0026rsquo;instar d\u0026rsquo;un break, peut donc interrompre une boucle dans le corps d\u0026rsquo;une fonction.\nL\u0026rsquo;appel d\u0026rsquo;une fonction est la valeur qu\u0026rsquo;elle retourne, qu\u0026rsquo;il s\u0026rsquo;agisse d\u0026rsquo;un entier, d\u0026rsquo;une liste, d\u0026rsquo;un dictionnaire, etc.\nUne fonction peut retourner plusieurs variables séparées par des virgules. L\u0026rsquo;appel est alors un tuple qui peut être déballé.\ndef somme_moyenne(liste) : s = 0 for e in liste : s += e m = s/len(liste) return s,m L = [1,2,3,4] print(type(somme_moyenne(L))) a,b = somme_moyenne(L) print(\u0026#34;somme :\u0026#34;,a,\u0026#34;et moyenne :\u0026#34;,b) print(somme_moyenne(L)[1]) \u0026lt;class 'tuple'\u0026gt;\nsomme : 10 et moyenne : 2.5\n2.5\nUne fonction peut aussi ne pas avoir d\u0026rsquo;argument :\ndef HelloWorld() : print(\u0026#39;\\x4B\\x49\\x4C\\x4C\\n\\x41\\x4C\\x4C\\n\\x48\\x55\\x4D\\x41\\x4E\u0026#39;) "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp4dicho/",
	"title": "TP 4 : algorithmes dichotomiques",
	"tags": [],
	"description": "",
	"content": "Algorithmes dichotomiques Cliquez sur cette invitation pour récupérer le repository du TP. Recherche dichotomique L\u0026rsquo;algorithme de recherche mis au point dans le tp1 compte dans le pire des cas autant d\u0026rsquo;étapes que l\u0026rsquo;ensemble scruté contient d\u0026rsquo;éléments.\nPeut-on faire mieux ?\nDans le cas, d\u0026rsquo;un ensemble ordonné trié, la réponse est oui. On peut même faire beaucoup mieux !\nImaginons que l\u0026rsquo;on cherche une carte dans un jeu trié en ordre croissant. L\u0026rsquo;idée est de regarder d\u0026rsquo;abord au milieu du paquet. Si la carte du milieu est plus petite (repectivement plus grande) que la carte cherchée, on en déduit que celle-ci ne peut être que dans la deuxième partie (respectivement dans la première partie) du paquet (si elle est bien présente).\nOn peut alors se débarrasser de la moitié des cartes environ et on recommence la manœuvre avec les cartes restantes.\n  Voilà ci-dessous une tentative d\u0026rsquo;implémentation de cet algorithme :\ndef recherche_dicho(L,x) : n = len(L) g, d = 0, n-1 while g \u0026lt; d : i = (g + d)//2 if x \u0026lt; L[i] : d = i - 1 elif x \u0026gt; L[i] : g = i + 1 else : return True return False  Testez cet algorithme et constatez qu\u0026rsquo;il contient une erreur.\nRecopier ci-dessous une liste triée et un élément à rechercher qui mettent en échec l\u0026rsquo;algorithme.\n  Corrigez l\u0026rsquo;algorithme recherche_dicho_corr en ajoutant un seul caractère.\nAttention, tout autre ajout, même un espace, rendra faux l\u0026rsquo;exercice.\n La figure suivante est un arbre binaire décrivant tous les chemins possibles que prend l\u0026rsquo;algorithme à partir d\u0026rsquo;une liste de 16 éléments (en vert, le nombre d\u0026rsquo;éléments restant).\nCet algorithme peut se montrer bien plus rapide que la recherche simple du TP1.\nRéouvrons la liste de mots de passe du TP2 mais en la transformant en liste de mots plutôt qu\u0026rsquo;en long texte.\n# importation de la classique liste de mots de passe rockyou (cela prend quelques secondes) from urllib.request import urlopen url = \u0026#39;http://cordier-phychi.toile-libre.org/Info/github/rockyou.txt\u0026#39; rockyou = urlopen(url).read().decode(\u0026#39;latin-1\u0026#39;).split() rockyou = sorted(rockyou) print(len(rockyou),\u0026#39;mots de passe\u0026#39;) 14445388 mots de passe\ndef trouve_indice(L, x): \u0026#39;\u0026#39;\u0026#39; trouve_indice(L : liste, x : type des éléments de L) -\u0026gt; soit un entier, soit un booléen postcondition : renvoie l\u0026#39;indice d\u0026#39;un éléments x lorsqu\u0026#39;il est présent dans la liste L et renvoie False lorsqu\u0026#39;il est absent \u0026#39;\u0026#39;\u0026#39; for indice, element in enumerate(L): if element == x: return indice return False Rq : enumerate est une fonction native souvent très pratique.\nhelp(enumerate) Help on class enumerate in module builtins: class enumerate(object) | enumerate(iterable, start=0) | | Return an enumerate object. | | iterable | an object supporting iteration | | The enumerate object yields pairs containing a count (from start, which | defaults to zero) and a value yielded by the iterable argument. | | enumerate is useful for obtaining an indexed list: | (0, seq[0]), (1, seq[1]), (2, seq[2]), ... | | Methods defined here: | | __getattribute__(self, name, /) | Return getattr(self, name). | | __iter__(self, /) | Implement iter(self). | | __next__(self, /) | Implement next(self). | | __reduce__(...) | Return state information for pickling. | | ---------------------------------------------------------------------- | Static methods defined here: | | __new__(*args, **kwargs) from builtins.type | Create and return a new object. See help(type) for accurate signature. from time import time from random import randint import matplotlib.pyplot as plt plt.style.use(\u0026#39;seaborn\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 6) Indice, T_ch = [], [] liste_noms = [\u0026#39;567890\u0026#39;,\u0026#39;billgates\u0026#39;,\u0026#39;dollars\u0026#39;,\u0026#39;jklmno\u0026#39;,\u0026#39;pupuce\u0026#39;,\u0026#39;zorro\u0026#39;] for nom in liste_noms: start = time() i = trouve_indice(rockyou,nom) stop = time() Indice.append(i) T_ch.append(stop-start) print(f\u0026#34;{stop -start:.2e} s pour trouver \u0026#39;{nom}\u0026#39; qui est à la position {i}\u0026#34;) plt.plot(Indice,T_ch,\u0026#39;--\u0026#39;) plt.plot(Indice,T_ch,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) plt.xlabel(\u0026#34;Position dans la liste\u0026#34;) plt.ylabel(\u0026#34;Temps pour trouver le nom (s)\u0026#34;) 1.84e-01 s pour trouver '567890' qui est à la position 2612528\n3.93e-01 s pour trouver 'billgates' qui est à la position 5584305\n4.85e-01 s pour trouver 'dollars' qui est à la position 6925245\n6.32e-01 s pour trouver 'jklmno' qui est à la position 8867150\n8.32e-01 s pour trouver 'pupuce' qui est à la position 11949039\n1.01e+00 s pour trouver 'zorro' qui est à la position 14416270\n Comment semble évoluer le temps de recherche en fonction de la position dans la liste ?\n Avec l\u0026rsquo;algorithme de recherche dichotomique, on obtient :\nT_ch = [] liste_noms = [\u0026#39;567890\u0026#39;,\u0026#39;billgates\u0026#39;,\u0026#39;dollars\u0026#39;,\u0026#39;jklmno\u0026#39;,\u0026#39;pupuce\u0026#39;,\u0026#39;zorro\u0026#39;] for i,nom in zip(Indice,liste_noms): start = time() recherche_dicho_corr(rockyou,nom) stop = time() T_ch.append(stop-start) print(f\u0026#34;{stop -start:.2e} s pour trouver {nom} qui est à la position {i}\u0026#34;) plt.plot(Indice,T_ch,\u0026#39;--\u0026#39;) plt.plot(Indice,T_ch,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) for i in range(len(liste_noms)) : plt.text(Indice[i]+max(Indice)/100,T_ch[i],liste_noms[i]) plt.xlabel(\u0026#34;Position dans la liste (s)\u0026#34;) plt.ylabel(\u0026#34;Temps pour trouver le nom\u0026#34;) plt.savefig(\u0026#39;graph.png\u0026#39;,dpi=600) 1.41e-05 s pour trouver 567890 qui est à la position 2612528\n1.41e-05 s pour trouver billgates qui est à la position 5584305\n1.10e-05 s pour trouver dollars qui est à la position 6925245\n2.19e-05 s pour trouver jklmno qui est à la position 8867150\n1.12e-05 s pour trouver pupuce qui est à la position 11949039\n1.41e-05 s pour trouver zorro qui est à la position 14416270\nOn constate que l\u0026rsquo;algorithme dichotomique met beaucoup moins de temps et qu\u0026rsquo;il ne semble pas dépendre clairement de la position de l\u0026rsquo;élément.\nTentons de comparer le comportement des deux algorithmes quand la longueur de la liste augmente.\nQuel que soit l\u0026rsquo;algorithme de recherche, la pire situation possible correspond à la recherche d\u0026rsquo;un élément absent de la liste.\nSe placer dans ce pire des cas permet une comparaison plus sûre des algorithmes ; on sait à quoi s\u0026rsquo;attendre !\nMesurer un temps dépend de trop de paramètres (processeur, utilisation de la mémoire par le système, etc.).\nUne information plus universelle est le nombre d\u0026rsquo;étapes de l\u0026rsquo;algorithme.\nPlus précisément, concentrons sur le nombre de comparaisons entre l\u0026rsquo;élément recherché x et les éléments de la liste L.\nOn a construit ci-dessous la fonction trouve_indice_etapes dont la description est donnée :\ndef trouve_indice_etapes(L,x): \u0026#34;\u0026#34;\u0026#34; trouve_indice_etapes(liste : list, valeur : type des éléments de la liste) -\u0026gt; bool, int postcondition : retourne à la fois un booléen qui traduit la présence ou non de l\u0026#39;élément et un entier correspondant au nombre de comparaisons effectuées entre x et les éléments de L \u0026#34;\u0026#34;\u0026#34; nb_comp = 0 for indice, element in enumerate(L): nb_comp += 1 if element == valeur: return True,nb_comp return False,nb_comp  À vous de jouer pour construire sur le même modèle recherche_dico_etapes :\n def recherche_dicho_etapes(L,x) : \u0026#34;\u0026#34;\u0026#34; recherche_dicho_etapes(liste : list, valeur : type des éléments de la liste) -\u0026gt; bool, int postcondition : doit retourner à la fois un booléen qui traduit la présence ou non de l\u0026#39;élément et un entier correspondant au nombre de comparaisons effectuées entre x et les éléments de L \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Maintenant, comparons :\nimport pandas as pd NB_elts, NB_comp = [], [] nom = \u0026#39;???#!!!\u0026#39; liste_longueurs = [10*2**i for i in range(1,19)] for longueur in liste_longueurs: start = time() nb_comp = trouve_indice_etapes(rockyou[:longueur],nom)[1] stop = time() NB_elts.append(longueur) NB_comp.append(nb_comp) d = {\u0026#39;taille\u0026#39; : NB_elts,\u0026#39;# comparaisons\u0026#39;: NB_comp} tableau = pd.DataFrame(data=d) display(tableau) fig, axs = plt.subplots(2,figsize=(15,12)) axs[0].plot(NB_elts,NB_comp,\u0026#39;--\u0026#39;) axs[0].plot(NB_elts,NB_comp,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) axs[1].semilogx(NB_elts,NB_comp,\u0026#39;--\u0026#39;) axs[1].semilogx(NB_elts,NB_comp,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) axs[0].set(xlabel=\u0026#39;Longueur de la liste\u0026#39;, ylabel=\u0026#39;Nb de comparaisons\u0026#39;) axs[1].set(xlabel=\u0026#39;Longueur de la liste (axe logarithmique)\u0026#39;, ylabel=\u0026#39;Nb de comparaisons\u0026#39;)   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    taille # comparaisons     0 20 20   1 40 40   2 80 80   3 160 160   4 320 320   5 640 640   6 1280 1280   7 2560 2560   8 5120 5120   9 10240 10240   10 20480 20480   11 40960 40960   12 81920 81920   13 163840 163840   14 327680 327680   15 655360 655360   16 1310720 1310720   17 2621440 2621440     NB_elts, NB_comp = [], [] nom = \u0026#39;???#!!!\u0026#39; liste_longueurs = [10*2**i for i in range(1,19)] for longueur in liste_longueurs: start = time() nb_comp = recherche_dicho_etapes(rockyou[:longueur],nom)[1] stop = time() NB_elts.append(longueur) NB_comp.append(nb_comp) d = {\u0026#39;taille\u0026#39; : NB_elts,\u0026#39;# comparaisons\u0026#39;: NB_comp} tableau = pd.DataFrame(data=d) display(tableau) fig, axs = plt.subplots(2,figsize=(15,12)) axs[0].plot(NB_elts,NB_comp,\u0026#39;--\u0026#39;) axs[0].plot(NB_elts,NB_comp,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) axs[1].semilogx(NB_elts,NB_comp,\u0026#39;--\u0026#39;) axs[1].semilogx(NB_elts,NB_comp,\u0026#39;o\u0026#39;,c=\u0026#39;C2\u0026#39;) axs[0].set(xlabel=\u0026#39;Longueur de la liste\u0026#39;, ylabel=\u0026#39;Nb de comparaisons\u0026#39;) axs[1].set(xlabel=\u0026#39;Longueur de la liste (axe logarithmique)\u0026#39;, ylabel=\u0026#39;Nb de comparaisons\u0026#39;)   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    taille # comparaisons     0 20 5   1 40 6   2 80 7   3 160 8   4 320 9   5 640 10   6 1280 11   7 2560 12   8 5120 13   9 10240 14   10 20480 15   11 40960 16   12 81920 17   13 163840 18   14 327680 19   15 655360 20   16 1310720 21   17 2621440 22     Recherche dichotomique d\u0026rsquo;une racine On cherche à appliquer la méthode de la dichotomie (découpage en deux systématique d\u0026rsquo;un intervalle) à la recherche d\u0026rsquo;une racine.\nPlus précisément, on souhaite déterminer une approximation d’une racine (ou zéro) sur un intervalle $[a, b]$, avec une précision $ε$, d’une fonction continue et monotone $f$ sur cet intervalle et telle que $f(a)$ et $f(b)$ sont de signes opposés ($f(a)f(b)≤0)$. Elle consiste à comparer le signe de l’image $f\\left(\\frac{a + b}{2}\\right)$ du milieu de l’intervalle $[a, b]$ avec le signe de $f(a)$ et $f(b)$ pour réduire l’intervalle de recherche de manière itérative.\nPour déterminer $x_0$, racine de la fonction $f$, strictement monotone sur l’intervalle $[a, b]$, avec une précision $ε,$ on procède comme suit :\n On détermine le milieu de l’intervalle $m = \\frac{a+b}{2}$ ; On compare le signe de $f(m)$ avec celui de $f(a)$ et $f(b)$ pour déterminer dans quel intervalle $[a, m]$ ou $[m, b]$ se trouve la racine $x_0$ ; On affecte à $a$ (resp. $b$) la valeur de $m$ si la racine se trouve entre $m$ et $b$ (resp. $a$) ; On itère tant que $|a − b| \u0026gt; ε$, (ε est la précision définie initialement), et on renvoie $m$.   Construisez une fonction racine prenant en argument une fonction f, les bornes d\u0026rsquo;un intervalle a et b, et une précision eps et retournant la racine ainsi que le nombre d\u0026rsquo;itérations nécessaires. Vous vous assurerez grâce à un assert qu\u0026rsquo;au moins une racine existe bel et bien dans l\u0026rsquo;intervalle choisi et vous sécuriserez la boucle while en ajoutant une condition empèchant l\u0026rsquo;algorithme d\u0026rsquo;utiliser plus de 100 itérations.\n def racine(f,a,b,eps) : \u0026#34;\u0026#34;\u0026#34; racine(f : fonction, a : flottant, b : flottant, eps : flottant) -\u0026gt; racine : flottant, nbiter : entier précondition : f doit être une fonction n\u0026#39;ayant qu\u0026#39;un argument (un flottant) et ne retournant qu\u0026#39;un flottant. \u0026#34;\u0026#34;\u0026#34; ### BEGIN SOLUTION  Comment évolue l\u0026rsquo;accroissement du nombre d\u0026rsquo;iterations en fonction de l\u0026rsquo;accroissement du nombre de chiffres significatifs obtenus pour la racine ?\n "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/tp8correc/",
	"title": "TP 8 : correction et complexité",
	"tags": [],
	"description": "",
	"content": "TP 8 : correction et complexité Cliquez sur cette invitation pour récupérer le repository du TP. Multiplication égyptienne Considérons le code suivant, qui implémente un ancien algorithme égyptien.\na et b sont supposés être des entiers positifs.\ndef multegy(a, b) : p = 0 while a \u0026gt; 0 : if a%2 == 1 : p += b b *= 2 a //= 2 return p  Qui est le variant de boucle permettant de prover que meltegy termine toujours ?\n a : a b : b c : p d : autre réponse    Détaillez l\u0026rsquo;éxécution de multegy(23,5) en affectant à a_i, b_i, c_i, les valeurs rencontrées à chaque itération.\n Construisons la preuve de l\u0026rsquo;algorithme :\non va montrer que $a\\times b + p$ est un invariant de boucle et l\u0026rsquo;utiliser pour prouver que l\u0026rsquo;algorithme retourne bien le produit entre $a$ et $b$.\nNotons $a_k$, $b_k$, $p_k$, les valeurs de $a$, $b$ et $p$ après la ke itération et supposons $a_k\\times b_k + p_k = cste$.\n initialisation : pour $k=0$, $a_0=a$, $b_0=b$ et $p_0=0$. D\u0026rsquo;où $a_0\\times b_0+p_0=a\\times b$ conservation : à la boucle $k+1$, deux cas se présentent :  si $a$ est impair : $a_{k+1} = X$, $b_{k+1} = Y$ et $p_{k+1}= Z$.\nD\u0026rsquo;où $a_{k+1}\\times b_{k+1} + p_{k+1} = a_k\\times b_k - b_k +p_k+ b_k = a_k\\times b_k+p_k$ si $a$ est pair : $a_{k+1} = \\frac{a_k}{2}$, $b_{k+1} = b_k\\times 2$ et $p_{k+1}=p_k$.\nD\u0026rsquo;où $a_{k+1}\\times b_{k+1} + p_{k+1} = a_k\\times b_k + p_k$\nPar conséquent, $a_k\\times b_k + p_k$ est bien un invariant pour tout $k$.   terminaison : en sortie de boucle (itération $f$), $a_f = 0$, donc $a_f\\times b_f+p_f = p_f$. Or comme l\u0026rsquo;invariant est\u0026hellip; invariant, il garde toujours la valeur qu\u0026rsquo;il possède en entrée (pour $k=0$) : d\u0026rsquo;où $p_f = a\\times b$. Et comme la fonction retourne $p_f$, cqfd.   Que vallent X,Y et Z ?\n a : $a_k$, $b_k$, $p_k+b_k$ b : $\\frac{a_k-1}{2}$, $b_k\\times 2$, $p_k+b_k$ c : $\\frac{a_k+1}{2}$, $b_k\\times 2$, $p_k$    Quelle est la complexité de multegy (en supposant chacun des calculs comme élémentaire) ?\n a : $O(a)$ b : $O(a\\times b)$ c : $O(a\\log b)$ d : $O(\\log a)$ e : $O(b)$    Deux fonctions de recherche def cherche(s, m) : for k in range(len(s) - len(m) + 1) : b = True for i in range(len(m)) : if s[k + i] != m[i] : b = False if b : return True return False def cherche2(s, m) : for k in range(len(s) - len(m) + 1) : if s[k:k + len(m)] == m : return True return False  Quelle est la complexité de la fonction cherche ? Et celle de cherche2 ?\nAppelons len(s) n et len(m) p.\n a : les deux en $O(n\\times p)$ b : cherche en $O(n\\times p)$ et cherche2 en en $O(n)$ c : une autre réponse   Exécuter le code suivant peut vous aider à confirmer votre réponse.\nimport time from random import randint abc = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39; def motdenlettres(n) : mot = \u0026#39;\u0026#39; for i in range(n) : mot += abc[randint(0,25)] return mot print(\u0026#39;-\u0026#39;*30) print(\u0026#39;| n | p | cherche2 |\u0026#39;) print(\u0026#39;-\u0026#39;*30) for j in range(2,6) : n = 10**5*2**j s = motdenlettres(n) for k in range(3) : p = 10**4*2**k m = motdenlettres(p) d = time.time() cherche2(s,m) f = time.time() t = f - d print(f\u0026#39;|{n:^9d}|{p:^8d}|{t:^10.2E}|\u0026#39;) print(\u0026#39;-\u0026#39;*30)  Quelle est la complexité au meilleur de la fonction cherche ?\n a : $O(n)$ b : $O(p)$ c : $O(1)$   Remarque :\nOn peut déterminer ce que fait la fonction cherche en mettant en lumière deux invariants, un pour chaque boucle.\nLa boucle interne a pour invariant \u0026ldquo;b équivaut à s[k:k+i]==m[:i]\u0026rdquo;.\nEt la boucle externe a pour invariant \u0026ldquo;s[j:j+len(m)] != m pour tout j\u0026lt;k\u0026rdquo; car s\u0026rsquo;il y avait égalité, on serait sorti de la boucle avec le return True.\nOn en conclut que si la boucle n’est jamais interrompue par le return True alors m n’est pas un sous-mot de s.\nSi la boucle est interrompue, d’après l’invariant de la boucle intérieure, on a trouvé m dans s.\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/nombre/",
	"title": "Les nombres en machine",
	"tags": [],
	"description": "",
	"content": "Représentation des nombres Comment un nombre est-il représenté à l\u0026rsquo;intérieur d\u0026rsquo;un ordinateur ?\nL\u0026rsquo;espace pour représenter un nombre en machine est limité. Si cette limitation n\u0026rsquo;a pas trop d\u0026rsquo;impact pour les entiers (surtout en Python !) elle devient très handicapante pour représenter les réels.\nLa représentation machine d\u0026rsquo;un nombre est appelée mot machine. Sa taille est généralement aujourd\u0026rsquo;hui de 64 bits.\n  Les différentes bases Une écriture en base $b$ utilise $b$ chiffres différents :\n 0, 1, 2, 3, 4, 5, 6, 7, 8 et 9 pour la base décimale 0 et 1 pour la base binaire 0, 1, 2, 3 pour la base 4 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E et F pour la base hexadécimale  Un nombre $a$ écrit dans une basse $b$ se note $(a_n a_{n-1}\\cdots a_0)_b$ avec $(a_n a_{n-1}\\cdots a_0)_b = a_n\\times b^n + a_{n-1} \\times b^{n-1}+ \\cdots + a_0 = \\sum\\limits_{i=0}^{n} a_i,b^i$\n Conversions La conversion d’une base à une autre n’est pas un objectif de formation d\u0026rsquo;après le B.O. Néanmoins, la comparaison et les pièges des algorithmes qui suivent dépassent le simple enjeu de la conversion. Moralité, pas besoin d\u0026rsquo;apprendre par cœur ces algorithmes, mais leur étude est conseillée.\n  Pour convertir un nombre d\u0026rsquo;une base $b\u0026lt;10$ vers la base 10 :  Il suffit de calculer la somme précédente (si $b\u0026gt;10$, il faut en plus donner la valeur des nouveaux chiffres).\nComparaison de deux algorithmes :\n Algorithme classique :  def convbvers10(a,b) : \u0026#34;\u0026#34;\u0026#34; Convertit a de la base b à la base 10 le nombre à convertir a doit être passé en argument sous la forme d\u0026#39;une chaine de caractères \u0026#39;a_n...a_0\u0026#39; b, la base, est un entier inférieur à 10. La fonction retourne un entier en base 10. \u0026#34;\u0026#34;\u0026#34; s = 0 n = len(a)-1 for e in a : s += int(e)*b**n n -= 1 return s convbvers10(\u0026#39;100101101\u0026#39;,2) 301\nconvbvers10(\u0026#39;10231\u0026#39;,4) 301\n Méthode de Horner (qui utilise des multiplications imbriquées) :  $a = ((((a_nb+a_{n-1})b+a_{n-2})b+\\cdots)b+a_1)b+a_0$\nImplémentée en Python, cela donne :\ndef convbvers10_Horner(a,b) : \u0026#34;\u0026#34;\u0026#34; Convertit a de la base b à la base 10 en utilisant la méthode de Horner le nombre à convertir a doit être passé en argument sous la forme d\u0026#39;une chaine de caractères \u0026#39;a_n...a_0\u0026#39; b, la base, est un entier inférieur à 10. La fonction retourne un entier en base 10. \u0026#34;\u0026#34;\u0026#34; s = 0 for i in range(0,len(a)) : s = s*b + int(a[i]) return(s) convbvers10_Horner(\u0026#39;100101101\u0026#39;,2) 301\n Lequel de ces deux algorithmes est le plus eficace ?\n  la fonction Python native int() permet aussi de convertir un nombre écrit dans une base $b$ vers la base décimale en ajoutant $b$ en argument.\n int(\u0026#39;10231\u0026#39;,4) 301\n  Pour convertir de la base 10 vers la base $b$ :  On peut remarquer que le quotient de la division euclidienne de $a=(a_n a_{n-1}\\cdots a_0)_b$ par $b$ vaut $(a_n a_{n-1}\\cdots a_1)_b$ et que le reste vaut $a_0$. De même, le quotient de la division euclidienne de $(a_n a_{n-1}\\cdots a_1)_b$ par $b$ vaut $(a_n a_{n-1}\\cdots a_2)_b$ et le reste vaut $a_1$. Et on continue tant que le quotient est non nul. On obtient ainsi la décomposition de $a$ dans la base $b$.\nUn algorithme en découle naturellement :\ndef conv10versb(a,b) : \u0026#34;\u0026#34;\u0026#34; Arguments : nombre à convertir et base cible la fonction retourne une chaîne de caractère correspondant au nombre a dans la base b. \u0026#34;\u0026#34;\u0026#34; s = \u0026#39;\u0026#39; while a \u0026gt; 0 : s = str(a%b) + s # le dernier terme est ajouté à gauche de la chaîne ! a //= b return s conv10versb(301,2) '100101101'\n les fonctions Python natives bin() et hex() permettent de convertir directement un nombre de la base 10 vers les bases respectives 2 et 16 (ces fonctions retournent des chaînes de caractères).\n bin(301,2) '0b100101101'\n Usages des différentes bases  La base binaire :  C\u0026rsquo;est la base naturelle de l\u0026rsquo;ordinateur. Avec ses deux caractères (0 et 1), c\u0026rsquo;est la seule que peut adresser directement un ordinateur dont la nature même n\u0026rsquo;est qu\u0026rsquo;interrupteurs, passant ou non. Chaque bit est un chiffre binaire.\nEn base 2, les calculs sont facilités et la plupart des algorithmes scolaires des opérations de base marchent, voir sont simplifiés.\nPrenons l\u0026rsquo;exemple de la multiplication : chaque 1 du second facteur décale le premier facteur d\u0026rsquo;autant de rangs que son propre rang dans le second facteur, puis on additionne entre eux tous les différents termes obtenus (on utilisera cette méthode dans l\u0026rsquo;algorithme de multiplication égyptienne du TP8) .\nEn Python, on peut écrire un nombre directement en base 2 si on le précède des caractères 0b.\na = 0b1011011 b = 0b1011 a*b bin(a*b) '0b1111101001'\n  La base hexadécimale :  La base 16 joue un rôle particulier en informatique. Pour quelle raison ? L’écriture binaire d’un nombre présente l’inconvénient d’être très longue. Une base plus élevée est à cet égard préférable. Le choix de la base 10 pourrait paraître naturel, mais malheureusement, convertir un nombre de la base 10 à la base 2 ou inversement n’est pas simple. En revanche, nous allons voir que passer de la base 2 à la base 16 est naturel.\nPour écrire un nombre en base 16, nous avons besoin d’un caractère pour chacun des entiers de 0 à 15 ; on complète donc les chiffres de 0 à 9 par les lettres a, b, c, d, e et f.\nAinsi, $(\\text{a})_{16} = 10$, $(\\text{b})_{16} = 11$, $(\\text{c})_{16} = 12$, $(\\text{d})_{16} = 13$, $(\\text{e})_{16} = 14$, $(\\text{f})_{16} = 15$.\nSachant que $2^4 = 16$, tout nombre écrit en base 2 à l’aide de 4 chiffres s’écrit en base 16 à l’aide d’un seul chiffre :\nAussi, pour convertir un nombre quelconque de la base 2 à la base 16, il suffit de regrouper les chiffres qui le composent par paquet de 4 et convertir chacun de ces paquets en un chiffre en base 16.\nPar exemple $(1100,0111,1110,1011)_2$ = $(\\text{c}7\\text{eb})_{16}$.\nUn octet (8 bits) est donc représenté par au plus deux caractères hexadécimaux, ce qui explique l\u0026rsquo;intérêt de cette base (les octets, unité de mémoire, sont partout en informatique).\nExemple : une couleur peut être définie par trois octets représentant ses composantes RVB. Ci-dessous, chaque mot de 3 octets sert aussi à coder la couleur en HTML :\nff0000  00ff00  0000ff  aa00aa  777777  a3850e  07ab98  (code HTML du dernier mot : \u0026lt;font color=#07ab98\u0026gt; 07ab98 \u0026lt;/font\u0026gt;)\n$256^3 = 16\\,777\\,216$ couleurs différentes sont ainsi accessibles.\nChoix couleur :  Comme pour les nombres binaires, Python permet d\u0026rsquo;écrire directement en base 16 si on précède le nombre des caractères 0x.\n0xd 13\nbin(0xd) '0b1101'\nhex(0b11110111) '0xf7'\nLa plus \u0026ldquo;efficace\u0026rdquo; des bases est la base ternaire, suivie de près par la base binaire (où la notion d\u0026rsquo;efficacité est définie dans l\u0026rsquo;article en lien).\n  Codage des nombres entiers en machine Nombres entiers naturels Les entiers naturels sont essentiellement utilisés pour représenter les adresses en mémoire.\nUn mot machine de n bits permet de représenter tous les nombres naturels compris entre 0 et $2^n − 1$. Ainsi, un octet permet de coder les entiers allant de $0 = (00)_{16} = (0000,0000)_2$ à $255 = (\\text{ff})_{16} = (1111,1111)_2$, et 64 bits (soit 8 octets) tous les nombres allant de $0 = (0000,0000,0000,0000)_{16}$ à $2^{64}−1 = (\\text{ffff},\\text{ffff},\\text{ffff},\\text{ffff})_{16}$.\nNombres entiers relatifs Il faut un bit supplémentaire pour coder le signe. Le premier bit, 0 pour un nombre positif et 1 pour un nombre négatif, est donc réservé.\nAinsi, le plus grand entier relatif représentable sur n bits vaut $2^{n-1}-1$. Pour un processeur 64 bits, cela correspond à $2^{63}-1=(7\\text{fff},\\text{ffff},\\text{ffff},\\text{ffff})_{16}$\n2**63-1 9223372036854775807\n  codage binaire naturel signé  La méthode paraissant la plus simple pour coder les nombres relatifs est alors le codage binaire naturel signé : on place le bit de signe devant la valeur absolue de l\u0026rsquo;entier codé normalement sur $n-1$ bits. Par exemple, sur 4 bits, 3 est codé par le mot 0011 et -3 par 1011.\nSimple, oui, mais cela pose 2 problèmes :\n il y a 2 représentations de 0 (les mots 0000 et 1000 sur 4 bits), les opérations arithmétiques ne sont pas faciles (l\u0026rsquo;addition \u0026ldquo;normale\u0026rdquo; de 3 et -3 codés ainsi sur 4 bits donnerait 1110, soit -6\u0026hellip;).    complément à 2  La solution qui a été adoptée pour éviter ces problèmes est le complément à 2 :\nCe codage découle du problème posé par l\u0026rsquo;addition précédente : comment faire pour que l\u0026rsquo;addition de 2 nombres opposés vaille 0 ? La solution est d\u0026rsquo;utiliser l\u0026rsquo;absence du bit $n+1$ dans un codage à $n$ bits. Par exemple, à 4 bits, si on additionne $5$ ($0101$) avec $11$ ($1011$), on obtient $16$ ($\\color{red}{1}\\color{green}{0000}$) qui devient $0$ ($\\color{green}{0000}$) puisqu\u0026rsquo;il n\u0026rsquo;y a pas de 5e bit. Il suffit donc d\u0026rsquo;associer 11 à -5, et de la même façon, 8 à -8, 9 à -7, 10 à -6, 12 à -4, 13 à -3, 14 à -2, et 15 à -1.\nDe manière générale, pour un codage sur n bits, les $2^{n-1}$ premiers entiers, tous commençants par 0, sont les entiers positifs et on associe les $2^{n-1}$ entiers suivants, commençant par 1, donc négatifs, de façon à ce qu\u0026rsquo;il complète chaque entier positif à la puissance de 2 supérieure, $2^n$ (d\u0026rsquo;où \u0026ldquo;complément à 2\u0026rdquo;).\nLes nombres négatifs sont donc placés au-dessus plutôt qu\u0026rsquo;en dessous et on peut visualiser ça comme un enroulement sur un cercle des nombres positifs et négatifs.\nEn pratique, si on veut le mot codant -3, il suffit d\u0026rsquo;inverser chaque bit du codage de 3 et d\u0026rsquo;ajouter 1 :\n$0011 \\rightarrow 1100$\n$1100+1 = 1101$\ndonc $-3 \\rightarrow 1101$\n  Dépassement de capacité : On remarque qu\u0026rsquo;avec ce type de codage, un dépassement de capacité (ou overflow en anglais) ne lèvera pas d\u0026rsquo;erreur, mais aboutira à des valeurs aberrantes.\nSupposons par exemple que l\u0026rsquo;on veuille additionner 5 et 7 sur un codage 4 bits. On obtiendra\u0026hellip; -4 !\n    C\u0026rsquo;est un bug de ce type, un overflow, qui a fait exploser la fusée Ariane 5 lors de son vol inaugural (le vol 501) causant la perte de la fusée et de sa charge utile (4 satellites). Ce bug est un des plus coûteux de l\u0026rsquo;histoire (370 millions d\u0026rsquo;euros).\nC\u0026rsquo;est au niveau de la plateforme inertielle (ensemble des capteurs, accéléromètres et gyroscopes, permettant de guider la fusée), héritée de la fusée précédente Ariane 4, que le bug apparut. Plus précisément, c\u0026rsquo;est le capteur d\u0026rsquo;accélération horizontale qui fut débordé pendant sa phase de calibrage (lors des premières 40 s du vol). Codée sur 8 bits, la valeur d\u0026rsquo;accélération maximum représentable était donc de $2^7-1=127$, ce qui était suffisant pour Ariane 4 (valeur max : 64). Mais plus puissante et avec une trajectoire de décollage différente, Ariane 5 engendre des accélérations horizontales qui peuvent être jusqu\u0026rsquo;à 5 fois plus fortes pendant la phase de décollage (valeur max : 300). Cela aboutit à une valeur absurde que le guidage essaya de compenser\u0026hellip; boom.\nEt comble de la frustration : ce calibrage en début de vol était devenu inutile pour Ariane 5.\n Qu\u0026rsquo;en est-il de Python ?\nContrairement à la plupart des langages, Python n\u0026rsquo;alloue pas de taille à priori aux entiers. Par conséquent, ils peuvent dépasser la taille maximale adressable par le processeur et sont donc de précision arbitraire, la seule limite étant la taille totale de la RAM.\n2**200 1606938044258990275541962092341162602522202993782792835301376\nSi cela facilité pas mal les opérations arithmétiques sur les grands nombres, cela complique l\u0026rsquo;étude de la complexité, car si un entier prend plusieurs mots mémoires, la plupart de ses manipulations ne sont plus des étapes élémentaires.\\\nD\u0026rsquo;autre part, certain package très utilisé, et particulièrement NumPy, utilisent des entiers de précision fixée.\nimport numpy as np a = np.array(2**63-1) a.dtype dtype('int64')\nAjouter 1 à a va causer un overflow sans lever d\u0026rsquo;erreurs :\nb = a+1 b -9223372036854775808\na + b -1\n Codage des nombres décimaux en machine Nombres dyadiques Un nombre décimal $x$ est un nombre pouvant s\u0026rsquo;écrire sous la forme $\\frac{x}{10^n}$. Son développement décimal s\u0026rsquo;obtient en décomposant $x$ sur les puissances de 10 positives et négatives d\u0026rsquo;exposants allant au maximum jusqu\u0026rsquo;à -n : $\\frac{5}{8}=0,625=\\frac{625}{10^3} = \\frac{6}{10^1}+ \\frac{2}{10^2} + \\frac{5}{10^3}$. Mais la plupart des nombres ne possède pas un développement décimal fini ($\\frac{1}{3}=0,33333\\cdots$ par exemple).\nL\u0026rsquo;équivalent binaire des nombres décimaux correspond aux nombres dyadiques. Ainsi, $\\frac{5}{8}=\\frac{5}{2^3}$ est un nombre dyadique et son développement dyadique s\u0026rsquo;écrit : $\\frac{5}{8}=\\frac{1\\times 2^2+0\\times 2^1+1\\times 2^0}{8}=\\frac{1}{2^1}+\\frac{0}{2^2}+\\frac{1}{2^3}=(0,101)_2$\nComme pour les décimaux, la plupart des nombres ne possèdent pas un développement dyadique fini, mais cela ne correspond pas aux mêmes nombres ! C\u0026rsquo;est le cas par exemple de $0,1$ : $\\frac{1}{10} = (0,0001,1001,1001,1001\\cdots)_2$.\nLa représentation de $0,1$ sera donc nécessairement tronquée par la machine :\n0.1**2 0.010000000000000002\n0.1**2 == 0.01 False\nConclusion : cela n\u0026rsquo;a pas de sens de tester une égalité sur autre chose que des entiers.\nIl faut se restreindre à tester des inégalités :\nabs(0.1**2 - 0.01) \u0026lt; 1e-10 True\n Nombres en virgule flottante Nous connaissons la notation scientifique qui normalise tous les nombres décimaux avec une mantisse comprise entre 1 et 9,999… et une puissance de dix restituant la grandeur du nombre.\nLes nombres en virgule flottante (ou au format flottant) peuvent être vus comme l\u0026rsquo;équivalent informatique de la notation scientifique.\nLa notation flottante comprend trois composantes :\n le signe s, la mantisse m, l\u0026rsquo;exposant e de la puissance de b.  Un nombre $x$ s\u0026rsquo;écrit donc $x=s\\times m\\times b^e$ où $b$ est la base.\nEn faisant varier l\u0026rsquo;exposant, on fait « flotter » la virgule.\nLe format flottant est le format privilégié pour représenter les nombres décimaux en machine (la base est alors 2 bien sûr).\n Norme IEEE-754 La norme elle-même n\u0026rsquo;est pas à connaître, mais son principe permet de comprendre comment les mots machines correspondant aux flottants sont construits.\n Cette norme est actuellement le standard pour la représentation des nombres à virgule flottante en binaire.\nPour une architecture 64 bits, le signe est codé sur 1 bit, l\u0026rsquo;exposant sur 11 et la mantisse sur 52. Le format est alors dit double précision pour le distinguer du simple précision stocké sur 32 bits.\nComme le premier chiffre significatif d\u0026rsquo;un nombre binaire est nécessairement 1, ce 1 n\u0026rsquo;est pas inclus dans les 52 bits de la mantisse. Les 52 bits permettent donc 53 bits de précision grâce à ce bit caché. On dit alors que le flottant est normalisé.\n Exemple : comment est représenté le nombre décimal $13256,625$ ?\n$13256,625 = (11001111001000.101)_2 = 1,1001111001000101\\times 2^{13}$\nDonc l\u0026rsquo;exposant vaut 13, et comme on l\u0026rsquo;a dit, on omet le premier 1 dans la mantisse qui s\u0026rsquo;écrit donc :\n$1001111001000101000000000000000000000000000000000000$ (les 16 bits après le premier 1 de l\u0026rsquo;écriture binaire de $13256,625$ suivis de 36 zéros).\nL\u0026rsquo;exposant est représenté avec un décalage : on lui ajoute $2^{10}-1=1023$.\nCela permet de stocker des exposants allant de $-1022$ à $1023$ sur des valeurs toutes positives allant de $1$ à $2046$.\nDans notre cas, l\u0026rsquo;exposant est représenté avec la valeur $13+1023=1036=10000001100$\nAu final, la représentation au format flottant 64 bits normalisé de $13256,625$ est :\n$0\\;10000001100\\;1001111001000101000000000000000000000000000000000000$\nElle est exacte.\n Par contre, la représentation de $0,1$ est, elle, tronquée :\n$0\\;01111111011\\;1001100110011001100110011001100110011001100110011010$\nEn décimal, ce nombre correspond à $0,100000000000000005551115123126$.\n Les soucis des flottants En général, les 53 bits (en incluant le bit caché) permettent 15 chiffres significatifs en décimal ($\\log_{10} 2^{53} = 15,95$).\nTout calcul impliquant un nombre de chiffres plus grands sera sujet à une erreur d\u0026rsquo;arrondi.\nLa limite supérieure de l\u0026rsquo;erreur d\u0026rsquo;approximation relative causée par l\u0026rsquo;arrondi est appelée epsilon de la machine $\\varepsilon$.\nPour Python :\nimport sys eps = sys.float_info.epsilon eps 2.220446049250313e-16\nCette valeur est logiquement $2^{-52}$, la dernière position de la mantisse.\nConséquence de ces arrondis : lors de l\u0026rsquo;addition de deux nombres à l\u0026rsquo;écart relatif très important, il peut y avoir absorption du petit par le grand !\nL\u0026rsquo;addition de flottants n\u0026rsquo;est plus associative.\n (1 + 2.**53) - 2.**53 0.0\n1 + (2**53 - 2**53) 1\nExplication : $1+2^{53} = (1, \\underbrace{000\\cdots000}_\\text{52 zéros}\\,\\color{red}{1}\\color{black}{)_2 \\times 2^{53}} \\Rightarrow$ Le dernier 1 se voit tronqué.\n De plus, la multiplication de flottants n\u0026rsquo;est en général pas distributive.\n a, b, c = 100, 0.1, 0.2 a*b + a*c 30.0\na*(b+c) 30.000000000000004\n Beaucoup de calculs en flottants entraînent la perte de chiffres significatifs.\nLes cas les plus spectaculaires intervenant lorsqu\u0026rsquo;on soustrait deux nombres très proches.\n Prenons, pour simplifier, l\u0026rsquo;exemple de flottants décimaux dont la mantisse s\u0026rsquo;écrit sur 6 bits et représentons le calcul dont la forme exacte est :\n$1,2345432 - 1,23451 = 0,0000332$\nNotre système hypothétique est obligé de tronquer le premier terme $1,2345432 \\rightarrow 1,23454$.\nLe résultat de la soustraction donne alors :\n$1,23454 - 1,23451 = 0,00003$ On n\u0026rsquo;a plus qu\u0026rsquo;un seul chiffre significatif alors que le résultat exact avec ses 3 chiffres significatifs pouvait très bien être représenté par notre système à mantisse de 6 bits.\nOn parle alors de catastrophic cancellation.\nMême si les 15 chiffres significatifs des flottants double précision semblent beaucoup, des opérations répétées entraînent une cascade d\u0026rsquo;arrondis qui peuvent aboutir à des résultats dramatiques comme le montre l\u0026rsquo;exemple du missile patriot du TP.\nUne autre conséquence de la manière dont les flottants sont gérés est l\u0026rsquo;existence de valeur minimale et maximale stockable.\nLes calculs bayésiens, par exemple, requièrent de fréquentes multiplications entre petites probabilités. Mais en dessous d\u0026rsquo;une certaine valeur, un soupassement de capacité ou underflow amène le programme à afficher zéro.\nP = 1 for i in range(1,101) : if (i\u0026lt;6 or P\u0026lt;1e-306) : print(P) elif i == 10 : print(\u0026#39;...\u0026#39;) P *= 5e-4 1\n0.0005\n2.5e-07\n1.25e-10\n6.250000000000001e-14\n...\n1.0097419586828971e-307\n5.0487097934146e-311\n2.5243548965e-314\n1.2621776e-317\n6.31e-321\n5e-324\n0.0\nOn voit que la précision est progressivement abaissée avec l\u0026rsquo;affichage de nombres dits subnormaux (ce processus est appelé \u0026ldquo;gradual underflow\u0026rdquo;) avant l\u0026rsquo;affichage de zéro.\\\nLe plus petit nombre qui peut être représenté avec une précision complète est :\nsys.float_info.min 2.2250738585072014e-308\nDe l\u0026rsquo;autre côté, on a la possibilité d\u0026rsquo;un dépassement de capacité ou overflow. Le plus grand nombre affichable est :\nsys.float_info.max 1.7976931348623157e+308\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp5recu/",
	"title": "TP 5 : fonctions récursives",
	"tags": [],
	"description": "",
	"content": "Fonctions récursives   import numpy as np import matplotlib.pyplot as plt from matplotlib.patches import Rectangle plt.style.use(\u0026#39;seaborn\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (10, 10) fig, ax = plt.subplots() ax.set_aspect(1) couleurs = plt.rcParams[\u0026#39;axes.prop_cycle\u0026#39;].by_key()[\u0026#39;color\u0026#39;]  Visualisation des appels récursifs Installons un module permettant de représenter sous forme de graphe les différents appels récursifs d\u0026rsquo;une fonction.\n%%capture !pip install recursionvisualisation==0.2 On construit une fonction récursive somme(n) qui retourne la somme des n premiers entiers et on utilise un décorateur (fonction qui modifie le comportement d\u0026rsquo;autres fonctions) pour visualiser les différents appels récursifs faits par somme.\ncg = CallGraph() @viz(cg) # décorateur def somme(n): if n \u0026lt; 1: return 0 return n + somme(n - 1) print(somme(5)) cg.render() somme(5) = 15 On observe l\u0026rsquo;empilement des appels successifs de somme jusqu\u0026rsquo;à ce que le cas de base soit touché. Ces appels forment une pile d\u0026rsquo;exécution (ou pile d\u0026rsquo;appels, \u0026ldquo;call stack\u0026rdquo; en anglais).\nLe cas de base correspond à la première valeur retournée (0 ici) et donc au premier appel retiré de la pile. Tous les appels précédents sont restés en attente.\nOn remonte ensuite chronologiquement la pile des appels avec à chaque fois une nouvelle valeur retournée, jusqu\u0026rsquo;à l\u0026rsquo;appel initial, appelé appel terminal.\n Combien l\u0026rsquo;expression somme(100) va-t-elle provoquer d\u0026rsquo;appels de la fonction somme ?\n Les choses se compliquent si plusieurs appels récursifs sont faits dans la définition de la fonction.\nLe nombre d\u0026rsquo;appels progresse maintenant exponentiellement mais pas la taille de la pile d\u0026rsquo;exécution qui correspond au nombre de niveaux (à la profondeur de l\u0026rsquo;arbre).\ncg = CallGraph() @viz(cg) def fib(n): if n \u0026lt; 2: return n return fib(n-1) + fib(n-2) print(f\u0026#39;{fib(5) = }\u0026#39;) cg.render() fib(5) = 5 Comme on le voit ci-dessus, fib(5) fait 15 appels à la fonction mais la pile ne dépasse jamais 6 appels en attente.\nEn effet, fib(5) appelle fib(4) qui appelle fib(3)qui appelle fib(2) qui appelle fib(1). Comme fib(1) est un des deux cas de base possible, il retourne la valeur 1 et est retiré de la pile. Le dernier appel en attente de la pile est alors fib(2), on y retourne.\nfib(2) fait son deuxième appel : fib(0). fib(0) étant l\u0026rsquo;autre cas de base, il retourne une valeur (0) et est retiré de la pile. fib(2) peut maintenant elle aussi retourner une valeur (1+0) et est à son tour retirée de la pile.\nLe dernier appel en attente est dorénavant fib(3) qui fait maintenant son deuxième appel : fib(1). fib(1) retourne 1 et est retiré de la liste, fib(2) retourne 2 (1+1) et est retirée à son tour, et on remonte à fib(4) qui fait son deuxième appel, fib(2), qui elle-même appelle fib(1), etc.\n Quelle sera la taille maximale de la pile d\u0026rsquo;exécution de fib(100) ?\n  Deux tris récursifs Construisons les deux tris récursifs présentés dans la vidéo.\nTri insertion  Écrire la fonction insertion qui insert au bon endroit un nombre dans une liste triée afin qu\u0026rsquo;elle reste triée.\n def insertion(element,Ltriee) : \u0026#34;\u0026#34;\u0026#34; insertion(element : nombre, Ltriee : liste de nombres) -\u0026gt; Lsortie : liste de nombres insertion insert \u0026#39;nombre\u0026#39; au bon endroit dans \u0026#39;Ltriee\u0026#39; et retourne cette nouvelle liste. préconditions : \u0026#39;element\u0026#39; est un entier ou un flottant, \u0026#39;Ltriee\u0026#39; est une liste de nombres triée en ordre croissant postconditions : \u0026#39;Lsortie\u0026#39; est triée dans l\u0026#39;ordre croissant (et len(Lsortie)==len(Ltriee)+1) \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Exemple : insertion(5,[-12,1e-2,0,3,18]) doit renvoyer [-12,1e-2,0,3,5,18] .\n Combien d\u0026rsquo;itérations sont nécessaires dans le pire des cas pour insérer un élément dans une liste de longueur n ?\n  A : $n$ B : $2n$ C : $n^2$   Ajouter le cas de base à la fonction tri_insertion :\n def tri_insertion(liste) : n = len(liste) ### VOTRE CODE else : element = liste[0] reste = liste[1:] return insertion(element,tri_insertion(reste)) # si pas de return dans le else alors tous les appels de tri_insertion avec un len \u0026gt; 1 sont de type None !!!  Combien d\u0026rsquo;appels à tri_insertion sont faits au sein de tri_insertion(L) quand L à une taille n ?\n  A : $n-1$ B : $2^n$ C : $\\log_2(n)$   Tri fusion    Écrire la fonction fusion qui fusionne deux listes triées en une seule liste triée.\n def fusion(Ltrie1,Ltrie2) : \u0026#34;\u0026#34;\u0026#34; fusion(Ltrie1 : liste de nombres, Ltrie2 : liste de nombres) -\u0026gt; liste_sortie : liste de nombres fusion retourne une seule liste ordonnée à partir de deux sous-listes ordonnées. préconditions : Ltrie1 et Ltrie2 sont triées dans l\u0026#39;ordre croissant. postconditions : \u0026#39;Lfus\u0026#39; est triée dans l\u0026#39;ordre croissant (et len(Lfus)==len(Ltrie1)+len(Ltrie2)). \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Exemple : fusion([-12,3.5,18],[-2,15]) doit renvoyer [-12,-2,3.5,15,18].\n Compléter la définition de tri_fusion pour le rendre opérant.\n def tri_fusion(L) : n = len(L) if n == 1 : return L else : L = fusion(trifusion(L[:n//2]),trifusion(L[\u0026#39;...\u0026#39;])) return L Supposons que la longueur de la liste L soit une puissance de 2.\nAu niveau de récursivité $j$ (à l\u0026rsquo;appel initial de tri_fusion(L), $j=0$, pour les deux appels à tri_fusion au sein de tri_fusion(L), $j=1$, etc.), on a décomposé le problème initial en \u0026hellip; fusions, chacune opérant sur des sous-listes de taille \u0026hellip; .\n Par quoi faut-il compléter les pointillés respectivement ?\n  A : $2^j$ et $2^j$ B : $n/2^j$ et $n/2^j$ C : $2^j$ et $n/2^j$ D : $n/2^j$ et $2^j$   Algorithme d\u0026rsquo;Euclide Un des plus vieux algorithmes connus, l\u0026rsquo;algorithme d\u0026rsquo;Euclide, suit un raisonnement récursif et s\u0026rsquo;écrit donc naturellement de cette façon.\nPrincipe de l\u0026rsquo;algorithme : le plus grand commun divisieur (pgcd) entre deux nombres a et b est le même que celui entre b et le reste de la division euclidienne de a par b ($a\\pmod b$). Algébriquement, cela donne $\\text{pgcd}(a,b)=\\text{pgcd}(b,a\\pmod b)$.\nOn a donc ainsi réduit le problème initial en un problème plus simple, ce qui permet d\u0026rsquo;appliquer la technique algorithmique diviser pour régner.\n Écrivez une fonction récursive pgcd permettant de calculer le pgcd entre deux nombres (n\u0026rsquo;oubliez pas le cas de base qu\u0026rsquo;il vous faudra déterminer).\n def pgcd(a,b) : \u0026#34;\u0026#34;\u0026#34; pgcd(a:int,b:int)-\u0026gt;int \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE pgcd(1080,480) 120\nUne utilité géométrique du pgcd : le pavage d\u0026rsquo;un rectangle par les plus grands carrés possibles.\nax.clear() a = 1080 b = 480 ax.set_xlim([0, a]) ax.set_ylim([0, b]) ax.add_patch(Rectangle((0,0), a, b, color=\u0026#39;white\u0026#39;)) # Le côté du plus gros carré pavant le rectangle de longueur a et largeur b vaut pgcd(a,b) ! for i in range(a//pgcd(a,b)) : # a//pgcd(a,b) : nombre de carrés dans la longueur for j in range(b//pgcd(a,b)) : # b//pgcd(a,b) : nombre de carrés dans la largeur ax.add_patch(Rectangle((pgcd(a,b)*i, pgcd(a,b)*j), pgcd(a,b), pgcd(a,b),color=couleurs[(i+j)%2])) fig  Dessins récursifs def dessine_cercle(centre,rayon) : theta = np.linspace(0, 2*np.pi, 100) # permet d\u0026#39;avoir 100 valeurs entre 0 et 2pi x0,y0 = centre x = rayon*np.cos(theta)+x0 y = rayon*np.sin(theta)+y0 ax.plot(x, y) ax.fill(x, y) return fig ax.clear() dessine_cercle((4,6),5) # cercle de centre (4,6) et de rayon 5 def cercles(centre,rayon) : dessine_cercle(centre,rayon) if rayon \u0026gt; 0.1 : cercles(centre,rayon*0.9) return fig ax.clear() cercles((10,10),20)  Définir une fonction récursive dessin qui affiche l\u0026rsquo;image ci-dessous avec l\u0026rsquo;appel dessin((0,0),20).\n def dessin(centre,rayon) : ### VOTRE CODE return fig # La figure qui s\u0026#39;affiche en exécutant cette cellule doit être identique à l\u0026#39;image précédente. ax.clear() dessin((0,0),20)  L-système (système de Lindenmayer) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (7, 7) ax.clear() Pour tracer une ligne brisée allant du point $\\left(0;0\\right)$ au point $\\left(2;0\\right)$ en passant par le point $\\left(1;1\\right)$ avec matplotlib, on peut faire l\u0026rsquo;appel suivant à plot :\nax.plot([0, 1, 2], [0, 1, 0]) # [0, 1, 2] sont les valeurs des x # et [0, 1, 0] sont les valeurs des y fig Comme c\u0026rsquo;est plus courant de penser en termes de coordonnées, on va construire une fonction dessine_points qui permet de tracer des lignes joignant une liste de points donnés sous le format (x,y).\n Complétez la définition de dessine_points ci-dessous.\n def dessine_points(liste_points) : \u0026#34;\u0026#34;\u0026#34; précondition : liste_points est une liste de tuples contenant chacun deux nombres (x1,y1),(x2,y2),etc. \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE ax.plot(X,Y) return fig # les instructions suivantes doivent afficher le même graphe que plus haut. ax.clear() dessine_points([(0,0),(1,1),(2,0)]) Le \u0026ldquo;graphisme tortue\u0026rdquo; est un style de graphique où on commande le crayon en vue subjective ; on bouge un curseur (la tortue) sur le plan cartésien en retenant systématiquement sa position et sa direction actuelles (où est la tortue et vers où elle est tournée).\nDans la suite, on va faire en sorte de pouvoir envoyer trois ordres à la tortue codés chacun par un caractère :\n 'A' : avance d\u0026rsquo;une certaine longueur dans ta direction actuelle '+' : tourne dans le sens des aiguilles d\u0026rsquo;une montre d\u0026rsquo;un certain angle sans avancer '-' : tourne dans le sens inverse des aiguilles d\u0026rsquo;une montre d\u0026rsquo;un certain angle sans avancer  On va donc devoir convertir une suite de consignes comme 'A+A-A+A-A' en une liste de points.\nfrom math import pi, sin, cos  Compléter la définition de consigne_vers_points de façon à ce que le nouveau point (x_new,y_new) corresponde à une tortue ayant avancé de la distance D dans la direction actuelle depuis (x_old,y_old) (il manque seulement la définition de y_new).\n def consigne_vers_points(consigne,angle) : \u0026#34;\u0026#34;\u0026#34; consigne_vers_points(consigne : string) -\u0026gt; liste_de_points : list precondition : angle est donné en radian postcondition : liste_de_points est une liste de tuples contenant chacun deux nombres \u0026#34;\u0026#34;\u0026#34; liste_de_points = [(0,0)] # point de départ D = 1 # distance de laquelle la tortue avance à chaque F direction = 0 # direction initiale de la tortue (vers la droite) for c in consigne : x_old,y_old = liste_de_points[-1] if c == \u0026#39;A\u0026#39; : # création de x_new et y_new x_new = x_old + D*cos(direction) ### VOTRE CODE liste_de_points.append((x_new,y_new)) elif c == \u0026#39;+\u0026#39; : direction -= angle elif c == \u0026#39;-\u0026#39; : direction += angle return liste_de_points L\u0026rsquo;exécution des deux lignes suivantes doit afficher le graphe ci-dessous.\nax.clear() dessine_points(consigne_vers_points(\u0026#39;A-A+A--A-A\u0026#39;,pi/4))  Donner la consigne et l\u0026rsquo;angle permettant de tracer le triangle équilatéral suivant (ne pas utiliser plus de points que nécessaires (3) sous peine de voir sa solution non validée) :  ax.clear() consigne = \u0026#39;...\u0026#39; angle = 0 dessine_points(consigne_vers_points(consigne,angle)) Ajoutons un jeu de règles capables de transformer une chaîne de caractères.\nImaginons la séquence \u0026lsquo;abca\u0026rsquo; et les règles suivantes :\n 'a' -\u0026gt; 'b' 'b' -\u0026gt; 'aba'  Alors la séquence \u0026lsquo;abca\u0026rsquo; transformée par la règle devient \u0026lsquo;babacb\u0026rsquo; (\u0026lsquo;c\u0026rsquo; n\u0026rsquo;étant pas touché par la règle, il n\u0026rsquo;est pas modifié).\nOn va construire une fonction transformation prenant en argumant une chaîne de caractères appelée axiome et une règle donnée sous la forme d\u0026rsquo;un dictionnaire et retournant la séquence transformée.\nPour la règle de notre exemple, le dictionnaire serait {'a':'b','b':'aba'}.\ndef transformation(axiome,regle) : \u0026#34;\u0026#34;\u0026#34; transformation(axiome : string, regle : dictionnary) -\u0026gt; nvelle_chaine : string \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE axiome = \u0026#39;abca\u0026#39; regle = {\u0026#39;a\u0026#39;:\u0026#39;b\u0026#39;,\u0026#39;b\u0026#39;:\u0026#39;aba\u0026#39;} transformation(axiome,regle) Doit donner 'babacb'.\nFaisons maintenant en sorte de pouvoir appliquer la transformation à elle-même :\n si le niveau de récursivité vaut zéro, on retourne juste l\u0026rsquo;axiome, sinon, on retourne le résultat de la transformation appliquée non plus sur l\u0026rsquo;axiome, mais sur la transformation de l\u0026rsquo;axiome par la règle, et on diminue le niveau d\u0026rsquo;une unité (il faut nécessairement faire en sorte d\u0026rsquo;atterrir sur le cas de base).   Complétez la définition de la fonction ci-dessous et testez-la dans la cellule suivante (il ne manque que l\u0026rsquo;appel récursif).\n def transformation_recu(axiome,regle,niveau) : \u0026#34;\u0026#34;\u0026#34; transformation_recu(axiome : string , regle : dictionnary , niveau : int) -\u0026gt; nvelle_chaine : string precondition : niveau doit être un entier positif ! \u0026#34;\u0026#34;\u0026#34; if niveau \u0026gt; 0 : return transformation_recu(...,...,...) else : nvelle_chaine = axiome return nvelle_chaine axiome = \u0026#39;aba\u0026#39; regle = {\u0026#39;a\u0026#39;:\u0026#39;b\u0026#39;,\u0026#39;b\u0026#39;:\u0026#39;aba\u0026#39;} for i in range(6) : print(transformation_recu(axiome,regle,i)) # doit s\u0026#39;afficher : #aba #babab #abababababa #babababababababababab #abababababababababababababababababababababa #babababababababababababababababababababababababababababababababababababababababababab À partir d\u0026rsquo;un axiome, d\u0026rsquo;une règle de transformation, et de l\u0026rsquo;application récursive de la transformation sur l\u0026rsquo;axiome, on obtient une consigne permettant de faire dessiner des fractales à la tortue !\nPour le flacon de Koch, on part d\u0026rsquo;un triangle équilatéral comme axiome, et pour chaque segment de droite, on suit la règle de transformation induite par le schéma suivant.\\\n À vous de déterminer l\u0026rsquo;axiome (le triangle équilatérale demandé plus haut) et la bonne règle.\n axiome = \u0026#39;...\u0026#39; regle_Koch = {\u0026#39;A\u0026#39;:\u0026#39;...\u0026#39;} ax.clear() dessine_points(consigne_vers_points(transformation_recu(axiome,regle_Koch,5),pi/3)) Autre exemple : comment construire une surface 2D à partir d\u0026rsquo;une courbe 1D avec la courbe de Hilbert.\naxiome = \u0026#39;L\u0026#39; regle_Hilbert = {\u0026#39;L\u0026#39;:\u0026#39;-RA+LAL+AR-\u0026#39;,\u0026#39;R\u0026#39;: \u0026#39;+LA-RAR-AL+\u0026#39;} ax.clear() dessine_points(consigne_vers_points(transformation_recu(axiome,regle_Hilbert,6),pi/2)) Autre exemple : un triangle de Sierpinski.\naxiome = \u0026#34;YA\u0026#34; regle = {\u0026#34;X\u0026#34;:\u0026#34;YA+XA+Y\u0026#34;, \u0026#34;Y\u0026#34;:\u0026#34;XA-YA-X\u0026#34;} angle = pi/3 ax.clear() dessine_points(consigne_vers_points(transformation_recu(axiome,regle,7),angle)) Et enfin, une jolie courbe du dragon.\naxiome = \u0026#34;AX\u0026#34; regle = {\u0026#34;X\u0026#34;:\u0026#34;X+YA+\u0026#34;, \u0026#34;Y\u0026#34;:\u0026#34;-AX-Y\u0026#34;} angle = pi/2 ax.clear() dessine_points(consigne_vers_points(transformation_recu(axiome,regle,16),angle)) En donnant de la mémoire à la tortue, on va pouvoir dessiner des branches.\nPour cela, il faut ajouter deux nouvelles consignes à consigne_vers_points_branche :\n '[' : qui ajoute à une liste (la \u0026ldquo;mémoire\u0026rdquo;), la position actuelle de la tortue. '[' : qui permet à la tortue de retourner à la dernière position en mémoire.  Voici une implémentation possible d\u0026rsquo;une fonction consigne_vers_points_branche intégrant ces deux nouvelles consignes :\ndef consigne_vers_points_branche(consigne,angle) : liste_de_points = [(0,0)] D = 1 direction = pi/2 memoire = [] for c in consigne : x_old,y_old = liste_de_points[-1] if c == \u0026#39;A\u0026#39; : x_new = x_old+D*cos(direction) y_new = y_old+D*sin(direction) liste_de_points.append((x_new,y_new)) elif c == \u0026#39;+\u0026#39; : direction -= angle elif c == \u0026#39;-\u0026#39; : direction += angle elif c == \u0026#39;[\u0026#39; : memoire.append(((x_old,y_old),direction)) elif c == \u0026#39;]\u0026#39; : souvenir = memoire.pop() x_new,y_new = souvenir[0] direction = souvenir[1] liste_de_points.append((float(\u0026#39;nan\u0026#39;),float(\u0026#39;nan\u0026#39;))) liste_de_points.append((x_new,y_new)) return liste_de_points ax.clear() dessine_points(consigne_vers_points_branche(\u0026#39;A[-A]+A\u0026#39;, pi/4))  Reproduisez la figure suivante en définissant la bonne consigne et le bon angle :  Et en utilisant la récursivité, on peut désormais dessiner de jolis arbres :\naxiome = \u0026#39;P\u0026#39; regle = {\u0026#39;A\u0026#39;: \u0026#39;AA\u0026#39;, \u0026#39;P\u0026#39;: \u0026#39;A[+PA-[P]--P][---P]\u0026#39;} angle = pi*0.11 ax.clear() dessine_points(consigne_vers_points_branche(transformation_recu(axiome,regle,8),angle)) "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp6tri/",
	"title": "TP 6 : algorithmes de tri",
	"tags": [],
	"description": "",
	"content": "algorithmes de tri Trier c\u0026rsquo;est partir d\u0026rsquo;une structure de données désordonnée et la remettre en ordre.\nLes tris sont omniprésents en informatique et Tim Roughgarden (auteur d'Algorithms illuminated) en parle même comme de la \u0026ldquo;mère de tous les problèmes algorithmiques\u0026rdquo;.\nPlusieurs stratégies existent. On va en passer certaines en revue et essayer de trier les algorithmes de tri.\n Tris par comparaison La plupart des algorithmes de tri sont dits par comparaison car ils reposent sur des comparaisons deux à deux des éléments de la liste.\nOn a déjà rencontré deux algorithmes de tri par comparaison dans le TP sur la récursivité : le tri par insertion et le tri fusion.\nTri fusion def fusion(L1,L2) : \u0026#34;\u0026#34;\u0026#34; fusion(L1:list,L2:list)-\u0026gt;Lfus:list fusion retourne une seule liste ordonnée à partir de deux sous-listes ordonnées préconditions : L1 et L2 sont triée dans l\u0026#39;ordre croissant postconditions : \u0026#39;Lfus\u0026#39; est triée dans l\u0026#39;ordre croissant (et len(Lfus)==len(L1)+len(L2)) \u0026#34;\u0026#34;\u0026#34; if L1 == [] : return L2 if L2 == [] : return L1 if L1[0] \u0026lt;= L2[0] : # devient instable si \u0026lt; au lieu de \u0026lt;= ! return [L1[0]] + fusion(L1[1:],L2) else : return [L2[0]] + fusion(L1,L2[1:]) def tri_fusion(L) : n = len(L) if n \u0026lt;= 1 : return L else : return fusion(tri_fusion(L[:n//2]),tri_fusion(L[n//2:]))  Combien de comparaisons effectue l\u0026rsquo;algorithme de tri fusion pour ordonner [1,2,3,4,5,6,7,8] et [8,7,6,5,4,3,2,1] ?\n  A : 0 et 8 B : 8 et 16 C : 12 et 12 D : 16 et 8  Vous pouvez trouver la réponse à la main, mais vous pouvez aussi intégrer à fusion une variable globale nb_comp qui est incrémentée à chaque comparaison entre deux éléments de la liste.\nPensez à systématiquement réinitialiser nb_comp à 0 avant chaque appel de tri_fusion, car sinon la valeur continue à courir. C\u0026rsquo;est un des dangers des variables globales.\n Tri par insertion On va écrire une version itérative de l\u0026rsquo;algorithme de tri par insertion.\nSon principe : on compare chacun des éléments i de la liste donnée en argument (à partir du deuxième) à ceux qui le précèdent en remontant la liste un par un (i-1,i-2,etc.). Tant qu\u0026rsquo;un des éléments qui précèdent est plus grand que l\u0026rsquo;élément i, on les permute, jusqu\u0026rsquo;à ce que l\u0026rsquo;élément i soit à la bonne place.\nConstruisez d\u0026rsquo;abord une fonction permute(L,i,j) qui permute les éléments i et j d\u0026rsquo;une liste L.\ndef permute(L,i,j) : \u0026#34;\u0026#34;\u0026#34; permute(L:list,i:int,j:int)-\u0026gt;list 0 \u0026lt; i,j \u0026lt; len(L) \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE Puis complétez la fonction tri_insertion en utilisant permute.\ndef tri_insertion(L) : \u0026#34;\u0026#34;\u0026#34; tri_insertion(L:list)-\u0026gt;list \u0026#34;\u0026#34;\u0026#34; for i in range(1,len(L)) : j = i X = L[i] while j \u0026gt; 0 and L[j-1] \u0026gt; X : ### VOTRE CODE j -= 1 return L La cellule suivante permet de comparer le résultat de la fonction tri_insertion à la fonction native de tri sorted sur 1000 listes de 10 nombres tirés au hasard entre -5 et 5\nfrom random import randint,shuffle for i in range(1000) : L_desord = [randint(-5,5) for i in range(10)] assert tri_insertion(L_desord) == sorted(L_desord), f\u0026#34;y a un problème avec {L_desord} :\\ndonne {tri_insertion(L_desord)}\\nau lieu de {sorted(L_desord)}\u0026#34;  Combien de comparaisons effectue l\u0026rsquo;algorithme de tri insertion pour ordonner [1,2,3,4,5,6,7,8] et [8,7,6,5,4,3,2,1] ?\n  A : 7 et 28 B : 0 et 7 C : 28 et 28 D : 5 et 35   Combien de comparaisons demande le tri par insertion d\u0026rsquo;une liste de 200 éléments rangés en ordre inverse ?\n  Tri par sélection Principe : parmi les éléments de la liste, on cherche le plus petit, et on le permute avec le premier élément. Puis on recommence avec tous les éléments restants (tous moins le premier) : on cherche le plus petit et on le permute avec le deuxième élément. On recommence jusqu\u0026rsquo;à épuiser la liste\nfonction tri_selection(liste L)\nn ← longueur(L)\npour i de 0 à n - 2\nmin ← i\npour j de i + 1 à n - 1\nsi L[j] \u0026lt; L[min], alors min ← j\nfin pour\nsi min ≠ i, alors échanger L[i] et L[min]\nfin pour\nretourner L\nfin fonction\n Traduisez le peudocode ci-dessus en python.\n def tri_selection(L) : ### VOTRE CODE  Combien de comparaisons effectue l\u0026rsquo;algorithme de tri par sélection pour ordonner [1,2,3,4,5,6,7,8] et [8,7,6,5,4,3,2,1] ?\n  A : 7 et 28 B : 0 et 7 C : 28 et 28 D : 5 et 35  Le tri par sélection ressemble beaucoup au tri par insertion. Dans les deux, après k traversées de la liste, les k premiers éléments sont triés. Cependant la différence fondamentale entre les deux algorithmes est le sens dans lequel ces tris s\u0026rsquo;opèrent ; le tri par insertion trie de la fin vers le début alors que le tri par sélection tri du début vers la fin. Conséquence : dans le tri par sélection, les k premiers éléments de la liste en cours de tri sont les plus petits de la liste entière alors que dans le tri par insertion, ce sont seulement les k premiers éléments d\u0026rsquo;origine triés.\nLe tri par sélection doit toujours inspecter tous les éléments restant pour trouver le plus petit, tandis que le tri par insertion ne requiert qu\u0026rsquo;une seule comparaison quand le (k+1)e élément est plus grand que le ke ; lorsque c\u0026rsquo;est fréquent (si la liste est déjà partiellement triée), le tri par insertion est bien plus efficace. En moyenne, le tri par insertion nécessite de comparer et décaler la moitié des éléments seulement, ce qui correspond donc à la moitié des comparaisons que le tri par sélection doit faire.\nDans le pire des cas pour le tri par insertion (liste triée en sens inverse), les deux tris opèrent autant d\u0026rsquo;opérations l\u0026rsquo;un que l\u0026rsquo;autre, mais le tri par insertion va nécessiter plus de permutations puisqu\u0026rsquo;il décale toujours d\u0026rsquo;une position voisine à l\u0026rsquo;autre. Le dernier élément d\u0026rsquo;une liste renversée, par exemple, va devoir traverser toute la liste en échangeant sa place avec chacun des éléments qui le précèdent, alors qu\u0026rsquo;avec le tri par sélection, il n\u0026rsquo;y a jamais au plus qu\u0026rsquo;une permutation par élément.\nEn général, le tri par insertion va écrire dans la liste $O(n^2)$ fois (chaque permutation écrit dans la liste), alors que le tri par sélection va écrire seulement $O(n)$ fois. Pour cette raison, le tri par sélection peut être préférable au tri par insertion lorsque l\u0026rsquo;écriture sur la mémoire est significativement plus coûteuse que la lecture (comme sur les EEPROM ou sur les mémoires flash). Ce point est illustré dans l\u0026rsquo;animation interactive du début car limiter les permutations y correspond à limiter les déplacements, ce qui donne l\u0026rsquo;illusion d\u0026rsquo;un algorithme plus rapide.\n Tri à bulles Le tri à bulles est surtout à visée pédagogique, il ne sert quasiment jamais réellement. Il tire son nom du fait qu\u0026rsquo;on pousse vers la fin de la liste, de proche en proche, des éléments de plus en plus grands, comme une bulle qui grossit en remontant à la surface.\ndef tri_a_bulles(L) : n = len(L) for i in range(n-1): for j in range(n-i-1): if L[j] \u0026gt; L[j+1] : L = permute(L,j,j+1) return L  Combien de comparaisons effectue l\u0026rsquo;algorithme de tri à bulles pour ordonner [1,2,3,4,5,6,7,8] et [8,7,6,5,4,3,2,1] ?\n  A : 7 et 28 B : 0 et 7 C : 28 et 28 D : 5 et 35   Combien de comparaisons demande le tri à bulles d\u0026rsquo;une liste de 200 éléments rangés en ordre inverse ?\n  Tri rapide Le tri rapide n\u0026rsquo;est pas toujours le plus rapide\u0026hellip; Mais il peut l\u0026rsquo;être (surtout sur les grandes listes) !\nC\u0026rsquo;est un algorithme récursif utilisant une partition de la liste à trier.\nSon avantage sur le tri fusion est d\u0026rsquo;être un tri en place.\nDésavantage : il est instable.\n  def partitionner(L, g, d, pivot) : permute(L,pivot,d) j = g for i in range(g,d) : if L[i] \u0026lt;= L[d] : permute(L,i,j) j += 1 permute(L,d,j) return j def tri_rapide(L, g, d) : if g \u0026lt; d : pivot = randint(g,d) pivot = partitionner(L, g, d, pivot) tri_rapide(L, g, pivot-1) tri_rapide(L, pivot+1, d) return L La figure précédente permet de supposer que la complexité dans le pire des cas du tri fusion est égale à sa complexité dans le meilleur des cas et à la complexité en moyenne du tri rapide.\nGrâce aux listes par compréhension, on peut écrire une version beaucoup plus courte et claire du tri rapide. Son défaut est qu\u0026rsquo;elle nécessité la construction de nouvelles listes (le tri n\u0026rsquo;est alors plus en place !).\nOn va visualiser les différents appels récursifs grâce au module introduit dans le TP précédent et pour que l\u0026rsquo;analyse soit simple, on choisit systématiquement le premier élément de la liste comme pivot.\nLa vidéo suivante montre une implémentation de cette version avec des danseurs hongrois\u0026hellip;\n  from recursionvisualisation import viz, CallGraph cg = CallGraph() @viz(cg) def triRapide(elements) : if len(elements) \u0026lt;= 1 : return elements else : pivot = elements[0] plusPetit = triRapide([e for e in elements[1:] if e \u0026lt;= pivot]) plusGrand = triRapide([e for e in elements[1:] if e \u0026gt; pivot]) return plusPetit + [pivot] + plusGrand print(triRapide(\u0026#34;hanniballecter\u0026#34;)) cg.render() ['a', 'a', 'b', 'c', 'e', 'e', 'h', 'i', 'l', 'l', 'n', 'n', 'r', 't'] Placer le pivot en premier élément a un inconvénient : triRapide devient très lent avec les listes déjà triées (ou quasi triées).\n Quelle sera la taille de la pile d\u0026rsquo;exécution si on demande à triRapide de trier une liste de 500 éléments ?\n   Les tris par comparaison n\u0026rsquo;on que faire de la nature des éléments de la liste à trier du moment qu\u0026rsquo;on peut les comparer entre eux. On peut ainsi trier tout aussi bien des chaînes de caractères que des flottants.\nPar contre, si les éléments de la liste sont contraints d\u0026rsquo;une façon ou d\u0026rsquo;une autre, on peut essayer de tirer parti de la situation.\n  Tris non comparatifs Tri par dénombrement (ou par comptage) Si la liste à trier n\u0026rsquo;est constituée que d\u0026rsquo;entiers positifs, on peut mettre au point un tri très rapide n\u0026rsquo;utilisant aucune comparaison : le tri par dénombrement (counting sort).\nPrincipe : on construit un histogramme des valeurs de la liste à trier L dans une liste intermédiaire L_eff.\n Si m est la plus grande valeur des éléments de la liste à trier, alors la taille de L_eff doit valoir m+1. Et on initialise toutes ses valeurs à zéros. Chaque valeur L[i] de la liste à trier est donc aussi un indice de la liste L_eff ! On parcourt ensuite la liste à trier et on incrémente de 1 la valeur de l\u0026rsquo;élément L_eff[L[i]] de la liste intermédiaire. On obtient bien ainsi les effectifs pour chaque valeur de la liste à trier. Il suffit enfin de parcourir L_eff depuis le début et pour chaque élément L_eff[i] non nul, d\u0026rsquo;ajouter à une nouvelle liste L_sortie autant de fois i que la valeur de L[i]. Plus qu\u0026rsquo;à retourner L_sortie.  Implémentez la fonction tri_par_denombrement telle qu\u0026rsquo;elle est décrite ci-dessus.\ndef tri_par_denombrement(L,m) : \u0026#34;\u0026#34;\u0026#34; tri_par_denombrement(L:list,m:int)-\u0026gt;L_sortie:list m est la valeur maximum des éléments de L \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE  Le nombre d\u0026rsquo;étapes de tri_denombrement peut s\u0026rsquo;écrire en fonction du nombre d\u0026rsquo;éléments n de la liste comme :\n  A : $a$ B : $a\\times n + b$ C : $a\\times n^2+b\\times n + c$ D : $a\\times n^3+b\\times n^2 + c\\times n + d$   Comparer les tris Essayons maintenant de classer ces tris suivant différents critères.\nCommençons par ce qui est souvent le plus critique : leur complexité en temps. À quoi doit-on s\u0026rsquo;attendre lorsque la taille de la liste à trier prend un facteur d\u0026rsquo;échelle ?\nComplexité en temps Le graphe suivant présente le temps mis par les différents algorithmes pour trier des listes de taille croissante.\nOn peut classer ces algorithmes en 3 catégories de complexité temporelle :\n les tris par insertion, sélection et à bulles sont de complexité quadratique ($O(n^2)$) les tris fusion et rapide sont quasilinéaires ($O(n\\log n)$) le tri par dénombrement est linéaire ($O(n)$)  Pour des petites listes (et lorsque des tris non comparatifs ne sont pas applicables), le tri par insertion est en moyenne plus rapide que les autres alors que pour des grandes listes, c\u0026rsquo;est le tri rapide qui domine.\n Complexité en espace : en place ou non ? L\u0026rsquo;algorithme a-t-il besoin d\u0026rsquo;utiliser une liste intermédiaire pour opérer son tri ou parvient-il à écrire directement sur la liste d\u0026rsquo;origine. Dans ce dernier cas, les tri est dit en place.\n Dans la liste suivante, affectez à chaque variable correspondant à un algorithme de tri le caractère 'O' si son tri se fait en place ou 'X' sinon.\n # Retirer la mauvaise réponse triinsertion = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; tiselection = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; triabulles = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; trifusion = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; trirapide = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39; tridenombrement = \u0026#39;O\u0026#39; \u0026#39;X\u0026#39;  Stabilité Un algorithme de tri est stable s\u0026rsquo;il conserve l\u0026rsquo;ordre relatif de départ entre deux valeurs égales.\nDans l\u0026rsquo;animation suivante, un algorithme est stable si les deux barres noires et blanches restent toujours dans le même ordre après et avant le tri.\n On compte le nombre de fois que les caractères \u0026lsquo;r\u0026rsquo;, \u0026lsquo;c\u0026rsquo;, \u0026lsquo;q\u0026rsquo; et \u0026lsquo;p\u0026rsquo; apparaissent dans cette phrase :\n \u0026lsquo;r\u0026rsquo; : 6 \u0026lsquo;c\u0026rsquo; : 5 \u0026lsquo;q\u0026rsquo; : 2 \u0026lsquo;p\u0026rsquo; : 5  On crée à partir de ces données le tuple (('r',6),('c',5),('q',2),('p',5)).\nSi on trie ce tuple selon le premier élément de chacune des paires qu\u0026rsquo;il contient (tri alphabétique), tous les tris donnent le même résultat :\n(('c',5),('p',5),('q',2),('r',6))\nMais si maintenant, on part de ce tuple trié et qu\u0026rsquo;on le trie en fonction des effectifs, les algorithmes ne sont pas tous d\u0026rsquo;accords !\nPour vous en convaincre triez à la main (('c',5),('p',5),('q',2),('r',6)) en suivant l\u0026rsquo;algorithme du tri à bulle, puis en suivant l\u0026rsquo;algorithme de tri insertion.\nNotez ci-dessous les tuples obtenus.\n# tuple obtenu avec le tri à bulle (modifiez le tuple pour qu\u0026#39;il corresponde à ce que vous avez trouvé) T1 = ((\u0026#39;c\u0026#39;,5),(\u0026#39;p\u0026#39;,5),(\u0026#39;q\u0026#39;,2),(\u0026#39;r\u0026#39;,6)) # tuple obtenu avec le tri insertion (modifiez le tuple pour qu\u0026#39;il corresponde à ce que vous avez trouvé) T2 = ((\u0026#39;c\u0026#39;,5),(\u0026#39;p\u0026#39;,5),(\u0026#39;q\u0026#39;,2),(\u0026#39;r\u0026#39;,6)) On dit alors que le tri insertion n\u0026rsquo;est pas stable car il ne conserve pas nécessairement l\u0026rsquo;ordre de deux éléments égaux.\n tris instables : le tri sélection et le tri rapide.\n tris stables : le tri insertion, le tri à bulle et le tri fusion  Un tri instable peut sans trop de peine être rendu stable, il suffit de garder la trace de l\u0026rsquo;ordre initial pour les éléments égaux, mais cela a un coût !\nL\u0026rsquo;instabilité du tri par sélection peut être éliminée en utilisant une fonction intermédiaire minimum cherchant le plus petit des éléments restant à trier et en inserrant successivement les éléments trouvés en partant du début de la liste (attention à rester en place = pas de liste intermédiaire).\n Donnez le code de minimum et tri_selection_stable (avec une contrainte supplémentaire : le code de tri_selection_stable ne devra pas dépasser 3 lignes).\n def minimum(L) : \u0026#34;\u0026#34;\u0026#34; renvoie le plus petit élément de la liste \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE # le code de tri_selection_stable ne devra pas dépasser 3 lignes pour être considéré comme juste. def tri_selection_stable(L) : ### VOTRE CODE "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/tp9nombre/",
	"title": "TP 9 : nombres en machine",
	"tags": [],
	"description": "",
	"content": "TP9 : nombres Cliquez sur cette invitation pour récupérer le repository du TP. Exo 1 : nombres palindromiques  Déterminer grâce à un code Python le plus petit nombre supérieur ou égal à $10,000$ dont l\u0026rsquo;écriture est palindromique (se lisant pareil dans les deux sens) à la fois en base 10 et en base 2.\n ### VOTRE CODE # Affectez votre réponse (l\u0026#39;écriture en base 10 du nombre entier trouvé) à la variable nb nb = 3  Exo 2 : missiles Patriot Une batterie de missiles Patriot détecte les missiles ennemis et les intercepte avec un contre-missile. La batterie mesure le temps pour prévoir le déplacement des missiles ennemis.\nElle dispose d’un compteur (un entier) que nous appellerons c qui compte le nombre de dixièmes de secondes écoulés depuis sa mise en marche. Le temps écoulé t est calculé par l’opération t=c*0.1. Nous nous intéressons à l’erreur de calcul commise lors de cette multiplication.\nD’après un rapport du General Accounting Office, le logiciel du Patriot utilise des nombres à virgule fixe stockés dans un registre de 24 bits.\nLa représentation en virgule fixe utilisée est le format $Q1.23$ où seulement 1 bit est utilisé pour la partie entière et 23 bits le sont pour la partie fractionnaire.\nLa partie fractionnaire d\u0026rsquo;un réel ${x}=x-\\lfloor x\\rfloor$ est stockée sur les 23 bits en la transformant en l\u0026rsquo;entier $\\lfloor {x}\\times 2^{23}\\rfloor$ (où $\\lfloor\\rfloor$ est la partie entière), les chiffres au delà du 23ème après la virgule sont donc tronqués.\n Écrivez en base 2 le nombre 0,1 en ne gardant que 24 chiffres (23 après la virgule). On notera $z$ le nombre obtenu.\nVous pourrez vous aidez du code suivant (après l\u0026rsquo;avoir modifié de manière adéquate) pour déterminer la réponse ou utiliser la dernière phrase de l\u0026rsquo;énoncé (mais attention alors au petit piège).\n a = 2.7 avt = bin(int(a))[2:] + \u0026#39;,\u0026#39; n = a - int(a) apres = \u0026#39;\u0026#39; while len(apres)\u0026lt;9 : n *= 2 if n \u0026gt; 1 : apres += \u0026#39;1\u0026#39; n -= 1 else : apres += \u0026#39;0\u0026#39; print(avt+apres) 10,10110011\n# Affectez à la variable z la chaîne de caractères correspondant à l\u0026#39;écriture binaire demandée : z = \u0026#39;0,...\u0026#39; On note $\\varepsilon = |0,1 − z|$. La batterie de missiles Patriot fait une erreur de $\\varepsilon$ en approximant 0,1.\n Faites calculer par Python la valeur de $\\varepsilon$ et affectez cette valeur à une variable epsilon.\n # Vous affecterez la valeur à la variable epsilon epsilon = Début février 1991, l’armée israélienne a empiriquement constaté qu’au bout de 8h, la précision des missiles est significativement réduite. Puis, le 25 février 1991, six batteries de missiles Patriot (un bataillon) ont été déployées à Dhahran, en Arabie Saoudite, pendant 100h.\nNous noterons $e_8$ et $e_{100}$ l’erreur commise sur $t$ par la batterie au bout de 8h puis au bout de 100h.\n Calculez des deux erreurs précédentes.\n # Vous affecterez les valeurs aux variables e_8 et e_100 e_8 = e_100 = Un Scud a une vitesse de croisière de 1676 m/s (Mach 5).\n Pendant une durée $e_{100}$, de quelle distance $d$ (en m) se déplace un Scud ?\n # Vous affecterez la valeur à la variable d d = Suite à cette imprécision, un Scud irakien ne fut pas intercepté et causa 28 morts parmi les soldats américains.\n Exo 3 : overflows Les 3 \u0026ldquo;évènements\u0026rdquo; suivant correspondent au même bug : un dépassement de capacité d\u0026rsquo;entiers (signés ou non) codés sur 32 bits.\nLa FAA (Federal Aviation Administration) publie en 2015 une Airworthiness Directive ou AD (notification technique que les compagnies aériennes sont obligées de suivre) concernant un bug dans le logiciel des Boeing 787 : \u0026ldquo;This AD was prompted by the determination that a Model 787 airplane that has been powered continuously for 248 days can lose all alternating current (AC) electrical power due to the generator control units (GCUs) simultaneously going into failsafe mode.\u0026rdquo; Le logiciel mesure le temps depuis sa mise en route en incrémentant un compteur toutes les centisecondes.  D\u0026rsquo;après les informations fournies et vos réflexions, au bout de combien de centisecondes exactement, la capacité du compteur se trouve dépassée, expliquant le bug ?\n # Vous affecterez la valeur entière à la variable nb_centi nb_centi = En 2004, l\u0026rsquo;oubli d\u0026rsquo;un technicien de rebooter un serveur a provoqué une immense pagaille dans le ciel californien. En effet, le 14 septembre, les aiguilleurs du ciel des aéroports du sud californien ont perdu le contact vocal avec 400 avions pendant plus de 3 heures, heureusement sans graves conséquences (grâce à la réaction rapide des contrôleurs qui ont tout de suite utilisé leurs portables pour contacter d\u0026rsquo;autres centres de contrôle aérien). La maintenance de routine du système de communication consistait à le rebooter tous les 30 jours. Ce système mesure le temps depuis sa mise en route en incrémentant un compteur toutes les millisecondes.  D\u0026rsquo;après les informations fournies et vos réflexions, au bout de combien de millisecondes exactement, la capacité du compteur s\u0026rsquo;est trouvée dépassée, expliquant le bug ?\n # Vous affecterez la valeur entière à la variable nb_milli nb_centi = Le bug de l\u0026rsquo;an 2038 concerne les horloges des systèmes unix 32 bits dont le temps 0, appelé epoch, est le 1 janvier 1970 à 00:00:00 UT.\nimport time time.gmtime(0) time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=1, tm_isdst=0 Cela montre que les serveurs hébergeant Colab tournent sous Unix.\n  Au bout de combien de secondes exactement le problème lié au bug de 2038 se pose ?\n # Vous affecterez la valeur entière à la variable  nb_sec = "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/graphes/",
	"title": "Graphes",
	"tags": [],
	"description": "",
	"content": "Les graphes Quelques points et des traits pour les relier suffisent pour créer un graphe. Cette grande simplicité est pourtant à l\u0026rsquo;origine d\u0026rsquo;un foisonnement mathématiques impressionnant.\nUn peu d\u0026rsquo;histoire L\u0026rsquo;acte de naissance de la théorie des graphes date d\u0026rsquo;une petite énigme à laquelle s\u0026rsquo;attelaient sans succès les habitants de Königsberg. Comment un voyageur pouvait traverser les sept ponts sans jamais passer deux fois sur le même pont ? Euler résout le problème et fonda du même coup la théorie des graphes ! Un graphe permet d\u0026rsquo;extraire l\u0026rsquo;essence du problème : les arêtes sont les ponts et les sommets (ou nœuds) sont les zones accessibles depuis ces ponts (séparées par les bras de rivière).\nLa forme précise des lignes reliant les points n\u0026rsquo;a pas d\u0026rsquo;importance : elles ne font qu\u0026rsquo;indiquer l\u0026rsquo;existance de laison entre ces points (cela illustre le caractère topologique et non géométrique du problème). Euler compris alors que ce qu\u0026rsquo;on appelerait ensuite un chemin eulérien (un chemin reliant chaque sommet en ne passant qu\u0026rsquo;une fois par chaque arête) n\u0026rsquo;est possible que si le graphe ne compte pas plus de deux sommets d\u0026rsquo;où partent un nombre impair d\u0026rsquo;arêtes. Or dans le cas de Königsberg, il part un nombre impair d\u0026rsquo;arêtes de chacun des sept sommets ! Un chemin eulérien y est donc impossible.\nLorsqu\u0026rsquo;on trace un chemin eulérien sur un graphe, trois types de sommets se présentent : un sommet peut être soit un point de départ, soit un point d\u0026rsquo;arrivée, soit un point traversé (on y arrive puis on en repart). Et pour ces derniers, on aura toujours un nombre pair d\u0026rsquo;arêtes (autant d\u0026rsquo;arrivées que de départs)\u0026hellip;\n Ce premier pas d\u0026rsquo;Euler eut lieu en 1737, il fallut attendre ensuite plus de cent ans pour que Kirchhoff réutilise des graphes pour déterminer les intensités circulant dans les différentes branches d\u0026rsquo;un circuit électrique ; il met alors au point la notion d'arbre, des graphes sans boucle, en 1847.\nDix ans plus tard, c\u0026rsquo;est au tour de la chimie de s\u0026rsquo;attaquer aux graphes. En 1857, Cayley s\u0026rsquo;intéresse aux différentes structures possibles (isomères) d\u0026rsquo;une molécule ayant $n$ atomes de carbone et $2n+2$ atomes d\u0026rsquo;hydrogène (un alcane). Cela revient à trouver tous les arbres à $3n+2$ éléments tels que de chaque élément (chaque sommet) partent exactement une ou quatre arêtes (symbolisant les liaisons chimiques).\nEn 1869, enfin, les mathématiciens redécouvrent les graphes, par la voix de Jordan qui, sans connaître les travaux de Cayley, retrouve ses résultats.\nLes jeux ne sont pas en reste : en 1859, le mathématicien et physicien irlandais William Hamilton invente \u0026ldquo;The Icosian Game\u0026rdquo;, dont le but est de visiter une et une seule fois tous les sommets d\u0026rsquo;un dodécaèdre régulier. Un tel chemin est depuis appelé hamiltonien.\nApparemment voisin du problème du chemin eulérien (visiter une et une seule fois chaque arête), le problème du chemin hamiltonien est en réalité beaucoup plus difficile.\nPour ce qui est du jeu que vous pouvez tester ci-dessous, une règle supplémentaire impose que la fin du chemin soit adjacente à son début. En rejoignant le point de départ, on formerait alors un cycle et on appelle ainsi cycle hamiltonnien un cycle passant par tous les sommets.\n \nLe deuxième moitié du 20e siècle et l\u0026rsquo;avènement de l\u0026rsquo;informatique voit la théorie des graphes prendre son véritable essor : c\u0026rsquo;est en effet l\u0026rsquo;outil idéal pour décrire les réseaux complexes modernes.\n  Les réseaux sont partout : les réseaux sociaux et les réseaux de communication, mais on trouve aussi des réseaux dans des champs scientifiques très différents comme en biologie, logistique, linguistique, économie, etc.\nLa théorie des graphes donne un langage commun à la description de ces réseaux.\n Vocabulaire Graphes non orientés Un graphe $G$ est un ensemble de sommets (ou nœuds) S (notés $s_i$) et d'arêtes A (notées $\\{s_i,s_j\\}$) reliant deux à deux ces sommets. On note un tel graphe : $G = (S,A)$.\n Quelques exemples dans des champs variés :\n   Réseau Sommets Arêtes     transport aérien aéroports vols   plans routiers carrefours tronçons de routes   réseau génétique gènes facteurs de transcription   cerveau neurones synapses   colonie de fourmis jonctions traces de phéromones   appels téléphoniques numéro appel   réseau de citation auteur citation    Est représenté ci-dessus le graphe $G=(S,A)$ avec $S=\\{1,2,3,4,5,6\\}$ et $A=\\{\\{1,2\\},\\{1,5\\},\\{2,5\\},\\{3,3\\},\\{4,6\\}\\}$\nUne boucle est une arête reliant un sommet à lui-même.\n Exemple : il y a une boucle sur le sommet $3$.\nL\u0026rsquo;ensemble des sommets adjacents (joints par une arête) au sommet $s_i$, autrement dit les voisins du sommet $s_i$, se note : $Adj(s_i)=\\{s_j \\in S,\\{ s_i,s_j \\}\\in A\\}$.\n Exemple : $Adj(2)=\\{1,5\\}$\n Un graphe non orienté est dit simple s\u0026rsquo;il ne comporte pas de boucle et jamais plus d\u0026rsquo;une arête entre deux sommets.\n Le graphe ci-dessus n\u0026rsquo;est donc pas simple.\nOn appelle ordre d\u0026rsquo;un graphe le nombre de ses sommets ($card(S)$ ou plus simplement $|S|$).\n Exemple : pour le graphe ci-dessus $|S|=6$\nOn appelle taille d\u0026rsquo;un graphe le nombre de ses arêtes ($card(A)$ ou $|A|$).\n Exemple : pour le graphe ci-dessus $|A|=5$\n Graphes orientés Les arêtes d\u0026rsquo;un graphe non orienté sont symétriques, elles se parcourent indifféremment dans les deux sens, mais ce n\u0026rsquo;est pas toujours très pertinent. Considérons les exemples suivants :\n Supposons que l\u0026rsquo;on veuille modéliser un plan routier. On associe naturellement un carrefour à un sommet et une rue à une arête. Mais on a besoin en plus d\u0026rsquo;une notion de direction pour représenter les rues à sens unique. Pour modéliser des relations sociales, une arête entre Alice et Bob modélise un lien, mais comment représenter le fait que Bob connaisse Alice, mais que l\u0026rsquo;inverse soit faux ? Dans un réseau d\u0026rsquo;ordinateur, en particulier sans fil, le lien entre deux nœuds est généralement non symétrique dans le sens où un message peut être envoyé de A vers B, mais pas l\u0026rsquo;inverse.  Pour modéliser ce type de situation, on utilise des graphes orientés.\nDans un graphe orienté, les sommets sont reliés par des arcs que l\u0026rsquo;on peut identifier à des couples de sommets (un couple a un ordre) : au couple $(a,b)$ correspond un arc d\u0026rsquo;origine $a$ et d\u0026rsquo;extrémité $b$.\n L\u0026rsquo;arc $a = (s_i,s_j)$ est dit sortant en $s_i$ et incident ou entrant en $s_j$, et $s_j$ est un successeur de $s_i$, tandis que $s_i$ est un prédécesseur de $s_j$.\n L\u0026rsquo;ensemble des successeurs d\u0026rsquo;un sommet $s_i \\in S$ est noté $Succ(s_i) = \\{s_j \\in S,(s_i,s_j) \\in A\\}$.\nL\u0026rsquo;ensemble des prédécesseurs d\u0026rsquo;un sommet $s_i \\in S$ est noté $Pred(s_i) = \\{s_j \\in S,(s_j,s_i) \\in A\\}$.\n Un graphe orienté permet, par exemple, de résumer les relations dans un chi-fou-mi (ici dans la variante puits montrant bien que jouer \u0026ldquo;pierre\u0026rdquo; est sans intérêt, ou encore dans la variante pierre-feuille-ciseaux-lézard-spock de The Big Bang Theory). Pour \u0026ldquo;pierre-feuille-ciseaux-puits\u0026rdquo;, le graphe $G(S,A)$ a pour sommets $S=\\{pierre,feuille,ciseaux,puits\\}$ et pour arêtes $A=\\{(ciseaux,feuille),(feuille,puits),(feuille,pierre),(puits,pierre),(puits,ciseaux),(pierre,ciseaux)\\}$.\n Degré d\u0026rsquo;un sommet Dans un graphe non-orienté, le degré d\u0026rsquo;un sommet $s$ est le nombre d\u0026rsquo;arêtes incidentes à ce sommet (une boucle comptant pour 2).\nDans le cas d\u0026rsquo;un graphe simple, on aura $d(s) = |Adj(s)|$ (nombre de sommets adjacents).\n Dans un graphe orienté, le degré sortant d\u0026rsquo;un sommet $s$, noté $d_+(s)$, est le nombre d\u0026rsquo;arcs partant de $s$ (de la forme $(s,v)$ avec $s,v \\in S$).\nDans le cas d\u0026rsquo;un graphe simple, on aura $d_+(s) = |Succ(s)|$ (nombre de successeurs).\nDe même, le degré entrant d\u0026rsquo;un sommet $s$, noté $d_−(s)$, est le nombre d\u0026rsquo;arcs arrivant en $s$ (de la forme $(v, s)$ avec $s,v \\in S$).\nDans le cas d\u0026rsquo;un graphe simple, on aura $d_−(s) = |Pred(s)|$ (nombre de prédécesseurs).\nLe degré d\u0026rsquo;un sommet $s$ d\u0026rsquo;un graphe orienté est donc la somme des degré entrant et sortant : $d(s) = d_+(s) + d_−(s)$.\n Exemple : $d_+(puits)=2$ et $d_-(puits)=1$, d\u0026rsquo;où $d(puits) = d_+(puits) + d_−(puits)=2+1=3$\n Pour tout graphe, la somme des degrés de chaque sommet est le double du nombre d\u0026rsquo;arêtes. $$\\sum_{s \\in S} d(s) = 2*|A|$$\n $d(puits)=d(feuille)=d(ciseaux)=d(pierre)=3$ d\u0026rsquo;où $\\sum_{s \\in S} d(s) = 12$. Et on a bien $|A|=6$. Et pour un graphe orienté, la somme des degrés entrant vaut la somme des degrés sortants et est aussi égal au nombre d\u0026rsquo;arêtes. $$\\sum_{s \\in S} d_+(s) = \\sum_{s \\in S} d_-(s) = |A|$$\n     $d_+$ $d_-$     puits 2 1   feuille 2 1   ciseaux 1 2   pierre 1 2    $\\sum_{s \\in S} d_+(s) =\\sum_{s \\in S} d_-(s) =|A|=6$\nOn en déduit que pour tout graphe, il y a un nombre pair de sommets à degré impair.\n Le degré d\u0026rsquo;un sommet est un concept simple, mais fécond, utilisé dans des contextes très différents. Dans un réseau social, le degré d\u0026rsquo;un sommet traduit l\u0026rsquo;importance d\u0026rsquo;une personne dans le groupe. Dans un réseau de communication comme Internet, on apprend beaucoup sur l\u0026rsquo;organisation réelle du réseau à partir de la distribution obtenue en ordonnant les sommets par leurs degrés.\n Chemin, chaîne, cycle et circuit Cas des graphes orientés Soit $G = (S, A)$ un graphe orienté.\nUn chemin d\u0026rsquo;un sommet $u$ vers un sommet $v$ est une séquence $\u0026lt; s_0,s_1,s_2,\u0026hellip;,s_k \u0026gt;$ de sommets tels que $u = s_0$, $v = s_k$ et $(s_{i−1},s_i) \\in A$ pour tout $i \\in \\{1,\u0026hellip;,k\\}$.\nOn dira que le chemin contient les sommets $s_0,s_1,\u0026hellip;,s_k$ et les arcs $(s_0,s_1),(s_1,s_2),\u0026hellip;,(s_{k−1},s_k)$.\nLa longueur du chemin est le nombre d\u0026rsquo;arcs dans le chemin, c\u0026rsquo;est-à-dire $k$.\n S\u0026rsquo;il existe un chemin de $u$ à $v$, on dira que $v$ est accessible à partir de $u$.\n Un chemin $\u0026lt; s_0,s_1,\u0026hellip;,s_k \u0026gt;$ forme un circuit si $s_0 = s_k$ et si le chemin comporte au moins un arc ($k ≥ 1$).\n Une boucle est un circuit de longueur $1$.\n  $\u0026lt;6,3,2,1\u0026gt;$ est un chemin du graphe. $\u0026lt;1,5,3,2,1\u0026gt;$ est un circuit.  Cas des graphes non orientés Si $G = (S, A)$ est un graphe non orienté, on parlera de chaîne au lieu de chemin, et de cycle au lieu de circuit.\nDans le cas d\u0026rsquo;un cycle, toutes les arêtes doivent être distinctes.\nUn graphe sans cycle est dit acyclique.\n  Un arbre est est un graphe acyclique et connexe.\n La ligne A du RER forme un arbre, mais pas la ligne C.\n Distance dans un graphe La notion de longueur de chemin nous permet ensuite de définir la notion de distance dans un graphe.\nSoit un graphe $G=(S,A)$. La distance d\u0026rsquo;un sommet à un autre est la longueur du plus court chemin/chaîne entre ces deux sommets, ou $\\infty$ s\u0026rsquo;il n\u0026rsquo;y a pas un tel chemin/chaîne :\n$$ \\forall x,y \\in S,d(x,y)=\\left\\lbrace \\begin{array}{ll} k \\; \u0026amp;\\text{si le plus court chemin de x vers y est de longueur k}\\\\ \\infty \u0026amp;\\text{sinon}\\end{array}\\right. $$\n Le diamètre d\u0026rsquo;un graphe est la plus grande distance entre deux sommets.\n Exemple : dans le graphe orienté ci-dessus $d(2,3)=3$, et $d(3,6)=\\infty$ (le sommet $6$ n\u0026rsquo;est pas accessible depuis le sommet $3$). Le diamètre du graphe vaut, lui, 4 (il s\u0026rsquo;agit de $d(6,5)$).\n Connexité Un graphe non orienté est connexe si chaque sommet est accessible à partir de n\u0026rsquo;importe quel autre (pour tout couple de sommets distincts $(s_i,s_j) \\in S^2$, il existe une chaîne entre $s_i$ et $s_j$).\n Le graphe comportant les sommets $1,2,3,4$ n\u0026rsquo;est pas connexe mais celui comportant les sommets $5,6,7,8$ l\u0026rsquo;est !\n Représentation d\u0026rsquo;un graphe Listes d\u0026rsquo;adjacence Soit le graphe $G = (S,A)$ d\u0026rsquo;ordre $n$. On suppose que les sommets de $S$ sont numérotés de $1$ à $n$. La représentation par listes d\u0026rsquo;adjacence de $G$ consiste en un tableau $T$ de $n$ listes (un par sommet) :\nPour chaque sommet $s_i \\in S$, la liste d\u0026rsquo;adjacence $T[s_i]$ est une liste de tous les sommets $s_j$ tels qu\u0026rsquo;il existe un arc $(s_i,s_j) \\in A$ ou une arête $\\{s_i,s_j\\} \\in A$.\nAutrement dit, pour chaque sommet, on liste ses voisins accessibles.\n Dans chaque liste d\u0026rsquo;adjacence, les sommets sont généralement ordonnés arbitrairement.\nPour l\u0026rsquo;implémentation Python, on peut soit utiliser des listes imbriquées, soit un dictionnaire.\nExemple : # Avec un dictionnaire T = {1:[1,3],2:[1,3,4],3:[],4:[1,2,3,4]} # Avec des listes imbriquées T = [[1,3],[1,3,4],[],[1,2,3,4]] L\u0026rsquo;avantage du dictionnaire est qu\u0026rsquo;il n\u0026rsquo;impose pas d\u0026rsquo;avoir une correspondance entre le numéro du sommet et la position dans la liste d\u0026rsquo;adjacence (dans le cas de listes imbriquées T[0] sera toujours la liste correspondant au premier sommet, T[1], celle du deuxième, etc.).\nTaille mémoire nécessaire: si le graphe G est orienté, la somme des longueurs des listes d\u0026rsquo;adjacence est égale au nombre d\u0026rsquo;arcs de A, puisque l\u0026rsquo;existence d\u0026rsquo;un arc $(s_i,s_j)$ se traduit par la présence de $s_j$ dans la liste d\u0026rsquo;adjacence de $T[s_i]$.\nEn revanche, si le graphe n\u0026rsquo;est pas orienté, la somme des longueurs de toutes les listes d\u0026rsquo;adjacence est égale à deux fois le nombre d\u0026rsquo;arêtes du graphe, puisque si ${s_i,s_j}$ est une arête, alors $s_i$ appartient à la liste d\u0026rsquo;adjacence de $T[s_j]$, et vice versa.\nPar conséquent, la liste d\u0026rsquo;adjacence d\u0026rsquo;un graphe ayant $n$ sommets et $m$ arcs ou arêtes nécessite de l\u0026rsquo;ordre de $O(n + m)$ emplacements mémoire.\n Opérations sur les listes d\u0026rsquo;adjacence : pour tester l\u0026rsquo;existence d\u0026rsquo;un arc $(s_i, s_j)$ ou d\u0026rsquo;une arête ${s_i, s_j }$, on doit parcourir la liste d\u0026rsquo;adjacence de $T[s_i]$ jusqu\u0026rsquo;à trouver $s_j$.\nEn revanche, le calcul du degré d\u0026rsquo;un sommet, ou l\u0026rsquo;accès à tous les successeurs d\u0026rsquo;un sommet, est très efficace : il suffit de parcourir la liste d\u0026rsquo;adjacence associée au sommet. D\u0026rsquo;une façon plus générale, le parcours de l\u0026rsquo;ensemble des arcs/arêtes nécessite le parcours de toutes les listes d\u0026rsquo;adjacence, et prendra un temps de l\u0026rsquo;ordre de $p$, où $p$ est le nombre d\u0026rsquo;arcs/arêtes.\n Le calcul des prédécesseurs d\u0026rsquo;un sommet n\u0026rsquo;est pas pratique avec cette représentation. Il nécessite le parcours de toutes les listes d\u0026rsquo;adjacences de $T$.\nSi l\u0026rsquo;on a besoin de connaître les prédécesseurs d\u0026rsquo;un sommet, une solution est de maintenir, en plus de la liste d\u0026rsquo;adjacence des successeurs, la liste d\u0026rsquo;adjacence des prédécesseurs.\n Matrice d\u0026rsquo;adjacence Soit le graphe $G = (S,A)$ d\u0026rsquo;ordre $n$. On suppose que les sommets de $S$ sont numérotés de $1$ à $n$. La représentation par matrice d\u0026rsquo;adjacence de $G$ consiste en une matrice booléenne $M=(m_{i,j})$ de taille $n\\times n$ telle que $m_{i,j} = 1$ si $ (i,j) \\in A$, et $m_{i,j} = 0$ sinon.\n La matrice d\u0026rsquo;adjacence d\u0026rsquo;un graphe non orienté sera toujours symétrique, mais pas nécessairement celle d\u0026rsquo;un graphe orienté.\n Implémentation Python :\nM = [[1,0,1,0],[1,0,1,1],[0,0,0,0],[1,1,1,1]] # pour savoir si un arc joint le sommet 1 au sommet 3 M[0][2] # pour savoir si un arc joint le sommet 3 au sommet 1 M[2][0] Taille mémoire nécessaire : La matrice d\u0026rsquo;adjacence d\u0026rsquo;un graphe ayant $n$ sommets nécessite de l\u0026rsquo;ordre de $O(n^2)$ emplacements mémoire.\nSi le nombre d\u0026rsquo;arcs est très inférieur à $n^2$ (on parle alors de graphe creux), cette représentation est loin d\u0026rsquo;être optimale.\n Opérations sur les matrices d\u0026rsquo;adjacence :\nle test de l\u0026rsquo;existence d\u0026rsquo;un arc ou d\u0026rsquo;une arête avec une représentation par matrice d\u0026rsquo;adjacence est immédiat (il suffit de tester directement la case correspondante de la matrice).\nEn revanche, connaître le degré d\u0026rsquo;un sommet nécessite le parcours de toute une ligne (ou toute une colonne) de la matrice. D\u0026rsquo;une façon plus générale, le parcours de l\u0026rsquo;ensemble des arcs/arêtes nécessite la consultation de la totalité de la matrice, et prendra un temps de l\u0026rsquo;ordre de $n^2$.\n Application : Combien y a-t-il de chemins menant d\u0026rsquo;un sommet à un autre en exactement $n$ coups ?\nOn cherche donc les chemins de longueur $n$ entre deux sommets $i$ et $j$.\nSoit $M = (m_{i,j})$ la matrice d\u0026rsquo;adjacence d\u0026rsquo;un graphe $G(S,A)$. $M$ est donc aussi le nombre de chemin de $i$ à $j$ de longueur $1$ (une seul arête), que l\u0026rsquo;on va noter $m_{i,j}(1)$.\nL\u0026rsquo;idée est alors de découper le chemin de longueur $n$ en un chemin de longueur $n-1$ suivi d\u0026rsquo;un chemin de longueur $1$. Le nombre $m_{i,j}(n)$ de chemins de longueur $n$ est ainsi donné par : $$ m_{i,j}(n)=\\sum_{k=1}^{|S|}m_{i,k}(n-1)\\times m_{k,j}(1)$$ Pour $ m_{i,j}(2) $, on obtient $m_{i,j}(n)=\\sum_{k=1}^{|S|}m_{i,k}(1)\\times m_{k,j}(1)$ qui n\u0026rsquo;est autre que $M^2$ (on reconnaît en effet la formule du produit matriciel).\nEt par une récurrence immédiate, pour des chemins de longueur $n$, il suffit de calculer $M^n$.\nExemple : combien y a-t-il de chemins de longueur 4 entre les sommets 2 et 3 du graphe représenté ci-dessous. La matrice d\u0026rsquo;adjacence du graphe vaut $M = \\begin{pmatrix}1\u0026amp;1\u0026amp;0\\\\0\u0026amp;0\u0026amp;1\\\\1\u0026amp;1\u0026amp;0\\end{pmatrix}$. Utilisons Python pour calculer $M^4$ :\nimport numpy as np # librairie très utile pour les calculs sur matrices from numpy.linalg import matrix_power M = [[1,1,0],[0,0,1],[1,1,0]] M = np.array(M) # on convertit M en tableau numpy M4 = matrix_power(M,4) print(f\u0026#34;Il y a {M4[2][0]} chemins de longueur 4 du sommet 3 au sommet 1.\u0026#34;) Il y a 3 chemins de longueur 4 du sommet 3 au sommet 1.  Parcours d\u0026rsquo;un graphe Pour déterminer si un sommet est accessible depuis un autre sommet, il faut pouvoir parcourir méthodiquement l\u0026rsquo;ensemble du graphe.\nAlgorithme de parcours en largeur Une première méthode, l\u0026rsquo;algorithme de parcours en largeur (ou breadth-first algorithm), consiste à partir d\u0026rsquo;un nœud, d\u0026rsquo;explorer tous ses successeurs, puis les successeurs de chacun de ses successeurs, etc., jusqu\u0026rsquo;à ce qu\u0026rsquo;il n\u0026rsquo;y ait plus de sommets.\nCela revient à inspecter le graphe par couche concentrique de plus en plus éloignées du nœud source.\nPour implémenter un tel algorithme, la structure de données adaptée est la file.\n Les files (queues en anglais) sont des structures dynamiques (les éléments sont enfilés ou défilés) qui, à l\u0026rsquo;instar d\u0026rsquo;une file d\u0026rsquo;attente à une caisse, c\u0026rsquo;est le premier arrivé qui est le premier retiré (FIFO pour \u0026ldquo;first in first out\u0026rdquo;). Les files sont utilisées par exemple lorsqu\u0026rsquo;il y a une possibilité d\u0026rsquo;encombrement (pour une imprimante partagée par exemple).\n L\u0026rsquo;idée est de placer chaque nouveau successeur au bout d\u0026rsquo;une file (enfiler), puis de retirer un à un (défiler) les premiers arrivés (donc les plus proches) lorsqu\u0026rsquo;ils sont à leur tour inspectés.\nPour l\u0026rsquo;implémentation des files, on pourrait utiliser des listes python en ajoutant toujours les éléments à la fin et les retirant au début, mais ce n\u0026rsquo;est pas très efficace. En effet, l\u0026rsquo;ajout d\u0026rsquo;un élément en début de liste à un coût linéaire (proportionnel à la taille de la liste). On pourrait pourtant tirer partie de la structure particulièrement simple des files où seule deux positions (première et dernière) nous intéressent.\nMais comme souvent en python, un module dédié, ici collecions.deque, peut nous venir en aide. Il implément efficacement les files en permettant un enfilage et un défilage en temps constant.\nG = {\u0026#34;Bob\u0026#34; : [\u0026#34;Alice\u0026#34;,\u0026#34;Dave\u0026#34;,\u0026#34;Charlie\u0026#34;], \u0026#34;Alice\u0026#34; : [\u0026#34;Elisa\u0026#34;], \u0026#34;Charlie\u0026#34; : [\u0026#34;Elisa\u0026#34;,\u0026#34;Hector\u0026#34;], \u0026#34;Dave\u0026#34; : [\u0026#34;Farid\u0026#34;,\u0026#34;Gus\u0026#34;], \u0026#34;Elisa\u0026#34; : [], \u0026#34;Farid\u0026#34; : [], \u0026#34;Gus\u0026#34; : [], \u0026#34;Hector\u0026#34; : [] } from collections import deque # préconditions: graphe G(S,A) représenté par une liste d\u0026#39;adjacence par un dictionnaire et un sommet s de S # postconditions : un sommet est accessible depuis s si et seulement si il est marqué comme \u0026#34;vu\u0026#34; (dans la liste vus). def parcours_largeur(G,depart): file = deque() file.append(depart) Sommets = [] Vus = [] while file : sommet = file.popleft() # méthode de la classe deque permettant de défiler (équivaut à pop(0) sur une liste) if not sommet in Vus : file += G[sommet] Vus.append(sommet) # on marque les sommets vus (évite ici d\u0026#39;avoir 2 Elisa, mais ça peut être bien pire) Sommets.append(sommet) return Sommets parcours_largeur(G,\u0026quot;Bob\u0026quot;) renvoie ['Bob', 'Alice', 'Dave', 'Charlie', 'Elisa', 'Farid', 'Gus', 'Hector']. Si on ne marque pas les sommets vus (ici grâce à la liste vus), on se retrouve avec une boucle infinie dès qu\u0026rsquo;il y a un circuit ou un cycle (le simple graphe 🦉⇆🐘 par exemple).\n Que vaut la complexité temporelle de l\u0026rsquo;algorithme ? Que devient-elle sans l\u0026rsquo;utilisation de la classe deque fournissant une vraie file ?\n Exemples d\u0026rsquo;applications du parcours en largeur :\n utilisé par les robots d\u0026rsquo;exploration des moteurs de recherche pour construire l\u0026rsquo;index des pages web, recherche dans les réseaux sociaux, recherche d\u0026rsquo;un nœud voisin accessible dans les réseaux peer-to-peer.   Algorithme de parcours en profondeur Cette fois-ci, on explore jusqu\u0026rsquo;au bout chaque chaîne de successeurs du nœud source avant de passer à la suivante.\nCette fois-ci, la structure de données dynamique adaptée est la pile.\n Les piles (stacks en anglais) sont des structures dynamiques (des éléments sont ajoutés = empilés, ou retirés = dépilés) ayant la propriété que l’élément extrait est celui qui y a été introduit le plus récemment (\u0026ldquo;dernier entré, premier sortie\u0026rdquo; ou LIFO \u0026ldquo;last in first out\u0026rdquo; en anglais). C\u0026rsquo;est l\u0026rsquo;équivalent informatique d\u0026rsquo;une pile d\u0026rsquo;assiettes. Cette structure est par exemple utilisée dans la fonction \u0026ldquo;annuler\u0026rdquo; (CTR-Z) d\u0026rsquo;un logiciel ou encore dans le traitement des fonctions récursives (les piles seront étudiées plus en détail en seconde année).\n def parcours_profondeur(G,depart): pile = deque() pile.append(depart) Sommets = [] Vus = [] while pile : sommet = pile.pop() if not sommet in Vus : pile += G[sommet] Vus.append(sommet) Sommets.append(sommet) return Sommets parcours_largeur(G,\u0026quot;Bob\u0026quot;) renvoie ['Bob', 'Charlie', 'Hector', 'Elisa', 'Dave', 'Gus', 'Farid', 'Alice'].\nOn remarque que les deux algorithmes ne diffèrent que par la structure de données utilisée, mais loin d\u0026rsquo;être anodin, ce passage de la file à la pile change complètement le principe du parcours !\nCela illustre bien que la conception d\u0026rsquo;un algorithme est très dépendantes des structures de données utilisées.\nUne structure de donnée est une façon d\u0026rsquo;organiser les données de telle sorte que certaines opérations sur ces données soient très rapides. Une structure de donnée est donc spécialisée dans ces quelques opérations.\nLors de la conception, d\u0026rsquo;un algorithme, l\u0026rsquo;identification des différentes opérations à effectuer va guider le choix de la structure de donnée adaptée.\nPar exemple, l\u0026rsquo;algorithme de recherche en largeur doit gérer un ensemble où le premier élément ajouter doit toujours être le premier retiré (logique FIFO) $\\rightarrow$ utilisation d\u0026rsquo;une file qui gère l\u0026rsquo;ajout d\u0026rsquo;un élément à la fin d\u0026rsquo;une file d\u0026rsquo;attente et l\u0026rsquo;extraction au début en temps constant (elle est optimisé pour ça, mais en contrepartie, elle ne sait faire que ça).\nL\u0026rsquo;algorithme de recherche en profondeur suit lui la logique LIFO $\\rightarrow$ utilisation d\u0026rsquo;une pile.\nDernier exemple : l\u0026rsquo;algorithme de Dijkstra (décrit plus loin) a besoin à chaque itération d\u0026rsquo;ajouter un élément à un ensemble et d\u0026rsquo;en retirer le plus petit élément $\\rightarrow$ ce sont les deux opérations dont le tas s\u0026rsquo;est fait le spécialiste (le tas est un arbre binaire presque complet ordonné). Un tas spécialisé dans ces deux opérations s\u0026rsquo;appelle est aussi appelé file de priorité. Dans quels autres algorithmes pourrait avantageusement être utilisé un tas ?\n Nous n\u0026rsquo;avions pas réellement besoin de la classe deque pour implémenter efficacement la pile. En effet, si insérer un élément au début d\u0026rsquo;une liste python de taille $n$ a bien un coût linéaire ($O(n)$) et ralentit donc l\u0026rsquo;exécution par rapport à l\u0026rsquo;utilisation d\u0026rsquo;une file, retirer un élément à la fin (via pop) se fait en temps constant ($O(1)$).\n Exemples d\u0026rsquo;applications du parcours en profondeur :\n utilisé pour trouver un chemin entre deux sommets, détection de cycles dans un graphe, utilisé dans le tri topologique, utilisé pour trouver la sortie d\u0026rsquo;un labyrinthe.   Graphes pondérés Dans de nombreuses situations, les arêtes d\u0026rsquo;un graphe ne sont pas toutes équivalentes. On ajoute alors l\u0026rsquo;information du \u0026ldquo;coût\u0026rdquo; que cela représente d\u0026rsquo;emprunter telle ou telle arête. On appelle poids ces valeurs ajoutées aux arêtes/arcs.\nPar exemple, pour modéliser un réseau ferroviaire, on peut attribuer à chaque arête modélisant les jonctions entre deux gares la distance correspondante. Et pour un réseau de communication, le poids d\u0026rsquo;une arête correspondra plutôt au temps nécessaire pour transférer un message de taille élémentaire.\nOn obtient alors un graphe pondéré.\nOn utilise aussi souvent des graphes pondérés, plus particulièrement des arbres de probabilité (où chaque branche est affublée d\u0026rsquo;une probabilité) pour calculer des probabilités conditionnelles.\nExemple : Très souvent (particulièrement pour les réseaux de communication), l\u0026rsquo;information ajoutée au graphe un temps ou une distance et se pose alors le problème de l\u0026rsquo;optimisation d\u0026rsquo;un trajet entre deux sommets.\nLe poids d\u0026rsquo;un chemin est la somme des poids des arcs empruntés.\n La distance entre deux sommets (dans un graphe pondéré) correspond au chemin de poids minimum entre ces deux sommets.\n  Problème du plus court chemin Pas au programme de TSI mais plus prudent d\u0026rsquo;en avoir entendu parler pour l\u0026rsquo;épreuve de Centrale qui jusqu\u0026rsquo;à maintenant était commune aux autres sections.\n Si le graphe considéré n\u0026rsquo;est pas pondéré, l\u0026rsquo;algorithme de parcours en largeur, moyennant quelques adaptations, est tout à fait capable de faire le travail.\nAlgorithme de parcours en largeur Comme l\u0026rsquo;algorithme de parcours en largeur examine le graphe en couches concentriques depuis le sommet de départ, lorsqu\u0026rsquo;il parvient au sommet cible, on est sûr que le nombre d\u0026rsquo;arcs est minimal.\nIl suffit alors de joindre à la liste des sommets examinés, la liste des chemins permettant de parvenir à chacun de ces sommets (en incrémentant à chaque tour chacun des chemins du sommet correspondant de la nouvelle couche).\ndef recherche_largeur(G,depart,arrivee): file = [(depart,[depart])] # on remplace la file des sommets par une file de tuples (sommet,chemin) Vus = [] while file : sommet,chemin = file.pop(0) # pop(0) fait la même chose que le popleft des deque if sommet == arrivee : return chemin # si l\u0026#39;arrivée est atteinte, on retourne le chemin correspondant if not sommet in Vus : for s in G[sommet] : nv_chemin = chemin+[s] file.append((s,nv_chemin)) Vus.append(sommet) return False # si l\u0026#39;arrivée n\u0026#39;est pas atteinte, on renvoie Faux G = {\u0026#34;Minimes\u0026#34; : {\u0026#34;Tasdon\u0026#34;,\u0026#34;Hôpital\u0026#34;}, \u0026#34;Hôpital\u0026#34; : {\u0026#34;Verdun\u0026#34;}, \u0026#34;Verdun\u0026#34; : {\u0026#34;Stade\u0026#34;}, \u0026#34;Tasdon\u0026#34; : {\u0026#34;Cognehors\u0026#34;, \u0026#34;Lafond\u0026#34;}, \u0026#34;Cognehors\u0026#34; : {\u0026#34;Verdun\u0026#34;}, \u0026#34;Lafond\u0026#34; : {\u0026#34;Mireuil\u0026#34;}, \u0026#34;Mireuil\u0026#34; : {\u0026#34;Stade\u0026#34;}, \u0026#34;Stade\u0026#34; : {} } recherche_largeur(G,\u0026quot;Minimes\u0026quot;,\u0026quot;Stade\u0026quot;) retourne bien le chemin comportant le moins d\u0026rsquo;arêtes : ['Minimes', 'Hôpital', 'Verdun', 'Stade'].\nMais si on ajoute des poids, l\u0026rsquo;algorithme de recherche en largeur devient inefficace puisqu\u0026rsquo;il se borne à donner la même réponse (les pondérations sont nul part prises en compte !).\n G_pond = {\u0026#34;Minimes\u0026#34; : {\u0026#34;Tasdon\u0026#34;:5,\u0026#34;Hôpital\u0026#34;:4}, \u0026#34;Hôpital\u0026#34; : {\u0026#34;Verdun\u0026#34;:21}, \u0026#34;Verdun\u0026#34; : {\u0026#34;Stade\u0026#34;:4}, \u0026#34;Tasdon\u0026#34; : {\u0026#34;Cognehors\u0026#34;:7, \u0026#34;Lafond\u0026#34;:7}, \u0026#34;Cognehors\u0026#34; : {\u0026#34;Verdun\u0026#34;:8}, \u0026#34;Lafond\u0026#34; : {\u0026#34;Mireuil\u0026#34;:5}, \u0026#34;Mireuil\u0026#34; : {\u0026#34;Stade\u0026#34;:3}, \u0026#34;Stade\u0026#34; : {} } recherche_largeur(G_pond,\u0026quot;Minimes\u0026quot;,\u0026quot;Stade\u0026quot;) retourne à nouveau ['Minimes', 'Hôpital', 'Verdun', 'Stade'] alors qu\u0026rsquo;il y a maintenant des chemins plus rapides !\n Algorithme de Dijkstra # préconditions : un graphe orienté ￼pondéré G(S,A) avec des poids positifs pour chaque arc représenté par une liste d’adjacence grâce à un dictionnaire, un sommet s_0 de S # postcondition : pour chaque sommet ￼s_i de S la distance trouvée correspond bien au chemin le plus court entre s_0 et s_i (d(s_0,s_i)) def sommet_suivant(scores,vus) : \u0026#34;\u0026#34;\u0026#34; retourne le sommet absent de vus au plus bas score \u0026#34;\u0026#34;\u0026#34; plus_bas_score = float(\u0026#34;inf\u0026#34;) sommet_choisi = None for sommet in scores : score = scores[sommet] if score \u0026lt; plus_bas_score and sommet not in vus : plus_bas_score = score sommet_choisi = sommet return sommet_choisi def Dijkstra(G,depart) : # on construit Scores et Preds dans lesquels on mettra à jour les scores calculés et les prédecesseurs des sommets examinés Scores = {} Preds = {} # initialisation for s in G.keys() : Scores[s] = float(\u0026#34;inf\u0026#34;) Preds[s] = None Scores[depart] = 0 Vus = [] # liste pour stocker les sommets examinés sommet = sommet_suivant(Scores,Vus) while sommet is not None : score = Scores[sommet] Succ = G[sommet] for n in Succ.keys(): nv_score = score + Succ[n] if Scores[n] \u0026gt; nv_score : Scores[n] = nv_score Preds[n] = sommet Vus.append(sommet) sommet = sommet_suivant(Scores,Vus) return Preds,Scores preds,scores = Dijkstra(G_pond,\u0026#34;Minimes\u0026#34;) print(preds) print(scores) # Ce qui s\u0026#39;affiche : {\u0026#39;Minimes\u0026#39;: None, \u0026#39;Hôpital\u0026#39;: \u0026#39;Minimes\u0026#39;, \u0026#39;Verdun\u0026#39;: \u0026#39;Cognehors\u0026#39;, \u0026#39;Tasdon\u0026#39;: \u0026#39;Minimes\u0026#39;, \u0026#39;Cognehors\u0026#39;: \u0026#39;Tasdon\u0026#39;, \u0026#39;Lafond\u0026#39;: \u0026#39;Tasdon\u0026#39;, \u0026#39;Mireuil\u0026#39;: \u0026#39;Lafond\u0026#39;, \u0026#39;Stade\u0026#39;: \u0026#39;Mireuil\u0026#39;} {\u0026#39;Minimes\u0026#39;: 0, \u0026#39;Hôpital\u0026#39;: 4, \u0026#39;Verdun\u0026#39;: 20, \u0026#39;Tasdon\u0026#39;: 5, \u0026#39;Cognehors\u0026#39;: 12, \u0026#39;Lafond\u0026#39;: 12, \u0026#39;Mireuil\u0026#39;: 17, \u0026#39;Stade\u0026#39;: 20}     La complexité de cette implémentation de l\u0026rsquo;algorithme de Dijkstra est en $O(|S|^2)$ où comme vu plus haut, $|S|$ est le nombre de sommets du graphe.\n En effet, chaque sommet est inspecté pour être scoré et lors de chaque inspection (= chaque itération), on inspecte l\u0026rsquo;ensemble des successeurs de ce sommet (et dans le pire des cas, le sommet a $|S|-1$ successeurs).\nComme évoqué dans une notice précédente, on peut améliorer la complexité en utilisant une structure de donnée adaptée au problème : le tas.\nL\u0026rsquo;idée est d\u0026rsquo;améliorer le choix du prochain sommet inspecté, celui au plus bas score parmi les sommets pas encore validés. En effet, réinspecter systématiquement toute la liste des sommets restants ne semble pas optimal. C\u0026rsquo;est sur ce point que le tas vient à la rescousse :\nle tas est une structure de données de type arbre qui permet de retrouver directement l\u0026rsquo;élément que l\u0026rsquo;on veut traiter en priorité. Le tas garde en permanence le sommet de plus bas score en son sommet avec un coût logarithmique.\nConséquence : si on remplace la fonction sommet_suivant par un tas et ses opérations dédiées d\u0026rsquo;ajout et d\u0026rsquo;extraction, on passe d\u0026rsquo;une complexité linéaire à une complexité logarithmique pour cette opération.\nGrâce au tas, la complexité de Dijkstra est maintenant quasilinéaire ($O(|S|\\log|S|)$).\n import heapq # module implémentant un tas (heap en anglais) def Dijkstra(G, depart, arrivee): Scores = {sommet: float(\u0026#39;infinity\u0026#39;) for sommet in G} Preds = {sommet : None for sommet in G} Scores[depart] = 0 Vus = [] tas = [(0, depart)] # liste de tuples contenant le score et le sommet associé # le score correspond alors à la priorité du tas while tas : score_actuel, sommet_actuel = heapq.heappop(tas) # on retire l\u0026#39;élément prioritaire du tas if sommet_actuel == arrivee : return Preds,Scores,Vus if score_actuel \u0026lt;= Scores[sommet_actuel]: score_voisin = G[sommet_actuel] for voisin in score_voisin.keys(): if voisin not in Vus : Vus.append(voisin) score = score_actuel + score_voisin[voisin] if score \u0026lt; Scores[voisin]: Scores[voisin] = score Preds[voisin] = sommet_actuel heapq.heappush(tas, (score, voisin)) # on ajoute le score et le sommet au tas On verra dans le TP comment encore améliorer les choses grâce à l\u0026rsquo;utilisation d\u0026rsquo;une heuristique. On passe alors de l\u0026rsquo;algorithme de Dijkstra à l\u0026rsquo;algorithme A* (A star ou A étoile).\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_2/tp10graphes/",
	"title": "TP 10 : les graphes",
	"tags": [],
	"description": "",
	"content": "TP10 : les graphes Cliquez sur cette invitation pour récupérer le repository du TP.  Le dessin ci-dessus peut se représenter par (choisir la bonne réponse) :\n a : un graphe orienté b : un graphe non orienté    Le degré du sommet C vaut :\n a : 2 b : 3 c : 5    Le distance de F à C vaut :\n a : 1 b : 3 c : $\\infty$    En transformant les arcs en arêtes, quel serait le diamètre du graphe ?\n a : 4 b : 5 c : $\\infty$    Listes et matrices d\u0026rsquo;adjacence  Construire le graphe G_la correspondant au dessin du haut sous la forme d\u0026rsquo;une liste d\u0026rsquo;adjacence en utilisant un dictionnaire (sur le modèle du cours).\nLes sommets devront s\u0026rsquo;appeler \u0026quot;A\u0026quot;,\u0026quot;B\u0026quot;,\u0026quot;C\u0026quot;,\u0026quot;D\u0026quot;,\u0026quot;E\u0026quot; et \u0026quot;F\u0026quot;.\n  Construire maintenant le graphe G_ma correspondant au dessin ci-dessus sous la forme d\u0026rsquo;une matrice d\u0026rsquo;adjacence (en suivant le modèle donné dans le cours).\n  Manipulation d\u0026rsquo;un graphe Ajouter un sommet à un graphe  Construire une fonction qui ajoute un sommet S à un graphe G orienté. Le graphe G est représenté par une liste d\u0026rsquo;adjacence et on donne en argument de la fonction la liste des prédécesseurs et des successeurs du sommet S ($Pred(S)$ et $Succ(S)$).\n def ajouteSommet(G,S,pred,succ) : \u0026#34;\u0026#34;\u0026#34; ajouteSommet(G:dict,S:str,pred:list,succ:list)-\u0026gt;G:dict préconditions : G est un graphe dont certains des sommets font partie de la liste pred et certains de la liste succ. S est le nom d\u0026#39;un sommet n\u0026#39;appartenenat pas à G. G est modélisé par une liste d\u0026#39;adjacence utilisant un dictionnaire. pred et succ sont les listes des prédécesseurs et des successeurs de S. postcondition : la fonction retourne le graphe mis à jour (muté) avec le sommet S ajouté. \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Le graphe de gauche est modélisé ci-dessous par une liste d\u0026rsquo;adjacence :\nGraphe = {\u0026#39;A\u0026#39; : [\u0026#39;E\u0026#39;,\u0026#39;D\u0026#39;], \u0026#39;B\u0026#39; : [\u0026#39;D\u0026#39;], \u0026#39;C\u0026#39; : [\u0026#39;B\u0026#39;], \u0026#39;D\u0026#39; : [\u0026#39;C\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;E\u0026#39; : [], \u0026#39;F\u0026#39; : [\u0026#39;B\u0026#39;]} On souhaite lui ajouter le sommet 'G'.\n Compléter au préalable les listes Pred et Succ contenant les prédécesseurs et les successeurs de 'G'.\n Pred = [] Succ = []  Testez ensuite votre fonction ajouteSommet pour vérifier que le graphe est modifié comme souhaité.\n  Retirer un sommet à un graphe  On souhaite maintenant construire la fonction retireSommet permettant de retirer un sommet d\u0026rsquo;un graphe.\nElle prend en argument le graphe et un sommet du graphe.\nVous utiliserez un assert pour vous assurer que le sommet passé en argument appartient bien augraphe.\n def retireSommet(G,S) : \u0026#34;\u0026#34;\u0026#34; retireSommet(G:dict,S:str)-\u0026gt;G:dict préconditions : G est un graphe et S est un de ses sommets. G est modélisé par une liste d\u0026#39;adjacence utilisant un dictionnaire postcondition : la fonction retourne le graphe mis à jour (muté) avec le sommet S en moins \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Reprenons le graphe précédent avant l\u0026rsquo;ajout du sommet 'G'.\nGraphe = {\u0026#39;A\u0026#39; : [\u0026#39;E\u0026#39;,\u0026#39;D\u0026#39;], \u0026#39;C\u0026#39; : [\u0026#39;B\u0026#39;], \u0026#39;D\u0026#39; : [\u0026#39;C\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;E\u0026#39; : [], \u0026#39;F\u0026#39; : [\u0026#39;B\u0026#39;]}  Testez ensuite votre fonction retireSommet pour vérifier que le graphe est modifié comme souhaité.\n  Utilisation d\u0026rsquo;un module pour visualiser import networkx as nx from IPython.display import Image import pandas as pd Construisons la matrice d\u0026rsquo;adjacence d\u0026rsquo;un graphe non-orienté complet.\nmatrice = [[0, 2, 2, 3, 3, 2, 1, 1, 2, 1], [2, 0, 1, 2, 2, 1, 2, 1, 3, 1], [2, 1, 0, 3, 1, 1, 1, 1, 3, 2], [3, 2, 3, 0, 1, 1, 3, 1, 2, 3], [3, 2, 1, 1, 0, 2, 2, 3, 3, 1], [2, 1, 1, 1, 2, 0, 1, 3, 2, 1], [1, 2, 1, 3, 2, 1, 0, 2, 1, 1], [1, 1, 1, 1, 3, 3, 2, 0, 1, 3], [2, 3, 3, 2, 3, 2, 1, 1, 0, 3], [1, 1, 2, 3, 1, 1, 1, 3, 3, 0]]  Construisez à votre tour une matrice M semblable à la précédente en tirant chaque élément au hasard parmi la liste [1,2,3] grâce à la fonction choice du module random (choice(L) retourne un des éléments de L choisi au hasard).\nCette matrice devra n\u0026rsquo;avoir que des 0 dans sa diagonale et être symétrique.\nAttention: le nom de la matrice doit être M.\n from random import choice n = 10 # nombre de sommets # VOTRE CODE Si vous avez réussi à construire M vous pourrez utilisez votre matrice par la suite.\nOn transforme ensuite la matrice en dataframe pandas qui sera reconnue par le module networkx et on lui ajoute des lettres en en-tête de ligne et de colonne pour nommer les sommets.\nabc = \u0026#39;ABCDEFGHIJKLMNOPQRSTUVWXYZ\u0026#39; labels = list(abc[:n]) M_df = pd.DataFrame(matrice, index=labels, columns=labels) print(M_df)     A B C D E F G H I J     A 0 2 2 3 3 2 1 1 2 1   B 2 0 1 2 2 1 2 1 3 1   C 2 1 0 3 1 1 1 1 3 2   D 3 2 3 0 1 1 3 1 2 3   E 3 2 1 1 0 2 2 3 3 1   F 2 1 1 1 2 0 1 3 2 1   G 1 2 1 3 2 1 0 2 1 1   H 1 1 1 1 3 3 2 0 1 3   I 2 3 3 2 3 2 1 1 0 3   J 1 1 2 3 1 1 1 3 3 0    G_complet = nx.from_pandas_adjacency(M_df) # obtention du graphe networkx à partir de la dataframe weights = [G_complet[u][v][\u0026#39;weight\u0026#39;]*3 for u,v in G_complet.edges()] # liste des poids (*3) # Tracé options = {\u0026#34;font_size\u0026#34;: 20, \u0026#34;font_weight\u0026#34;:\u0026#34;bold\u0026#34;, \u0026#34;node_size\u0026#34;: 1000, \u0026#34;node_color\u0026#34;: \u0026#34;#34A5DA\u0026#34;, \u0026#34;edge_color\u0026#34;: weights, # couleur en fonction des poids \u0026#34;width\u0026#34;: weights, # épaisseur des arêtes en fonction des poids \u0026#34;edge_cmap\u0026#34;: plt.cm.Set3, \u0026#34;with_labels\u0026#34;: True, \u0026#34;font_color\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;linewidths\u0026#34;: 5, } pos = nx.shell_layout(G_complet) fig = plt.figure(figsize=(12, 12)) nx.draw(G_complet,pos=pos,**options) labels = nx.get_edge_attributes(G_complet,\u0026#39;weight\u0026#39;) nx.draw_networkx_edge_labels(G_complet, pos=pos,edge_labels=labels) plt.show()  Transformez la matrice matrice en une liste d\u0026rsquo;adjacence G_la n\u0026rsquo;utilisant que des dictionnaires.\nG_la devra ressembler à :\n {\u0026#39;A\u0026#39; : {\u0026#39;B\u0026#39;: 3, \u0026#39;C\u0026#39;: 3, \u0026#39;D\u0026#39;: 2, \u0026#39;E\u0026#39;: 1, \u0026#39;F\u0026#39;: 1, \u0026#39;G\u0026#39;: 2, \u0026#39;H\u0026#39;: 2, \u0026#39;I\u0026#39;: 1, \u0026#39;J\u0026#39;: 1}, \u0026#39;B\u0026#39; : {\u0026#39;A\u0026#39;: 3, \u0026#39;C\u0026#39;: 1, \u0026#39;D\u0026#39;: 3, \u0026#39;E\u0026#39;: 1, \u0026#39;F\u0026#39;: 3, \u0026#39;G\u0026#39;: 3, \u0026#39;H\u0026#39;: 3, \u0026#39;I\u0026#39;: 2, \u0026#39;J\u0026#39;: 1}, \u0026#39;C\u0026#39; : {\u0026#39;A\u0026#39;: 3, \u0026#39;B\u0026#39;: 1, \u0026#39;D\u0026#39;: 3, \u0026#39;E\u0026#39;: 3, \u0026#39;F\u0026#39;: 1, \u0026#39;G\u0026#39;: 1, \u0026#39;H\u0026#39;: 1, \u0026#39;I\u0026#39;: 2, \u0026#39;J\u0026#39;: 2}, \u0026#39;D\u0026#39; : {\u0026#39;A\u0026#39;: 2, \u0026#39;B\u0026#39;: 3, \u0026#39;C\u0026#39;: 3, \u0026#39;E\u0026#39;: 2, \u0026#39;F\u0026#39;: 3, \u0026#39;G\u0026#39;: 1, \u0026#39;H\u0026#39;: 1, \u0026#39;I\u0026#39;: 3, \u0026#39;J\u0026#39;: 2}, \u0026#39;E\u0026#39; : {\u0026#39;A\u0026#39;: 1, \u0026#39;B\u0026#39;: 1, \u0026#39;C\u0026#39;: 3, \u0026#39;D\u0026#39;: 2, \u0026#39;F\u0026#39;: 2, \u0026#39;G\u0026#39;: 1, \u0026#39;H\u0026#39;: 2, \u0026#39;I\u0026#39;: 1, \u0026#39;J\u0026#39;: 1}, \u0026#39;F\u0026#39; : {\u0026#39;A\u0026#39;: 1, \u0026#39;B\u0026#39;: 3, \u0026#39;C\u0026#39;: 1, \u0026#39;D\u0026#39;: 3, \u0026#39;E\u0026#39;: 2, \u0026#39;G\u0026#39;: 3, \u0026#39;H\u0026#39;: 1, \u0026#39;I\u0026#39;: 2, \u0026#39;J\u0026#39;: 3}, \u0026#39;G\u0026#39; : {\u0026#39;A\u0026#39;: 2, \u0026#39;B\u0026#39;: 3, \u0026#39;C\u0026#39;: 1, \u0026#39;D\u0026#39;: 1, \u0026#39;E\u0026#39;: 1, \u0026#39;F\u0026#39;: 3, \u0026#39;H\u0026#39;: 1, \u0026#39;I\u0026#39;: 3, \u0026#39;J\u0026#39;: 2}, \u0026#39;H\u0026#39; : {\u0026#39;A\u0026#39;: 2, \u0026#39;B\u0026#39;: 3, \u0026#39;C\u0026#39;: 1, \u0026#39;D\u0026#39;: 1, \u0026#39;E\u0026#39;: 2, \u0026#39;F\u0026#39;: 1, \u0026#39;G\u0026#39;: 1, \u0026#39;I\u0026#39;: 1, \u0026#39;J\u0026#39;: 2}, \u0026#39;I\u0026#39; : {\u0026#39;A\u0026#39;: 1, \u0026#39;B\u0026#39;: 2, \u0026#39;C\u0026#39;: 2, \u0026#39;D\u0026#39;: 3, \u0026#39;E\u0026#39;: 1, \u0026#39;F\u0026#39;: 2, \u0026#39;G\u0026#39;: 3, \u0026#39;H\u0026#39;: 1, \u0026#39;J\u0026#39;: 1}, \u0026#39;J\u0026#39; : {\u0026#39;A\u0026#39;: 1, \u0026#39;B\u0026#39;: 1, \u0026#39;C\u0026#39;: 2, \u0026#39;D\u0026#39;: 2, \u0026#39;E\u0026#39;: 1, \u0026#39;F\u0026#39;: 3, \u0026#39;G\u0026#39;: 2, \u0026#39;H\u0026#39;: 2, \u0026#39;I\u0026#39;: 1}}  Une application concrète des graphes : l\u0026rsquo;arbre couvrant minimal Supposons que chaque sommet du graphe précédent représente les nœuds d\u0026rsquo;un réseau que l\u0026rsquo;on souhait relier à moindre coût. Ces sommets peuvent être des villes que l\u0026rsquo;on veut relier électriquement, des champs à irriguer, des serveurs à relier, etc. Les différents poids des arêtes matérialisent la difficulté ou le coût de la liaison entre les deux sommets.\nComment trouver facilement le moyen de relier tout le monde en minimisant les coûts ? Il faut trouver un arbre couvrant minimal du graphe.\nUn arbre couvrant est un arbre (graphe sans cycle) qui rejoint tous les sommets d\u0026rsquo;un graphe connexe.\nL\u0026rsquo;arbre couvrant minimal est l\u0026rsquo;arbre couvrant dont la somme des poids des arêtes est minimale.\nChercher une solution par force brute devient rapidement impossible quand le nombre de sommets du graphe augmente. La formule de Cayley nous dit qu\u0026rsquo;il y aura $n^{n-2}$ arbres couvrants d\u0026rsquo;un graphe complet connexe comportant n sommets (avec seulement 100 sommets, cela fait plus de possibilités que le nombre d\u0026rsquo;atomes dans l\u0026rsquo;univers).\n Quelle serait donc le type de complexité d\u0026rsquo;une exploration par force brute de tous les arbres couvrants ?\n a : logarithmique en n b : polynomiale en n c : exponentielle en n   Grâce à l'algorithme de Prim, on peut trouver l\u0026rsquo;arbre couvrant minimal d\u0026rsquo;un graphe connexe pondéré en temps raisonable !\nMais commençons d\u0026rsquo;abord par construire une fonction qui vérifie si un graphe est connexe ou non.\nPour cela, on va utiliser l'algorithme de parcours en profondeur (Deep-First Search) sur le graphe à tester en partant d\u0026rsquo;un sommet quelconque et vérifier que tous les sommets sont visités.\nfrom collections import deque def parcours_profondeur(G,depart): pile = deque() pile.append(depart) Sommets = [] Vus = [] while pile : sommet = pile.pop() if not sommet in Vus : pile += G[sommet] Vus.append(sommet) Sommets.append(sommet) return Sommets  Construisez la fonction verifConnexe qui vérifie si un graphe est connexe ou non.\nVous utiliserez la fonction parcours_profondeur dans votre code.\nVous pourrez ensuite tester ci-dessous si votre fonction fait le travail sur les deux listes d\u0026rsquo;adjacence G_la et Gt_la.\nDans le premier cas, le graphe est évidemment connexe, et on a construit le deuxième pour qu\u0026rsquo;il ne le soit pas.\n def verifConnexe(G): \u0026#34;\u0026#34;\u0026#34; verifConnexe(G : dict) -\u0026gt; bool précondition : G est un graphe sous la forme d\u0026#39;une liste d\u0026#39;adjacence représentée par un dictionnaire comme ci-dessus postcondition : la fonction retourne True si le graphe est connexe, False sinon \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE # Construction d\u0026#39;un graphe G_nc non connexe G_nc = nx.Graph() G_nc.add_nodes_from([i for i in range(1,9)]) color_map = [\u0026#39;red\u0026#39; if node \u0026lt;=4 else \u0026#39;green\u0026#39; for node in G_nc] G_nc.add_edges_from([(1, 2), (1, 3),(2,4),(1,4),(5,7),(6,7),(5,8),(7,8)]) posi = nx.kamada_kawai_layout(G_nc) options = {\u0026#34;node_size\u0026#34;: 200, \u0026#34;node_color\u0026#34;: color_map, \u0026#34;edge_color\u0026#34;: color_map, \u0026#34;linewidths\u0026#34;: 1, \u0026#34;width\u0026#34;: 1, \u0026#34;with_labels\u0026#34;: False, } G_nc_la = nx.to_dict_of_dicts(G_nc) nx.draw(G_nc,posi,**options) print(\u0026#39;G_la est connexe :\u0026#39;,verifConnexe(G_la)) print(\u0026#39;G_nc_la est connexe :\u0026#39;,verifConnexe(G_nc_la)) True\nFalse\nImplémentons maintenant une version lente (quadratique) de l'algorithme de Prim.\nComme Dijkstra, Prim est un algorithme glouton. À chaque itération, il se jette sur l\u0026rsquo;arête de poids le plus faible permettant de traverser la frontière entre l\u0026rsquo;ensemble des sommets déjà inspectés et l\u0026rsquo;ensemble des autres. Une fois l\u0026rsquo;arête choisie, on ajoute le sommet non inspecté qu\u0026rsquo;elle relie à l\u0026rsquo;ensemble des sommets inspectés.\n Intégrez à l\u0026rsquo;algorithme ci-dessous une assertion testant si le graphe donné en argumant est bien connexe et ajoutez une variable cout à l\u0026rsquo;algorithme qui enregistre le coût de l\u0026rsquo;arbre final retourné et qui devra elle aussi être retournée.\nLa sortie doit donc devenir : return A, cout\n def Prim(G) : \u0026#34;\u0026#34;\u0026#34; Prim(G : dict) -\u0026gt; A : liste de tuples , cout : nombre G est donné sous la forme d\u0026#39;une liste d\u0026#39;adjacence implémenté par un dictionnaire A est une liste d\u0026#39;arêtes représentées par un tuple (A,B) où A et B sont les deux sommets délimitant l\u0026#39;arête cout est le coût de l\u0026#39;arbre A (somme des pondération des arêtes constituant A) postcondition : A doit être un arbre couvrant minimal \u0026#34;\u0026#34;\u0026#34; inf = float(\u0026#39;inf\u0026#39;) NX = list(G.keys()) S0 = NX[0] # un dictionnaire n\u0026#39;est pas ordonné donc pas indiçable d\u0026#39;où list() X = [S0] NX.remove(S0) A = [] while NX != [] : # invariant : A est l\u0026#39;arbre couvrant minimal de X Min = inf for S1 in X : for S2 in NX : if G[S1].get(S2,inf) \u0026lt; Min : # get(clé,v0) renvoie la valeur liée à la clé si la clé existe et v0 sinon (permet d\u0026#39;éviter les \u0026#34;key error\u0026#34;) Min = G[S1][S2] # là, on sait que S2 est bien un voisin de S1 Fmin = S2 Dmin = S1 X.append(Fmin) NX.remove(Fmin) A.append((Dmin,Fmin)) return A Traçons maintenant l\u0026rsquo;arbre couvrant minimal trouvé par Prim.\nA = Prim_corr(G_la) H = nx.Graph() for S in abc[:n] : H.add_node(S) for S1,S2 in A[0] : H.add_edge(S1,S2,weight=10) F = nx.compose(G_complet,H) weights = [5 if F[u][v][\u0026#39;weight\u0026#39;]==10 else 0 for u,v in F.edges()] options = {\u0026#34;font_size\u0026#34;: 20, \u0026#34;font_weight\u0026#34;:\u0026#34;bold\u0026#34;, \u0026#34;node_size\u0026#34;: 1000, \u0026#34;node_color\u0026#34;: \u0026#34;#34A5DA\u0026#34;, \u0026#34;edge_color\u0026#34;: weights, \u0026#34;width\u0026#34;: weights, \u0026#34;edge_cmap\u0026#34;: plt.cm.bwr, \u0026#34;with_labels\u0026#34;: True, \u0026#34;font_color\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;linewidths\u0026#34;: 1, } fig = plt.figure(figsize=(12, 12)) nx.draw(F,pos=pos,**options) plt.show() Et voilà ! En deux coups de cuillère à pot, on a trouvé un arbre couvrant minimal sans s\u0026rsquo;infliger l\u0026rsquo;inspection systématique des $10^8$ arbres couvrants possibles\u0026hellip;\n Lien entre structures de données et graphes, exemple du tas Le tas (ou file de priorité) est une structure de données permettant d\u0026rsquo;obtenir rapidement le plus petit élément d\u0026rsquo;un ensemble. On peut se représenter un tas par un arbre binaire presque complet ordonné.\n  Pour implémenter un tas, on retranscrit l\u0026rsquo;arbre binaire sous la forme d\u0026rsquo;une liste.\n En vous aidant de la vidéo ci-dessus, choisir parmi les listes suivantes celle qui peut représenter un tas :\n  a : [3,5,8,5,13,11,9,6,12,15,18,11,12] b : [3,5,8,5,13,7,9,6,12,15,18,11,12,10] c : [3,5,8,5,13,11,9,6,12,15,18,11,11,10,12]   Construire une fonction plusPetitEnfant qui retourne la position du petit enfant d\u0026rsquo;un élément dans le tas.\nLa fonction prend en argument le tas (représenté sous la forme d\u0026rsquo;une liste) et la position du parent.\nLa fonction retourne la position du plus petit enfant.\nSi l\u0026rsquo;élément n\u0026rsquo;a pas d\u0026rsquo;enfant, la fonction retourne None.\nAttention : les positions dans le tas vont de 1 à n (et non de 0 à n-1) où n est le nombre d\u0026rsquo;éléments dans le tas\n def plusPetitEnfant(tas,position) : \u0026#34;\u0026#34;\u0026#34; plusPetitEnfant(tas : list, position : int) -\u0026gt; int ou Nonetype \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Tas = [3,7,8,8,7,9,12,7,8,8,8,10] enfants(Tas,2)  Construire les fonctions insert et extractMin (pour cette dernière, pensez à utiliser plusPetitEnfant).\nOn supposera que le tas ne contient que des entiers.\n def insert(tas,x) : \u0026#34;\u0026#34;\u0026#34; insert(tas : list , x : int) -\u0026gt; Nonetype la fonction doit ajouter un élément au tas de manière à ce qu\u0026#39;il reste un arbre binaire presque complet tout en respectant l\u0026#39;invariant : les valeurs des parents doivent être inférieures à celles des enfants. la fonction ne retourne rien. \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE def extractMin(tas) : \u0026#34;\u0026#34;\u0026#34; extractMin(tas : list) -\u0026gt; Min : int la fonction doit retirer la racine du tas tout en respectant l\u0026#39;invariant : les valeurs des parents doivent être inférieures à celles des enfants. \u0026#34;\u0026#34;\u0026#34; # VOTRE CODE Construisons maintenant un tri par tas et montrons qu\u0026rsquo;il est bien plus rapide que le tri par sélection dont il est issu.\ndef triParSelection(liste) : n = len(liste) for i in range(n-1) : min = i for j in range(i+1,n) : if liste[j]\u0026lt;liste[min] : min = j if min != i : liste[i], liste[min] = liste[min], liste[i] return L def triParTas(liste) : T = [] Ltrie = [] n = len(liste) for e in liste : insert(T,e) for i in range(n) : Ltrie.append(extractMin(T)) return Ltrie L = [-13,12,5,1,95,4] print(triParSelection(L)) print(triParTas(L)) [-13, 1, 4, 5, 12, 95]\n[-13, 1, 4, 5, 12, 95]\nfrom time import time from random import randint import matplotlib.pyplot as plt plt.style.use(\u0026#39;ggplot\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 5) I, T_trisel, T_tritas = [], [], [] for i in range(100,1000,1) : L = [] L = [randint(0,i) for k in range(i)] start1 = time() triParSelection(L) stop1 = time() T_trisel.append(stop1-start1) start2 = time() triParTas(L) stop2 = time() T_tritas.append(stop2-start2) I.append(i) plt.plot(I,T_trisel,label=\u0026#34;tri par sélection\u0026#34;) plt.plot(I,T_tritas,label=\u0026#34;tri par tas\u0026#34;) plt.xlabel(\u0026#39;taille de la liste\u0026#39;) plt.ylabel(\u0026#34;temps d\u0026#39;exécution (s)\u0026#34;) plt.legend() Les graphes nous ont donc ici permis de mettre au point une structure de données capable d\u0026rsquo;upgrader tout algorithme nécessitant une détermination répétée d\u0026rsquo;un plus petit (ou grand) élément dans un ensemble.\n Parcours d\u0026rsquo;un graphe Détecteur de cycle Les graphes orientés sont générallement utilisés pour représenter un ensemble de dépendances (l\u0026rsquo;ensemble des prérequis d\u0026rsquo;un cours, l\u0026rsquo;ensemble des installations nécessaires au fonctionnement d\u0026rsquo;un programme, etc\u0026hellip;).\nEt la présence de cycles dans de tels graphes est synonyme de bloquage (exemple : pour faire la première tâche, vous attendez la seconde, et pour faire la seconde, vous attendez la première\u0026hellip;). Quelle que soit l\u0026rsquo;application, détecter les cycles est donc primordial pour éviter de se retrouver dans ce type de situation.\nUne idée pour détecter un cycle est d\u0026rsquo;utiliser à nouveau le parcours en profondeur. Si on tombe sur un sommet déjà exploré au cours de la progression dans une branche, alors on a affaire à un cycle.\nPoint important : on suppose ici que les graphes donnés en argument à la fonction sont non orientés.\nLe problème que pose ce type de graphe pour la recherche de cycle est la présence systématique du sommet considéré dans la liste de ses voisins (si \u0026lsquo;A\u0026rsquo; est le voisin de \u0026lsquo;B\u0026rsquo; alors \u0026lsquo;B\u0026rsquo; est le voisin de \u0026lsquo;A\u0026rsquo;) puisqu\u0026rsquo;un graphe non-orienté permet les aller-retour.\nEn retirant systématiquement de la liste des voisins d\u0026rsquo;un sommet les sommets dont lui-même est le voisin, on peut s\u0026rsquo;assurer de la présence d\u0026rsquo;un cycle si le parcours en profondeur rencontre un sommet présent dans Vus.\nAu final, on oriente le graphe non-orienté pour éviter d\u0026rsquo;être piégé par un aller-retour entre deux voisins\u0026hellip; Et on l\u0026rsquo;oriente de façon à s\u0026rsquo;éloiner du sommet choisi comme point de départ.\nExemple : on transforme {'A' : ['B'], 'B' : ['A','C'], 'C' : ['B']} en {'A' : ['B'], 'B' : ['C'], 'C' : []}. Et pour {'A' : ['B','C','D'], 'B' : ['A','C'], 'C' : ['A','B','D'], 'D' : ['A','C']}, il y a trois possibilités suivant qu\u0026rsquo;après \u0026lsquo;A\u0026rsquo;, on continue avec \u0026lsquo;B\u0026rsquo;, \u0026lsquo;C\u0026rsquo; ou \u0026lsquo;D\u0026rsquo;.  Ajoutez donc à la fonction un bout de code qui transforme G en l\u0026rsquo;orientant.\n from collections import deque def detecteCycles(G,depart): \u0026#34;\u0026#34;\u0026#34; detecteCycles(G : dict , depart) -\u0026gt; bool depart est une des clés de G detecteCycles doit retourner True si un cycle est rencontré \u0026#34;\u0026#34;\u0026#34; pile = deque() pile.append(depart) Sommets = [] Vus = [] # on transforme G en un graphe orienté # VOTRE CODE while pile : sommet = pile.pop() if not sommet in Vus : Voisins = G[sommet].copy() pile += Voisins Vus.append(sommet) Sommets.append(sommet) else : return True return False  Testez votre fonction sur les trois graphes suivants :\n G1 = {\u0026#39;A\u0026#39; : [\u0026#39;B\u0026#39;], \u0026#39;B\u0026#39; : [\u0026#39;A\u0026#39;,\u0026#39;C\u0026#39;], \u0026#39;C\u0026#39; : [\u0026#39;B\u0026#39;,\u0026#39;D\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;D\u0026#39; : [\u0026#39;C\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;E\u0026#39; : [\u0026#39;C\u0026#39;,\u0026#39;D\u0026#39;]} G2 = {\u0026#39;A\u0026#39; : [\u0026#39;B\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;B\u0026#39; : [\u0026#39;A\u0026#39;,\u0026#39;C\u0026#39;], \u0026#39;C\u0026#39; : [\u0026#39;B\u0026#39;,\u0026#39;D\u0026#39;], \u0026#39;D\u0026#39; : [\u0026#39;C\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;E\u0026#39; : [\u0026#39;A\u0026#39;,\u0026#39;D\u0026#39;]} G3 = {\u0026#39;A\u0026#39; : [\u0026#39;B\u0026#39;,\u0026#39;E\u0026#39;], \u0026#39;B\u0026#39; : [\u0026#39;A\u0026#39;,\u0026#39;C\u0026#39;], \u0026#39;C\u0026#39; : [\u0026#39;B\u0026#39;,\u0026#39;D\u0026#39;], \u0026#39;D\u0026#39; : [\u0026#39;C\u0026#39;], \u0026#39;E\u0026#39; : [\u0026#39;A\u0026#39;]}  Plus court chemin Une autre application ultra importante des graphes : trouver le plus vite possible le plus court chemin entre deux points.\nOn peut presque toujours modéliser un déplacement comme un chemin sur un graphe (ou plutôt une chaîne dans le cas présent car nos graphes ne seront pas orientés).\nReprésentons par exemple la carte d\u0026rsquo;un petit jeu vidéo sous forme de graphe.\nPour cela, on transforme chaque lieu possible en un sommet et chaque transition possible d\u0026rsquo;un point à un autre comme une arête.\nCréons une petite carte de 20 cases sur 20 avec des déplacements possibles horizontaux, verticaux mais aussi diagonaux d\u0026rsquo;une case à une cas voisine.\nTous les arcs reçoivent d\u0026rsquo;abord le même poids de 1.\ncarte = {} imax = 20 jmax = 20 for i in range(imax) : for j in range(jmax) : poids_voisins = {} if i \u0026gt; 0 : poids_voisins[(i-1,j)] = 1 if j \u0026gt; 0 : poids_voisins[(i,j-1)] = 1 if i \u0026gt; 0 and j \u0026gt; 0 : poids_voisins[(i-1,j-1)] = 1 if i \u0026lt; imax-1 : poids_voisins[(i+1,j)] = 1 if j \u0026lt; jmax-1 : poids_voisins[(i,j+1)] = 1 if i \u0026lt; imax-1 and j \u0026lt; jmax-1 : poids_voisins[(i+1,j+1)] = 1 carte[(i,j)] = poids_voisins Compliquons notre carte en y rajoutant différents environnements : des mérécages où il est difficile de se mouvoir et des murs infranchissables.\nPour modéliser les mérécages on va modifier les pondérations : on augmente le poids des arêtes amenant à des sommets s\u0026rsquo;y trouvant. Et pour les murs, on va retirer du graphe les sommets s\u0026rsquo;y trouvant.\n# marécages limites_marecages = ((5,19),(5,12)) # s\u0026#39;étendent de 5 à 19 en largeur, et de 5 à 12 en hauteur for sommet in carte.keys() : for voisin in carte[sommet].keys() : i,j = voisin if limites_marecages[0][0]\u0026lt;=i\u0026lt;=limites_marecages[0][1] and limites_marecages[1][0]\u0026lt;=j\u0026lt;=limites_marecages[1][1] : carte[sommet][voisin] = 5 # murs (on retire les sommets concernés (y compris des voisins)) limites_murs = ((17,11),(16,11),(15,11),(17,12),(16,12),(15,12),(15,13),(15,14),(15,15),(15,16),(15,17),(15,18),(14,18),(13,18),(12,18),(11,18),(11,17)) # chaque couple (a,b) correspond aux coordonnées d\u0026#39;une case de mur for sommet in carte.copy().keys() : for voisin in carte[sommet].copy().keys() : i,j = voisin if (i,j) in limites_murs : del carte[sommet][voisin] for sommet in carte.copy().keys() : i,j = sommet if (i,j) in limites_murs : del carte[sommet] Définissons les sommets de départ et d\u0026rsquo;arrivée.\ndepart = (2,2) arrivee = (17,16) Et construsions enfin une fonction permettant de tracer la carte en faisant apparaître les marécages, les murs et les points de départ et d\u0026rsquo;arrivée.\nimport matplotlib.pyplot as plt from matplotlib.patches import Rectangle plt.style.use(\u0026#39;seaborn\u0026#39;) fig, ax = plt.subplots(figsize=(15,15)) coul_bords = (0/255,110/255,118/255) coul_marec = (155/255,207/255,255/255) coul_prairie = (214/255,232/255,147/255) coul_murs = (0.3,0.3,0.3) coul_depart = (39/255,187/255,40/255) coul_arrivee = (255/255,25/255,0/255) coul_chemin = (255/255,209/255,247/255) def trace_terrain(dim,dep,arr,marec,murs) : for i in range(dim[0]) : for j in range(dim[1]) : ax.add_patch(Rectangle((i, j), 1, 1, edgecolor = coul_bords, facecolor = coul_prairie, fill=True, lw=2)) for i in range(marec[0][0],marec[0][1]+1) : for j in range(marec[1][0],marec[1][1]+1) : ax.add_patch(Rectangle((i, j), 1, 1, edgecolor = coul_bords, facecolor = coul_marec, fill=True, lw=2)) for coord in murs : ax.add_patch(Rectangle((coord[0], coord[1]), 1, 1, edgecolor = coul_bords, facecolor = (0.3,0.3,0.3), fill=True, lw=2)) ax.add_patch(Rectangle(dep, 1, 1, edgecolor = coul_bords, facecolor = coul_depart, fill=True, lw=2)) ax.add_patch(Rectangle(arr, 1, 1, edgecolor = coul_bords, facecolor = coul_arrivee, fill=True, lw=2)) ax.autoscale_view() trace_terrain((20,20),depart,arrivee,limites_marecages,limites_murs) Recherche en largeur Utilisons l'algorithme de recherche en largeur (Breadth-First Search ou BFS) vu en cours pour tenter de trouver la plus petite chaîne de sommets reliant le départ à l\u0026rsquo;arrivée.\ndef recherche_largeur(G,depart,arrivee): file = [(depart,[depart])] Vus = [] while file : sommet,chemin = file.pop(0) if sommet == arrivee : return chemin,Vus if not sommet in Vus : for s in G[sommet] : nv_chemin = chemin+[s] file.append((s,nv_chemin)) Vus.append(sommet) return False Chaîne obtenue :\nrecherche_largeur(carte,depart,arrivee)[0] [(2, 2),(3, 2),(4, 2),(5, 2),(6, 2),(7, 2),(8, 2),(9, 2),(10, 3),(11, 4),(12, 5),(13, 6),(14, 7),\n(15, 8),(16, 9),(17, 10),(18, 11),(18, 12),(18, 13),(17, 13),(17, 14),(17, 15),(17, 16)]\nTraçons la chaîne en rose sur la carte :\ntrace_terrain((20,20),depart,arrivee,limites_marecages,limites_murs) for sommet in recherche_largeur(carte,depart,arrivee)[0][1:-1] : ax.add_patch(Rectangle(sommet,1, 1,edgecolor=coul_bords,facecolor=coul_chemin,fill=True,lw=2)) fig On constate donc que la recherche en largeur trouve un chemin très court qui évite bien le mur.\nVisualisons aussi (en les blanchissant) l\u0026rsquo;ensemble des sommets inspectés par l\u0026rsquo;algorithme pour trouver son chemin.\ntrace_terrain((20,20),depart,arrivee,limites_marecages,limites_murs) for sommet in recherche_largeur(carte,depart,arrivee)[1] : ax.add_patch(Rectangle(sommet,1,1,edgecolor=coul_bords,facecolor=(1,1,1,0.8),fill=True,lw=2)) fig Quasiment toute la carte a été inspectée\u0026hellip;\n Répondez aux trois questions suivantes :\n le chemin trouvé est-il le plus court possible indépendemment des pondérations ? le chemin trouvé est-il le plus court possible si on prend en compte les pondérations? l\u0026rsquo;algorithme est-il efficace en terme de nombre de sommets inspectés ?    Dijkstra Passons de la recherche en largeur à l\u0026rsquo;algorithme de Dijkstra. On utilise l\u0026rsquo;implémentation du cours avec des tas (file de priorité) fournis par le module heapq.\nimport heapq def Dijkstra(G, depart, arrivee): Scores = {sommet: float(\u0026#39;inf\u0026#39;) for sommet in G} Preds = {sommet : None for sommet in G} Scores[depart] = 0 Vus = [] tas = [(0, depart)] while tas : score_actuel, sommet_actuel = heapq.heappop(tas) if sommet_actuel == arrivee : return Preds,Scores,Vus if score_actuel \u0026lt;= Scores[sommet_actuel]: score_voisin = G[sommet_actuel] for voisin in score_voisin.keys(): if voisin not in Vus : Vus.append(voisin) score = score_actuel + score_voisin[voisin] if score \u0026lt; Scores[voisin]: Scores[voisin] = score Preds[voisin] = sommet_actuel heapq.heappush(tas, (score, voisin)) Preds = Dijkstra(carte,depart,arrivee)[0]  Définissez une fonction qui reconstitue la plus petite chaîne à partir de la liste des prédécesseurs fournie par Dijkstra.\n def reconstruction_chaine(predecesseurs,depart,arrivee) : \u0026#34;\u0026#34;\u0026#34; reconstruction_chemin(predecesseur : dict , depart : tuple , arrivee : tuple) -\u0026gt; chemin : liste de tuples predecesseur est un dictionnaire qui pour chaque clé sous forme de tuple (x,y) (un des sommets) donne son prédécesseur là aussi sous forme de tuple (x\u0026#39;,y\u0026#39;). la liste retournée, chaine, doit contenir la liste des sommets (chaque sommet est un tuple (x,y)) allant du depart à l\u0026#39;arrivee. \u0026#34;\u0026#34;\u0026#34; chaine = [depart] s = arrivee # VOTRE CODE return chaine chaine_Dijk = reconstruction_chaine(Preds,depart,arrivee) Vérifiez que votre chaîne est bien la même que celle ci-dessous :\nchaine_Dijk = [(2, 2),(16, 16),(16, 17),(16, 18),(16, 19),(15, 19),(14, 19),(13, 19),(12, 19),(11, 19),(10, 18),(9, 17),(8, 16),(7, 15),(6, 14),(5, 13),(4, 12),(3, 11),(2, 10),(2, 9),(2, 8),(2, 7),(2, 6),(2, 5),(2, 4),(2, 3),(2, 2)] Traçons la chaîne obtenue.\ntrace_terrain((20,20),depart,arrivee,limites_marecages,limites_murs) for sommet in chaine_Dijk[1:-1] : ax.add_patch(Rectangle(sommet,1,1,edgecolor=coul_bords,facecolor=coul_chemin,fill=True,lw=2)) fig On constate que le chemin trouvé par Dijkstra prend maintenant soin de contourner le marécage.\ntrace_terrain((20,20),depart,arrivee,limites_marecages,limites_murs) for sommet in Dijkstra(carte,depart,arrivee)[2] : ax.add_patch(Rectangle(sommet,1,1,edgecolor=coul_bords,facecolor=(1,1,1,0.8),fill=True,lw=2)) fig À nouveau, une grande partie de la carte est inspectée.\n Répondez aux trois questions suivantes :\n le chemin trouvé est-il le plus court possible indépendemment des pondérations ? le chemin trouvé est-il le plus court possible si on prend en compte les pondérations? l\u0026rsquo;algorithme est-il efficace en terme de nombre de sommets inspectés ?    Ajout d\u0026rsquo;une heuristique Pour améliorer la vitesse des algorithmes précédents, on va leur ajouter une heuristique. Une heuristique est une petite recette, une règle simple, que l\u0026rsquo;algorithme va suivre pour s\u0026rsquo;économiser des étapes.\nLe point noir des algorithmes précédents est qu\u0026rsquo;ils semblent contraints de parcourir quasiment toute la carte avant d\u0026rsquo;être sûr d\u0026rsquo;avoir trouvé le bon chemin.\nOn va les aider en les guidant vers l\u0026rsquo;arrivée.\nL\u0026rsquo;heuristique va donc consister à guider le choix du prochain sommet de manière à ce qu\u0026rsquo;il diminue la distance jusqu\u0026rsquo;à l\u0026rsquo;arrivée. On le dirrige en quelque sorte ves sa destination\u0026hellip;\nImplémentons donc une fonction distance qui donne la distance entre deux sommets A et B.\nMais quelle distance ? Plusieurs définition non équivalentes sont pssibles : distance euclidienne, distance de Manhattan\u0026hellip;\nIci, on va utiliser la distance de Tchebychev qui correspond à la distance sur un échiquier où les mouvements en diagonale coûte 1.\ndef distance(A,B) : x_A,y_A = A x_B,y_B = B X = abs(x_B-x_A) Y = abs(y_B-y_A) return max(X,Y) Implémentons maintenant une variante de la recherche en largeur qui intègre l\u0026rsquo;heuristique grâce à un tas : pour chaque nouveau voisin inspecté, on calcule sa distance à l\u0026rsquo;arrivée puis on l\u0026rsquo;ajoute à un tas avec cette distance comme clé de classement.\nOn s\u0026rsquo;assure ainsi à chaque itération de retirer du tas le sommet rapprochant le plus de la destination finale.\nIl s\u0026rsquo;agit à nouveau d\u0026rsquo;un algorithme glouton.\nimport heapq def bfs_glouton(G,depart,arrivee) : tas = [(0, depart)] Vus = [] Preds = dict() Preds[depart] = None while tas : dist_actuelle, sommet_actuel = heapq.heappop(tas) # on retire le sommet le plus proche de l\u0026#39;arrivée if sommet_actuel == arrivee : return Preds,Vus for voisin in G[sommet_actuel]: if voisin not in Vus : Vus.append(voisin) if voisin not in Preds: dist = distance(arrivee, voisin) heapq.heappush(tas, (dist, voisin)) # on place dans le tas le voisin affublé de sa distance Preds[voisin] = sommet_actuel bfs_glouton(carte,depart,arrivee) chaine_glouton = reconstruction_chaine(bfs_glouton(carte,depart,arrivee)[0],depart,arrivee) trace_terrain((20,20),depart,arrivee,limites_marecages,limites_murs) for sommet in chaine_glouton[1:-1] : ax.add_patch(Rectangle(sommet,1,1,edgecolor=coul_bords,facecolor=coul_chemin,fill=True,lw=2)) fig On voit que le chemin se dirige tout de suite vers l\u0026rsquo;arrivée, jusqu\u0026rsquo;à rencontrer un mur\u0026hellip;\ntrace_terrain((20,20),depart,arrivee,limites_marecages,limites_murs) for sommet in bfs_glouton(carte,depart,arrivee)[1] : ax.add_patch(Rectangle(sommet,1,1,edgecolor=coul_bords,facecolor=(1,1,1,0.8),fill=True,lw=2)) fig Le nombre de sommets inspectés a spectaculairement diminué !\n Répondez aux trois questions suivantes :\n le chemin trouvé est-il le plus court possible indépendemment des pondérations ? le chemin trouvé est-il le plus court possible si on prend en compte les pondérations? l\u0026rsquo;algorithme est-il efficace en terme de nombre de sommets inspectés ?    A* Appliquons maintenant l\u0026rsquo;heuristique à l\u0026rsquo;algorithme de Dijkstra. On obtient l'algorithme A* (A étoile ou A star).\ndef Astar(G, depart, arrivee): Scores = {sommet: float(\u0026#39;inf\u0026#39;) for sommet in G} Preds = {sommet : None for sommet in G} Scores[depart] = 0 Vus = [] tas = [(0, 0, depart)] while tas : _, score_actuel, sommet_actuel = heapq.heappop(tas) # on utilise par convention \u0026#39;_\u0026#39; pour déballer un élément d\u0026#39;un tuple dont on ne fera pas usage. if sommet_actuel == arrivee : return Preds,Scores,Vus if score_actuel \u0026lt;= Scores[sommet_actuel]: score_voisin = G[sommet_actuel] for voisin in score_voisin.keys(): if voisin not in Vus : Vus.append(voisin) score = score_actuel + score_voisin[voisin] if score \u0026lt; Scores[voisin]: Scores[voisin] = score Preds[voisin] = sommet_actuel heuristique = score + distance(voisin,arrivee) heapq.heappush(tas, (heuristique, score, voisin)) chaine_Astar = reconstruction_chaine(Astar(carte,depart,arrivee)[0],depart,arrivee) trace_terrain((20,20),depart,arrivee,limites_marecages,limites_murs) for sommet in chaine_Astar[1:-1] : ax.add_patch(Rectangle(sommet,1,1,edgecolor=coul_bords,facecolor=coul_chemin,fill=True,lw=2)) fig trace_terrain((20,20),depart,arrivee,limites_marecages,limites_murs) for sommet in Astar(carte,depart,arrivee)[2] : ax.add_patch(Rectangle(sommet,1,1,edgecolor=coul_bords,facecolor=(1,1,1,0.8),fill=True,lw=2)) fig  Répondez aux trois questions suivantes :\n le chemin trouvé est-il le plus court possible indépendemment des pondérations ? le chemin trouvé est-il le plus court possible si on prend en compte les pondérations? l\u0026rsquo;algorithme est-il efficace en terme de nombre de sommets inspectés ?   "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/semestre_1/tp7image/",
	"title": "TP 7 : matrices de pixels et image",
	"tags": [],
	"description": "",
	"content": "Tableau de pixels et images Importer une image PIL (python imaging library) est l\u0026rsquo;une des librairies Python permettant de manipuler des fichiers image. On va l\u0026rsquo;utiliser en association avec numpy qui est le module de choix pour jouer avec des tableaux numériques.\nfrom PIL import Image import urllib.request # pour récupérer une image sur le web from IPython.display import display # pour afficher dans le notebook import matplotlib.pyplot as plt import numpy as np plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = (15,10) urllib.request.urlretrieve(\u0026#39;https://i.redd.it/quqjmqmi44q51.jpg\u0026#39;, \u0026#39;girafe\u0026#39;) # récupération du fichier image image_girafe = np.array(Image.open(\u0026#39;girafe\u0026#39;)) # le fichier est convertie en un tableau numpy girafe = Image.fromarray(image_girafe) # le tableau est converti en un objet image display(girafe) # affichage On a récupéré les données de l\u0026rsquo;image dans un tableau à trois dimensions numpy.\nLes deux premières dimensions correspondent aux coordonnées spatiales du pixel et l\u0026rsquo;indexation d\u0026rsquo;un tableau numpy autorise l\u0026rsquo;utilisation de virgules pour imiter les coordonnées mathématiques (mais les x et les y sont inversés car il s\u0026rsquo;agit de matrices et on commence toujours par indexer les lignes avant les colonnes). Le pixel ayant la coordonnée cartésienne $(x,y)$ avec une origine $(0,0)$ en haut à gauche va donc correspondre à l\u0026rsquo;élément image[y,x] (on peut aussi, comme avec les listes python, obtenir l\u0026rsquo;élément via image[y][x]).\nEt à chacun de ses pixels correspond un tableau de 3 entiers compris entre 0 et 255 codant la couleur du pixel (codage rgb, un nombre pour l\u0026rsquo;intensité du rouge, un pour l\u0026rsquo;intensité du vert et le dernier pour le bleu). C\u0026rsquo;est la 3e dimension du tableau.\nprint(image_girafe.shape) (1263, 843, 3)\nhauteur, largeur, _ = image_girafe.shape print(f\u0026#39;largeur : {largeur} pixels, hauteur : {hauteur} pixels\u0026#39;) largeur : 843 pixels, hauteur : 1263 pixel\nprint(image_girafe[20,700]) print(image_girafe[20][700]) [96 96 60]\n[96 96 60]\n Codage RGB RGB pour Red Green Blue (RVB en français) est un système de codage informatique des couleurs. Il repose sur la synthèse additive et suit donc le même principe que le codage des couleurs dans notre cerveau à partir des signaux envoyés par trois cellules spécialisées tapissant nos rétines, les cones, chacune ayant un spectre d\u0026rsquo;absorption centré sur les longueurs d\u0026rsquo;onde correspondantes à l\u0026rsquo;une des trois couleurs, rouge, vert ou bleu.\nlongueur = 400 synthese = np.zeros([longueur, longueur, 3], dtype=np.uint8) # création d\u0026#39;un tableau de dimension 3 (2 dimensions spatiales + la couleur) dont les entrées sont des entiers non signés codés sur 8 bits taille = longueur//2 x1,y1 = longueur//8,5*longueur//16 x2,y2 = longueur//4,longueur//8 x3,y3 = 3*longueur//8,3*longueur//8 synthese[y1:y1+taille,x1:x1+taille] = [255, 0, 0] synthese[y2:y2+taille,x2:x2+taille] = [0, 255, 0] synthese[y3:y3+taille,x3:x3+taille] = [0, 0, 255] affichage = Image.fromarray(synthese) display(affichage) On voit qu\u0026rsquo;il manque à l\u0026rsquo;image les zones de superposition.\n Modifier l\u0026rsquo;image synthese pour reproduire la figure suivante.\n Faisons notre propre expérience physique de synthèse additive en codant des zones où les pixels alternent 2 couleurs primaires :\nlargeur = 900 hauteur = 300 synth_phy = np.zeros([hauteur, largeur, 3], dtype=np.uint8) for i in range(hauteur) : for j in range(largeur//3) : if (i+j)%2 : synth_phy[i,j] = [255,0,0] else : synth_phy[i,j] = [0,255,0] for i in range(hauteur) : for j in range(largeur//3,2*largeur//3) : if (i+j)%2 : synth_phy[i,j] = [0,0,255] else : synth_phy[i,j] = [0,255,0] for i in range(hauteur) : for j in range(2*largeur//3,largeur) : if (i+j)%2 : synth_phy[i,j] = [0,0,255] else : synth_phy[i,j] = [255,0,0] synth_phy = Image.fromarray(synth_phy) display(synth_phy) Récupérons les composantes bleues, vertes et rouges de la photo de girafe :\nimage_R = image_girafe.copy() image_R[:,:,(1,2)] = 0 # équivalent à : # for i in range(hauteur) : # for j in range(largeur) : # image_R[i][j][1] = 0 # image_R[i][j][2] = 0 image_G = image_girafe.copy() image_G[:,:,(0,2)] = 0 image_B = image_girafe.copy() image_B[:,:,(0,1)] = 0 rvb = np.concatenate((image_R, image_G, image_B), axis=1) rvb = Image.fromarray(rvb) display(rvb) La superposition des trois filtres reproduit les couleurs d\u0026rsquo;origine.\nimage_rec = image_B.copy() image_rec[:,60:500] += image_G[:,60:500] image_rec[75:650,:] += image_R[75:650,:] image_rec = Image.fromarray(image_rec) display Dans le codage RGB utilisé aujourd\u0026rsquo;hui, l\u0026rsquo;intensité de chacune des 3 couleurs primaires est codée sur un octet (8 bits), ce qui permet une profondeur de 24 bits pour différentier les couleurs.\n Combien de couleurs sont alors représentables par ce système ?\n Fabriquons une image contenant toutes ces couleurs.\nL\u0026rsquo;idée est de fabriquer d\u0026rsquo;abord une image $256\\times 256$ contenant toutes les nuances possibles de vert et rouge, de l\u0026rsquo;agrandir d\u0026rsquo;un facteur 16 de manière à qu\u0026rsquo;une combinaison rouge/vert unique corresponde à un gros pixel de $16\\times16$. Et on additionne à chacun de ces gros pixels une image $16\\times16$ bleu contenant les 256 teintes de bleu disposées en spirale.\nL\u0026rsquo;image rouge/verte est assez simple à coder (l\u0026rsquo;exécution met un peu de temps) :\nL1 = 4096 rougevert = np.zeros([L1, L1, 3], dtype=np.uint8) for r in range(256*16) : for g in range(256*16) : rougevert[r,g]=[r//16,g//16,0] plt.imshow(rougevert) Fabriquer la spirale bleue est plus dur\u0026hellip;\nL\u0026rsquo;image doit faire $16\\times16$ et contenir toutes les nuances de bleu. On commence en haut à gauche (x=0 et y=0) par du noir (0,0,0), et on progresse dans le sens des aiguilles d\u0026rsquo;une montre en ajoutant 1 à l\u0026rsquo;intensité du bleu à chaque pixel successif de la spirale pour finir au centre (en position x=7, y=8 pour être précis) par un pixel 100% bleu (0,0,255).\n Construisez la spirale bleue (du moins la matrice qui sera représentée par la spirale bleue).\n # vous appellerez votre image \u0026#34;bleu\u0026#34; L2 = 16 bleu = np.zeros([L2, L2, 3], dtype=np.uint8) ### VOTRE CODE plt.imshow(bleu) # cette commande devra afficher une image similaire à celle de l\u0026#39;énoncé ! longueur = 4096 rougevertbleu = np.zeros([longueur, longueur, 3], dtype=np.uint8) for i in range(0,4096,16) : for j in range(0,4096,16) : rougevertbleu[i:i+16,j:j+16] = rougevert[i:i+16,j:j+16]+bleu rougevertbleu = Image.fromarray(rougevertbleu) display(rougevertbleu) Les premières consoles de jeu avaient des graphismes de 6 bits (de profondeur). Plutôt que 256 possibilités pour chaque sous-pixel, on en était réduit à seulement 4 choix (2 bits).\n Définissez une fonction permettant de convertir l\u0026rsquo;image de la giraffe en 6 bits.\n def sixbit(image) : \u0026#34;\u0026#34;\u0026#34; prend en argument un tableau numpy à 3 dimensions () obtenu comme plus haut via np.array(Image.open(\u0026#39;nom\u0026#39;)) et renvoie un nouveau tableau de mêmes dimensions correspondant à une conversion en 6 bits de l\u0026#39;image (chacune des 3 couleurs doit maintant n\u0026#39;avoir que 4 valeurs d\u0026#39;intensité possibles uniformément réparties). \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE girafe = Image.fromarray(sixbit(image_girafe)) display(girafe) On peut très facilement inverser les couleurs de l\u0026rsquo;image. Une ligne suffit :\nimage_inv = 255-image_girafe image_inv = Image.fromarray(image_inv) display(image_inv) Construire une fonction NB qui retourne une version \u0026ldquo;niveau de gris\u0026rdquo; de l\u0026rsquo;image donnée en argument.\nPrincipe de la manœuvre : $(r,g,b)\\rightarrow (\\frac{r+g+b}{3},\\frac{r+g+b}{3},\\frac{r+g+b}{3})$\ndef NB(image) : \u0026#34;\u0026#34;\u0026#34; prend en argument un tableau numpy à 3 dimensions () obtenu comme plus haut via np.array(Image.open(\u0026#39;nom\u0026#39;)) et renvoie un nouveau tableau correspondant à une conversion en niveau de gris de l\u0026#39;image. \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE giraffe_NB = Image.fromarray(NB(image_girafe)) display(giraffe_NB)  Transformation d\u0026rsquo;une image  Construisez une fonction recadrage qui prend en argument l\u0026rsquo;image à recadrer, les coordonnées du coin supérieur gauche du nouveau cadre (sous la forme d\u0026rsquo;un tuple (x,y)), la largeur et la hauteur du nouveau cadre.\nFaites en sorte que recadrage(image_girafe,(30,50),500,600) recadre la tête de la girafe comme ci-dessous.\n def recadrage(image,xy_coin,l_cadre,h_cadre) : \u0026#34;\u0026#34;\u0026#34; prend en argument un tableau numpy à 3 dimensions (hauteur,largeur,3) obtenu comme plus haut via np.array(Image.open(\u0026#39;nom\u0026#39;)) et renvoie un nouveau tableau à 3 dimensions (h_cadre,l_cadre,3). L\u0026#39;argument xy_coin est un tuple (x,y) où x et y sont des entiers correspondants aux coordonnées du coin supérieur gauche du nouveau cadre. l_cadre et h_cadre étant des nombres de pixels, ils doivent être entiers. \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE affichage = Image.fromarray(recadrage(image_girafe,(30,50),500,600)) display(affichage)  Construisez ensuite une fonction rotation qui tourne l\u0026rsquo;image de 90° vers la gauche en modifiant la disposition des pixels.\n def rotation(image) : \u0026#34;\u0026#34;\u0026#34; prend en argument un tableau numpy à 3 dimensions (hauteur,largeur,3) obtenu comme plus haut via np.array(Image.open(\u0026#39;nom\u0026#39;)) et renvoie un nouveau tableau correspondant à l\u0026#39;image tournée de 90° vers la gauche. \u0026#34;\u0026#34;\u0026#34; ### VOTRE CODE affichage = Image.fromarray(rotation(image_girafe)) display(affichage) On peut aussi s\u0026rsquo;amuser avec les symétries :\nimage_sym = np.copy(image_girafe) for i in range(min(hauteur,largeur)) : for j in range(min(hauteur,largeur)) : image_sym[i][j]=image_sym[j][i] affichage = Image.fromarray(image_sym) display(affichage)  Traitement d\u0026rsquo;image (filtrage) On va maintenant passer à des transormations plus évoluées :\n flou amélioration de la netteté détection des contours  Elles reposent sur des convolutions dont la recette est la suivante :\n une petite matrice, la matrice de convolution, appelée noyau, est choisie, on balaye l\u0026rsquo;image à traiter avec un cadre ayant la taille de la matrice, à l\u0026rsquo;intérieur du cadre, on multiplie chacune des valeurs d\u0026rsquo;intensité des pixels par le coefficient correspondant de la matrice, on somme tous ces produits et on attribue la valeur au pixel au centre du cadre.  Suivant le noyau utilisé, on va modifier l\u0026rsquo;image de différentes façons.\n Floutage L\u0026rsquo;idée va être de moyenner la valeur des pixels à l\u0026rsquo;intérieur du bloc grâce à la matrice F suivante :\n$$ F=\\frac{1}{9}\\begin{pmatrix}1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\\end{pmatrix} $$ Cela revient à passer l\u0026rsquo;image dans un filtre passe-bas (= un moyenneur).\nEn effet, la valeur de l\u0026rsquo;intensité d\u0026rsquo;un pixel sera maintenant une moyenne entre tous ses voisins.\ndef conv_np(A,B) : l = len(A) C = np.zeros((l-2, l-2),dtype=int) for i in range(3) : for j in range(3) : C += B[i,j]*A[i:l-2+i,j:l-2+j] return C A = np.array([[2,2,2,2,2], [2,1,1,1,2], [2,1,3,4,2], [2,1,2,1,2], [2,2,3,2,2]]) B = np.array([[1,0,1], [0,2,0], [1,0,1]]) C = conv_np(A,B) print(C) [[11 11 11] [ 9 10 15] [12 13 12]]   Que valent les éléments $c_{ij}$ de la matrice $C$ donnée par conv_np(A,B) ?\n  a : $\\sum_{k=1}^{3}a_{ik}b_{kj}$ b : $\\sum_{i=1}^{3}\\sum_{j=1}^{3}a_{(5-i)(5-j)}b_{ij}$ c : $\\sum_{i=1}^{3}\\sum_{j=1}^{3}a_{(i+1)(j+1)}b_{ij}$  La fonction suivante réalise la même tâche. Elle est moins rapide, mais permet de jouer avec des matrices $B$ plus grandes que $3\\times 3$ grâce à l\u0026rsquo;introduction du paramètre marge.\ndef conv(A,B,marge) : A = A.astype(np.int16) hauteur, largeur = A.shape C = A.copy() for i in range(marge,hauteur-marge) : for j in range(marge,largeur-marge) : C[i,j] = (A[i-marge:i+marge+1,j-marge:j+marge+1]*B).sum() return C On va ainsi pouvoir contrôler l\u0026rsquo;intensité du floutage en liant la taille de la matrice $B$ au paramètre force.\ndef flou(image,force) : \u0026#34;\u0026#34;\u0026#34; flou(image,intensite_flou)-\u0026gt;image_floue image doit être un tableau dimension d\u0026#39;entier non signés codés sur 8 bits intensité_flou est un entier \u0026gt;= 1 image_floue est du même type qu\u0026#39;image \u0026#34;\u0026#34;\u0026#34; taille = 2*force+1 # taille de la matrice F F = np.ones((taille,taille))*1/taille**2 # matrice pour la convolution marge = (taille-1)//2 image_floue = image.copy() hauteur,largeur = image_floue.shape image_floue = conv(image,F,marge) image_floue = image_floue.astype(np.uint8) return image_floue urllib.request.urlretrieve(\u0026#39;https://fichier0.cirkwi.com/image/photo/poi/800x500/545297/fr/0.jpg\u0026#39;, \u0026#39;LaR\u0026#39;) image = np.array(Image.open(\u0026#39;LaR\u0026#39;)) hauteur,largeur,_ = image.shape LaR = np.zeros([hauteur, largeur]) # on associe maintenant à chaque pixel un seul chiffre : l\u0026#39;intensité de gris (entre 0 et 255) LaR = NB(image)[:,:,0] # il suffit de récupérer une des 3 couleurs de la conversion en niveau de gris de l\u0026#39;image affichage = Image.fromarray(LaR) display(affichage) LaR_floues = (LaR,) # un singulet nécessite cette petite virgule pour être reconnu for i in range(1,5) : LaR_floues += (flou(LaR,i),) comparaison = np.concatenate(LaR_floues, axis=1) affichage = Image.fromarray(comparaison) display(affichage) Les matrices F utilisées dans les 4 images floutées : $\\frac{1}{9}\\begin{pmatrix}1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\\end{pmatrix}$,$\\frac{1}{16}\\begin{pmatrix}1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\\end{pmatrix}$,$\\frac{1}{25}\\begin{pmatrix}1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\end{pmatrix}$,$\\frac{1}{36}\\begin{pmatrix}1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\\\1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\u0026amp;1\\end{pmatrix}$.\nPlus la matrices est grande, plus on moyenne de points voisins, plus le flou est important\u0026hellip;\n Amélioration de la netteté On ne veut maintenant plus moyenner, mais au contraire accentuer les différences.\nPour cela, on choisit un noyau $N$ qui récompense les variations entre pixels voisins et est sans effet dans les zones de mêmes teintes : $$N=\\begin{pmatrix}0\u0026amp;-1\u0026amp;0\\\\-1\u0026amp;5\u0026amp;-1\\\\0\u0026amp;-1\u0026amp;0\\end{pmatrix}$$\n Sur le modèle de la fonction flou, mais en plus simple, car pas besoin ici de s\u0026rsquo;embêter avec une marge variable (conv_np est donc utilisable), complétez la définition de la fonction net qui renvoie le résultat d\u0026rsquo;une image convoluée par $N$.\n def net(image) : \u0026#34;\u0026#34;\u0026#34; net(image)-\u0026gt;image_nette \u0026#34;\u0026#34;\u0026#34; image = image.astype(np.int32) ### VOTRE CODE # on fixe les valeurs qui ont dépassé 255 à 255 et celles sous 0 à 0. image_nette[image_nette\u0026lt;0] = 0 image_nette[image_nette\u0026gt;255] = 255 image_nette = image_nette.astype(np.uint8) return image_nette LaR_nette = net(LaR_floues[1]) comparaison = np.concatenate((LaR_floues[1][1:-1,1:-1],LaR_nette), axis=1) affichage = Image.fromarray(comparaison) display(affichage)  Détection de contour (filtre de Sobel) On va agir en deux temps, grâce à deux noyaux.\nLe premier, $S_x$, va donner des valeurs d\u0026rsquo;autant plus loin de $0$ qu\u0026rsquo;il y a un fort gradient horizontal dans le bloc $3\\times3$ de l\u0026rsquo;image inspectée.\nEt l\u0026rsquo;autre, $S_y$, va mettre en valeur les gradients verticaux.\n$S_x = \\begin{pmatrix}-1\u0026amp;0\u0026amp;1\\\\-2\u0026amp;0\u0026amp;2\\\\-1\u0026amp;0\u0026amp;1\\end{pmatrix}$ et $S_y = \\begin{pmatrix}1\u0026amp;2\u0026amp;1\\\\0\u0026amp;0\u0026amp;0\\\\-1\u0026amp;-2\u0026amp;-1\\end{pmatrix}$\n$S_x$ fait la différence entre les voisins de droite et ceux de gauche quand $S_y$ fait la différence entre les voisins du dessus et ceux de dessous.\ndef grad_x(image) : image = image.astype(np.int32) Sx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]) image_gradx = conv_np(image,Sx) # les gradients peuvent très bien être négatifs. On translate alors toutes les valeurs pour que la plus basse soit zéro. image_gradx = image_gradx - np.min(image_gradx) # on normalise ensuite en faisant en sorte que la plus haute valeur vaille 255 image_gradx = image_gradx/np.max(image_gradx)*255 image_gradx = image_gradx.astype(np.uint8) return image_gradx  Écrivez la fonction grad_y sur le même modèle :\n def grad_y(image) : ### VOTRE CODE Gx = grad_x(LaR) Gy = grad_y(LaR) comparaison = np.concatenate((Gx,Gy), axis=0) affichage = Image.fromarray(comparaison) display(affichage) Le gradient global $G$ s\u0026rsquo;obtient en \u0026ldquo;pythagorisant\u0026rdquo; Gx et Gy : $G=\\sqrt{G_x^2+G_y^2}$.\nRemarque : cela revient finalement à appliquer un filtre passe-haut à l\u0026rsquo;image.\ndef grad(image) : Gx = grad_x(image).astype(np.int32) Gy = grad_y(image).astype(np.int32) image_grad = np.sqrt(Gx**2+Gy**2) image_grad = image_grad/np.max(image_grad)*255 image_grad = image_grad.astype(np.uint8) return image_grad affichage = Image.fromarray(grad(LaR)) display(affichage) L\u0026rsquo;effet de relief est rendu par l\u0026rsquo;information sur la direction du gradient, information inutile si le contour est tout ce qui nous intéresse (que l\u0026rsquo;on passe d\u0026rsquo;une forte intensité à une faible ou l\u0026rsquo;inverse détecte un contour dans les deux cas).\nOn va donc reprendre les définitions en prenant les valeurs absolues des gradients.\ndef grad_abs_x(image) : image = image.astype(np.int32) Sx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]) image_gradx = np.abs(conv_np(image,Sx)) image_gradx = image_gradx/np.max(image_gradx)*255 image_gradx = image_gradx.astype(np.uint8) return image_gradx def grad_abs_y(image) : image = image.astype(np.int32) Sy = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]) image_grady = np.abs(conv_np(image,Sy)) image_grady = image_grady/np.max(image_grady)*255 image_grady = image_grady.astype(np.uint8) return image_grady def contour(image) : Gx = gradabs_x(image).astype(np.int32) Gy = gradabs_y(image).astype(np.int32) image_cont = np.sqrt(Gx**2+Gy**2) image_cont = image_cont/np.max(image_cont)*255 image_cont = image_cont.astype(np.uint8) return image_cont affichage = Image.fromarray(contour(LaR)) display(affichage)  Parmi les images suivantes numérotées de 1 à 4, laquelle est produite par :\n  A : grad_x(echiquier) B : grad_abs_y(echiquier) C : contour(echiquier) D : grad(echiquier) où echiquier est l\u0026rsquo;image suivante :  Quand on joue avec des images, les erreurs de code donne parfois des résultats étonnants. N\u0026rsquo;hésitez pas à enregistrer/copier vos bizarreries, s\u0026rsquo;il y en a. Je récompenserai la plus belle/tordue.\nCi-dessous, un échec faisant tomber la pluie sur La Rochelle\u0026hellip; "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/python/divers/",
	"title": "Divers",
	"tags": [],
	"description": "",
	"content": "Divers Commentaires Tous les langages de programmations permettent d\u0026rsquo;introduire des commentaires dans le code qui servent d\u0026rsquo;aides et de repères à celui qui lit le code, mais qui sont ignorés lors de l\u0026rsquo;exécution.\nEn Python, les commentaires sont introduits par le symbole dièse (hashtag) #.\n Utilisation de print print est la première fonction native que l\u0026rsquo;on rencontre. C\u0026rsquo;est une fonction à effet de bord : elle ne retourne rien (elle est de type None), mais elle permet d\u0026rsquo;afficher une chaîne de caractères, ou le contenu d\u0026rsquo;une variable, quel que soit son type.\nnom = \u0026#39;Joe\u0026#39; age = 212 print(nom,\u0026#39;a\u0026#39;,age,\u0026#39;ans.\u0026#39;) Joe a 212 ans.\nDe plus, print affiche par défaut un retour à la ligne.\nLes caractères d\u0026rsquo;échapement font partie de la chaîne de caractères, mais sont interprétés par print comme des commandes. Le plus utilisé est le retour à la ligne \\n.\nprint(\u0026#34;a\\nb\\nc\u0026#34;) a\nb\nc\nBien que non exigible, l\u0026rsquo;utilisation des f-strings, introduites depuis Python 3.6, peut s\u0026rsquo;avérer très pratique. Les f-strings permettent d\u0026rsquo;inserrer des variables dans des chaînes de caractères et de les mettre en forme avec une syntaxe minimale.\nPour les utiliser, il suffit de mettre un f devant la chaîne de caractères et de placer chaque variable entre accolade.\nprint(f\u0026#39;{nom} a {age} ans.\u0026#39;) print(f\u0026#39;{nom = }, {age = }) # très pratique pour les jeux de tests Joe a 212 ans.\nnom = 'Joe', age = 212\n Importation de modules import module Pour importer le module machin, il suffit d\u0026rsquo;écrire import machin. Chaque fonction contenue dans le module devra alors être applée en utilisant la notation point : machin.fonction (le point désigne ici une relation d\u0026rsquo;appartenance caractéristique de la programmation orientée objet).\nimport math print(f\u0026#39;{math.sqrt(2) = }\u0026#39;) math.sqrt(2) = 1.4142135623730951\n import module as X Lorsqu\u0026rsquo;on utilise fréquemment un module, il est pratique d\u0026rsquo;abréger son nom. Pour cela, on ajoute le raccourci souhaité après un as lors de l\u0026rsquo;import : import machin as mch.\nimport numpy as np import matplotlib.pyplot as plt X = np.linspace(-np.pi,np.pi,100) Y = np.sin(X) plt.plot(X,Y)  from module import x,y On peut aussi récupérer uniquement certaines fonctions ou variables d\u0026rsquo;un module afin d\u0026rsquo;y avoir accès directement (sans utiliser machin.).\nfrom math import pi,cos print(f\u0026#39;{cos(pi) = }\u0026#39;) cos(pi) = -1.0\n from module import * Lorsqu\u0026rsquo;on est sûr que cela ne va pas poser problème, on peut importer tout le contenu du module de la même manière. On utilise alors l\u0026rsquo;étoile * qui signifie \u0026ldquo;tout\u0026rdquo;.\nCe type d\u0026rsquo;import est néanmoins déconseillé à moins de très bien connaître le contenu du module. Le danger est que dans l\u0026rsquo;ensemble de ce qui est importé, il peut se trouver des variables ou des fonctions ayant un nom déjà attribué. L\u0026rsquo;import réaffectera alors ces variables contre notre gré et sans nous le dire.\nd = 8 e = 2 from math import * print(sqrt(d ** e)) 16.88210319127114\n Manipulation de fichier texte Ouvrir et fermer un fichier Un objet file est créé par l\u0026rsquo;utilisation de la fonction open(nom du fichier,mode) qui prend deux arguments.\nf = open(\u0026#39;monfichier.txt\u0026#39;,\u0026#39;w\u0026#39;)   Le premier argument, nom du fichier, est une chaîne contenant le nom du fichier. Ce nom peut être donné avec le chemin d\u0026rsquo;accès absolu ou seulement l\u0026rsquo;arborescence relative au dossier dans lequel le programme est exécuté.\nEn écrivant un nom sans chemin, le fichier se trouve dans le répertoire courant.\n  Le deuxième argument, mode, est une chaîne d\u0026rsquo;un ou deux caractères décrivant la façon dont le fichier est utilisé.\nmode peut être r quand le fichier n\u0026rsquo;est accédé qu\u0026rsquo;en lecture, w en écriture seulement (un fichier existant portant le même nom sera alors écrasé) et a ouvre le fichier en mode ajout (toute donnée écrite dans le fichier est automatiquement ajoutée à la fin). r+ ouvre le fichier en mode lecture/écriture. L\u0026rsquo;argument mode est optionnel, sa valeur par défaut est r.\nb collé à la fin du mode indique que le fichier doit être ouvert en mode binaire c\u0026rsquo;est-à-dire que les données sont lues et écrites sous forme d\u0026rsquo;octets (type bytes). Ce mode est à utiliser pour les fichiers contenant autre chose que du texte.\n  Les objets file sont fermés grâce à la méthode close() : f.close() par exemple. Python ferme les fichiers automatiquement lorsque le programme se termine.\n Écrire dans un fichier La méthode write() d\u0026rsquo;un objet file écrit une chaîne de caractères dans le fichier et renvoie le nombre de caractères inscrits.\nf.write(\u0026#39;Coucou monde !\u0026#39;) 14\nPlus pratique, la fonction native print() peut accepter en argument un objet file. Plutôt que d\u0026rsquo;être affichée sur le shell, la sortie de print() est alors redirigée vers ce fichier.\nprint(\u0026#39;\\nKill all humans\u0026#39;, file=f) f.close() Exemple : le programme suivant écrit les quatre premières puissances de tous les entiers entre 1 et 1000, chaque champ étant séparé par une virgule, dans le fichier puissances.txt.\nfi = open(\u0026#39;puissances.txt\u0026#39;,\u0026#39;w\u0026#39;) for i in range(1,1001) : print(i, i**2, i**3, i**4, sep=\u0026#39;, \u0026#39;, file=fi) fi.close()  Lire un fichier Pour lire n bytes d\u0026rsquo;un fichier, on utilise f.read(n). En omettant n, tout le fichier est lu.\nreadline() lit une seule ligne d\u0026rsquo;un fichier jusqu\u0026rsquo;au, en l\u0026rsquo;incluant, caractère \\n de nouvelle ligne. Un nouvel appel de readline() lit la ligne suivante et ainsi de suite.\nread() et readline() renvoie toutes les deux une chaîne vide lorsque la fin du fichier est atteinte.\nPour lire en une fois toutes les lignes dans une liste de chaînes, on utilise f.readlines().\nLes objet file sont itérables. On peut ainsi retourner chaque ligne d\u0026rsquo;un fichier une à une en utilisant une boucle :\nf = open(\u0026#39;monfichier.txt\u0026#39;) for ligne in f : print(ligne, end=\u0026#39;\u0026#39;) f.close() Coucou monde !\n.\n.\n.\nKill all humans\nComme ligne contient déjà le caractère de nouvelle ligne lorsqu\u0026rsquo;elle est lue, on utilise end = '' pour empêcher print d\u0026rsquo;en ajouter un autre.\nCette méthode de lecture ligne à ligne est à privilégier pour les gros fichiers à moins de vraiment vouloir contenir en mémoire l\u0026rsquo;ensemble du fichier.\nGrâce à la méthode split, on peut transformer un texte en une liste de ces éléments. L’argument de split correspond aux caractères utilisés comme séparateur. Par défaut il s’agit du caractère d’espacement ' ' (si on veut découper un texte en paragraphe, on utilisera le caractère d’échappement de retour à la ligne \\n).\nfo = open(\u0026#39;monfichier.txt\u0026#39;) texte = fo.read() liste1 = texte.split(\u0026#39;\\n\u0026#39;) liste2 = texte.split() print(liste1) print(liste2) fo.close() ['Coucou monde !', '.', '.', '.', 'Kill all humans']\n['Coucou', 'monde', '!', '.', '.', '.', 'Kill', 'all', 'humans']\nPour lire les nombres du fichier 'puissance.txt' écrit précédemment, les colonnes doivent être converties en une liste d\u0026rsquo;entiers.\nPour cela, chaque ligne doit être décomposée en ses différents champs et chaque champ explicitement converti en entier grâce à int() :\nfo = open(\u0026#39;puissances.txt\u0026#39;) carrés, cubes, puiss4 = [],[],[] lignes = fo.readlines() fo.close() for ligne in lignes : champs = ligne.split(\u0026#39;,\u0026#39;) carrés.append(int(champs[1])) cubes.append(int(champs[2])) puiss4.append(int(champs[3])) n = 500 print(n, \u0026#39;au cube vaut\u0026#39;, cubes[n-1]) 500 au cube vaut 125000000\nMais en pratique, il vaut mieux utiliser les bibliothèques NumPy ou Pandas pour des fichiers de données comme celui-ci.\nVous apprendrez aussi au 3e trimestre à utiliser les méthodes des bases de données.\n  Les assertions Les assertions sont un moyen simple de s’assurer, avant de continuer, qu’une condition est respectée.\nOn utilise la syntaxe : assert test. Si le test renvoie True, l’exécution se poursuit normalement. Sinon, une exception AssertionError est levée.\nOn peut utiliser les assertions pour s’assurer que les arguments d’une fonction vont permettre son exécution.\nOn peut par exemple sécuriser la définition d\u0026rsquo;une fonction racines donnant les racines d\u0026rsquo;un trinôme du second degré. On va s’assurer que les arguments passés sont bien des nombres (et renvoyer un message explicatif si ce n’est pas le cas) :\nimport math def racines(a,b,c) : \u0026#34;\u0026#34;\u0026#34;Retourne les racines de ax^2 + bx + c\u0026#34;\u0026#34;\u0026#34; type_nombre = (float,int) assert (type(a) in type_nombre) and (type(b) in type_nombre) and (type(c) in type_nombre),\u0026#34;les arguments doivent être des nombres !\u0026#34; d = b**2 - 4*a*c r1 = (-b - math.sqrt(d))/2/a r2 = (-b + math.sqrt(d))/2/a return r1, r2 racines(1,6,5) retourne (-5.0, -1.0), mais racines(1,6,'5') lève l\u0026rsquo;erreur suivante :\nAssertionError: les arguments de la fonction racines doivent être des nombres !\n"
},
{
	"uri": "https://info-tsi-vieljeux.github.io/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "But Compétences visées (d\u0026rsquo;après le BO) :  analyser et modéliser un problème ou une situation, notammant en utilisant les objets conceptuels de l\u0026rsquo;informatique pertinents (table relationnelle, graphe, dictionnaire, etc.) ; imaginer et concevoir une solution, décomposer en blocs, se ramener à des sous-problèmes simples et indépendants, adopter une stratégie appropriée, décrire une démarche, un algorithme ou une structure de données permettant de résoudre le problème ; décrire et spécifier les caractéristiques d’un processus, les données d’un problème, ou celles manipulées par un algorithme ou une fonction ; mettre en œuvre une solution, par la traduction d’un algorithme ou d’une structure de données dans un langage de programmation ou un langage de requête ; justifier et critiquer une solution, que ce soit en démontrant un algorithme par une preuve mathématique ou en développant des processus d’évaluation, de contrôle, de validation d’un code que l’on a produit ; communiquer à l’écrit ou à l’oral, présenter des travaux informatiques, une problématique et sa solution ; défendre ses choix ; documenter sa production et son implémentation.  Préalable Pour le fonctionnement des 3 prochains trimestres, il faut que vous ayez :\n un compte Google (ancien ou créé pour l\u0026rsquo;occasion) pour pouvoir utiliser Colaboratory un compte Github où seront créés les reopositories des TP (répertoires à l\u0026rsquo;historique sauvegardé).   La vidéo suivante présente le protocole à suivre pour être opérationnel :\n   Déroulement Pour chaque TP, on suivra la démarche suivante :\n Vous trouverez un lien à cliquer au début de l\u0026rsquo;énoncé du TP sur ce site web. Il s\u0026rsquo;agit d\u0026rsquo;une invitation générer par Github Classroom. En acceptant l'\u0026ldquo;assignment\u0026rdquo; (le travail demandé), un nouveau repository est créé sur Github.\nIl contient un ou plusieurs fichiers notebook python (d\u0026rsquo;extension \u0026ldquo;.ipynb\u0026rdquo;) produits par l\u0026rsquo;application Jupyter notebook. Ce sont ces fichiers qu\u0026rsquo;il va falloir modifier pour gagner des points. Un notebook est découpé en cellules qui peuvent contenir soit du texte et des images, soit du code. Chaque cellule peut s\u0026rsquo;exécuter individuellement et fait alors tourner le code qu\u0026rsquo;elle contient, mais Github n\u0026rsquo;est pas encore capable d\u0026rsquo;interagir avec un notebook aujourd\u0026rsquo;hui.\nOn passe par une solution en ligne pour y pallier : Colaboratory (ou Colab). Pour transiter de Github à Colab, la démarche est très simple (sur le papier\u0026hellip;) : une fois qu\u0026rsquo;on a cliqué sur le notebook, il suffit de modifier l\u0026rsquo;adresse url en ajoutant \u0026ldquo;tocolab\u0026rdquo; après github (\u0026lsquo;https://github.com/blablabla/tpx.ipynb' $\\rightarrow$ \u0026lsquo;https://githubtocolab.com/blablabla/tpx.ipynb' ). Si pour une raison ou une autre, vous n\u0026rsquo;arrivez pas à passer de Github à Colab directement, il y a une autre méthode, un peu moins confortable, mais qui fonctionnera à coup sûr : vous téléchargez le notebook depuis github sur votre disque (pour cela, il faut d\u0026rsquo;abord cliquer sur Raw pour accéder au code source, puis sauvegarder la page en prenant soin que le navigateur n\u0026rsquo;ajoute pas une extension après le .ipynb), puis vous l\u0026rsquo;importez depuis Colab.  Le vrai travail commence alors. Des consignes sont disséminées dans le notebook et il faudra modifier les cellules en fonction de ce qui est demandé. Généralement, l\u0026rsquo;endroit où une modification est attendu est clairement indiqué par le commentaire # VOTRE CODE. Tout est exécutable, ce qui veut dire que vous pouvez tester immédiatement vos modifications. Vous pouvez aussi ajouter autant de cellules que souhaité, où vous le souhaitez.\nSeules les cellules de test contenant les commentaires # Cellule de test, ne pas modifier ne doivent en aucun cas être modifiées ou supprimées. Pour être validées, vos modifications devront être sauvegardées dans le repo github du TP. Depuis Colab, il suffit théoriquement d\u0026rsquo;aller sur Fichier \u0026gt; Enregistrer une copie dans Github, puis de sélectionner le repo du TP.\nL\u0026rsquo;autre solution est d\u0026rsquo;enregistrer le fichier modifié sur le disque (Fichier \u0026gt; Télécharger \u0026gt; Télécharger le fichier .ipynb) puis de le glisser sur la fenêtre Github du repo (ou de cliquer sur Add file \u0026gt; Upload files). Pensez alors à commiter (= cliquer sur le bouton vert commit) pour valider.\nAttention, il ne faut pas créer un autre fichier ! C\u0026rsquo;est le notebook portant le nom initial qui sera ramassé et corrigé une fois le temps imparti pour le TP écoulé.  Aide  La partie Feedback du repository du TP, caché dans l\u0026rsquo;onglet Pull requests, permet de me demander de l\u0026rsquo;aide en dehors des TP. Ou vous pouvez m\u0026rsquo;envoyer un mail à l\u0026rsquo;adresse suivante : cordier.info @ protonmail.ch  "
},
{
	"uri": "https://info-tsi-vieljeux.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://info-tsi-vieljeux.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]